{"meta":{"title":"又瘦了三斤","subtitle":"","description":"","author":"张存","url":"https://blog.zhangcun.store","root":"/"},"pages":[{"title":"about","date":"2021-09-16T07:16:04.000Z","updated":"2021-09-16T07:16:41.032Z","comments":true,"path":"about/index.html","permalink":"https://blog.zhangcun.store/about/index.html","excerpt":"","text":""},{"title":"categories","date":"2021-09-16T07:13:35.000Z","updated":"2021-09-16T07:14:38.692Z","comments":true,"path":"categories/index.html","permalink":"https://blog.zhangcun.store/categories/index.html","excerpt":"","text":""},{"title":"壁纸","date":"2021-09-16T07:40:46.000Z","updated":"2021-09-16T07:41:36.342Z","comments":true,"path":"bizhi/index.html","permalink":"https://blog.zhangcun.store/bizhi/index.html","excerpt":"","text":""},{"title":"friends","date":"2021-09-16T07:22:58.000Z","updated":"2021-09-16T07:25:04.985Z","comments":true,"path":"friends/index.html","permalink":"https://blog.zhangcun.store/friends/index.html","excerpt":"","text":""},{"title":"图库","date":"2021-09-16T07:38:49.000Z","updated":"2021-09-16T07:40:02.040Z","comments":true,"path":"gallery/index.html","permalink":"https://blog.zhangcun.store/gallery/index.html","excerpt":"","text":"壁纸 收藏的一些壁纸 古典图片 中国古典图片 风景 风景图片"},{"title":"tags","date":"2021-09-16T07:15:02.000Z","updated":"2021-09-16T07:15:33.467Z","comments":true,"path":"tags/index.html","permalink":"https://blog.zhangcun.store/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"docker-compose ports 与 expose 的区别","slug":"docker-compose-ports-与-expose-的区别","date":"2022-06-30T08:50:43.000Z","updated":"2022-06-30T08:50:45.817Z","comments":true,"path":"2022/06/30/docker-compose-ports-yu-expose-de-qu-bie/","link":"","permalink":"https://blog.zhangcun.store/2022/06/30/docker-compose-ports-yu-expose-de-qu-bie/","excerpt":"","text":"docker-compose中有两种方式可以暴露容器的端口：ports和expose。 ports ports暴露容器端口到主机的任意端口或指定端口，用法： ports: - &quot;80:80&quot; # 绑定容器的80端口到主机的80端口 - &quot;9000:8080&quot; # 绑定容器的8080端口到主机的9000端口 - &quot;443&quot; # 绑定容器的443端口到主机的任意端口，容器启动时随机分配绑定的主机端口号 不管是否指定主机端口，使用ports都会将端口暴露给主机。 容器中可以运行一些网络应用，要让外部也可以访问这些应用，可以通过 -P（大写） 或 -p （小写） 参数来指定端口映射。 (1) 当使用-P标记时，Docker 会随机映射一个49000~49900的端口到内部容器开放的网络端口。 使用docker ps可以看到，本地主机的 49155 被映射到了容器的 5000 端口。此时访问本机的 49155 端口即可访问容器内 web 应用提供的界面。 $ sudo docker run -d -P training/webapp python app.py $ sudo docker ps -l CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES bc533791f3f5 training/webapp:latest python app.py 5 seconds ago Up 2 seconds 0.0.0.0:49155-&gt;5000/tcp nostalgic_morse 同样的，可以通过docker logs命令来查看应用的信息。 $ sudo docker logs -f nostalgic_morse * Running on http://0.0.0.0:5000/ 10.0.2.2 - - [23/May/2014 20:16:31] &quot;GET / HTTP/1.1&quot; 200 - 10.0.2.2 - - [23/May/2014 20:16:31] &quot;GET /favicon.ico HTTP/1.1&quot; 404 - (2) -p（小写）则可以指定要映射的IP和端口，但是在一个指定端口上只可以绑定一个容器。支持的格式有 hostPort:containerPort、ip:hostPort:containerPort、ip::containerPort。 expose expose暴露容器给link到当前容器的容器，用法： expose: - &quot;3000&quot; - &quot;8000&quot; 以上指令将当前容器的端口3000和8000暴露给link到本容器的容器。 和ports的区别是，expose不会将端口暴露给主机。","categories":[],"tags":[],"author":"张存"},{"title":"Zabbix unreachable poller processes more than 75% busy","slug":"Zabbix-unreachable-poller-processes-more-than-75-busy","date":"2022-06-30T08:41:10.000Z","updated":"2022-06-30T08:41:22.171Z","comments":true,"path":"2022/06/30/zabbix-unreachable-poller-processes-more-than-75-busy/","link":"","permalink":"https://blog.zhangcun.store/2022/06/30/zabbix-unreachable-poller-processes-more-than-75-busy/","excerpt":"","text":"Zabbix unreachable poller processes more than 75% busy1.通过Zabbix agent采集数据的设备处于moniting的状态但是此时机器死机或其他原因导致zabbix agent死掉server获取不到数据，此时unreachable poller就会升高。 2.通过Zabbix agent采集数据的设备处于moniting的状态但是server向agent获取数据时时间过长，经常超过server甚至的timeout时间，此时unreachable poller就会升高。 Serverd端zabbix_server.conf配置调整 StartPollers=10 StartPollersUnreachable=10#上面配置要根据服务器的性能自行调整","categories":[],"tags":[],"author":"张存"},{"title":"docker-compose 部署apollo springboot整合（多环境）","slug":"docker-compose-部署apollo-springboot整合（多环境）","date":"2022-06-30T08:36:57.000Z","updated":"2022-06-30T08:37:09.046Z","comments":true,"path":"2022/06/30/docker-compose-bu-shu-apollo-springboot-zheng-he-duo-huan-jing/","link":"","permalink":"https://blog.zhangcun.store/2022/06/30/docker-compose-bu-shu-apollo-springboot-zheng-he-duo-huan-jing/","excerpt":"","text":"1.前言 由于项目需求，需要在单台服务器上部署apollo，并配置多环境，试了官网的快速开始docker，用里面的sh文件启动，实现多环境较为麻烦（需要该配置文件和脚本文件），后来在网上 2. 部署说明 版本：apollo-1.8.0 部署方式：docker-compose 3. 部署步骤 3.1 下载源码,创建数据库 源码地址： https://github.com/ctripcorp/apollo/tree/v1.2.0 创建数据库 apollo 要部署三个模块：apollo-configservice,apollo-adminservice,apollo-portal 其中apollo-configservice,apollo-adminservice要分环境部署，各个环境下apollo-configservice,apollo-adminservice公用一个数据库(参考官网)，apollo-portal独用一个数据库 共五个个数据库，apollo-configservice,apollo-adminservice分别在dev,fat,uat,pro一个数据库，apollo-portal一个数据库，如下图所示： 数据库修改ServerConfig表中的记录： 下面每一个表的eureka.service.url都做对应修改 ApolloConfigDB_DEV http://192.168.64.201:8080/eureka/ ApolloConfigDB_FAT http://192.168.64.201:8081/eureka/ ApolloConfigDB_UAT http://192.168.64.201:8082/eureka/ ApolloConfigDB_PRO http://192.168.64.201:8083/eureka/ ApolloPortalDB apollo-portal 的修改有所不同，同样是ServerConfig表，但是不是配置URL而是配置启用的环境，如下 dev,fat,uat,pro 3.2 编译源码 官网下载对应的版本的源码，导入idea，如下图，我这里标记了几个重要的模块以及目录 直接使用maven打包（不用apollo自带的build.sh，这种方式要改配置），直接打包后，取到config、admin、portal对应的zip包以及对应的Dockerfile文件，以及创建.env文件、docker-compose.yml、apollo-env.properties文件，最终文件目录结构如下： 3.3 编写docker-compose.yml .env文件 该文件用于定义docker-compose.yml文件中使用的变量,主要是暴露的端口定义，数据库连接串信息 VERSION=1.2.0 LOG_BASE_DIR=/data/apollo BUILD_BASE_DIR=/data/docker-image IP_ADDRESS=192.168.64.201 CONFIG_PORT_DEV=8080 CONFIG_PORT_FAT=8081 CONFIG_PORT_UAT=8082 CONFIG_PORT_PRO=8083 ADMIN_PORT_DEV=8090 ADMIN_PORT_FAT=8091 ADMIN_PORT_UAT=8092 ADMIN_PORT_PRO=8093 DATASOURCE_URL_DEV=jdbc:mysql://192.168.64.201:13306/huayun_ApolloConfigDB_DEV?characterEncoding=utf8 DATASOURCE_URL_FAT=jdbc:mysql://192.168.64.201:13306/huayun_ApolloConfigDB_FAT?characterEncoding=utf8 DATASOURCE_URL_UAT=jdbc:mysql://192.168.64.201:13306/huayun_ApolloConfigDB_UAT?characterEncoding=utf8 DATASOURCE_URL_PRO=jdbc:mysql://192.168.64.201:13306/huayun_ApolloConfigDB_PRO?characterEncoding=utf8 PORTAL_DATASOURCE_URL=jdbc:mysql://192.168.64.201:13306/huayun_ApolloPortalDB?characterEncoding=utf8 DATASOURCE_USERNAME=root DATASOURCE_PASSWORD=root apollo-env.properties dev.meta=http://192.168.64.201:8080 fat.meta=http://192.168.64.201:8081 uat.meta=http://192.168.64.201:8082 pro.meta=http://192.168.64.201:8083 docker-compose.yml version: &#39;3&#39; services: # 开发环境 configservice apollo-configservice-dev: container_name: apollo-configservice-dev build: apollo-configservice/ image: apollo-configservice restart: always environment: SPRING_DATASOURCE_URL: $&#123;DATASOURCE_URL_DEV&#125; SPRING_DATASOURCE_USERNAME: $&#123;DATASOURCE_USERNAME&#125; SPRING_DATASOURCE_PASSWORD: $&#123;DATASOURCE_PASSWORD&#125; EUREKA_INSTANCE_IP_ADDRESS: $&#123;IP_ADDRESS&#125; EUREKA_INSTANCE_HOME_PAGE_URL: http://$&#123;IP_ADDRESS&#125;:$&#123;CONFIG_PORT_DEV&#125; volumes: - $&#123;LOG_BASE_DIR&#125;/apollo-configservice-dev/logs:/opt/logs ports: - &quot;$&#123;CONFIG_PORT_DEV&#125;:8080&quot; # 开发环境 adminservice apollo-adminservice-dev: container_name: apollo-adminservice-dev build: apollo-adminservice/ image: apollo-adminservice restart: always depends_on: - apollo-configservice-dev environment: SPRING_DATASOURCE_URL: $&#123;DATASOURCE_URL_DEV&#125; SPRING_DATASOURCE_USERNAME: $&#123;DATASOURCE_USERNAME&#125; SPRING_DATASOURCE_PASSWORD: $&#123;DATASOURCE_PASSWORD&#125; EUREKA_INSTANCE_IP_ADDRESS: $&#123;IP_ADDRESS&#125; EUREKA_INSTANCE_HOME_PAGE_URL: http://$&#123;IP_ADDRESS&#125;:$&#123;ADMIN_PORT_DEV&#125; volumes: - $&#123;LOG_BASE_DIR&#125;/apollo-adminservice-dev/logs:/opt/logs ports: - &quot;$&#123;ADMIN_PORT_DEV&#125;:8090&quot; # fat configservice apollo-configservice-fat: container_name: apollo-configservice-fat build: apollo-configservice/ image: apollo-configservice restart: always environment: SPRING_DATASOURCE_URL: $&#123;DATASOURCE_URL_FAT&#125; SPRING_DATASOURCE_USERNAME: $&#123;DATASOURCE_USERNAME&#125; SPRING_DATASOURCE_PASSWORD: $&#123;DATASOURCE_PASSWORD&#125; EUREKA_INSTANCE_IP_ADDRESS: $&#123;IP_ADDRESS&#125; EUREKA_INSTANCE_HOME_PAGE_URL: http://$&#123;IP_ADDRESS&#125;:$&#123;CONFIG_PORT_FAT&#125; volumes: - $&#123;LOG_BASE_DIR&#125;/apollo-configservice-fat/logs:/opt/logs ports: - &quot;$&#123;CONFIG_PORT_FAT&#125;:8080&quot; # fat adminservice apollo-adminservice-fat: container_name: apollo-adminservice-fat build: apollo-adminservice/ image: apollo-adminservice restart: always depends_on: - apollo-configservice-fat environment: SPRING_DATASOURCE_URL: $&#123;DATASOURCE_URL_FAT&#125; SPRING_DATASOURCE_USERNAME: $&#123;DATASOURCE_USERNAME&#125; SPRING_DATASOURCE_PASSWORD: $&#123;DATASOURCE_PASSWORD&#125; EUREKA_INSTANCE_IP_ADDRESS: $&#123;IP_ADDRESS&#125; EUREKA_INSTANCE_HOME_PAGE_URL: http://$&#123;IP_ADDRESS&#125;:$&#123;ADMIN_PORT_FAT&#125; volumes: - $&#123;LOG_BASE_DIR&#125;/apollo-adminservice-fat/logs:/opt/logs ports: - &quot;$&#123;ADMIN_PORT_FAT&#125;:8090&quot; # uat configservice apollo-configservice-uat: container_name: apollo-configservice-uat build: apollo-configservice/ image: apollo-configservice restart: always environment: SPRING_DATASOURCE_URL: $&#123;DATASOURCE_URL_UAT&#125; SPRING_DATASOURCE_USERNAME: $&#123;DATASOURCE_USERNAME&#125; SPRING_DATASOURCE_PASSWORD: $&#123;DATASOURCE_PASSWORD&#125; EUREKA_INSTANCE_IP_ADDRESS: $&#123;IP_ADDRESS&#125; EUREKA_INSTANCE_HOME_PAGE_URL: http://$&#123;IP_ADDRESS&#125;:$&#123;CONFIG_PORT_UAT&#125; volumes: - $&#123;LOG_BASE_DIR&#125;/apollo-configservice-uat/logs:/opt/logs ports: - &quot;$&#123;CONFIG_PORT_UAT&#125;:8080&quot; # uat adminservice apollo-adminservice-uat: container_name: apollo-adminservice-uat build: apollo-adminservice/ image: apollo-adminservice restart: always depends_on: - apollo-configservice-uat environment: SPRING_DATASOURCE_URL: $&#123;DATASOURCE_URL_UAT&#125; SPRING_DATASOURCE_USERNAME: $&#123;DATASOURCE_USERNAME&#125; SPRING_DATASOURCE_PASSWORD: $&#123;DATASOURCE_PASSWORD&#125; EUREKA_INSTANCE_IP_ADDRESS: $&#123;IP_ADDRESS&#125; EUREKA_INSTANCE_HOME_PAGE_URL: http://$&#123;IP_ADDRESS&#125;:$&#123;ADMIN_PORT_UAT&#125; volumes: - $&#123;LOG_BASE_DIR&#125;/apollo-adminservice-uat/logs:/opt/logs ports: - &quot;$&#123;ADMIN_PORT_UAT&#125;:8090&quot; # pro configservice apollo-configservice-pro: container_name: apollo-configservice-pro build: apollo-configservice/ image: apollo-configservice restart: always environment: SPRING_DATASOURCE_URL: $&#123;DATASOURCE_URL_PRO&#125; SPRING_DATASOURCE_USERNAME: $&#123;DATASOURCE_USERNAME&#125; SPRING_DATASOURCE_PASSWORD: $&#123;DATASOURCE_PASSWORD&#125; EUREKA_INSTANCE_IP_ADDRESS: $&#123;IP_ADDRESS&#125; EUREKA_INSTANCE_HOME_PAGE_URL: http://$&#123;IP_ADDRESS&#125;:$&#123;CONFIG_PORT_PRO&#125; volumes: - $&#123;LOG_BASE_DIR&#125;/apollo-configservice-pro/logs:/opt/logs ports: - &quot;$&#123;CONFIG_PORT_PRO&#125;:8080&quot; # pro adminservice apollo-adminservice-pro: container_name: apollo-adminservice-pro build: apollo-adminservice/ image: apollo-adminservice restart: always depends_on: - apollo-configservice-pro environment: SPRING_DATASOURCE_URL: $&#123;DATASOURCE_URL_PRO&#125; SPRING_DATASOURCE_USERNAME: $&#123;DATASOURCE_USERNAME&#125; SPRING_DATASOURCE_PASSWORD: $&#123;DATASOURCE_PASSWORD&#125; EUREKA_INSTANCE_IP_ADDRESS: $&#123;IP_ADDRESS&#125; EUREKA_INSTANCE_HOME_PAGE_URL: http://$&#123;IP_ADDRESS&#125;:$&#123;ADMIN_PORT_PRO&#125; volumes: - $&#123;LOG_BASE_DIR&#125;/apollo-adminservice-pro/logs:/opt/logs ports: - &quot;$&#123;ADMIN_PORT_PRO&#125;:8090&quot; # portal apollo-portal: container_name: apollo-portal build: apollo-portal/ image: apollo-portal restart: always depends_on: - apollo-adminservice-dev - apollo-adminservice-fat - apollo-adminservice-uat - apollo-adminservice-pro environment: SPRING_DATASOURCE_URL: $&#123;PORTAL_DATASOURCE_URL&#125; SPRING_DATASOURCE_USERNAME: $&#123;DATASOURCE_USERNAME&#125; SPRING_DATASOURCE_PASSWORD: $&#123;DATASOURCE_PASSWORD&#125; APOLLO_PROFILE: github,auth volumes: - $&#123;LOG_BASE_DIR&#125;/apollo-portal/logs:/opt/logs - $&#123;BUILD_BASE_DIR&#125;/docker-compose-huayun/apollo-env.properties:/apollo-portal/config/apollo-env.properties ports: - &quot;8070:8070&quot; 各个环境下的apollo-configservice和apollo-adminservice中有两个参数解释一下： EUREKA_INSTANCE_IP_ADDRESS 指定服务想eureaka注册时使用物理机器IP地址 EUREKA_INSTANCE_HOME_PAGE_URL 该参数配置当前服务的注册全路径，如果不配置，Java应用客户端无法连接apollo服务端 3.4 启动容器 将修改后的docker-compose文件夹打包，上传到centos主机的/data/docker-image目录下(你可以更改，记得更改.env中的配置的BUILD_BASE_DIR对应的值为你的目录即可)，解压，如下： 进入docker-compose目录 启动容器 docker-compose up -d 观察各个服务启动的日志(我这里的日志挂在在了物理机的/data/apollo目录下)，服务一开始会有报错，因为注册中心启动需要一定的时间 3.5 apollo后台多环境验证，以及后台功能验证 确认服务启动 查看日志，看到portal有如下日志，则服务都已启动 或查看注册中心注册的服务信息，地址分别是： http://192.168.64.201:8080/ http://192.168.64.201:8081/ http://192.168.64.201:8082/ http://192.168.64.201:8083/ 看到服务注册成功即可。 访问apollo后台 http://192.168.64.201:8070/ 登录用户名密码：apollo/admin 登录后验证创建用户，看是不是会报错，能创建用户成功就OK了。 3.6 apollo客户端(Java应用)接入测试 新建一个springboot2的web项目,整合apollo客户端，项目结构如下： pom.xml，加入apollo客户端依赖 &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.6.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.huayun&lt;/groupId&gt; &lt;artifactId&gt;huayun-apollo-test&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;1.18.8&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;artifactId&gt;apollo-client&lt;/artifactId&gt; &lt;groupId&gt;com.ctrip.framework.apollo&lt;/groupId&gt; &lt;version&gt;1.5.0&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; 启动类App.java，加@EnableApolloConfig开启apollo package com.huayun.apollo; import com.ctrip.framework.apollo.spring.annotation.EnableApolloConfig; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; @EnableApolloConfig @SpringBootApplication public class App &#123; public static void main(String[] args) &#123; SpringApplication.run(App.class,args); &#125; &#125; application.yml定义服务端口 server: port: 8001 apollo-env.properties定义apollo服务的meta信息 dev.meta=http://192.168.64.201:8080 fat.meta=http://192.168.64.201:8081 uat.meta=http://192.168.64.201:8082 pro.meta=http://192.168.64.201:8083 app.properties定义appid,与apollo服务端appId对应 app.id=huayun-apollo-test 测试controller ApolloController.java,就是简单的获取apollo中配置的aaa的值，并返回 package com.huayun.apollo.controller; import com.ctrip.framework.apollo.Config; import com.ctrip.framework.apollo.ConfigService; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RequestMethod; import org.springframework.web.bind.annotation.RestController; @RestController public class ApolloController &#123; @GetMapping(&quot;/test&quot;) public Object test()&#123; Config config = ConfigService.getAppConfig(); //config instance is singleton for each namespace and is never null String someKey = &quot;aaa&quot;; int someDefaultValue = -1; int value = config.getIntProperty(someKey, someDefaultValue); return value; &#125; &#125; apollo服务端配置aaa在各个环境不同的值 为测试项目配置App的启动参数 -Denv=dev 分别为env配置不同的环境，测试获取到的aaa的值，aaa的值为对应的环境的值，那么就成功了。","categories":[],"tags":[],"author":"张存"},{"title":"curl查看出口公网IP地址","slug":"curl查看出口公网IP地址","date":"2022-06-30T08:12:37.000Z","updated":"2022-06-30T08:12:57.920Z","comments":true,"path":"2022/06/30/curl-cha-kan-chu-kou-gong-wang-ip-di-zhi/","link":"","permalink":"https://blog.zhangcun.store/2022/06/30/curl-cha-kan-chu-kou-gong-wang-ip-di-zhi/","excerpt":"","text":"使用一些内网服务器，有时候需要查看出口公网IP [root@docker02 ~]# curl ipinfo.io &#123; &quot;ip&quot;: &quot;114.251.151.151&quot;, \\\\公网出口IP &quot;city&quot;: &quot;Beijing&quot;, \\\\地理位置 ...... &#125; 或者 [root@docker02 ~]# curl cip.cc IP : 114.251.151.151 地址 : 中国 北京 运营商 : 联通 数据二 : 北京市 | 联通 数据三 : URL : http://www.cip.cc/114.251.122.178","categories":[],"tags":[],"author":"张存"},{"title":"Nginx访问日志（access_log）配置及信息详解","slug":"Nginx访问日志（access-log）配置及信息详解","date":"2022-06-30T08:11:42.000Z","updated":"2022-06-30T08:11:46.167Z","comments":true,"path":"2022/06/30/nginx-fang-wen-ri-zhi-access-log-pei-zhi-ji-xin-xi-xiang-jie/","link":"","permalink":"https://blog.zhangcun.store/2022/06/30/nginx-fang-wen-ri-zhi-access-log-pei-zhi-ji-xin-xi-xiang-jie/","excerpt":"","text":"Nginx访问日志主要有两个参数控制： log_format #用来定义记录日志的格式（可以定义多种日志格式，取不同名字即可） access_log #用来指定日至文件的路径及使用的何种日志格式记录日志 # log_format main &#39;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#39; # &#39;$status $body_bytes_sent &quot;$http_referer&quot; &#39; # &#39;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&#39;; access_log的默认值： #access_log logs/access.log main; 1 log_format log_format语法格式及参数语法说明如下: log_format &lt;NAME&gt; &lt;Strin­­­g&gt;; 关键字 格式标签 日志格式 关键字：其中关键字error_log不能改变 格式标签：格式标签是给一套日志格式设置一个独特的名字 日志格式：给日志设置格式 作用域 : http eg: log_format compression &#39;$remote_addr - $remote_user [$time_local] &#39; &#39;&quot;$request&quot; $status $bytes_sent &#39; &#39;&quot;$http_referer&quot; &quot;$http_user_agent&quot; &quot;$gzip_ratio&quot;&#39;; access_log /spool/logs/nginx-access.log compression buffer=32k; log_format格式变量： 参数 说明 示例 $remote_addr 客户端地址 211.28.65.253 $remote_user 客户端用户名称 -- $time_local 访问时间和时区 18/Jul/2012:17:00:01 +0800 $request 请求的URI和HTTP协议 &quot;GET /article-10000.html HTTP/1.1&quot; $http_host 请求地址，即浏览器中你输入的地址（IP或域名） www.wang.com 192.168.100.100 $status HTTP请求状态 200 $upstream_status upstream状态 200 $body_bytes_sent 发送给客户端文件内容大小 1547 $http_referer url跳转来源 https://www.baidu.com/ $http_user_agent 用户终端浏览器等信息 &quot;Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 5.1; Trident/4.0; SV1; GTB7.0; .NET4.0C; $ssl_protocol SSL协议版本 TLSv1 $ssl_cipher 交换数据中的算法 RC4-SHA $upstream_addr 后台upstream的地址，即真正提供服务的主机地址 10.10.10.100:80 $request_time 整个请求的总时间 0.205 $upstream_response_time 请求过程中，upstream响应时间 0.002 access_log 语法格式及参数语法说明如下: access_log &lt;FILE&gt; &lt;NAME&gt;; 关键字 日志文件 格式标签 关键字：其中关键字error_log不能改变 日志文件：可以指定任意存放日志的目录 格式标签：给日志文件套用指定的日志格式 其他语法： access_log off; #关闭access_log，即不记录访问日志 access_log path [format [buffer=size [flush=time]] [if=condition]]; access_log path format gzip[=level] [buffer=size] [flush=time] [if=condition]; access_log syslog:server=address[,parameter=value] [format [if=condition]]; 说明： buffer=size #为存放访问日志的缓冲区大小 flush=time #为缓冲区的日志刷到磁盘的时间 gzip[=level] #表示压缩级别 [if = condition] #表示其他条件 作用域（参数的标签段位置） : http, server, location, if in location, limit_except eg: access_log /spool/logs/nginx-access.log compression buffer=32k; 1 open_log_file_cache 使用open_log_file_cache来设置日志文件缓存(默认是off)。 max:设置缓存中的最大文件描述符数量，如果缓存被占满，采用LRU算法将描述符关闭。 inactive:设置存活时间，默认是10s min_uses:设置在inactive时间段内，日志文件最少使用多少次后，该日志文件描述符记入缓存中，默认是1次 valid:设置检查频率，默认60s off：禁用缓存 语法格式: open_log_file_cache max=N [inactive=time] [min_uses=N] [valid=time]; open_log_file_cache off; 默认值: open_log_file_cache off; 作用域: http, server, location eg： open_log_file_cache max=1000 inactive=20s valid=1m min_uses=2; 1 参考资料：http://nginx.org/en/docs/http/ngx_http_log_module.html nginx日志调试技巧 设置 Nginx 仅记录来自于你的 IP 的错误 当你设置日志级别成 debug，如果你在调试一个在线的高流量网站的话，你的错误日志可能会记录每个请求的很多消息，这样会变得毫无意义。 在events&#123;…&#125;中配置如下内容，可以使 Nginx 记录仅仅来自于你的 IP 的错误日志。 events &#123; debug_connection 1.2.3.4; &#125; 调试 nginx rewrite 规则 调试rewrite规则时，如果规则写错只会看见一个404页面，可以在配置文件中开启nginx rewrite日志，进行调试。 server &#123; error_log /var/logs/nginx/example.com.error.log; rewrite_log on; &#125; rewrite_log on; 开启后，它将发送所有的 rewrite 相关的日志信息到 error_log 文件中，使用 [notice] 级别。随后就可以在error_log 查看rewrite信息了。 使用location记录指定URL的日志 server &#123; error_log /var/logs/nginx/example.com.error.log; location /static/ &#123; error_log /var/logs/nginx/static-error.log debug; &#125; &#125; Nginx配置访问日志过程: （1）创建log_format语句 worker_processes 1; error_log logs/error.log error; events &#123; worker_connections 1024; &#125; http &#123; include status.conf; include mime.types; default_type application/octet-stream; sendfile on; keepalive_timeout 65; log_format main &#39;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#39; &#39;$status $body_bytes_sent &quot;$http_referer&quot; &#39; &#39;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&#39;; access_log logs/access.log main; server &#123; listen 80; server_name localhost; rewrite ^/.* http://www.wl.com permanent; &#125; include vhost/*.conf; &#125; （2）插入access_log语句 server &#123; access_log /data/log/www; listen 80; server_name abc.com www.wl.com; location / &#123; root /data/www/www; index index.html index.htm; &#125; error_log logs/error_www.wl.com.log error; access_log logs/access_www.wl.com.log main; #新增内容↑ &#125; （3）重启服务 nginx -t nginx -s reload 1 2 常用例子 main格式 log_format main &#39;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#39; &#39;$status $body_bytes_sent &quot;$http_referer&quot; &#39; &#39;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&#39; &#39;$upstream_addr $upstream_response_time $request_time &#39;; access_log logs/access.log main; json格式 log_format logstash_json &#39;&#123;&quot;@timestamp&quot;:&quot;$time_iso8601&quot;,&#39; &#39;&quot;host&quot;: &quot;$server_addr&quot;,&#39; &#39;&quot;client&quot;: &quot;$remote_addr&quot;,&#39; &#39;&quot;size&quot;: $body_bytes_sent,&#39; &#39;&quot;responsetime&quot;: $request_time,&#39; &#39;&quot;domain&quot;: &quot;$host&quot;,&#39; &#39;&quot;url&quot;:&quot;$request_uri&quot;,&#39; &#39;&quot;referer&quot;: &quot;$http_referer&quot;,&#39; &#39;&quot;agent&quot;: &quot;$http_user_agent&quot;,&#39; &#39;&quot;status&quot;:&quot;$status&quot;,&#39; &#39;&quot;x_forwarded_for&quot;:&quot;$http_x_forwarded_for&quot;&#125;&#39;; 解释： u r i 请 求 中 的 当 前 U R I ( 不 带 请 求 参 数 ， 参 数 位 于 uri 请求中的当前URI(不带请求参数，参数位于uri请求中的当前URI(不带请求参数，参数位于args)，不同于浏览器传递的$request_uri的值，它可以通过内部重定向，或者使用index指令进行修改。不包括协议和主机名，例如/foo/bar.html。 r e q u e s t u r i 这 个 变 量 等 于 包 含 一 些 客 户 端 请 求 参 数 的 原 始 U R I ， 它 无 法 修 改 ， 请 查 看 request_uri 这个变量等于包含一些客户端请求参数的原始URI，它无法修改，请查看request u ​ ri这个变量等于包含一些客户端请求参数的原始URI，它无法修改，请查看uri更改或重写URI。 也就是说：r e q u e s t u r i 是 原 始 请 求 U R L ， request_uri是原始请求URL，request u​ ri是原始请求URL，uri则是经过nginx处理请求后剔除参数的URL,所以会将汉字表现为union。 坑点： 使用u r i 可 以 在 n g i n x 对 U R L 进 行 更 改 或 重 写 ， 但 是 用 于 日 志 输 出 可 以 使 用 uri 可以在nginx对URL进行更改或重写，但是用于日志输出可以使用uri可以在nginx对URL进行更改或重写，但是用于日志输出可以使用request_uri代替，如无特殊业务需求，完全可以替换。 压缩格式 日志中增加了压缩的信息。 http &#123; log_format compression &#39;$remote_addr - $remote_user [$time_local] &#39; &#39;&quot;$request&quot; $status $body_bytes_sent &#39; &#39;&quot;$http_referer&quot; &quot;$http_user_agent&quot; &quot;$gzip_ratio&quot;&#39;; server &#123; gzip on; access_log /spool/logs/nginx-access.log compression; ... &#125; &#125; upstream格式 增加upstream消耗的时间。 http &#123; log_format upstream_time &#39;$remote_addr - $remote_user [$time_local] &#39; &#39;&quot;$request&quot; $status $body_bytes_sent &#39; &#39;&quot;$http_referer&quot; &quot;$http_user_agent&quot;&#39; &#39;rt=$request_time uct=&quot;$upstream_connect_time&quot; uht=&quot;$upstream_header_time&quot; urt=&quot;$upstream_response_time&quot;&#39;; server &#123; access_log /spool/logs/nginx-access.log upstream_time; ... &#125; &#125; 统计信息 统计status 出现的次数 awk &#39;&#123;print $9&#125;&#39; access.log | sort | uniq -c | sort -rn 36461 200 483 500 87 404 9 400 3 302 1 499 1 403 1 301 显示返回302状态码的URL。 awk &#39;($9 ~ /302/)&#39; access.log | awk &#39;&#123;print $7&#125;&#39; | sort | uniq -c | sort -rn 1 /wp-login.php 1 /wp-admin/plugins.php?action=activate&amp;plugin=ewww-image-optimizer%2Fewww-image-optimizer.php&amp;_wpnonce=cc4a379131 1 /wp-admin/","categories":[],"tags":[],"author":"张存"},{"title":"隐藏Nginx版本号的简单方法","slug":"隐藏Nginx版本号的简单方法-1","date":"2022-06-24T04:52:48.000Z","updated":"2022-06-24T04:55:10.930Z","comments":true,"path":"2022/06/24/yin-cang-nginx-ban-ben-hao-de-jian-dan-fang-fa-1/","link":"","permalink":"https://blog.zhangcun.store/2022/06/24/yin-cang-nginx-ban-ben-hao-de-jian-dan-fang-fa-1/","excerpt":"","text":"Nginx默认是显示版本号的，其他人就可以看到你的服务器nginx版本是1.8.0。这样暴露出来的版本号就容易变成攻击者可利用的信息。所以，从安全的角度来说，隐藏版本号会相对安全些！ 具体步骤如下： 1、进入nginx配置文件的目录（此目录根据安装时决定），用vim编辑打开 # vim nginx.conf 在http &#123;—&#125;里加上server_tokens off; 如： http &#123; …… sendfile on; tcp_nopush on; keepalive_timeout 60; tcp_nodelay on; server_tokens off; ……. 2、编辑php-fpm配置文件，如fastcgi.conf或fcgi.conf（这个配置文件名也可以自定义的，根据具体文件名修改）： 找到： fastcgi_param SERVER_SOFTWARE nginx/$nginx_version; 改为： fastcgi_param SERVER_SOFTWARE nginx; 3、重新加载nginx配置： # /etc/init.d/nginx reload 这样就完全对外隐藏了nginx版本号了，就是出现404、501等页面也不会显示nginx版本。","categories":[],"tags":[],"author":"张存"},{"title":"python 2安装pip","slug":"python-2安装pip","date":"2022-06-20T10:57:21.000Z","updated":"2022-06-20T10:58:43.535Z","comments":true,"path":"2022/06/20/python-2-an-zhuang-pip/","link":"","permalink":"https://blog.zhangcun.store/2022/06/20/python-2-an-zhuang-pip/","excerpt":"","text":"安装python-pip工具 先安装setup-tools wget https://pypi.python.org/packages/2.7/s/setuptools/setuptools-0.6c11-py2.7.egg --no-check-certificate chmod +x setuptools-0.6c11-py2.7.egg sh setuptools-0.6c11-py2.7.egg 安装pip wget https://pypi.python.org/packages/source/p/pip/pip-1.3.1.tar.gz --no-check-certificate cp pip-1.3.1.tar.gz /usr/src/ tar zxvf pip-1.3.1.tar.gz cd pip-1.3.1 python setup.py install ln -s /usr/local/python2.7/bin/pip /usr/bin/pip","categories":[],"tags":[],"author":"张存"},{"title":"Ubuntu 中sendmail 的安装、配置与发送邮件的具体实现","slug":"Ubuntu-中sendmail-的安装、配置与发送邮件的具体实现","date":"2022-06-20T10:53:52.000Z","updated":"2022-06-20T10:55:26.673Z","comments":true,"path":"2022/06/20/ubuntu-zhong-sendmail-de-an-zhuang-pei-zhi-yu-fa-song-you-jian-de-ju-ti-shi-xian/","link":"","permalink":"https://blog.zhangcun.store/2022/06/20/ubuntu-zhong-sendmail-de-an-zhuang-pei-zhi-yu-fa-song-you-jian-de-ju-ti-shi-xian/","excerpt":"","text":"一、安装软件包 ubuntu中sendmail函数可以很方便的发送邮件，ubuntu sendmail先要安装两个包。 必需安装的两个包： sudo apt-get install sendmail sudo apt-get install sendmail-cf 安装工具包： Ubuntu下使用最常用的mail功能，需要安装mailutils， 安装命令：sudo apt-get install mailutils //centos没有 -bash: mail: command not found 呵呵，显然mailx没有安装，于是： yum -y install mailx 然后whois命令也没有 yum -y install jwhois 使用带附件的功能，则还需要安装sharutils， 安装命令：sudo apt-get install sharutils 终端输入命令：ps aux |grep sendmail 输出如下： root 20978 0.0 0.3 8300 1940 ? Ss 06:34 0:00 sendmail: MTA: accepting connections root 21711 0.0 0.1 3008 776 pts/0 S+ 06:51 0:00 grep sendmail 说明sendmail 已经安装成功并启动了 二、配置 # vi /etc/mail/sendmail.mc dnl TRUST_AUTH_MECH(`EXTERNAL DIGEST-MD5 CRAM-MD5 LOGIN PLAIN&#39;)dnl dnl define(`confAUTH_MECHANISMS&#39;, `EXTERNAL GS SAPI DIGEST-MD5 CRAM-MD5 LOGIN PLAIN&#39;)dnl 将上面两行的dnl去掉。在sendmail文件中，dnl表示该行为注释行，是无效的，因此通过去除行首的dnl字符串可以开启相应的设置行。 sendmail 默认只会为本机用户发送邮件，只有把它扩展到整个Internet，才会成为真正的邮件服务器。 打开sendmail的配置宏文件：/etc/mail/sendmail.mc vim /etc/mail/sendmail.mc DAEMON_OPTIONS(`Family=inet, Name=MTA-v4, Port=smtp, Addr=127.0.0.1&#39;)dnl&lt;/span&gt; 把127.0.0.1修改为0.0.0.0 ，表明可以连接到任何服务器。 生成新的配置文件： cd /etc/mail mv sendmail.cf sendmail.cf-bak //做一个备份 m4 sendmail.mc &gt; sendmail.cf // &quot;&gt;&quot;的左右有空格。若提示错误说明你没有安装sendmail-cf 软件包 三、发送邮件 常用发送邮件方式如下： 1.如何写一般的邮件： mail test@126.com Cc 编辑抄送对象，Subject:邮件主题,输入回车，邮件正文后，按Ctrl-D结束 2.快速发送方式： echo “邮件正文” | mail -s 邮件主题 test@126.com 3.以文件内容作为邮件正文来发送： mail -s test test@126.com &lt; test.txt 4.发送带附件的邮件： uuencode 附件名称 附件显示名称 | mail -s 邮件主题 发送地址 例如： uuencode test.txt test.txt | mail -s Test test@126.com 参考发送例子： uuencode 1014-0529.txt 1014-0529.txt |mail -s biaoti 邮箱地址 （发送了附件1014-0529.txt，比较常用） mutt -s nihao 邮箱地址 -a nihao.txt &lt; nihao.txt 这种经常会被腾讯企业邮箱放到垃圾邮件箱中，一般不用。","categories":[],"tags":[],"author":"张存"},{"title":"apt安装特定版本软件","slug":"apt安装特定版本软件","date":"2022-06-20T10:52:05.000Z","updated":"2022-06-20T10:52:07.555Z","comments":true,"path":"2022/06/20/apt-an-zhuang-te-ding-ban-ben-ruan-jian/","link":"","permalink":"https://blog.zhangcun.store/2022/06/20/apt-an-zhuang-te-ding-ban-ben-ruan-jian/","excerpt":"","text":"sudo apt install software=version version是软件版本号，software是要安装的软件","categories":[],"tags":[],"author":"张存"},{"title":"Linux find查找指定文件 按照名称 然后cp拷贝到指定目录且指定文件名","slug":"Linux-find查找指定文件-按照名称-然后cp拷贝到指定目录且指定文件名","date":"2022-06-20T10:50:16.000Z","updated":"2022-06-20T10:50:48.002Z","comments":true,"path":"2022/06/20/linux-find-cha-zhao-zhi-ding-wen-jian-an-zhao-ming-cheng-ran-hou-cp-kao-bei-dao-zhi-ding-mu-lu-qie-zhi-ding-wen-jian-ming/","link":"","permalink":"https://blog.zhangcun.store/2022/06/20/linux-find-cha-zhao-zhi-ding-wen-jian-an-zhao-ming-cheng-ran-hou-cp-kao-bei-dao-zhi-ding-mu-lu-qie-zhi-ding-wen-jian-ming/","excerpt":"","text":"1.先查看了查找文件的指令规范 就是 find指令 Find命令的一般形式为： find pathname -options [-print -exec -ok] 让我们来看看该命令的参数： pathname: find命令所查找的目录路径。例如用.来表示当前目录，用/来表示系统根目录。 -print： find命令将匹配的文件输出到标准输出。 -exec： find命令对匹配的文件执行该参数所给出的shell命令。相应命令的形式为&#39;command&#39; &#123;&#125; \\;，注意&#123;&#125;和\\；之间的空格。 -ok： 和-exec的作用相同，只不过以一种更为安全的模式来执行该参数所给出的shell命令，在执行每一个命令之前，都会给出提示，让用户来确定是否执行。 find命令选项: -name：按照文件名查找文件。 -inum: 按照inode号查找文件 -perm：按照文件权限来查找文件。 -prune：使用这一选项可以使f i n d命令不在当前指定的目录中查找，如果同时使用-depth选项，那么-prune将被find命令忽略。 -user： 按照文件属主来查找文件。 -group：按照文件所属的组来查找文件。 -mtime -n +n：按照文件的更改时间来查找文件，-n表示文件更改时间距现在n天以内，+n表示文件更改时 间距现在n天以前。Find命令还有-atime和-ctime选项，但它们都和-mtime选项。 -nogroup：查找无有效所属组的文件，即该文件所属的组在/etc/groups中不存在。 -nouser：查找无有效属主的文件，即该文件的属主在/etc/passwd中不存在。 -newer file1 ! -newer file2：查找更改时间比文件file1新但比文件file2旧的文 件。 -type查找某一类型的文件，诸如： b - 块设备文件。 d - 目录。 c - 字符设备文件。 p - 管道文件。 l - 符号链接文件。 f - 普通文件。 -size n：[c] 查找文件长度为n块的文件，带有c时表示文件长度以字节计。 -depth：在查找文件时，首先查找当前目录中的文件，然后再在其子目录中查找。 -fstype：查找位于某一类型文件系统中的文件，这些文件系统类型通常可以在配置文件/etc/fstab中找 到，该配置文件中包含了本系统中有关文件系统的信息。 2. 编写指令 find /var -name &quot;boot.log&quot; -exec cp &#123;&#125; /var/log/testroad-boot.log \\; 执行成功！ 3.遇到问题 刚开始的指令是这样的： find /var -name &quot;boot.log&quot; -exec cp &#123;&#125;/var/log/testroad-boot.log\\; 错误信息： find: missing argument to `-exec&#39; 解决办法：增加空格在&#123;&#125;\\的中间. 就是因为刚开始忽略了&#123;&#125;\\之间的空格，导致执行失败。希望同样问题的朋友会提供帮助.","categories":[],"tags":[],"author":"张存"},{"title":"基于本地/Oracle官方jdk构建jdk镜像","slug":"基于本地-Oracle官方jdk构建jdk镜像","date":"2022-06-20T10:19:00.000Z","updated":"2022-06-20T10:19:48.782Z","comments":true,"path":"2022/06/20/ji-yu-ben-di-oracle-guan-fang-jdk-gou-jian-jdk-jing-xiang/","link":"","permalink":"https://blog.zhangcun.store/2022/06/20/ji-yu-ben-di-oracle-guan-fang-jdk-gou-jian-jdk-jing-xiang/","excerpt":"","text":"1、基于本地jdk进行构建 目录结构： Dockerfile jdk1.8.0_181.tar.gz Dokcerfile内容如下： FROM frolvlad/alpine-glibc:alpine-3.8 MAINTAINER youpanpan ADD jdk1.8.0_181.tar.gz /usr/local/ ENV JAVA_HOME /usr/local/jdk1.8.0_181 ENV PATH $&#123;PATH&#125;:$&#123;JAVA_HOME&#125;/bin ENV CLASSPATH $&#123;JAVA_HOME&#125;/lib/dt.jar:$&#123;JAVA_HOME&#125;/lib/tools.jar 这里有一个点：因为tar.gz ADD 到/usr/local/后，会自动解压为jdk1.8.0_181，所以这里设置的JAVA_HOME为/usr/local/jdk1.8.8_181 之前一直以为ADD 到的目录就是JDK的目录，所以写的是/usr/local/jdk1.8.0_181，所以导致后面执行java命令一直出错 相应的进行构建 docker build -t localjdk .然后使用镜像运行并执行java -version命令 docker run -it localjdk java -version 相应的数出了jdk的版本号，说明构建成功 2、使用Oracle官方jdk 参考https://github.com/frol/docker-alpine-oraclejdk8 除了使用这里的Dockerfile文件外，也可以直接使用frolvlad/alpine-oraclejre8镜像 这里的jdk版本因为删除了一些不必要的文件所以，镜像大小会有所下降 使用官方jdk并删除掉一些文件后，镜像大小为165MB，而基于本地jdk的方式会比较大一些，因为没有删掉那些不必要的文件，我们也可以先删除本地jdk中不必要的文件，这样大小应该是和官方下载的jdk镜像差不多。 有了上述的jdk镜像后，我们就可以基于上述jdk镜像，构建基于java环境的应用程序部署包了 目录结构： Dockerfile gs-om-ms.jar Dockerfile内容如下： FROM jdk:latest ADD gs-om-ms.jar gs-om-ms.jar EXPOSE 8988 ENTRYPOINT [&quot;java&quot;, &quot;-jar&quot;, &quot;gs-om-ms.jar&quot;] 基于上述的jdk镜像，添加程序包，并开放8988端口，接着容器启动后执行java -jar gs-om-ms.jar命令 这样就启动起来了","categories":[],"tags":[],"author":"张存"},{"title":"crontab每周一执行一次","slug":"crontab每周一执行一次","date":"2022-06-17T08:11:19.000Z","updated":"2022-06-17T09:00:07.327Z","comments":true,"path":"2022/06/17/crontab-mei-zhou-yi-zhi-xing-yi-ci/","link":"","permalink":"https://blog.zhangcun.store/2022/06/17/crontab-mei-zhou-yi-zhi-xing-yi-ci/","excerpt":"","text":"linux定时执行任务命令是我们在日常工作中经常用的，一般情况下，我们都是通过linux的crontab软件来实现，crontab是定时来执行一个命令或者一个脚本;但是如果你临时只执行一次命令的话，那么我们也可以采用at命令，同时可以实现我们的目标。 先从crontab开始分享，我们一般通过命令 crontab -l 来查看已经定时执行的任务，我们要新增呢，我们在命令行输入 #crontab -e 如果第一次执行，他会提示你选择默认编译器，一般我选择vim(vi、nano也可以) 我举例定时关机说明： 分 时 日 月 周 命令 0 1 * * 1 /sbin/shutdown -h now 这个意思就是在每周一的一点执行 /sbin/shutdown定时关机(root下才可以关机)当然你可以写个脚本，给予执行权限(x)，然后输入脚本的绝对路径，这里也可以定时执行。","categories":[],"tags":[],"author":"张存"},{"title":"Nginx 改变错误日志打印级别","slug":"Nginx-改变错误日志打印级别","date":"2022-06-17T08:06:36.000Z","updated":"2022-06-17T08:07:05.811Z","comments":true,"path":"2022/06/17/nginx-gai-bian-cuo-wu-ri-zhi-da-yin-ji-bie/","link":"","permalink":"https://blog.zhangcun.store/2022/06/17/nginx-gai-bian-cuo-wu-ri-zhi-da-yin-ji-bie/","excerpt":"","text":"Nginx 改变错误日志打印级别 user root;worker_processes 2; worker_rlimit_nofile 10240;error_log logs/nginx_error.log crit; events{ use epoll; worker_connections 2048;} 如果想改变nginx错误日志的打印级别，第四行添加以上字段。 nginx的error_log类型如下（从左到右：debug最详细 crit最少）： [ debug | info | notice | warn | error | crit ] 例如：error_log logs/nginx_error.log crit; 注意error_log off并不能关闭日志记录功能，它将日志文件写入一个文件名为off的文件中，如果你想关闭错误日志记录功能，应使用以下配置：error_log /dev/null crit; 把存储位置设置到Linux的黑洞中去","categories":[],"tags":[],"author":"张存"},{"title":"Ubuntu 18.04 编译安装 Python2.7.17","slug":"Ubuntu-18-04-编译安装-Python2-7-17","date":"2022-06-17T08:01:52.000Z","updated":"2022-06-17T08:01:55.001Z","comments":true,"path":"2022/06/17/ubuntu-18-04-bian-yi-an-zhuang-python2-7-17/","link":"","permalink":"https://blog.zhangcun.store/2022/06/17/ubuntu-18-04-bian-yi-an-zhuang-python2-7-17/","excerpt":"","text":"1、安装依赖 sudo apt-get install build-essential checkinstall sudo apt-get install libreadline-gplv2-dev libncursesw5-dev libssl-dev libsqlite3-dev tk-dev libgdbm-dev libc6-dev libbz2-dev 2、下载并解压缩 wget https://www.python.org/ftp/python/2.7.17/Python-2.7.17.tgz tar -xvf Python-2.7.17.tgz 3、编译安装 ，一路回车安装完成 ./configure --enable-optimizations make sudo checkinstall 安装位置：/usr/lib/python2.7 4、安装 PIP wget https://bootstrap.pypa.io/get-pip.py sudo python get-pip.pytar -xvf Python-2.7.17.tgz 5、显示版本信息 python –version 6、卸载 python sudo dpkg -r python","categories":[],"tags":[],"author":"张存"},{"title":"Linux上如何查看物理CPU个数，核数，线程数","slug":"Linux上如何查看物理CPU个数，核数，线程数","date":"2022-06-17T07:42:43.000Z","updated":"2022-06-17T07:51:39.657Z","comments":true,"path":"2022/06/17/linux-shang-ru-he-cha-kan-wu-li-cpu-ge-shu-he-shu-xian-cheng-shu/","link":"","permalink":"https://blog.zhangcun.store/2022/06/17/linux-shang-ru-he-cha-kan-wu-li-cpu-ge-shu-he-shu-xian-cheng-shu/","excerpt":"","text":"首先，看看什么是超线程概念 超线程技术就是利用特殊的硬件指令，把两个逻辑内核模拟成两个物理芯片，让单个处理器都能使用线程级并行计算，进而兼容多线程操作系统和软件，减少了CPU的闲置时间，提高的CPU的运行效率。 超线程技术是在一颗CPU同时执行多个程序而共同分享一颗CPU内的资源，理论上要像两颗CPU一样在同一时间执行两个线程，虽然采用超线程技术能同时执行两个线程，但它并不象两个真正的CPU那样，每个CPU都具有独立的资源。当两个线程都同时需要某一个资源时，其中一个要暂时停止，并让出资源，直到这些资源闲置后才能继续。因此超线程的性能并不等于两颗CPU的性能。 其次，看看物理CPU个数，核数以及线程数的关系 总核数 = 物理CPU个数 * 每颗物理CPU的核数 总逻辑CPU数 = 物理CPU个数 * 每颗物理CPU的核数 * 超线程数 上述公式中，逻辑CPU数即线程数 如何查看CPU物理个数 # grep &#39;physical id&#39; /proc/cpuinfo | sort -u physical id : 0 physical id : 1 如何查看每个物理CPU的核数 # grep &#39;core id&#39; /proc/cpuinfo | sort -u | wc -l 8 如何查看总的逻辑CPU个数 # grep &#39;processor&#39; /proc/cpuinfo | sort -u | wc -l 32 32/8/2=2，可见该CPU支持并已打开超线程。 如何查看CPU的型号 # dmidecode -s processor-version Intel(R) Xeon(R) CPU E5-2658 @ 2.10GHz Intel(R) Xeon(R) CPU E5-2658 @ 2.10GHz 关于物理CPU，核数以及超线程的区别 A core is the most basic computational unit of a processor. A processor is made up of one or more cores. Tradition processors had only one core while modern processors have multiple cores. A core consists of an ALU, CU, and a set of registers. A core consists of two levels of caches called L1 and L2 which is there in each core. A processor consists of a cache that is shared by call cores called L3 cache. It is common to all cores. A processor depending on the architecture can consist of a memory controller and an input/output controller. Certain processor packages consist of Graphics Processing Units (GPU) as well. A core that does not have hyper-threading can execute only one instruction at a time while a multicore processor made up of several cores can execute several instructions parallel. If a processor is made up of 4 cores that do not support hyper threading then that processor can execute 4 instructions at the same time. A core having hyper-threading technology has redundant functional units so that they can execute multiple instructions at a time. For example, a core with 2 threads can execute 2 instructions at the same time hence a processor with 4 such cores can execute 2×4 instructions parallel. These threads are usually called logical cores and the task manager of Windows generally show the number of logical cores but not the physical cores.","categories":[],"tags":[],"author":"张存"},{"title":"Linux设置UTC时区","slug":"Linux设置UTC时区","date":"2022-06-17T07:35:24.000Z","updated":"2022-06-17T07:35:47.865Z","comments":true,"path":"2022/06/17/linux-she-zhi-utc-shi-qu/","link":"","permalink":"https://blog.zhangcun.store/2022/06/17/linux-she-zhi-utc-shi-qu/","excerpt":"","text":"设置UTC时区命令 ln -sf /usr/share/zoneinfo/UTC /etc/localtime 具体案例： 执行前 [root@HOST etc]#cd /etc [root@HOST etc]# ll | grep local -rw-r--r--. 1 root root 19 Mar 25 2018 locale.conf lrwxrwxrwx 1 root root 35 Mar 12 16:06 localtime -&gt; ../usr/share/zoneinfo/Asia/Shanghai [root@HOST etc]# date Tue Mar 16 14:49:58 CST 2021 [root@HOST etc]# ln -sf /usr/share/zoneinfo/UTC /etc/localtime 执行后 [root@HOST etc]# date Tue Mar 16 06:50:32 UTC 2021 [root@HOST etc]# ll | grep local -rw-r--r--. 1 root root 19 Mar 25 2018 locale.conf lrwxrwxrwx 1 root root 23 Mar 16 06:50 localtime -&gt; /usr/share/zoneinfo/UTC","categories":[],"tags":[],"author":"张存"},{"title":"Nginx下同域部署多个Vue项目（history路由模式），报404、500错误","slug":"Nginx下同域部署多个Vue项目（history路由模式），报404、500错误","date":"2022-06-17T07:26:46.000Z","updated":"2022-06-17T07:29:36.093Z","comments":true,"path":"2022/06/17/nginx-xia-tong-yu-bu-shu-duo-ge-vue-xiang-mu-history-lu-you-mo-shi-bao-404-500-cuo-wu/","link":"","permalink":"https://blog.zhangcun.store/2022/06/17/nginx-xia-tong-yu-bu-shu-duo-ge-vue-xiang-mu-history-lu-you-mo-shi-bao-404-500-cuo-wu/","excerpt":"","text":"一、环境 系统: windows nginx: 1.20.2 nodejs: v10.24.0 npm: v6.14.11 @vue/cli: 4.5.13 二、问题描述 新建Vue项目的时候，如果选择hash模式的话，地址上都会带一个#号，本人嫌太丑，选择了history模式，到了部署项目的时候，刚好又需要多个项目部署在一起。部署完发现：① js、css文件找不到、② 页面报404、③ 页面报500。 三、问题解决 1、修改vue项目中的vue.config.js文件 a项目增加以下内容： module.exports = &#123; ... // 其他内容省略 publicPath: process.env.NODE_ENV === &#39;production&#39; ? &#39;/a&#39; : &#39;/&#39;, // production 正式环境，development 开发环境 &#125;; b项目增加以下内容： module.exports = &#123; ... // 其他内容省略 publicPath: process.env.NODE_ENV === &#39;production&#39; ? &#39;/b&#39; : &#39;/&#39;, // production 正式环境，development 开发环境 &#125;; 2、修改Nginx的nginx.conf配置文件 server &#123; listen 12345; server_name localhost; #charset koi8-r; #access_log logs/host.access.log main; location / &#123; root html; # 只能有一个root，可以有多个alias index index.html index.htm; #下面这一句是重点，意思就是将地址都导向index.html try_files $uri $uri/ /index.html; &#125; location /a &#123; # a项目 alias html/a; index index.html index.htm; #下面这一句是重点，意思就是将地址都导向index.html try_files $uri $uri/ /a/index.html; &#125; location /b &#123; # b项目 alias html/b; index index.html index.htm; #下面这一句是重点，意思就是将地址都导向index.html try_files $uri $uri/ /b/index.html; &#125; #error_page 404 /404.html; # redirect server error pages to the static page /50x.html # error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125; # proxy the PHP scripts to Apache listening on 127.0.0.1:80 # #location ~ \\.php$ &#123; # proxy_pass http://127.0.0.1; #&#125; # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000 # #location ~ \\.php$ &#123; # root html; # fastcgi_pass 127.0.0.1:9000; # fastcgi_index index.php; # fastcgi_param SCRIPT_FILENAME /scripts$fastcgi_script_name; # include fastcgi_params; #&#125; # deny access to .htaccess files, if Apache&#39;s document root # concurs with nginx&#39;s one # #location ~ /\\.ht &#123; # deny all; #&#125; &#125; 好了，这样配置好后就可以解决以上所有的问题了。","categories":[],"tags":[],"author":"张存"},{"title":"apt查看安装包可用版本号","slug":"apt查看安装包可用版本号","date":"2022-06-17T06:24:50.000Z","updated":"2022-06-17T06:25:22.390Z","comments":true,"path":"2022/06/17/apt-cha-kan-an-zhuang-bao-ke-yong-ban-ben-hao/","link":"","permalink":"https://blog.zhangcun.store/2022/06/17/apt-cha-kan-an-zhuang-bao-ke-yong-ban-ben-hao/","excerpt":"","text":"例如要显示curl可安装的版本号： sudo apt-cache madison curl 如果想看apt能安装哪些跟curl关键词相关的软件，运行以下命令， sudo apt-cache search curl","categories":[],"tags":[],"author":"张存"},{"title":"linux tar的排除,Tar命令排除指定目录","slug":"linux-tar的排除-Tar命令排除指定目录","date":"2022-06-17T06:21:50.000Z","updated":"2022-06-17T06:22:16.399Z","comments":true,"path":"2022/06/17/linux-tar-de-pai-chu-tar-ming-ling-pai-chu-zhi-ding-mu-lu/","link":"","permalink":"https://blog.zhangcun.store/2022/06/17/linux-tar-de-pai-chu-tar-ming-ling-pai-chu-zhi-ding-mu-lu/","excerpt":"","text":"Tar命令多用于备份，基本用法大家应该都知道一些，那么如何使用tar命令排除指定目录或指定文件的参数你知道吗? 举例： # ls 123 chinastor1 chinastor2 chinastor3 chinastor4 test1 test2 主目录叫123，其下有chinastor1 chinastor2 chinastor3 chinastor4 test1 test2共6个子目录。 用tar命令压缩保存一下，但是排除test1和test2两个目录，格式如下：(注意，主目录一定要放在最后！！！) # tar cvf 123.tar --exclude=test1 --exclude=test2 123 tar命令参数 t，可以浏览这个tar包，格式如下: # tar tvf 123.tar drwxrwxr-x chinastor.com/pg811892 0 2014-05-06 06:47 123/ drwxrwxr-x chinastor.com/pg811892 0 2014-05-06 06:47 123/chinastor3/ drwxrwxr-x chinastor.com/pg811892 0 2014-05-06 06:47 123/chinastor2/ drwxrwxr-x chinastor.com/pg811892 0 2014-05-06 06:47 123/chinastor1/ drwxrwxr-x chinastor.com/pg811892 0 2014-05-06 06:47 123/chinastor4/ 可以看到test1和test2被排除了吧。 想要直接tar成一个.tar.gz包的话，加z参数，格式如下： #tar czvf123.tar.gz --exclude=test1 --exclude=test2 123 浏览.tar.gz包的命令参数如下： #tar tzvf 123.tar.gz drwxrwxr-x chinastor.com/pg811892 0 2014-05-06 06:47 123/ drwxrwxr-x chinastor.com/pg811892 0 2014-05-06 06:47 123/chinastor3/ drwxrwxr-x chinastor.com/pg811892 0 2014-05-06 06:47 123/chinastor2/ drwxrwxr-x chinastor.com/pg811892 0 2014-05-06 06:47 123/chinastor1/ drwxrwxr-x chinastor.com/pg811892 0 2014-05-06 06:47 123/chinastor4/ 如果想排除指定的文件，也是可以的，比如要排除子目录test1下的所有txt文件，格式如下： # tar -zcvf 123.tar.gz --exclude=123/test1/*.txt 123","categories":[],"tags":[],"author":"张存"},{"title":"多主机多节点docker-compose部署elasticsearch集群","slug":"多主机多节点docker-compose部署elasticsearch集群","date":"2022-06-16T09:31:13.000Z","updated":"2022-06-16T09:34:22.643Z","comments":true,"path":"2022/06/16/duo-zhu-ji-duo-jie-dian-docker-compose-bu-shu-elasticsearch-ji-qun/","link":"","permalink":"https://blog.zhangcun.store/2022/06/16/duo-zhu-ji-duo-jie-dian-docker-compose-bu-shu-elasticsearch-ji-qun/","excerpt":"","text":"1、创建服务文件夹路径 [root@ip-172-93-1-78 deploy]# mkdir elasticsearch [root@ip-172-93-1-78 deploy]# cd elasticsearch/ [root@ip-172-93-1-78 elasticsearch]# ls [root@ip-172-93-1-78 elasticsearch]# pwd /data/deploy/elasticsearch [root@ip-172-93-1-78 elasticsearch]# mkdir logs data 2、编写docker-compose文件内容 [root@ip-172-93-1-78 elasticsearch]# vim docker-compose.yml version: &#39;3&#39; services: elasticsearch: # 服务名称 image: elasticsearch:7.1.1 # 使用的镜像 container_name: elasticsearch # 容器名称 restart: always # 失败自动重启策略 environment: - node.name=node-44 # 节点名称，集群模式下每个节点名称唯一 - network.publish_host=192.168.1.44 # 用于集群内各机器间通信,对外使用，其他机器访问本机器的es服务，一般为本机宿主机IP - network.host=0.0.0.0 # 设置绑定的ip地址，可以是ipv4或ipv6的，默认为0.0.0.0，即本机 - discovery.seed_hosts=192.168.1.44,192.168.1.45,192.168.1.46 # es7.0之后新增的写法，写入候选主节点的设备地址，在开启服务后，如果master挂了，哪些可以被投票选为主节点 - cluster.initial_master_nodes=192.168.1.44,192.168.1.45,192.168.1.46 # es7.0之后新增的配置，初始化一个新的集群时需要此配置来选举master - cluster.name=es-cluster # 集群名称，相同名称为一个集群， 三个es节点须一致 # - http.cors.enabled=true # 是否支持跨域，是：true // 这里设置不起作用，但是可以将此文件映射到宿主机进行修改，然后重启，解决跨域 # - http.cors.allow-origin=&quot;*&quot; # 表示支持所有域名 // 这里设置不起作用，但是可以将此文件映射到宿主机进行修改，然后重启，解决跨域 - bootstrap.memory_lock=true # 内存交换的选项，官网建议为true - &quot;ES_JAVA_OPTS=-Xms512m -Xmx512m&quot; # 设置内存，如内存不足，可以尝试调低点 ulimits: # 栈内存的上限 memlock: soft: -1 # 不限制 hard: -1 # 不限制 volumes: - ./elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml # 将容器中es的配置文件映射到本地，设置跨域， 否则head插件无法连接该节点 - ./data:/usr/share/elasticsearch/data # 存放数据的文件， 注意：这里的esdata为 顶级volumes下的一项。 ports: - 9200:9200 # http端口，可以直接浏览器访问 - 9300:9300 # es集群之间相互访问的端口，jar之间就是通过此端口进行tcp协议通信，遵循tcp协议。 编写elasticsearch.yml文件 [root@ip-172-93-1-78 elasticsearch]# vim elasticsearch.yml bootstrap.memory_lock: false cluster.name: &quot;es-server&quot; node.name: node1 node.master: true node.data: true network.host: 0.0.0.0 http.port: 9200 path.logs: /usr/share/elasticsearch/logs http.cors.enabled: true http.cors.allow-origin: &quot;*&quot; xpack.security.audit.enabled: true 编写jvm配置文件 [root@ip-172-93-1-78 elasticsearch]# cat conf/jvm.options -Djna.nosys=true # turn off a JDK optimization that throws away stack traces for common # exceptions because stack traces are important for debugging -XX:-OmitStackTraceInFastThrow # flags to configure Netty -Dio.netty.noUnsafe=true -Dio.netty.noKeySetOptimization=true -Dio.netty.recycler.maxCapacityPerThread=0 # log4j 2 -Dlog4j.shutdownHookEnabled=false -Dlog4j2.disable.jmx=true -Djava.io.tmpdir=$&#123;ES_TMPDIR&#125; ## heap dumps # generate a heap dump when an allocation from the Java heap fails # heap dumps are created in the working directory of the JVM -XX:+HeapDumpOnOutOfMemoryError # specify an alternative path for heap dumps; ensure the directory exists and # has sufficient space -XX:HeapDumpPath=data # specify an alternative path for JVM fatal error logs -XX:ErrorFile=logs/hs_err_pid%p.log ## JDK 8 GC logging 8:-XX:+PrintGCDetails 8:-XX:+PrintGCDateStamps 8:-XX:+PrintTenuringDistribution 8:-XX:+PrintGCApplicationStoppedTime 8:-Xloggc:logs/gc.log 8:-XX:+UseGCLogFileRotation 8:-XX:NumberOfGCLogFiles=32 8:-XX:GCLogFileSize=64m # JDK 9+ GC logging 9-:-Xlog:gc*,gc+age=trace,safepoint:file=logs/gc.log:utctime,pid,tags:filecount=32,filesize=64m # due to internationalization enhancements in JDK 9 Elasticsearch need to set the provider to COMPAT otherwise # time/date parsing will break in an incompatible way for some date patterns and locals 9-:-Djava.locale.providers=COMPAT # temporary workaround for C2 bug with JDK 10 on hardware with AVX-512 10-:-XX:UseAVX=2 启动elasticsearch服务 [root@ip-172-93-1-78 elasticsearch]# cat conf/jvm.options -Djna.nosys=true # turn off a JDK optimization that throws away stack traces for common # exceptions because stack traces are important for debugging -XX:-OmitStackTraceInFastThrow # flags to configure Netty -Dio.netty.noUnsafe=true -Dio.netty.noKeySetOptimization=true -Dio.netty.recycler.maxCapacityPerThread=0 # log4j 2 -Dlog4j.shutdownHookEnabled=false -Dlog4j2.disable.jmx=true -Djava.io.tmpdir=$&#123;ES_TMPDIR&#125; ## heap dumps # generate a heap dump when an allocation from the Java heap fails # heap dumps are created in the working directory of the JVM -XX:+HeapDumpOnOutOfMemoryError # specify an alternative path for heap dumps; ensure the directory exists and # has sufficient space -XX:HeapDumpPath=data # specify an alternative path for JVM fatal error logs -XX:ErrorFile=logs/hs_err_pid%p.log ## JDK 8 GC logging 8:-XX:+PrintGCDetails 8:-XX:+PrintGCDateStamps 8:-XX:+PrintTenuringDistribution 8:-XX:+PrintGCApplicationStoppedTime 8:-Xloggc:logs/gc.log 8:-XX:+UseGCLogFileRotation 8:-XX:NumberOfGCLogFiles=32 8:-XX:GCLogFileSize=64m # JDK 9+ GC logging 9-:-Xlog:gc*,gc+age=trace,safepoint:file=logs/gc.log:utctime,pid,tags:filecount=32,filesize=64m # due to internationalization enhancements in JDK 9 Elasticsearch need to set the provider to COMPAT otherwise # time/date parsing will break in an incompatible way for some date patterns and locals 9-:-Djava.locale.providers=COMPAT # temporary workaround for C2 bug with JDK 10 on hardware with AVX-512 10-:-XX:UseAVX=2","categories":[],"tags":[],"author":"张存"},{"title":"Elasticsearch OutOfMemoryError Java堆空间","slug":"Elasticsearch-OutOfMemoryError-Java堆空间","date":"2022-06-16T09:05:51.000Z","updated":"2022-06-16T09:06:10.136Z","comments":true,"path":"2022/06/16/elasticsearch-outofmemoryerror-java-dui-kong-jian/","link":"","permalink":"https://blog.zhangcun.store/2022/06/16/elasticsearch-outofmemoryerror-java-dui-kong-jian/","excerpt":"","text":"我正在运行一个8核，32g RAM弹性搜索节点，5个碎片，4亿个(小)文件。 一切都运行良好，直到我运行防攻击搜索，然后碎片开始失败与： java.lang.OutOfMemoryError: Java heap space 我已经改变了堆大小： 导出ES_HEAP_SIZE = 16g(也可以将ES_MAX_MEM和ES_MIN_MEM相同) 也改变了弹性搜索的yml文件： bootstrap. 相关专题：ElasticSearch 我正在运行一个8核，32g RAM弹性搜索节点，5个碎片，4亿个(小)文件。 一切都运行良好，直到我运行防攻击搜索，然后碎片开始失败与： java.lang.OutOfMemoryError: Java heap space 我已经改变了堆大小： 导出ES_HEAP_SIZE = 16g(也可以将ES_MAX_MEM和ES_MIN_MEM相同) 也改变了弹性搜索的yml文件： bootstrap.mlockall: true 甚至(安装文件推荐)： sudo sysctl -w vm.max_map_count=262144 重启服务依然没有没有影响，还是java.lang.OutOfMemoryError：Java堆空间 任何其他建议？除了不运行查询？ 查询是： https://localhost:9200/my_index_name/_search?search_type=count &#123; &quot;aggs&quot;: &#123; &quot;distinct_hostname&quot;: &#123; &quot;cardinality&quot;: &#123; &quot;field&quot;: &quot;hostname&quot; &#125; &#125; &#125; &#125; 我想我发现了错误。我使用’服务’来运行弹性搜索，因此我的环境变量被剥离了。我必须使用相应的env变量(特别是ES_HEAP_SIZE = 16g)更新/ etc / default / elasticsearch文件。 到目前为止，它运行良好，应用程序不会出错。","categories":[],"tags":[],"author":"张存"},{"title":"Linux修改文件句柄数及vm.max_map_count、stack size","slug":"Linux修改文件句柄数及vm-max-map-count、stack-size","date":"2022-06-16T09:03:48.000Z","updated":"2022-06-16T09:04:51.240Z","comments":true,"path":"2022/06/16/linux-xiu-gai-wen-jian-ju-bing-shu-ji-vm-max-map-count-stack-size/","link":"","permalink":"https://blog.zhangcun.store/2022/06/16/linux-xiu-gai-wen-jian-ju-bing-shu-ji-vm-max-map-count-stack-size/","excerpt":"","text":"一、修改文件句柄数 1.1.查看当前大小 ulimit -a 1.2.临时修改 ulimit -n 4096 1.3.永久修改 vim /etc/security/limits.conf * soft nofile 65536 * hard nofile 65536 重新登录后生效 二、修改max user processes进程数 2.1.临时修改 ulimit -u 65536 2.1.永久修改 vim /etc/security/limits.conf * soft nproc 65536 * hard nproc 65536 三、调整vm.max_map_count的大小 max_map_count文件包含限制一个进程可以拥有的VMA(虚拟内存区域)的数量 报错“max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144]” 3.1.查看当前值 sysctl -a|grep vm.max_map_count 3.2.临时修改 sysctl -w vm.max_map_count=262144 3.3.永久修改 vim /etc/sysctl.conf vm.max_map_count=262144 sysctl -p 四、调整stack size的大小 查看：ulimit -a,默认是8192，即8M 临时修改 ulimit -s 1024 永久修改 vi /etc/security/limits.conf soft stack 1024 hard stack 1024 注意： nofile nofile表示单个进程可以打开的最大文件句柄数（默认值，软限制：1024，硬限制：4096） /proc/sys/fs/file-max表示整个系统内核可以分配的最大文件句柄数（默认值约为物理内存转换成kb的值/10），如需修改执行命令：echo ‘fs.file-max=104857600’ &gt;&gt; /etc/sysctl.conf &amp;&amp; sysctl -q -p /proc/sys/fs/file-nr表示整个系统内核的文件句柄统计数据（只读），包含三个值，1：整个系统内核已分配的文件句柄数，2：整个系统内核已分配但未使用的文件句柄数（一般情况下为0），3：整个系统内核可以分配的最大文件句柄数（等于file-max） /proc/sys/fs/nr_open表示单个进程可以分配的最大文件句柄数（默认值为1048576），如需修改执行命令：echo ‘fs.nr_open=2097152’ &gt;&gt; /etc/sysctl.conf &amp;&amp; sysctl -q -p nofile的值不能超过nr_open的值，如果配置文件中nofile的硬限制的值超过nr_open的值将会导致无法登录系统 单个进程可以打开的最大文件句柄数由nofile和file-max同时约束，假如一个进程已打开的文件句柄数小于nofile，但整个系统内核所有进程打开的文件句柄数已经达到file-max，此时这个进程也不能再打开文件句柄了 nproc nproc表示单个用户创建的进程数（默认值，软限制：threads-max/2，硬限制：threads-max/2），线程的实现其实是一个轻量级的进程，所以线程也算进程 /proc/sys/kernel/threads-max表示整个系统内核可以分配的最大线程数，如需修改执行命令：echo ‘kernel.threads-max=1048576’ &gt;&gt; /etc/sysctl.conf &amp;&amp; sysctl -q -p /proc/sys/kernel/pid_max表示整个系统内核可以分配的最大进程ID（默认值为32768，2个字节的最大值），也就是说，整个系统内核最多只能分配pid_max个进程或线程，如需修改执行命令：echo ‘kernel.pid_max=1048576’ &gt;&gt; /etc/sysctl.conf &amp;&amp; sysctl -q -p /proc/sys/vm/max_map_count表示单个进程可以分配的内存映射区域的最大数量（默认值为65530），由于java中每创建一个线程需要分配2个内存映射区域，并且jvm本身也要占用部分内存映射区域，所以java程序理论上最多可以创建的线程数为略小于max_map_count/2（实际上还受jvm参数-Xms、-Xmx、-Xss以及操作系统物理内存的影响），如需修改执行命令：echo ‘vm.max_map_count=2097152’ &gt;&gt; /etc/sysctl.conf &amp;&amp; sysctl -q -p 单个进程可以创建的线程数由nproc、threads-max、pid_max、max_map_count以及系统资源同时约束，达到其中一个的上限就不能再创建线程了 CentOS7中/etc/security/limits.d/20-nproc.conf（CentOS6是90-nproc.conf）会覆盖/etc/security/limits.conf中的nproc配置，前提条件是，(20|90)-nproc.conf和limits.conf的domain相同或者(20|90)-nproc.conf比limits.conf的domain更具体，优先级从高到低分别为： /etc/security/limits.d/(20|90)-nproc.conf中domain为具体用户的配置 /etc/security/limits.conf中domain为具体用户的配置 /etc/security/limits.d/(20|90)-nproc.conf中domain为通配符（）的配置 /etc/security/limits.conf中domain为通配符（）的配置 注意事项 domain中具体用户比通配符（*）优先级高 软限制不能大于硬限制，如果配置文件中软限制设置的比硬限制高，则软限制会使用硬限制的值，通过ulimit命令设置软限制不能超过硬限制。root用户可以通过ulimit命令降低和提高硬限制（nofile的值不能超过nr_open的值）。非root用户可以通过ulimit命令降低硬限制，但不可以通过ulimit命令提高硬限制。","categories":[],"tags":[],"author":"张存"},{"title":"同时查看所有docker容器的日志","slug":"同时查看所有docker容器的日志","date":"2022-06-16T09:00:42.000Z","updated":"2022-06-16T12:30:15.555Z","comments":true,"path":"2022/06/16/tong-shi-cha-kan-suo-you-docker-rong-qi-de-ri-zhi/","link":"","permalink":"https://blog.zhangcun.store/2022/06/16/tong-shi-cha-kan-suo-you-docker-rong-qi-de-ri-zhi/","excerpt":"","text":"我目前使用docker作为后端，当我第一次用 启动时 docker-compose up 我一次得到所有4个码头工人的日志输出，所以我可以看到他们在请求进来时如何相互交互。看起来像这样，一个请求从nginx到couchdb http://i.imgur.com/E4GQ43F.png 现在的问题是我在GCE上运行负载均衡，当新VM启动时，它会自动启动docker并正常运行，我希望能够访问负载均衡的VM并查看实时日志，但我不能让docker允许我这种风格，当我使用日志时，它给我正常的所有白色字体，没有标签来自它。 使用docker events 什么都不做，它不会返回任何信息。 tldr;获取视图的最佳方式是什么，与运行时获得的日志输出相同＆＃34; docker-compose up＆＃34; 5 个答案: 如果使用docker-compose，请使用 docker-compose logs --tail=0 --follow 而不是 docker logs --tail=0 --follow 这将获得我最初寻找的输出。 您可以使用以下命令查看所有正在运行的容器的日志 docker ps -q | xargs -L 1 docker logs 理论上，如果xargs与--follow一起运行，而xargs的数量大于正在运行的容器的数量，那么这对-P &lt;count&gt;也可能适用。 我使用此变量的变体来尾部（-跟随）所有日志，并指示当时哪个日志在尾部。此bash包括stdout和stderr。请注意，之后您可能需要清除*。&#123;log，err&#125;的/ tmp目录。 for c in $(docker ps -a --format=&quot;&#123;&#123;.Names&#125;&#125;&quot;) do docker logs -f $c &gt; /tmp/$c.log 2&gt; /tmp/$c.err &amp; done tail -f /tmp/*.&#123;log,err&#125; 希望这会有所帮助。如今，伐木变得如此麻烦，而其他下车的老人都在抱怨... 答案 3 :(得分：1) 如果使用的是Docker Swarm，则可以通过以下方式找到服务 docker service ls 获取ID，然后运行 docker service logs $ID -f 如果使用tty：true定义服务，则必须使用--raw标志运行。请注意，这不会告诉您哪个容器正在提供输出的日志条目。 试试“看” 这是一个用于 docker 容器的快速而肮脏的 multitail/xtail。 #watch &#39;docker ps --format &quot;&#123;&#123;.Names&#125;&#125;&quot; | sort | xargs --verbose --max-args=1 -- docker logs --tail=8 --timestamps&#39; 根据需要调整参数“--tail=8”，使所有内容仍然适合一个屏幕。 当容器停止和重新启动时，上面列出的“xargs”方法将停止工作。这里的这种“观察”方法没有这个问题。 （但也不是很好。）","categories":[],"tags":[],"author":"张存"},{"title":"我要自学网","slug":"我要自学网","date":"2022-06-16T08:56:00.000Z","updated":"2022-06-16T08:56:01.803Z","comments":true,"path":"2022/06/16/wo-yao-zi-xue-wang/","link":"","permalink":"https://blog.zhangcun.store/2022/06/16/wo-yao-zi-xue-wang/","excerpt":"","text":"https://www.51zxw.net","categories":[],"tags":[],"author":"张存"},{"title":"ps查看完整程序执行路径","slug":"ps查看完整程序执行路径","date":"2022-06-16T08:52:57.000Z","updated":"2022-06-16T08:53:56.688Z","comments":true,"path":"2022/06/16/ps-cha-kan-wan-zheng-cheng-xu-zhi-xing-lu-jing/","link":"","permalink":"https://blog.zhangcun.store/2022/06/16/ps-cha-kan-wan-zheng-cheng-xu-zhi-xing-lu-jing/","excerpt":"","text":"在linux下查看进程大家都会想到用 ps -ef|grep *** 可是看到的不是全路径，怎么看全路径呢？ 每个进程启动之后在 /proc下面有一个于pid对应的路径 例如：ps -ef|grep java liu 2233 4366 0 18:56 pts/2 00:00:00 java GateWar.war ls -l /proc/2233 注意cwd，即是你要查找的进程所在路径","categories":[],"tags":[],"author":"张存"},{"title":"ubantu批量下载依赖包+apt命令list","slug":"ubantu批量下载依赖包-apt命令list","date":"2022-06-16T08:49:43.000Z","updated":"2022-06-16T08:50:11.003Z","comments":true,"path":"2022/06/16/ubantu-pi-liang-xia-zai-yi-lai-bao-apt-ming-ling-list/","link":"","permalink":"https://blog.zhangcun.store/2022/06/16/ubantu-pi-liang-xia-zai-yi-lai-bao-apt-ming-ling-list/","excerpt":"","text":"apt install aptitude aptitude --download-only install docker.io 默认下载地址 /var/cache/apt/archives/ sudo apt-get install package 安装软件包 sudo apt-get install package - - reinstall 重新安装软件包 sudo apt-get -f install 修复安装软件包&quot;-f = ——fix-missing&quot; sudo apt-get remove package 删除软件包 sudo apt-get remove package - - purge 删除软件包，包括删除配置文件等 sudo apt-get update 更新源及/etc/apt/sources.list sudo apt-get upgrade 更新已安装的软件包 sudo apt-get dist-upgrade 升级系统安装的软件包 sudo apt-get dselect-upgrade 使用 dselect 升级 sudo apt-get build-dep package 安装相关的编译环境 sudo apt-get clean &amp;&amp; sudo apt-get autoclean 清理无用的软件包 sudo apt-get check 检查是否有损坏的依赖 apt-cache search package 搜索软件包 apt-cache show package 获取包的相关信息，如说明、大小、版本等 apt-cache depends package 了解使用依赖 apt-cache rdepends package 是查看该软件包被哪些软件包依赖","categories":[],"tags":[],"author":"张存"},{"title":"HTTP 499 状态码 nginx下 499错误","slug":"HTTP-499-状态码-nginx下-499错误","date":"2022-06-16T08:45:26.000Z","updated":"2022-06-16T08:47:58.798Z","comments":true,"path":"2022/06/16/http-499-zhuang-tai-ma-nginx-xia-499-cuo-wu/","link":"","permalink":"https://blog.zhangcun.store/2022/06/16/http-499-zhuang-tai-ma-nginx-xia-499-cuo-wu/","excerpt":"","text":"日志记录中HTTP状态码出现499错误有多种情况，我遇到的一种情况是nginx反代到一个永远打不开的后端，就这样了，日志状态记录是499、发送字节数是0。 老是有用户反映网站系统时好时坏，因为线上的产品很长时间没有修改，所以前端程序的问题基本上可以排除，于是就想着是Get方式调用的接口不稳定，问了相关人员，说没有问题，为了拿到确切证据，于是我问相关人员要了nginx服务器的日志文件（awstats日志），分析后发现日志中很多错误码为499的错误，约占整个日志文件的1%，而它只占全部报错的70%左右（全部报错见下图），那么所有报错加起来就要超过1%了，这个量还是特别大的。 499错误是什么？让我们看看NGINX的源码中的定义： ngx_string(ngx_http_error_495_page), /* 495, https certificate error */ ngx_string(ngx_http_error_496_page), /* 496, https no certificate */ ngx_string(ngx_http_error_497_page), /* 497, http to https */ ngx_string(ngx_http_error_404_page), /* 498, canceled */ ngx_null_string, /* 499, client has closed connection */ 可以看到，499对应的是 “client has closed connection”。这很有可能是因为服务器端处理的时间过长，客户端“不耐烦”了。 Nginx 499错误的原因及解决方法 打开Nginx的access.log发现在最后一次的提交是出现了HTTP1.1 499 0 -这样的错误，在百度搜索nginx 499错误，结果都是说客户端主动断开了连接。 但经过我的测试这显然不是客户端的问题，因为使用端口+IP直接访问后端服务器不存在此问题，后来测试nginx发现如果两次提交post过快就会出现499的情况，看来是nginx认为是不安全的连接，主动拒绝了客户端的连接. 但搜索相关问题一直找不到解决方法，最后终于在google上搜索到一英文论坛上有关于此错误的解决方法： proxy_ignore_client_abort on; Don’t know if this is safe. 就是说要配置参数 proxy_ignore_client_abort on; 表示代理服务端不要主要主动关闭客户端连接。 以此配置重启nginx,问题果然得到解决。只是安全方面稍有欠缺，但比总是出现找不到服务器好多了。 还有一种原因是 我后来测试发现 确实是客户端关闭了连接,或者说连接超时 ,无论你设置多少超时时间多没用 原来是php进程不够用了 改善一下php进程数 问题解决 默认测试环境才开5个子进程。日志记录中HTTP状态码出现499错误有多种情况，我遇到的一种情况是nginx反代到一个永远打不开的后端，就这样了，日志状态记录是499、发送字节数是0。 老是有用户反映网站系统时好时坏，因为线上的产品很长时间没有修改，所以前端程序的问题基本上可以排除，于是就想着是Get方式调用的接口不稳定，问了相关人员，说没有问题，为了拿到确切证据，于是我问相关人员要了nginx服务器的日志文件（awstats日志），分析后发现日志中很多错误码为499的错误，约占整个日志文件的1%，而它只占全部报错的70%左右（全部报错见下图），那么所有报错加起来就要超过1%了，这个量还是特别大的。 499错误是什么？让我们看看NGINX的源码中的定义： ngx_string(ngx_http_error_495_page), /* 495, https certificate error */ ngx_string(ngx_http_error_496_page), /* 496, https no certificate */ ngx_string(ngx_http_error_497_page), /* 497, http to https */ ngx_string(ngx_http_error_404_page), /* 498, canceled */ ngx_null_string, /* 499, client has closed connection */ 可以看到，499对应的是 “client has closed connection”。这很有可能是因为服务器端处理的时间过长，客户端“不耐烦”了。 Nginx 499错误的原因及解决方法 打开Nginx的access.log发现在最后一次的提交是出现了HTTP1.1 499 0 -这样的错误，在百度搜索nginx 499错误，结果都是说客户端主动断开了连接。 但经过我的测试这显然不是客户端的问题，因为使用端口+IP直接访问后端服务器不存在此问题，后来测试nginx发现如果两次提交post过快就会出现499的情况，看来是nginx认为是不安全的连接，主动拒绝了客户端的连接. 但搜索相关问题一直找不到解决方法，最后终于在google上搜索到一英文论坛上有关于此错误的解决方法： proxy_ignore_client_abort on; Don’t know if this is safe. 就是说要配置参数 proxy_ignore_client_abort on; 表示代理服务端不要主要主动关闭客户端连接。 以此配置重启nginx,问题果然得到解决。只是安全方面稍有欠缺，但比总是出现找不到服务器好多了。 还有一种原因是 我后来测试发现 确实是客户端关闭了连接,或者说连接超时 ,无论你设置多少超时时间多没用 原来是php进程不够用了 改善一下php进程数 问题解决 默认测试环境才开5个子进程。","categories":[],"tags":[],"author":"张存"},{"title":"搬瓦工搭建 ShadowSocks 翻墙（VPN）- 更换密码","slug":"搬瓦工搭建-ShadowSocks-翻墙（VPN）-更换密码","date":"2022-06-16T08:42:56.000Z","updated":"2022-06-16T08:43:10.730Z","comments":true,"path":"2022/06/16/ban-wa-gong-da-jian-shadowsocks-fan-qiang-vpn-geng-huan-mi-ma/","link":"","permalink":"https://blog.zhangcun.store/2022/06/16/ban-wa-gong-da-jian-shadowsocks-fan-qiang-vpn-geng-huan-mi-ma/","excerpt":"","text":"在 搬瓦工搭建 ShadowSocks 翻墙（VPN） 一文中的 “三、安装 SSR 脚本” 步骤结束后的打印信息： INFO: loading config from /etc/shadowsocks-python/config.json2019-03-28 05:14:24 INFO loading libcrypto from libcrypto.so.10Starting Shadowsocks success Congratulations, Shadowsocks-Python server install completed!看到 VPN 服务的配置信息是不是有点激动呢？有配置那是否意味着更改配置信息就能达到我们的目的呢？ 在终端操作命令 vi /etc/shadowsocks-python/config.json 可以看到 &#123; &quot;server&quot;:&quot;0.0.0.0&quot;, &quot;server_port&quot;:11260, &quot;local_address&quot;:&quot;127.0.0.1&quot;, &quot;local_port&quot;:1080, &quot;password&quot;:&quot;123456&quot;, &quot;timeout&quot;:300, &quot;method&quot;:&quot;aes-256-cfb&quot;, &quot;fast_open&quot;:false &#125; 在看到 password 后，说明我们可以试试修改 password 的值。编辑 /etc/shadowsocks-python/config.json，修改 password 的值为 12345678，保存退出。","categories":[],"tags":[],"author":"张存"},{"title":"Slurm 20.02.3 集群添加gpu节点","slug":"Slurm-20-02-3-集群添加gpu节点","date":"2022-06-16T08:39:08.000Z","updated":"2022-06-16T08:39:31.712Z","comments":true,"path":"2022/06/16/slurm-20-02-3-ji-qun-tian-jia-gpu-jie-dian/","link":"","permalink":"https://blog.zhangcun.store/2022/06/16/slurm-20-02-3-ji-qun-tian-jia-gpu-jie-dian/","excerpt":"","text":"为slurm集群增加GPU节点 1 环境准备 一个slurm管理节点(186.31.29.21)，一个GPU节点(183.31.28.247) GPU节点的GPU型号为GTX1080Ti，驱动版本为440.100，CUDA版本为10.0，安装了对应的cudnn。 其实，slurm对GPU的型号及驱动并不敏感，slurm只是去/dev下面去找硬件设备，然后使其作为slurm的通用资源。 2 修改配置文件 管理节点： 在slurm.conf中，修改如下两项 GresTypes=gpu NodeName= gupnode01 Gres=gpu:1 CPUs=56 RealMemory=256000 Socket=2 State=UNKNOWN 第一行是指明通用资源的类型为gpu 第二行中，重要的参数是 `Gres=gpu:1` gpu代表类型，冒号后的数字代表数量，1个GPU就是1，8个就是8。 计算节点： 计算节点除了要 slurm.conf还需要gres.conf，slurm官方文档说，把 gres.conf中的东西写到slurm.conf中也未尝不可~ NodeName=gpunode01 Name=gpu File=/dev/nvidia0 这一行重要的就是知名节点名字和GPU File的位置 。 3 关闭防火墙、测试 要使用gpu节点， 一定要关闭防火墙`systemctl stop firewalld` 最好也清除并关闭iptables `iptables -t nat -F` `iptables -t filter -F` `systemctl stop iptables` 最好将selinux关闭，`vi /etc/selinux/config` 将SELINUX改为disable 然后我们就可以使用GPU了 这里有个使用python tensorflow-1.14的GPU测试脚本，大家可以拿去试试 import tensorflow as tf with tf.device(&#39;/gpu:0&#39;) v1 = tf.constant([1.0, 2.0, 3.0], shape=[3], name=&#39;v1&#39;) v2 = tf.constant([1.0, 2.0, 3.0], shape=[3], name=&#39;v2&#39;) sumV = v1 + v2 with tf.Session() as sess: print(sess.run(sumV)) 使用slurm srun运行此脚本，命令为： srun --gres=gpu:1 python3 test_gpu.py END","categories":[],"tags":[],"author":"张存"},{"title":"slurm集群安装","slug":"slurm集群安装","date":"2022-06-16T08:32:02.000Z","updated":"2022-06-16T08:33:51.257Z","comments":true,"path":"2022/06/16/slurm-ji-qun-an-zhuang/","link":"","permalink":"https://blog.zhangcun.store/2022/06/16/slurm-ji-qun-an-zhuang/","excerpt":"","text":"环境：三台物理机，os均为ubuntu-18-04 LTS，hostname分别为tian-609-06、tian-609-07、tian-609-08。其中tian-609-06作为控制节点和计算节点，其他节点作为计算节点。 sudo apt install munge slurm-wlm 1 2、配置/etc/slurm-llnl/slurm.conf文件（所有机器，配置一样） # slurm.conf file generated by configurator easy.html. # Put this file on all nodes of your cluster. # See the slurm.conf man page for more information. # ControlMachine=tian-609-06 #&lt;YOUR-HOST-NAME&gt; #ControlAddr= # #MailProg=/bin/mail MpiDefault=none #MpiParams=ports=#-# ProctrackType=proctrack/pgid ReturnToService=1 SlurmctldPidFile=/var/run/slurm-llnl/slurmctld.pid #SlurmctldPort=6817 SlurmdPidFile=/var/run/slurm-llnl/slurmd.pid #SlurmdPort=6818 SlurmdSpoolDir=/var/lib/slurm-llnl/slurmd SlurmUser=slurm #SlurmdUser=root StateSaveLocation=/var/lib/slurm-llnl/slurmctld SwitchType=switch/none TaskPlugin=task/none # # # TIMERS #KillWait=30 #MinJobAge=300 #SlurmctldTimeout=120 #SlurmdTimeout=300 # # # SCHEDULING FastSchedule=1 SchedulerType=sched/builtin #SchedulerPort=7321 SelectType=select/linear # # # LOGGING AND ACCOUNTING AccountingStorageType=accounting_storage/none #AccountingStoragePass=/var/run/munge/global.socket.2 ClusterName=workstation #&lt;YOUR-HOST-NAME&gt; #JobAcctGatherFrequency=30 JobAcctGatherType=jobacct_gather/none #SlurmctldDebug=3 SlurmctldLogFile=/var/log/slurm-llnl/slurmctld.log #SlurmdDebug=4 SlurmdLogFile=/var/log/slurm-llnl/slurmd.log # # # COMPUTE NODES NodeName=tian-609-06,tian-609-07,tian-609-08 CPUs=48 Sockets=2 CoresPerSocket=12 RealMemory=257731 ThreadsPerCore=2 State=IDLE PartitionName=debug Nodes=tian-609-06,tian-609-07,tian-609-08 Default=YES MaxTime=INFINITE State=UP 3、将/etc/hosts中配置对应的hostname和ip（所有机器） 4、开启slurm sudo systemctl enable slurmctld（控制节点tian-609-06） sudo service slurmctld start（控制节点tian-609-06） sudo systemctl enable slurmd（计算节点tian-609-[06-08]） sudo service slurmd start（计算节点tian-609-[06-08]） 5、将控制节点的/etc/munge/munge.key拷贝至其他机器相同目录，文件所属用户和用户组均为slurm 6、开启munge sudo /etc/init.d/munge start（所有节点） 7、查看slurm集群状态 &gt; sinfo PARTITION AVAIL TIMELIMIT NODES STATE NODELIST debug* up infinite 3 idle tian-609-[06-08] 8、执行命令（测试） &gt; srun -N 3 hostname tian-609-07 tian-609-08 tian-609-06","categories":[],"tags":[],"author":"张存"},{"title":"docker部署skywalking并接入java服务","slug":"docker部署skywalking并接入java服务","date":"2022-06-16T07:24:20.000Z","updated":"2022-06-16T07:47:57.339Z","comments":true,"path":"2022/06/16/docker-bu-shu-skywalking-bing-jie-ru-java-fu-wu/","link":"","permalink":"https://blog.zhangcun.store/2022/06/16/docker-bu-shu-skywalking-bing-jie-ru-java-fu-wu/","excerpt":"","text":"项目结构 制作docker-compose.yml并在控制台输入命令：docker-compose up -d (说明：-d代表在后台运行；保证端口9200/9300/8080/11800/12800未被占用；docker-compose没有设置networkt会自动以当前目录生成(xxx_default)，当前目录为skywalking即network=skywalking_default)，即可完成skywalking的制作。 version: &#39;2&#39; services: elasticsearch: image: elasticsearch:6.8.0 container_name: skywalking-es restart: always ports: - 9200:9200 - 9300:9300 environment: discovery.type: single-node TZ: Asia/Shanghai oap: image: apache/skywalking-oap-server:6.1.0 container_name: skywalking-oap depends_on: - elasticsearch links: - elasticsearch restart: always #前边为外网端口号,后边为容器应用端口号 ports: - 11800:11800 - 12800:12800 environment: # 设置时区 TZ: Asia/Shanghai ui: image: apache/skywalking-ui:6.4.0 container_name: skywalking-ui depends_on: - oap links: - oap restart: always ports: - 8080:8080 #设置环境,配置覆盖yml的配置 environment: collector.ribbon.listOfServers: oap:12800 security.user.admin.password: 123456 检查是否正确启动elasticsearch和skywalking 制作Dockerfile生成基础镜像给java服务使用，控制台命令输入：docker build -t centos.skywalking.base:0.0.1 . FROM centos:7 WORKDIR /app RUN yum install -y wget &amp;&amp; \\ yum install -y java-1.8.0-openjdk ADD http://mirrors.tuna.tsinghua.edu.cn/apache/skywalking/6.4.0/apache-skywalking-apm-6.4.0.tar.gz /app RUN tar -xf apache-skywalking-apm-6.4.0.tar.gz &amp;&amp; \\ mv apache-skywalking-apm-bin skywalking RUN ls /app java服务接入swalking(多个同理)，Dockerfile制作并在控制台输入： 1、docker build -t test:0.0.1 . 2、docker run -it -d --net skywalking_default -p 9812:9812 test:0.0.1 FROM centos.skywalking.base:0.0.1 COPY /target/app.jar /app/app.jar EXPOSE 9812 ENTRYPOINT java -javaagent:/app/skywalking/agent/skywalking-agent.jar -Dskywalking.agent.service_name=xxxtest -Dskywalking.collector.backend_service=172.19.0.3:11800 -Dserver.port=9812 -jar app.jar Dskywalking.agent.service_name=xxx 指定java服务名称 -Dserver.port=xxx 指定java服务启动端口 Dskywalking.collector.backend_service=xxx oap服务收集ip默认为127.0.0.1:11800 查看启动的oap服务容器的ip，命令：docker inspect skywalking-oap。以下的IPAddress即为oap服务ip","categories":[],"tags":[],"author":"张存"},{"title":"zabbix-get安装使用","slug":"zabbix-get安装使用","date":"2022-06-15T10:21:52.000Z","updated":"2022-06-15T10:24:08.196Z","comments":true,"path":"2022/06/15/zabbix-get-an-zhuang-shi-yong/","link":"","permalink":"https://blog.zhangcun.store/2022/06/15/zabbix-get-an-zhuang-shi-yong/","excerpt":"","text":"安装 一般在zabbix-server上安装，如果在其他机器上安装的话可能会无法访问agent rpm -ivh http://repo.zabbix.com/zabbix/3.2/rhel/7/x86_64/zabbix-release-3.2-1.el7.noarch.rpm yum install epel-release yum install zabbix-get 使用 agent编辑配置文件 在zabbix-agent机器上编辑/etc/zabbix_agentd.conf 增加一行 UserParameter=login-user1,who|wc -l 或者打开附属配置文件： 在/etc/zabbix/zabbix_agentd.d目录下新增test.conf 编辑test.conf并加入以下内容： UserParameter=login-user,uptime | awk -F &#39; &#39; &#39;&#123;print $6&#125;&#39; UserParameter=login-user2,uptime 以上两种方法都可以获得登录人数，现在为了测试，两种方法同时使用 然后重启zabbix-agent： systemctl restart zabbix-agent 执行zabbix_get命令 在zabbix-server上执行： zabbix_get -s 192.168.88.142 -p 10050 -k login-user zabbix_get -s 192.168.88.142 -p 10050 -k login-user1 zabbix_get -s 192.168.88.142 -p 10050 -k login-user2 | awk -F &#39; &#39; &#39;&#123;print $6&#125;&#39;","categories":[],"tags":[],"author":"张存"},{"title":"Nginx：配置静态资源304缓存","slug":"Nginx：配置静态资源304缓存","date":"2022-06-15T09:18:07.000Z","updated":"2022-06-15T09:18:36.033Z","comments":true,"path":"2022/06/15/nginx-pei-zhi-jing-tai-zi-yuan-304-huan-cun/","link":"","permalink":"https://blog.zhangcun.store/2022/06/15/nginx-pei-zhi-jing-tai-zi-yuan-304-huan-cun/","excerpt":"","text":"location ~ \\.(jpg|png|jpeg|gif)$ &#123; expires 30d; root /data/www/wizzer.cn/; &#125; location ~ \\.(js|css)$ &#123; expires 2h; root /data/www/wizzer.cn/; &#125;","categories":[],"tags":[],"author":"张存"},{"title":"zabbix 报错整理","slug":"zabbix-报错整理","date":"2022-06-15T09:11:58.000Z","updated":"2022-06-15T09:12:29.688Z","comments":true,"path":"2022/06/15/zabbix-bao-cuo-zheng-li/","link":"","permalink":"https://blog.zhangcun.store/2022/06/15/zabbix-bao-cuo-zheng-li/","excerpt":"","text":"1.first network error, wait for 15 seconds zabbix-server日志中： Zabbix agent item &quot;ITERM NAME&quot; on host &quot;HOSTNAME&quot; failed: first network error, wait for 15 seconds 在zabbix-server 的web界面，看到一个自定义iterm报错，报错内容 ZBX_NOTSUPPORTED: Timeout while executing a shell script. 然后我到服务器上手动执行这个自定义的UserParameter，看了一下执行的时间大概在6s左右。 但是，zabbix_server.conf的超时时间Timeout默认为4. 增大Timeout时间间隔。 Timeout=30 修改完配置文件重启zabbix-server后，notSupported的iterm become supportd了。然后日志中也不在把上述报错了。","categories":[],"tags":[],"author":"张存"},{"title":"NVIDIA驱动失效简单解决方案：NVIDIA-SMI has failed because it couldn‘t communicate with the NVIDIA driver.","slug":"NVIDIA驱动失效简单解决方案：NVIDIA-SMI-has-failed-because-it-couldn‘t-communicate-with-the-NVIDIA-driver","date":"2022-06-15T09:06:17.000Z","updated":"2022-06-15T09:09:59.334Z","comments":true,"path":"2022/06/15/nvidia-qu-dong-shi-xiao-jian-dan-jie-jue-fang-an-nvidia-smi-has-failed-because-it-couldn-t-communicate-with-the-nvidia-driver/","link":"","permalink":"https://blog.zhangcun.store/2022/06/15/nvidia-qu-dong-shi-xiao-jian-dan-jie-jue-fang-an-nvidia-smi-has-failed-because-it-couldn-t-communicate-with-the-nvidia-driver/","excerpt":"","text":"前言： 以下方法，不需要重装驱动，简单快捷。适用于Ubuntu系统下，之前已经安装过驱动，但驱动失效的问题。如果此方法仍然无法解决问题，可参考Ubuntu下安装nvidia显卡驱动，重装驱动。 前段时间刚装了驱动：Ubuntu下安装nvidia显卡驱动 但是最近准备用GPU跑模型时，提示cuda 不存在。前段时间刚装的驱动，怎么会不存在呢？ 第一步，打开终端，先用nvidia-smi查看一下，发现如下报错： NVIDIA-SMI has failed because it couldn&#39;t communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running. 第二步，使用nvcc -V检查驱动和cuda。 nvcc: NVIDIA (R) Cuda compiler driver Copyright (c) 2005-2018 NVIDIA Corporation Built on Sat_Aug_25_21:08:01_CDT_2018 Cuda compilation tools, release 10.0, V10.0.130 发现驱动是存在的，于是进行下一步 第三步，查看已安装驱动的版本信息 ls /usr/src | grep nvidia 1 比如我的驱动版本是：nvidia-450.57 第四步，依次输入以下命令 sudo apt-get install dkms sudo dkms install -m nvidia -v 450.57 等待安装完成后，再次输入nvidia-smi，查看GPU使用状态： 最后，我们熟悉的页面又回来了！问题得以解决！","categories":[],"tags":[],"author":"张存"},{"title":"CentOS7使用Yum命令安装中文语言包","slug":"CentOS7使用Yum命令安装中文语言包","date":"2022-06-15T08:56:57.000Z","updated":"2022-06-15T08:57:49.137Z","comments":true,"path":"2022/06/15/centos7-shi-yong-yum-ming-ling-an-zhuang-zhong-wen-yu-yan-bao/","link":"","permalink":"https://blog.zhangcun.store/2022/06/15/centos7-shi-yong-yum-ming-ling-an-zhuang-zhong-wen-yu-yan-bao/","excerpt":"","text":"检查已安装的语言包查看系统是否有安装中文语言包 （列出所有可用的公共语言环境的名称，包含有zh_CN） [root@localhost ~]# locale -a |grep &quot;zh_CN&quot; zh_CN zh_CN.gb18030 zh_CN.gb2312 zh_CN.gbk zh_CN.utf8 若发现以上几项，说明系统已安装中文语言包，无需再安装 {语言代号}_{国家代号}.{字符集} zh是中文的代号、CN是中国的代号、gb18030,gb2312,utf8是语言字符集 安装语言包 [root@localhost ~]# yum groupinstall &quot;fonts&quot; 配置使用语言包 [root@localhost ~]# cat /etc/locale.conf LANG=en_US.UTF-8 [root@localhost ~]# cp /etc/locale.conf /etc/locale.conf.bak [root@localhost ~]# vim /etc/locale.conf # 修改后原英文错误信息会变成中文信息 LANG=&quot;zh_CN.GB18030&quot; LANGUAGE=&quot;zh_CN.GB18030:zh_CN.GB2312:zh_CN&quot; SUPPORTED=&quot;zh_CN.UTF-8:zh_CN:zh:en_US.UTF-8:en_US:en&quot; SYSFONT=&quot;lat0-sun16&quot; [root@localhost ~]# localectl set-locale LANG=zh_CN.UTF-8 [root@localhost ~]# export.UTF8 # 将系统语言临时设置为中文，export方式不需要重新登录，或者直接reboot重启系统 [root@localhost ~]# echo $LANG # 查看当前使用的系统语言 zh_CN.UTF8","categories":[],"tags":[],"author":"张存"},{"title":"企业异地组网：docker-compose 搭建 openvpn","slug":"企业异地组网：docker-compose-搭建-openvpn","date":"2022-05-31T03:24:54.000Z","updated":"2022-05-31T06:41:27.795Z","comments":true,"path":"2022/05/31/qi-ye-yi-di-zu-wang-docker-compose-da-jian-openvpn/","link":"","permalink":"https://blog.zhangcun.store/2022/05/31/qi-ye-yi-di-zu-wang-docker-compose-da-jian-openvpn/","excerpt":"","text":"前言 因为总公司跟分公司不在同一个地区，需要构建一个虚拟局域网把两个公司的网络组合一起，达到网络互通的目的。对比一番后，选择选择了免费开源的openvpn的方案。本文介绍如何通过docker-compose 构建openvpn 实现企业异地组网。 特别说明，此方案的服务器必须有公网IP或者域名，如果都没有，可以先查一下内网穿透相关知识。 环境介绍 - 这里是列表文本服务端 CentOS 7.6 - 客户端 Windows 10 openvpn 目录 手动创建如下目录： image.png data 用于存放openvpn配置 client 存放生成客户端配置文件 docker-compose.yml version: &#39;2&#39; services: openvpn: container_name: openvpn image: kylemanna/openvpn volumes: - &quot;./data:/etc/openvpn&quot; ports: - &#39;1194:1194/udp&#39; cap_add: - NET_ADMIN restart: always privileged: true 配置openvpn # 请把后面的 udp 改成自己的网址 docker-compose run --rm openvpn ovpn_genconfig -u udp://vpn.nuomiphp.com # 生成密钥文件，输入密钥和CA名称 docker-compose run --rm openvpn ovpn_initpki # 启动服务 docker-compose up -d 如果需要更多定制配置： #生成配置文件 #-d 取消默认配置 -c 打开c2c模式 -u 指定当前IP #-s 划分服务器子网 -C 指定算法 docker-compose run --rm openvpn ovpn_genconfig -d -c -C &#39;AES-256-CBC&#39; -u udp://vpn.nuomiphp.com -s 192.168.1.0/24 用户操作 添加用户 1.生成证书 #生成一个叫test的用户，输入密钥 docker-compose run --rm openvpn easyrsa build-client-full test nopass or 如果生成的用户需要输入密码则把后面的nopass去掉： docker-compose run --rm openvpn easyrsa build-client-full test 2.导出test用户证书到client文件夹里 docker-compose run --rm openvpn ovpn_getclient test &gt; ./client/test.ovpn 删除用户 //删除用户证书 docker-compose run --rm openvpn easyrsa revoke user //更新证书数据库 docker-compose run --rm openvpn easyrsa gen-crl update-db //重启openvpn容器 docker restart openvpn 客户端下载及安装，此链接需要翻墙 https://openvpn.net/community-downloads/ 本文以windows客户端演示 1.启动客户端，选择FILE image.png 2.把刚才生成的./client/test.ovpn下载到本地，然后导入即可 优化改进 为了减少工作量，方便快速配置，可以使用如下两个增添用户的脚本。 OpenVPN 创建用户脚本： #!/bin/bash read -p &quot;please your username: &quot; NAME OVPN_DATA=&quot;openvpn-data&quot; LOCALIP=&quot;IP&quot; docker run -v $OVPN_DATA:/etc/openvpn --rm -it kylemanna/openvpn easyrsa build-client-full $NAME nopass docker run -v $OVPN_DATA:/etc/openvpn --rm kylemanna/openvpn ovpn_getclient $NAME &gt; /data/openvpn/conf/&quot;$NAME&quot;.ovpn #修改端口(可选) sed -i &quot;s/$LOCALIP 1194/$LOCALIP 1194/g&quot; /data/openvpn/conf/&quot;$NAME&quot;.ovpn #压缩(可选) echo &quot;comp-lzo&quot; &gt;&gt; /data/openvpn/conf/&quot;$NAME&quot;.ovpn docker restart openvpn echo &quot;CA saved to /data/openvpn/conf/$NAME.ovpn&quot; OpenVPN 删除用户脚本，次基本基于docker，需要自行改造成docker-compose： #!/bin/bash read -p &quot;Delete username: &quot; DNAME OVPN_DATA=&quot;openvpn-data&quot; docker run -v $OVPN_DATA:/etc/openvpn --rm -it kylemanna/openvpn easyrsa revoke $DNAME docker run -v $OVPN_DATA:/etc/openvpn --rm -it kylemanna/openvpn easyrsa gen-crl docker run -v $OVPN_DATA:/etc/openvpn --rm -it kylemanna/openvpn rm -f /etc/openvpn/pki/reqs/&quot;$DNAME&quot;.req docker run -v $OVPN_DATA:/etc/openvpn --rm -it kylemanna/openvpn rm -f /etc/openvpn/pki/private/&quot;$DNAME&quot;.key docker run -v $OVPN_DATA:/etc/openvpn --rm -it kylemanna/openvpn rm -f /etc/openvpn/pki/issued/&quot;$DNAME&quot;.crt #删除相关用户conf(可选) docker run -v $OVPN_DATA:/etc/openvpn --rm -it kylemanna/openvpn rm -f /data/openvpn/conf/&quot;$DNAME&quot; docker restart openvpn echo &quot;Deleted $DNAME","categories":[],"tags":[],"author":"张存"},{"title":"zabbix命令之：zabbix_get命令","slug":"zabbix命令之：zabbix-get命令","date":"2022-05-31T03:09:12.000Z","updated":"2022-05-31T03:09:42.859Z","comments":true,"path":"2022/05/31/zabbix-ming-ling-zhi-zabbix-get-ming-ling/","link":"","permalink":"https://blog.zhangcun.store/2022/05/31/zabbix-ming-ling-zhi-zabbix-get-ming-ling/","excerpt":"","text":"zabbix_get命令是在server端用来检查agent端的一个命令，在添加完主机或者触发器后，不能正常获得数据，可以用zabbix_get来检查能否采集到数据，以便判断问题症结所在。 zabbix_get 参数说明： -s --host： 指定客户端主机名或者IP -p --port：客户端端口，默认10050 -I --source-address：指定源IP，写上zabbix server的ip地址即可，一般留空，服务器如果有多ip的时候，你指定一个。 -k --key：你想获取的key 至于使用长参数还是短的，自己选，我经常使用-s而不是-host， 如果不知道key参数可以使用 zabbix_agentd -p 寻找自己想要找的参数 [root@host~]# zabbix_agentd -p | grep system.cpu.load system.cpu.load[all,avg1] [d|0.040000] 如果不知道zabbix_get在什么路径，可以使用find / -name zabbix_get查找 [root@host ~]# find / -name zabbix_get /usr/local/zabbix/bin/zabbix_get /data/tools/zabbix-4.0.3/src/zabbix_get /data/tools/zabbix-4.0.3/src/zabbix_get/zabbix_get 案例： [root@zabbix ~]# zabbix_get -s 192.168.1.7 -p 10050 -k system.cpu.load[all,avg1] 0.000000","categories":[],"tags":[],"author":"张存"},{"title":"docker-compose部署ELK","slug":"docker-compose部署ELK-1","date":"2022-05-31T03:01:25.000Z","updated":"2022-05-31T03:06:44.686Z","comments":true,"path":"2022/05/31/docker-compose-bu-shu-elk-1/","link":"","permalink":"https://blog.zhangcun.store/2022/05/31/docker-compose-bu-shu-elk-1/","excerpt":"","text":"kibana.yml [root@topcheer config]# cat kibana.yml server.host: &quot;0.0.0.0&quot; elasticsearch.url: http://elasticsearch01:9200 xpack: apm.ui.enabled: false graph.enabled: false ml.enabled: false monitoring.enabled: false reporting.enabled: false security.enabled: false grokdebugger.enabled: false searchprofiler.enabled: false [root@topcheer config]# logstash的conf [root@topcheer pipeline]# cat logstash-test.conf input &#123; file &#123; path =&gt; [&quot;/usr/share/logstash/pipeline/logs/test.log&quot;] start_position =&gt; &quot;beginning&quot; &#125; &#125; output &#123; elasticsearch &#123; hosts =&gt; [&quot;elasticsearch01:9200&quot;] &#125; &#125; [root@topcheer pipeline]# 别的配置都没有变，然后新增docker-compose.yml [root@topcheer config]# cat docker-compose.yml version: &#39;2&#39; services: elasticsearch01: #服务名称（不是容器名,名称最好不要含有特殊字符，碰到过用下划线时运行出错） image: docker.elastic.co/elasticsearch/elasticsearch:6.4.3 container_name: elasticsearch01 #容器名称 volumes: #挂载文件 - ./elasticsearch/logs/:/usr/share/logs/ - /elk/config/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml:ro ports: - &quot;9200:9200&quot; #暴露的端口信息和docker run -d -p 80:80一样 - &quot;9300:9300&quot; environment: #设置镜像变量，它可以保存变量到镜像里面 ES_JAVA_OPTS: &quot;-Xmx512m -Xms512m&quot; networks: #加入指定网络 - elk logstash_test: image: docker.elastic.co/logstash/logstash:6.4.3 container_name: logstash01 volumes: - /elk/config/logstash/config/:/usr/share/logstash/config/:ro - /elk/config/logstash/pipeline/:/usr/share/logstash/pipeline/ ports: - &quot;5044:5044&quot; - &quot;9600:9600&quot; environment: LS_JAVA_OPTS: &quot;-Xmx512m -Xms512m&quot; networks: - elk depends_on: #标签解决了容器的依赖、启动先后的问题 - elasticsearch01 kibana_test: image: docker.elastic.co/kibana/kibana:6.4.3 container_name: kibana01 volumes: - /elk/config/kibana.yml:/usr/share/kibana/config/kibana.yml ports: - &quot;5601:5601&quot; networks: - elk depends_on: - elasticsearch01 networks: elk: driver: bridge [root@topcheer config]# 然后执行docker-compose up -d [root@topcheer config]# docker-compose ps Name Command State Ports --------------------------------------------------------------------------------------------------------- elasticsearch01 /usr/local/bin/docker-entr ... Up 0.0.0.0:9200-&gt;9200/tcp, 0.0.0.0:9300-&gt;9300/tcp kibana01 /usr/local/bin/kibana-docker Up 0.0.0.0:5601-&gt;5601/tcp logstash01 /usr/local/bin/docker-entr ... Up 0.0.0.0:5044-&gt;5044/tcp, 0.0.0.0:9600-&gt;9600/tcp","categories":[],"tags":[],"author":"张存"},{"title":"linux中监控CPU、内存和磁盘状态的shell脚本。（centos7）","slug":"linux中监控CPU、内存和磁盘状态的shell脚本。（centos7）","date":"2022-05-30T03:33:41.000Z","updated":"2022-05-30T03:37:01.109Z","comments":true,"path":"2022/05/30/linux-zhong-jian-kong-cpu-nei-cun-he-ci-pan-zhuang-tai-de-shell-jiao-ben-centos7/","link":"","permalink":"https://blog.zhangcun.store/2022/05/30/linux-zhong-jian-kong-cpu-nei-cun-he-ci-pan-zhuang-tai-de-shell-jiao-ben-centos7/","excerpt":"","text":"这篇博客中所写的脚本，在实际工作中并没有什么卵用，工作中并不会用到这种脚本去监控。不过自己写一遍，可以让初学者对CPU、内存、磁盘等一些基础知识和基础命令更加了解。 1、利用vmstat工具监控CPU详细信息，然后基于/proc/stat计算CPU利用率进行监控，超过80报警并提取出占用cpu最高的前十进程。 vmstat是Linux系统监控工具，使用vmstat命令可以得到关于进程、内存、内存分页、堵塞IO、traps及CPU活动的信息。 r：运行队列中的进程数；b：等待IO的进程数。 swpd：已用虚拟内存大小（k）；free：空闲内存大小；buff：已用缓冲大小；cache：已用缓存大小。 si：每秒从交换区写入内存的大小（kb/s）；so：每秒从内存写入交换分区的大小。 bi：每秒读取的块数；bo每秒写入的块数。 in：每秒中断数，包括时钟中断；cs：每秒上下文切换数。 us(user time)：用户进程执行消耗cpu时间；sy(system time)：系统进程执行消耗cpu时间；id：空闲时间（包括IO等待时间）；wa：等待IO时间。 /proc/stat： 这个文件包含了所有CPU活动的信息，该文件中的所有值都是从系统启动开始累计到当前时刻。可以利用其中信息计算cpu的利用率。 每行每个参数的意思为（以第一行为例，单位：jiffies，1jiffies=0.01秒）： user（62124）：从系统启动开始累计到当前时刻，用户态的CPU时间，不包含 nice值为负进程。 nice（11）：从系统启动开始累计到当前时刻。 system（47890）：从系统启动开始累计到当前时刻，nice值为负的进程所占用的CPU时间。 idle（8715270）：从系统启动开始累计到当前时刻，除硬盘IO等待时间以外其它等待时间。 iowait（84729）：从系统启动开始累计到当前时刻，硬盘IO等待时间。 irq（0）：从系统启动开始累计到当前时刻，硬中断时间。 softirq（1483）：从系统启动开始累计到当前时刻，软中断时间。 CPU时间=user+nice+system+idle+iowait+irq+softirq。 CPU利用率=(idle2-idle1)/(cpu2-cpu1)*100。 ps aux： 显示其他用户启动的进程（a） 查看系统中属于自己的进程（x） 启动这个进程的用户和启动时间 （u） 代码如下： 复制代码 #!/bin/bash # CPU_us=$(vmstat | awk &#39;&#123;print $13&#125;&#39; | sed -n &#39;$p&#39;) CPU_sy=$(vmstat | awk &#39;&#123;print $14&#125;&#39; | sed -n &#39;$p&#39;) CPU_id=$(vmstat | awk &#39;&#123;print $15&#125;&#39; | sed -n &#39;$p&#39;) CPU_wa=$(vmstat | awk &#39;&#123;print $16&#125;&#39; | sed -n &#39;$p&#39;) CPU_st=$(vmstat | awk &#39;&#123;print $17&#125;&#39; | sed -n &#39;$p&#39;) CPU1=`cat /proc/stat | grep &#39;cpu &#39; | awk &#39;&#123;print $2&quot; &quot;$3&quot; &quot;$4&quot; &quot;$5&quot; &quot;$6&quot; &quot;$7&quot; &quot;$8&#125;&#39;` sleep 5 CPU2=`cat /proc/stat | grep &#39;cpu &#39; | awk &#39;&#123;print $2&quot; &quot;$3&quot; &quot;$4&quot; &quot;$5&quot; &quot;$6&quot; &quot;$7&quot; &quot;$8&#125;&#39;` IDLE1=`echo $CPU1 | awk &#39;&#123;print $4&#125;&#39;` IDLE2=`echo $CPU2 | awk &#39;&#123;print $4&#125;&#39;` CPU1_TOTAL=`echo $CPU1 | awk &#39;&#123;print $1+$2+$3+$4+$5+$6+$7&#125;&#39;` CPU2_TOTAL=`echo $CPU2 | awk &#39;&#123;print $1+$2+$3+$4+$5+$6+$7&#125;&#39;` IDLE=`echo &quot;$IDLE2-$IDLE1&quot; | bc` CPU_TOTAL=`echo &quot;$CPU2_TOTAL-$CPU1_TOTAL&quot; | bc` #echo -e &quot;IDLE2:$IDLE2\\nIDLE1:$IDLE1\\nCPU2:$CPU2_TOTAL\\nCPU1:$CPU1_TOTAL&quot; #echo -e &quot;IDLE:$IDLE\\nCPU:$CPU_TOTAL&quot; RATE=`echo &quot;scale=4;($CPU_TOTAL-$IDLE)/$CPU_TOTAL*100&quot; | bc | awk &#39;&#123;printf &quot;%.2f&quot;,$1&#125;&#39;` echo -e &quot;us=$CPU_us\\tsy=$CPU_sy\\tid=$CPU_id\\twa=$CPU_wa\\tst=$CPU_st&quot; echo &quot;CPU_RATE:$&#123;RATE&#125;%&quot; CPU_RATE=`echo $RATE | cut -d. -f1` #echo &quot;CPU_RATE:$CPU_RATE&quot; if [ $CPU_RATE -ge 80 ] then echo &quot;CPU Warn&quot; ps aux | grep -v USER | sort -rn -k3 | head fi 复制代码 2、利用free工具监控内存利用率，超过80报警并提取出占用内存最高的前十进程。 代码如下： 复制代码 #!/bin/bash # total=$(free -m | sed -n &#39;2p&#39; | awk &#39;&#123;print $2&#125;&#39;) used=$(free -m | sed -n &#39;2p&#39; | awk &#39;&#123;print $3&#125;&#39;) free=$(free -m | sed -n &#39;2p&#39; | awk &#39;&#123;print $4&#125;&#39;) shared=$(free -m | sed -n &#39;2p&#39; | awk &#39;&#123;print $5&#125;&#39;) buff=$(free -m | sed -n &#39;2p&#39; | awk &#39;&#123;print $6&#125;&#39;) cached=$(free -m | sed -n &#39;2p&#39; | awk &#39;&#123;print $7&#125;&#39;) rate=`echo &quot;scale=2;$used/$total&quot; | bc | awk -F. &#39;&#123;print $2&#125;&#39;` echo -e &quot;total\\tused\\tfree\\tshared\\tbuffer\\tavailable&quot; echo -e &quot;$&#123;total&#125;M\\t$&#123;used&#125;M\\t$&#123;free&#125;M\\t$&#123;shared&#125;M\\t$&#123;buff&#125;M\\t$&#123;cached&#125;M\\nrate:$&#123;rate&#125;%&quot; if [ $rate -ge 80 ] then echo &quot;Memory Warn&quot; ps aux | grep -v USER | sort -rn -k4 | head fi 复制代码 3、利用df命令监控磁盘利用率，超过80报警。 df ：显示磁盘分区上的可使用的磁盘空间。 -h 以更易读的方式显示； -P 使用POSIX的输出格式。 复制代码 #!/bin/bash # DEV=`df -hP | grep &#39;^/dev/*&#39; | cut -d&#39; &#39; -f1 | sort` for I in $DEV do dev=`df -Ph | grep $I | awk &#39;&#123;print $1&#125;&#39;` size=`df -Ph | grep $I | awk &#39;&#123;print $2&#125;&#39;` used=`df -Ph | grep $I | awk &#39;&#123;print $3&#125;&#39;` free=`df -Ph | grep $I | awk &#39;&#123;print $4&#125;&#39;` rate=`df -Ph | grep $I | awk &#39;&#123;print $5&#125;&#39;` mount=`df -Ph | grep $I | awk &#39;&#123;print $6&#125;&#39;` echo -e &quot;$I:\\tsize:$size\\tused:$used\\tfree:$free\\trate:$rate\\tmount:$mount&quot; F=`echo $rate | awk -F% &#39;&#123;print $1&#125;&#39;` if [ $F -ge 80 ]；then echo &quot;$mount Warn&quot; else echo &quot;It&#39;s OK&quot; fi done 复制代码 CPU物理信息 查看物理cpu个数： cat /proc/cpuinfo | grep &quot;physical id&quot; | uniq | wc -l 查看cpu核数： cat /proc/cpuinfo | grep &quot;cpu cores&quot; | uniq 查看逻辑cpu个数： cat /proc/cpuinfo | grep &quot;processor&quot; | wc -l","categories":[],"tags":[],"author":"张存"},{"title":"win10开启多用户同时远程登录","slug":"win10开启多用户同时远程登录","date":"2022-05-30T03:24:27.000Z","updated":"2022-05-30T03:24:29.174Z","comments":true,"path":"2022/05/30/win10-kai-qi-duo-yong-hu-tong-shi-yuan-cheng-deng-lu/","link":"","permalink":"https://blog.zhangcun.store/2022/05/30/win10-kai-qi-duo-yong-hu-tong-shi-yuan-cheng-deng-lu/","excerpt":"","text":"https://blog.csdn.net/Perfect886/article/details/118526972","categories":[],"tags":[],"author":"张存"},{"title":"docker-compose 部署 jenkins","slug":"docker-compose-部署-jenkins","date":"2022-05-19T13:14:08.000Z","updated":"2022-05-19T13:15:20.120Z","comments":true,"path":"2022/05/19/docker-compose-bu-shu-jenkins/","link":"","permalink":"https://blog.zhangcun.store/2022/05/19/docker-compose-bu-shu-jenkins/","excerpt":"","text":"一. docker-compose.yaml version: &#39;3&#39; services: jenkins: image: &#39;jenkinsci/blueocean&#39; container_name: jenkins restart: always ports: - &#39;8099:8080&#39; - &#39;50000:50000&#39; volumes: - &#39;/var/jenkins_home:/var/jenkins_home&#39; 二. 命令 同目录下执行 docker-compose up -d 三. 问题 3.1 jenkinsci/blueocean与jenkins/jenkins区别 jenkinsci/blueocean image(来自 the Docker Hub repository)。 该镜像包含当前的长期支持 (LTS) 的Jenkins版本 （可以投入使用） ，捆绑了所有Blue Ocean插件和功能。这意味着你不需要单独安装Blue Ocean插件。（推荐） jenkins/jenkins 只包含基础的镜像，需要自己手动去安装插件，可理解为基础版本。 3.2 权限问题/var/jenkins_home 没权限 执行如下指令，对宿主机目录进行授权 chown -R 1000:1000 /var/jenkins_home (或者自定义一个路径) 3.3 初始化账户密码 在上面目录中寻找/secrets/initialAdminPassword文件，查看其中密码即可","categories":[],"tags":[],"author":"张存"},{"title":"禁止用户使用 sudo su 命令进入root 模式","slug":"禁止用户使用-sudo-su-命令进入root-模式","date":"2022-05-19T08:10:54.000Z","updated":"2022-05-19T08:11:04.814Z","comments":true,"path":"2022/05/19/jin-zhi-yong-hu-shi-yong-sudo-su-ming-ling-jin-ru-root-mo-shi/","link":"","permalink":"https://blog.zhangcun.store/2022/05/19/jin-zhi-yong-hu-shi-yong-sudo-su-ming-ling-jin-ru-root-mo-shi/","excerpt":"","text":"1. 修改 /etc/sudoers 的权限, 用来写入文件 # chmod 777 /etc/sudoers 2. 修改sudo 可以执行的命令 vim /etc/sudoers # 打开 sudo 控制文件 apuser ALL=(ALL:ALL) ALL,!/bin/su # 在文件结尾, 追加此内容 :wq # 保存并退出 ! 取反的意思 追加的内容意思就是所有用户, 所有组都不允许使用 /bin/su 命令 如果想要普通用户, 使用指定的命令就直接使用 &quot;,&quot; 分割 在 &quot;!/bin/su&quot; 后面追加即可 如果不想让普通用户使用, 只需要在指定命令的开头写入 ! 取反即可 写入命令时必须写绝对路径 3. 将文件的权限修改回来 # chmod 0440 /etc/sudoers","categories":[],"tags":[],"author":"张存"},{"title":"ubuntu远程利用邮箱客户端发送邮件","slug":"ubuntu远程利用邮箱客户端发送邮件","date":"2022-05-19T08:08:38.000Z","updated":"2022-05-19T08:09:46.974Z","comments":true,"path":"2022/05/19/ubuntu-yuan-cheng-li-yong-you-xiang-ke-hu-duan-fa-song-you-jian/","link":"","permalink":"https://blog.zhangcun.store/2022/05/19/ubuntu-yuan-cheng-li-yong-you-xiang-ke-hu-duan-fa-song-you-jian/","excerpt":"","text":"添加软件源并安装 部分软件库缺失这个软件，阿里云的库里面有，添加源 sudo vim /etc/apt/sources.list # 打开源地址列表 deb http://cz.archive.ubuntu.com/ubuntu xenial main universe # 在文件末端添加此行，添加阿里云软件源 sudo apt update # 更新库 sudo apt install heirloom-mailx -y # 安装heirloom-mailx 配置 vim /etc/s-nail.rc # 在最后加上： set from=&quot;xxxxx@163.com&quot; #发件地址 set smtp=&quot;smtp.163.com&quot; #smtp服务器 set smtp-auth-user=&quot;xxxxxx@163.com&quot; #登录发件地址 set smtp-auth-password=&quot;xxxx&quot; #授权码 set smtp-auth=login #登录方式，默认是login，也可以改成CRAM-MD5或PLAIN方式 常用的设置 n：不读入设置文件(本系统中是/etc/s-nail.rc)（这个文件允许用户使用外部邮件传输代理而不是使用系统自带的sendmail发送邮件）。 s：设置邮件的主题信息。 c：使用一个抄送列表。 b：使用一个密送列表。 echo &quot;内容&quot;|s-nail -s &quot;主题&quot; xxxx@163.com,xxxx@outlook.com #多个邮箱用逗号隔开 #或者： s-nail -s &quot;邮件主题&quot; xxx@163.com &lt; result.txt ps:加参数v可以看到mail输出的详细信息 s-nail -vs &quot;邮件主题&quot; xxx@163.com &lt; result.txt #发送带附件邮件 s-nail -a 附件 -s &quot;主题&quot; 收件地址 &lt; 文件(邮件正文.txt) s-nail -a /xxx.tar.gz -s &quot;主题&quot; xxx@163.com &lt; ./xxx.txt #shell 当编辑器,编辑完内容后按Ctrl-D结束 s-nail -s &#39;主题‘ xxx@163.com","categories":[],"tags":[],"author":"张存"},{"title":"linux限制普通用户命令,sudo 限制普通用户权限(示例代码)","slug":"linux限制普通用户命令-sudo-限制普通用户权限-示例代码","date":"2022-05-19T08:07:13.000Z","updated":"2022-05-19T08:07:46.362Z","comments":true,"path":"2022/05/19/linux-xian-zhi-pu-tong-yong-hu-ming-ling-sudo-xian-zhi-pu-tong-yong-hu-quan-xian-shi-li-dai-ma/","link":"","permalink":"https://blog.zhangcun.store/2022/05/19/linux-xian-zhi-pu-tong-yong-hu-ming-ling-sudo-xian-zhi-pu-tong-yong-hu-quan-xian-shi-li-dai-ma/","excerpt":"","text":"限制用户sudo所能执行的命令 linux是多用户多任务的分时操作系统,共享该系统的用户往往不只一个。 但由于root账户密码的敏感性和root账号的无限制权限, 有必要通过useradd创建一些普通用户, 只让他们拥有不完全的权限; 如有必要，再来申请执行一些root权限的指令。 sudo就是来解决这个需求的。 sudo命令的执行流程是: 当前用户转换到root, 然后以root身份执行命令, 执行完成后, 直接退回到当前用户. 需要注意的是: 执行sudo时输入的密码, 是当前用户的密码, 并非root密码. 赋予用户sudo操作的权限 [[email protected] ~]# visudo #在99行下面添加以下内容 zhang ALL=(ALL) ALL #如果是命令使用下面的方式：zhang ALL=(ALL) /bin/touch(多个权限用“，”分开，ALL所有权限，NOPASSWD: ALL免密码) 注： 一般常用sudo命令来临时获得root权限执行一些特权命令。这很方便，但是也有一个问题： 普通用户可以通过sudo命令完成用户的增删和密码的更改，甚至是对root用户的密码更改！！！ 如： [email protected]$:sudo passwd root Input the new UNIX pass word: 这样就可以直接越过root直接修改root的密码。这是非常危险的。 解决办法 1、 groupadd admin 创建一个admin用户组，后边在设置权限时会用到 2、usermod -a -G admin [用户] 将用户添加到admin组 3、在这里可以通过 /etc/sudoers 文件限制 $:sudo visudo 注意，这命令在最后修改sudoers文件中，也要加以限制，否则还可以通过这个命令恢复。 在这个文件中修改默认的以下两行： %admin ALL=(ALL) ALL %sudo ALL=(ALL) ALL 为以下： %admin ALL=/usr/sbin/,/sbin/,/usr/bin/,!/usr/bin/passwd,!/usr/sbin/visudo,!/usr/sbin/useradd,!/usr/sbin/userdel %sudo ALL=/usr/sbin/,/sbin/,/usr/bin/,!/usr/bin/passwd,!/usr/sbin/visudo,!/usr/sbin/useradd,!/usr/sbin/userdel","categories":[],"tags":[],"author":"张存"},{"title":"vim的补充及文件输入输出管理","slug":"vim的补充及文件输入输出管理","date":"2022-05-19T08:04:08.000Z","updated":"2022-05-19T08:05:55.689Z","comments":true,"path":"2022/05/19/vim-de-bu-chong-ji-wen-jian-shu-ru-shu-chu-guan-li/","link":"","permalink":"https://blog.zhangcun.store/2022/05/19/vim-de-bu-chong-ji-wen-jian-shu-ru-shu-chu-guan-li/","excerpt":"","text":"一、vim的功能补充 1.可视化操作 a、在vim中不能使用鼠标框选，若要操作某一区域，需要进入可视化模式（ctrl+v），按上|下|左|右操作即可 b、可视化模式下批量添加字符 将光标停在所要操作的行的第1列---&gt;移动光标选择要添加字符的列---&gt;“I”进入插入模式---&gt;编辑要插入的字符 ---&gt;&quot;ESC&quot;退出即可添加成功 2.vim中字符的替换 %s/word1/word2/g ##全文将word1替换成word2 2，15s/word1/word2/g ##在2-15行之间将word1替换成word2 g ##全文替换，没有g表示只替换每行的第一个 例：将1-10行中的bin全部替换成hello，使用1，10s/bin/hello/g，更改前如下： 更改后如下： 3.vim中字符的查找 /关键字 ##全文匹配关键字 n ##向下匹配关键字 N ##向上匹配关键字 例：匹配关键字：/sbin 4.vim中光标的移动 G ##快速移动到最后一行 ：n ##快速移动到第n行 gg ##快速移动到第一行 5.vim中同时编辑多个文件 ：sp filename ##同一vim下打开新文件 ：ctrl+w 上 ##光标进入上面窗口编辑 ：ctrl+w 下 ##光标进入下面窗口编辑 6.插入模式 i ##在光标所在位置插入字符 I ##在光标所在行行首插入字符 o ##在光标所在行的下一行插入字符 O ##在光标所在行的上一行插入字符 s ##删除光标所在字符并插入字符 S ##删除光标所在行并插入字符 a ##在光标所在字符的下一个字符处插入字符 A ##在光标所在行行尾插入字符 7.退出模式 ：q ##对文件不做任何操作，退出 ：q！ ##对文件内容有操作，但不保存退出 ：wq ##对文件保存并退出 ：wq！ ##强制对文件保存退出，只针对root用户或文件所有人生效 ：w filename ##相当于另存新件 ：ZZ ##对文件有操作，保存退出；对文件没有操作，直接退出 二、文件输入输出管理 1.输入输出的定义 输入：用鼠标、键盘等硬件在系统中录入的字符 输出：系统接受到功能字符，经过进程处理产生的字符 注意：系统输出结果有两种：编号1的正确输出和编号2的错误输出，输出结果被系统默认输出到字符设备 2.如何管理输出 a、非交互式多行录入 例如运行程序，自动更改密码 b、重定向输出 &gt; ##重定向正确输出 2&gt; ##重定向错误输出 &amp;&gt; ##重定向所有输出 2&gt;&amp;1 #把错误输出转换为正确输出 c、追加 注意：重定向会覆盖原文件，若在原文件后追加，使用以下命令 &gt;&gt; ##追加正确输出 2&gt;&gt; ##追加错误输出 &amp;&gt;&gt; ##追加所有输出 d、管道命令 管道符 | ##只有编号为1的输出（即正确输出）可通过管道 注意：管道符将输入变为输出，但不会保存！如需要保存，使用以下命令 输出结果 | tee filename","categories":[],"tags":[],"author":"张存"},{"title":"Linux禁止普通用户使用某些命令","slug":"Linux禁止普通用户使用某些命令","date":"2022-05-17T16:10:10.000Z","updated":"2022-05-17T16:12:27.446Z","comments":true,"path":"2022/05/18/linux-jin-zhi-pu-tong-yong-hu-shi-yong-mou-xie-ming-ling/","link":"","permalink":"https://blog.zhangcun.store/2022/05/18/linux-jin-zhi-pu-tong-yong-hu-shi-yong-mou-xie-ming-ling/","excerpt":"","text":"1.例如xiaowei这个普通用户禁止使用rm命令怎么实现。 默认情况下普通用户都是有rm命令权限的，我看到这个第一也是想到了利用visudo来做，但是没有实现，且这个用户是已经存在的用户，尝试一会儿没有实现。后面又想到了setfacl这个命令，实现过程如下： 首先在CentOS7中/bin 目录是/usr/bin的快捷方式，这里设置一个就可以了 ①找到rm命令的位置 [root@db01 ~]# which rm alias rm=&#39;rm -i&#39; /usr/bin/rm ②设置特殊权限 [root@db01 ~]# setfacl -m u:xiaowei:r /usr/bin/rm ③用普通用户xiaowei登录测试，rm命令已经不能使用了 [root@db01 ~]# su - xiaowei Last login: Tue Jan 26 19:10:09 CST 2021 from 10.0.0.1 on pts/2 [xiaowei@db01 ~]$ touch a.txt [xiaowei@db01 ~]$ rm a.txt -bash: /bin/rm: Permission denied [xiaowei@db01 ~]$ \\rm a.txt -bash: /bin/rm: Permission denied 另外假设要排除的命令很多，这种方法有点不适用，visudo应该能实现，后续再补上。","categories":[],"tags":[],"author":"张存"},{"title":"docker-compose运行elasticsearch+elastichd","slug":"docker-compose运行elasticsearch-elastichd","date":"2022-05-17T16:04:05.000Z","updated":"2022-05-17T16:05:09.428Z","comments":true,"path":"2022/05/18/docker-compose-yun-xing-elasticsearch-elastichd/","link":"","permalink":"https://blog.zhangcun.store/2022/05/18/docker-compose-yun-xing-elasticsearch-elastichd/","excerpt":"","text":"ersion: &#39;3&#39; ervices: elasticsearch: image: elasticsearch:7.5.1 container_name: elasticsearch networks: - net-es volumes: - ./data/:/usr/share/elasticsearch/data #这里将elasticsearch的数据文件映射本地，以保证下次如果删除了容器还有数据 environment: - discovery.type=single-node ports: - &quot;9200:9200&quot; elastichd: image: containerize/elastichd:latest container_name: elasticsearch-hd networks: - net-es ports: - &quot;9800:9800&quot; depends_on: - &quot;elasticsearch&quot; links: - &quot;elasticsearch:demo&quot; 这里要注意，es和eshd要在相同网络才能被links etworks: net-es: external: false 安装ik分词器 ./bin/elasticsearch-plugin install https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v7.5.1/elasticsearch-analysis-ik-7.5.1.zip 查看容器ip docker inspect elasticsearch | grep IPAddress","categories":[],"tags":[],"author":"张存"},{"title":"mysqldump 导出提示Couldn't execute SELECT COLUMN_NAME...","slug":"mysqldump-导出提示Couldn-t-execute-SELECT-COLUMN-NAME","date":"2022-05-17T16:01:51.000Z","updated":"2022-05-17T16:02:07.649Z","comments":true,"path":"2022/05/18/mysqldump-dao-chu-ti-shi-couldn-t-execute-select-column-name/","link":"","permalink":"https://blog.zhangcun.store/2022/05/18/mysqldump-dao-chu-ti-shi-couldn-t-execute-select-column-name/","excerpt":"","text":"mysqldump 导出提示Couldn’t execute SELECT COLUMN_NAME… mysqldump命令： 导出数据库：mysqldump -h ip -u root -p dbname &gt; db.sql; 导出数据库中的某个表：mysqldump -h ip -u root -p dbname tablename &gt; tablename.sql; 错误提示： mysqldump: Couldn&#39;t execute &#39;SELECT COLUMN_NAME, JSON_EXTRACT(HISTOGRAM, &#39;$.&quot;number-of-buckets-specified&quot;&#39;) FROM information_schema.COLUMN_STATISTICS 原因： 因为新版的mysqldump默认启用了一个新标志，通过- -column-statistics=0来禁用他 解决方法： mysqldump --column-statistics=0 -h ip -u root -p dbname &gt; db.sql;","categories":[],"tags":[],"author":"张存"},{"title":"使用 docker 搭建 openvpn，创建、删除用户证书","slug":"使用-docker-搭建-openvpn，创建、删除用户证书","date":"2022-05-17T15:37:06.000Z","updated":"2022-05-17T15:43:40.761Z","comments":true,"path":"2022/05/17/shi-yong-docker-da-jian-openvpn-chuang-jian-shan-chu-yong-hu-zheng-shu/","link":"","permalink":"https://blog.zhangcun.store/2022/05/17/shi-yong-docker-da-jian-openvpn-chuang-jian-shan-chu-yong-hu-zheng-shu/","excerpt":"","text":"我自己的配置，服务器：ubuntu16.04 + docker 17.12.0-ce；客户端：win10 + openvpn2.4.5 1 在 dockerhub 上搜索 openvpn， 2 在 terminal 配置环境变量，Pick a name for the $OVPN_DATA data volume container，输入以下命令 export OVPN_DATA=openvpn_data 3 创建一个数据卷存储配置文件和证书等文件 docker volume create --name $OVPN_DATA 4 Initialize the $OVPN_DATA container that will hold the configuration files and certificates. The container will prompt for a passphrase to protect the private key used by the newly generated certificate authority. 初始化配置文件到数据卷中。 //docker run -v $OVPN_DATA:/etc/openvpn --rm kylemanna/openvpn ovpn_genconfig -u udp://VPN.SERVERNAME.COM //VPN.SERVERNAME.COM 表示openvpn服务器的ip地址，使用udp协议 docker run -v $OVPN_DATA:/etc/openvpn --rm kylemanna/openvpn ovpn_genconfig -u udp://140.143.167.220 初始化配置，并保存授权密码 docker run -v $OVPN_DATA:/etc/openvpn --rm -it kylemanna/openvpn ovpn_initpki 5 开启 openvpn 容器 docker run -v $OVPN_DATA:/etc/openvpn -d -p 1194:1194/udp --cap-add=NET_ADMIN --name=openvpn kylemanna/openvpn 6 生成用户证书，如果需要生成多个用户证书可以执行多次该命令 //不需要密码，如果需要用户连接时输入密码将最后的 nopass 去掉 //docker run -v $OVPN_DATA:/etc/openvpn --rm -it kylemanna/openvpn easyrsa build-client-full CLIENTNAME nopass docker run -v $OVPN_DATA:/etc/openvpn --rm -it kylemanna/openvpn easyrsa build-client-full tencent nopass 说明：安全做法应该加上访问密码，用户连接时输入密码比较安全。防止证书被盗后随意链接。用法如下 docker run -v $OVPN_DATA:/etc/openvpn --rm -it kylemanna/openvpn easyrsa build-client-full tencent Generating a 2048 bit RSA private key ................................................................................................................................................................................................................+++ ................................................................................+++ writing new private key to &#39;/etc/openvpn/pki/private/tencent.key.XXXXBFnjfh&#39; Enter PEM pass phrase: //用户连接密码 Verifying - Enter PEM pass phrase: ----- Using configuration from /usr/share/easy-rsa/openssl-1.0.cnf Enter pass phrase for /etc/openvpn/pki/private/ca.key: //上一步输入的授权密码 Check that the request matches the signature Signature ok The Subject&#39;s Distinguished Name is as follows commonName :ASN.1 12:&#39;tencent&#39; Certificate is to be certified until Mar 3 10:00:03 2028 GMT (3650 days) Write out database with 1 new entries Data Base Updated 7 将用户证书导出到本地文件 //docker run -v $OVPN_DATA:/etc/openvpn --rm kylemanna/openvpn ovpn_getclient CLIENTNAME &gt; CLIENTNAME.ovpn docker run -v $OVPN_DATA:/etc/openvpn --rm kylemanna/openvpn ovpn_getclient tencent &gt; tencent.ovpn 8 在 win10 系统上安装 openvpn 客户端软件，将导出的文件 tencent.ovpn 放到 openvpn 的配置文件夹中，默认是 C:\\Program Files\\OpenVPN\\config 运行 openvpn 客户端软件，链接 使用 ip 查询网站可以看到，没有连接前 和 连接后的 ip 不一样了！！ 二、删除用户证书 在某些时候，不想让某些用户使用了。可以删除用户证书。 例如：删除上面创建的 tencent 用户证书 1 删除用户证书 docker run -v $OVPN_DATA:/etc/openvpn --rm -it kylemanna/openvpn easyrsa revoke tencent Please confirm you wish to revoke the certificate with the following subject: subject= commonName = tencent Type the word &#39;yes&#39; to continue, or any other input to abort. Continue with revocation: yes Using configuration from /usr/share/easy-rsa/openssl-1.0.cnf Enter pass phrase for /etc/openvpn/pki/private/ca.key: Revoking Certificate DC3DA3513871192FE8085FDB56B38F47. Data Base Updated IMPORTNT!!! Revocation was successful. You must run gen-crl and upload a CRL to your infrastructure in order to prevent the revoked cert from being accepted. 2 更新证书数据库 docker run -v $OVPN_DATA:/etc/openvpn --rm -it kylemanna/openvpn easyrsa gen-crl update-db 3 将 openvpn 容器重启 docker restart openvpn 至此用户 tencent 的证书删除完毕。可以验证他不能链接了！！！","categories":[],"tags":[],"author":"张存"},{"title":"docker-compose入门示例：一键部署 Nginx+Tomcat+Mysql","slug":"docker-compose入门示例：一键部署-Nginx-Tomcat-Mysql","date":"2022-05-17T15:23:56.000Z","updated":"2022-05-17T15:27:04.060Z","comments":true,"path":"2022/05/17/docker-compose-ru-men-shi-li-yi-jian-bu-shu-nginx-tomcat-mysql/","link":"","permalink":"https://blog.zhangcun.store/2022/05/17/docker-compose-ru-men-shi-li-yi-jian-bu-shu-nginx-tomcat-mysql/","excerpt":"","text":"整体环境配置 整体环境的配置，如果一个一个 Dockerfile 去写，那么是相当麻烦的，好在 Docker 有一个名为 Docker-Compose 的工具提供，我们可以使用它一次性完成整体环境的配置： 首先我们看看 docker-compose.yml 配置文件的内容： version: &quot;3&quot; services: mysql: container_name: mysql image: 192.168.1.30:5000/mysql:5.7 #从私有仓库拉镜像 restart: always volumes: - ./mysql/data/:/var/lib/mysql/ #映射mysql的数据目录到宿主机，保存数据 - ./mysql/conf/mysqld.cnf:/etc/mysql/mysql.conf.d/mysqld.cnf #把mysql的配置文件映射到容器的相应目录 ports: - &quot;6033:3306&quot; environment: - MYSQL_ROOT_PASSWORD=123456 nginx: container_name: nginx restart: always image: 192.168.1.30:5000/nginx ports: - 80:80 - 443:443 - 5050:5050 - 4040:4040 volumes: - ./nginx/conf/nginx.conf:/etc/nginx/nginx.conf #映射nginx的配置文件到容器里 - ./nginx/logs/:/var/log/nginx/ - ./nginx/data/:/var/share/nginx/html/ #映射nginx的网页目录到容器里 links: - tomcat:t1 #连接 tomcat镜像 tomcat: container_name: tomcat restart: always image: 192.168.1.30:5000/tomcat ports: - 8080:8080 - 8009:8009 volumes: - ./tomcat/conf/server.xml:/usr/local/tomcat/conf/server.xml #映射 tomcat的配置文件到容器里 - ./tomcat/webapps/web:/usr/local/tomcat/webapps/web #映射一个web服务 - ./tomcat/logs/:/usr/local/tomcat/logs/ links: - mysql:m1 #连接数据库镜像 一共设置了三个 service，分别是 mysql, nginx, tomcat，其中，需要注意的地方是它们的 volumes 以及 links。 mysql 环境配置 首先看看最简单的 mysql，它没有设置 links，因为是其他容器来连接它，不需要设置links。但是 mysql 的 volumes 最为重要，如果不设置 volumes 的话，每一次 docker 重启，或者 mysql 的 container 重启，database 数据就会啥都没有了。所以 mysql 的 volumes设置了mysql 产生的 data 文件需要映射到宿主机的./mysql/data 目录下，这个目录可以自己定，mysql 的配置文件从宿主机的./mysql/conf/mysqld.conf 读取，内容可自己配置好。nginx 环境配置 它也设置了 volumes和links，这个地方的 links，建立了与 tomcat 容器的连接，因为nginx 负责监听 80 端口，tomcat 负责监听 8080 端口，nginx 接收到动态网页需要由 tomcat 来处理，就要转发到 8080端口。docker 的环境下，nginx 直接将请求转发到 8080，tomcat 是不会转发的。所以用llinks，这里的值为 t1，为名字。在 nginx.conf文件中，要加上如下配置： 在http端中加 upstream backend &#123; #后台负载均衡容器及端口，本例为一个，t1 tomcat容器的名字 server t1:8080; &#125; 在server加 location / &#123; proxy_pass http://backend$request_uri; proxy_set_header Host $host:$server_port; proxy_set_header X-Real-IP $remote_addr; client_max_body_size 10m; &#125; tomcat 环境配置 volumes: - ./tomcat/conf/server.xml:/usr/local/tomcat/conf/server.xml #映射 tomcat的配置文件到容器里 - ./tomcat/webapps/web:/usr/local/tomcat/webapps/web #映射一个web服务 该server.xml文件提前在宿主机配置好，包括web网页；同时把web映射到容器的相应目录。 最后执行如下命令： docker-compose up 或者 docker-compose -f *.yaml文件名 创建容器。如果没有出现错误，创建成功。 一般的错误，都是因为挂载目录有错误，有的是写错了，有的是映射到容器中的相应目录不正确，关于容器的目录我总结如下： mysql：:/etc/mysql/mysql.conf.d/mysqld.cnf 为配置文件位置 nginx: :/etc/nginx/nginx.conf 为配置文件位置，/var/share/nginx/html/ 为nginx的网页目录 tomcat: :/usr/local/tomcat/conf/server.xml 为tomcat的配置文件位置，/usr/local/tomcat/webapps 为网页站点目录 通过以上我们不只可以一键创建一个mysql，nginx, tomcat 的动静分离网站环境，同时我们对 docker-compose 有了一定的了解，使我们轻松完成docker-compose 的入门学习。","categories":[],"tags":[],"author":"张存"},{"title":"alpine中设置时区（Dockerfile版）","slug":"alpine中设置时区（Dockerfile版）","date":"2022-05-17T15:19:41.000Z","updated":"2022-05-17T15:20:06.181Z","comments":true,"path":"2022/05/17/alpine-zhong-she-zhi-shi-qu-dockerfile-ban/","link":"","permalink":"https://blog.zhangcun.store/2022/05/17/alpine-zhong-she-zhi-shi-qu-dockerfile-ban/","excerpt":"","text":"FROM alpine:3.12 ENV TZ Asia/Shanghai RUN apk -U upgrade &amp;&amp; apk add tzdata &amp;&amp; cp /usr/share/zoneinfo/$&#123;TZ&#125; /etc/localtime &amp;&amp; echo $&#123;TZ&#125; &gt; /etc/timezone CMD [&quot;date&quot;]","categories":[],"tags":[],"author":"张存"},{"title":"ubuntu修改pip的官方源为豆瓣源","slug":"ubuntu修改pip的官方源为豆瓣源","date":"2022-05-17T14:24:43.000Z","updated":"2022-05-17T14:25:13.291Z","comments":true,"path":"2022/05/17/ubuntu-xiu-gai-pip-de-guan-fang-yuan-wei-dou-ban-yuan/","link":"","permalink":"https://blog.zhangcun.store/2022/05/17/ubuntu-xiu-gai-pip-de-guan-fang-yuan-wei-dou-ban-yuan/","excerpt":"","text":"ubuntu修改pip的官方源为豆瓣源编辑配置文件, 如果没有就新建一份 mkdir ~/.pip vim ~/.pip/pip.conf 然后编辑pip.conf，输入 [global] index-url = http://pypi.douban.com/simple trusted-host = pypi.douban.com","categories":[],"tags":[],"author":"张存"},{"title":"Too many open files in system","slug":"Too-many-open-files-in-system","date":"2022-05-17T14:21:46.000Z","updated":"2022-05-17T14:22:17.434Z","comments":true,"path":"2022/05/17/too-many-open-files-in-system/","link":"","permalink":"https://blog.zhangcun.store/2022/05/17/too-many-open-files-in-system/","excerpt":"","text":"如果系统报错 Too many open files in system 检查措施如下： ……1: : : ulimit -n或者ulimit -a #查看当前系统允许打开的最大文件数（软限制的文件数，相当于是警告但系统仍然能登陆，还有个硬限制，文件数到了这个值系统就登录不进去了） cat /etc/security/limits.conf #打开这个文件能看到以下信息，可以修改 * soft nofile 1024 #软限制打开文件的最大数 * hard nofile 10240 #硬限制打开文件的最大数 * soft noproc 1024 #软限制打开进程的最大数 * hard noproc 10240 #硬限制打开文件的最大数 echo &quot;session required /lib/security/pam_limits.so&quot; &gt;&gt; /etc/pam.d/login echo &quot;session required /lib/security/$ISA/pam_limits.so&quot; &gt;&gt; /etc/pam.d/system-auth 主要用这种方法……2.................: : : lsof|wc -l #检查当前系统已经打开的文件数 cat /proc/sys/fs/file-max #查看系统设定的最大打开文件数，将两个数比较下，如果已经打开的比规定的多，那就执行下面操作：：：： echo 一倍的数值 &gt;/proc/sys/fs/file-max 这样的话报错就没有了，但只是临时生效，系统重启失效 vi /etc/sysctl.conf #在最后一行添加fs.file-max = 一倍的数值 sysctl -p #重启生效 ulimit -a #查看各个功能有无限制 数据段长度：ulimit -d unlimited #设置为无限制 最大内存大小：ulimit -m unlimited #设置为无限制 堆栈大小：ulimit -s unlimited #设置为无限制 CPU 时间：ulimit -t unlimited #设置为无限制 虚拟内存：ulimit -v unlimited #设置为无限制","categories":[],"tags":[],"author":"张存"},{"title":"ubuntu 18.04更换源","slug":"ubuntu-18-04更换源","date":"2022-05-17T14:19:14.000Z","updated":"2022-05-17T14:19:58.028Z","comments":true,"path":"2022/05/17/ubuntu-18-04-geng-huan-yuan/","link":"","permalink":"https://blog.zhangcun.store/2022/05/17/ubuntu-18-04-geng-huan-yuan/","excerpt":"","text":"sudo cp /etc/apt/sources.list /etc/apt/sources.list.bak //备份 sudo vim /etc/apt/sources.list //修改 ##阿里云源 deb http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiverse ##中科大源 deb https://mirrors.ustc.edu.cn/ubuntu/ bionic main restricted universe multiverse deb-src https://mirrors.ustc.edu.cn/ubuntu/ bionic main restricted universe multiverse deb https://mirrors.ustc.edu.cn/ubuntu/ bionic-updates main restricted universe multiverse deb-src https://mirrors.ustc.edu.cn/ubuntu/ bionic-updates main restricted universe multiverse deb https://mirrors.ustc.edu.cn/ubuntu/ bionic-backports main restricted universe multiverse deb-src https://mirrors.ustc.edu.cn/ubuntu/ bionic-backports main restricted universe multiverse deb https://mirrors.ustc.edu.cn/ubuntu/ bionic-security main restricted universe multiverse deb-src https://mirrors.ustc.edu.cn/ubuntu/ bionic-security main restricted universe multiverse deb https://mirrors.ustc.edu.cn/ubuntu/ bionic-proposed main restricted universe multiverse deb-src https://mirrors.ustc.edu.cn/ubuntu/ bionic-proposed main restricted universe multiverse ##清华源 deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic main restricted universe multiverse deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-updates main restricted universe multiverse deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-updates main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-backports main restricted universe multiverse deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-backports main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-security main restricted universe multiverse deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-security main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-proposed main restricted universe multiverse deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-proposed main restricted universe multiverse sudo apt-get update","categories":[],"tags":[],"author":"张存"},{"title":"删除pip安装缓存","slug":"删除pip安装缓存","date":"2022-05-17T13:58:15.000Z","updated":"2022-05-17T13:58:53.761Z","comments":true,"path":"2022/05/17/shan-chu-pip-an-zhuang-huan-cun/","link":"","permalink":"https://blog.zhangcun.store/2022/05/17/shan-chu-pip-an-zhuang-huan-cun/","excerpt":"","text":"指定–no-cache-dir确保安装不缓存如果pip版本在6.0以上，可以在安装时使用–no-cache-dir参数，查看pip版本 pip -V pip命令格式： 如果pip版本在6.0以下，可以使用如下命令升级pip版本 pip install -U pip 删除已缓存文件，根据各自不同的操作系统，删除对应目录缓存文件 Linux and Unix ~/.cache/pip # and it respects the XDG_CACHE_HOME directory. OS X ~/Library/Caches/pip Windows %LocalAppData%\\pip\\Cache https://stackoverflow.com/questions/9510474/removing-pips-cach","categories":[],"tags":[],"author":"张存"},{"title":"报错：Zabbix数据库版本与当前需求不匹配","slug":"报错：Zabbix数据库版本与当前需求不匹配","date":"2022-05-17T13:54:29.000Z","updated":"2022-05-17T13:55:33.171Z","comments":true,"path":"2022/05/17/bao-cuo-zabbix-shu-ju-ku-ban-ben-yu-dang-qian-xu-qiu-bu-pi-pei/","link":"","permalink":"https://blog.zhangcun.store/2022/05/17/bao-cuo-zabbix-shu-ju-ku-ban-ben-yu-dang-qian-xu-qiu-bu-pi-pei/","excerpt":"","text":"报错：The Zabbix database version does not match current requirements. Your database version: 5000000. Required version: 4000000. Please contact your system administrator. 问题原因： 当前数据库版本与所需数据库版本不一致； 解决方法： 登录数据库，修改数据库版本的mandatory值至4000000 MariaDB [(none)]&gt; use zabbix; Reading table information for completion of table and column names You can turn off this feature to get a quicker startup with -A Database changed MariaDB [zabbix]&gt; select version(); +----------------+ | version() | +----------------+ | 5.5.68-MariaDB | +----------------+ 1 row in set (0.00 sec) MariaDB [zabbix]&gt; update dbversion set mandatory=4000000; Query OK, 1 row affected (0.00 sec) Rows matched: 1 Changed: 1 Warnings: 0 MariaDB [zabbix]&gt; flush privileges; Query OK, 0 rows affected (0.00 sec) MariaDB [zabbix]&gt; select version(); 重启zabbix-server端即可","categories":[],"tags":[],"author":"张存"},{"title":"zabbix docker-compose 运行配置","slug":"zabbix-docker-compose-运行配置","date":"2022-05-17T13:17:53.000Z","updated":"2022-05-17T13:18:29.476Z","comments":true,"path":"2022/05/17/zabbix-docker-compose-yun-xing-pei-zhi/","link":"","permalink":"https://blog.zhangcun.store/2022/05/17/zabbix-docker-compose-yun-xing-pei-zhi/","excerpt":"","text":"zabbix docker-compose 运行配置网上看到一堆使用docker-compose 运行zabbix ，都不台好用，或者因为版本问题，以下是一个整理的docker-compose ，可以参考 docker-compose version: “3” services: mysql-server: image: mysql:5.7.16 container_name: mysql-server command: --character-set-server=utf8 --interactive_timeout=120 --wait_timeout=120 --log_warnings=1 --collation-server=utf8_bin --sql_mode=STRICT_TRANS_TABLES,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION --lower_case_table_names=1 restart: always environment: - MYSQL_DATABASE=zabbix - MYSQL_USER=zabbix - MYSQL_PASSWORD=zabbix - MYSQL_ROOT_PASSWORD=zabbix ports: - 3306:3306 volumes: - /data/mysql:/var/lib/mysql - /etc/localtime:/etc/localtime - /etc/timezone:/etc/timezone zabbix-server-mysql: image: zabbix/zabbix-server-mysql:5.0.0 container_name: zabbix-server-mysql ulimits: nproc: 65535 nofile: soft: 20000 hard: 40000 privileged: true cap_add: - ALL restart: always environment: - DB_SERVER_HOST=mysql-server - MYSQL_USER=zabbix - ZBX_CACHESIZE=4096M - MYSQL_PASSWORD=zabbix - MYSQL_DATABASE=zabbix - MYSQL_ROOT_PASSWORD=zabbix ports: - 10051:10051 sysctls: - net.ipv4.ip_local_port_range=1024 65000 - net.ipv4.conf.all.accept_redirects=0 - net.ipv4.conf.all.secure_redirects=0 - net.ipv4.conf.all.send_redirects=0 links: - mysql-server:mysql depends_on: - mysql-server volumes: - /etc/localtime:/etc/localtime - /etc/timezone:/etc/timezone - zabbix-server-conf:/etc/zabbix - zabbix-server-alertscripts:/usr/lib/zabbix/alertscripts ​ zabbix-web: image: zabbix/zabbix-web-nginx-mysql:5.0.0 environment: - DB_SERVER_HOST=mysql-server - MYSQL_USER=zabbix - PHP_TZ=Asia/Shanghai - MYSQL_PASSWORD=zabbix - MYSQL_DATABASE=zabbix - MYSQL_ROOT_PASSWORD=zabbix restart: always ports: - 80:8080 volumes: - /etc/localtime:/etc/localtime - /etc/timezone:/etc/timezone links: - mysql-server:mysql - zabbix-server-mysql:zabbix-server depends_on: - mysql-server - zabbix-server-mysql zabbix-agent: image: zabbix/zabbix-agent privileged: true restart: always cap_add: - ALL volumes: - /etc/timezone:/etc/timezone environment: ZBX_SERVER_HOST: zabbix-server-mysql ports: - &#39;10050:10050&#39; volumes: zabbix-server-conf: zabbix-server-alertscripts: 启动docker-compose up -d","categories":[],"tags":[],"author":"张存"},{"title":"通过docker-compose一键部署zabbix监控平台","slug":"通过docker-compose一键部署zabbix监控平台","date":"2022-05-17T13:08:45.000Z","updated":"2022-05-17T13:14:39.336Z","comments":true,"path":"2022/05/17/tong-guo-docker-compose-yi-jian-bu-shu-zabbix-jian-kong-ping-tai/","link":"","permalink":"https://blog.zhangcun.store/2022/05/17/tong-guo-docker-compose-yi-jian-bu-shu-zabbix-jian-kong-ping-tai/","excerpt":"","text":"通过docker启动zabbix监控平台已经很方便了，下面我们可以使用一种更加方便的方式启动，那就是docker的compose功能。 当然，首先我们还是得需要有一个docker的环境，至于安装方式这里就不说了。在我的博客docker分类中有写安装方式。 下面，我们直接利用docker环境安装compose功能。compose的安装很方式有多种，下面我们使用二进制方式进行安装。 下载地址为https://github.com/docker/compose/releases 具体命令为： curl -L https://github.com/docker/compose/releases/download/1.29.2/docker-compose-`uname -s`-`uname -m` &gt; /usr/local/bin/docker-compose chmod +x /usr/local/bin/docker-compose 输入docker-compose可以显示帮助信息表示安装成功。 下面我们就可以通过编写docker-compose.yml文件来部署服务了。 首先创建一个yml文件的存放位置，在创建一个yml文件 mkdir -p /data2/zabbix cd /data2/zabbix/ vim docker-compose.yml 注意：yml文件的名称是固定的。 yml文件内容：可以直接复制使用，也可简单修改在使用 version: &#39;3&#39; services: zabbix-web-nginx-mysql: image: zabbix/zabbix-web-nginx-mysql:centos-5.2-latest restart: always environment: - DB_SERVER_HOST=zabbix-mysql - MYSQL_DATABASE=zabbix - MYSQL_USER=zabbix - MYSQL_PASSWORD=zabbix - MYSQL_ROOT_PASSWORD=123qwe - ZBX_SERVER_HOST=zabbix-server-mysql ports: - 8080:8080 volumes: - /etc/localtime:/etc/localtime - /data2/zabbix/fonts/DejaVuSans.ttf:/usr/share/zabbix/assets/fonts/DejaVuSans.ttf networks: - zbx_net depends_on: - zabbix-server-mysql - zabbix-mysql zabbix-mysql: image: mysql:8.0.23 restart: always ports: - 3306:3306 environment: - MYSQL_DATABASE=zabbix - MYSQL_USER=zabbix - MYSQL_PASSWORD=zabbix - MYSQL_ROOT_PASSWORD=123qwe command: - mysqld - --default-authentication-plugin=mysql_native_password - --character-set-server=utf8 - --collation-server=utf8_bin volumes: - /etc/localtime:/etc/localtime - /data2/zabbix/db:/var/lib/mysql networks: - zbx_net zabbix-java-gateway: image: zabbix/zabbix-java-gateway:centos-5.2-latest restart: always volumes: - /etc/localtime:/etc/localtime networks: - zbx_net zabbix-server-mysql: image: zabbix/zabbix-server-mysql:centos-5.2-latest restart: always volumes: - zabbix-server-vol:/etc/zabbix - /data2/zabbix/alertscripts:/usr/lib/zabbix/alertscripts - /etc/localtime:/etc/localtime ports: - 10051:10051 environment: - DB_SERVER_HOST=zabbix-mysql - MYSQL_DATABASE=zabbix - MYSQL_USER=zabbix - MYSQL_PASSWORD=zabbix - MYSQL_ROOT_PASSWORD=123qwe - ZBX_JAVAGATEWAY=zabbix-java-gateway - ZBX_JAVAGATEWAY_ENABLE=true - ZBX_JAVAGATEWAYPORT=10052 depends_on: - zabbix-mysql networks: - zbx_net zabbix-agent: image: zabbix/zabbix-agent:centos-5.2-latest restart: always ports: - 10050:10050 environment: - ZBX_HOSTNAME=Zabbix server - ZBX_SERVER_HOST=zabbix-server-mysql - ZBX_SERVER_PORT=10051 networks: - zbx_net networks: zbx_net: driver: bridge volumes: zabbix-server-vol: 创建完yml文件，我们还需要把文件中用到的目录创建出来mkdir alertscripts db fonts 进入到fonts目录，下载中文语言包文件cd fontswget https://dl.cactifans.com/zabbix_docker/msty.ttfmv msty.ttf DejaVuSans.ttf 当准备工作都完成了，接下来我们就运行这个文件，看看是否能一键安装zabbix监控平台运行docker-compose.yml文件的方式：（在yml文件所在目录运行）docker-compose up -d1结果如下： Creating network &quot;zabbix_zbx_net&quot; with driver &quot;bridge&quot; Creating volume &quot;zabbix_zabbix-server-vol&quot; with default driver Pulling zabbix-web-nginx-mysql (zabbix/zabbix-web-nginx-mysql:centos-5.2-latest)... centos-5.2-latest: Pulling from zabbix/zabbix-web-nginx-mysql Digest: sha256:9a84a6b86dd748d3f3843efd1f744d1f3e3fc9bd39105470239aae6a81cd51f5 Status: Downloaded newer image for zabbix/zabbix-web-nginx-mysql:centos-5.2-latest Creating zabbix_zabbix-mysql_1 ... done Creating zabbix_zabbix-agent_1 ... done Creating zabbix_zabbix-java-gateway_1 ... done Creating zabbix_zabbix-server-mysql_1 ... done Creating zabbix_zabbix-web-nginx-mysql_1 ... done 查看容器启动状态命令： docker-compose ps 查看容器启动日志： docker-compose logs 查看容器启动的进程： docker-compose top 容器停止、启动、删除、构建命令： docker-compose stop docker-compose start docker-compose down docker-compose up -d 注：-d参数为后台运行 接下来可以通过浏览器访问登录页面，默认账号密码：Admin、zabbix 我们要修改一下配置，将ip更换为容器名称，不然会检测不到 稍微等待一会，会发现监控成功 将文字调整为中文页面 到此可以看到显示页面为中文。部署部分内容到此为止","categories":[],"tags":[],"author":"张存"},{"title":"基于docker的elasticsearch 7.5.1 搭建","slug":"基于docker的elasticsearch-7-5-1-搭建","date":"2022-05-13T09:36:27.000Z","updated":"2022-05-13T09:55:46.338Z","comments":true,"path":"2022/05/13/ji-yu-docker-de-elasticsearch-7-5-1-da-jian/","link":"","permalink":"https://blog.zhangcun.store/2022/05/13/ji-yu-docker-de-elasticsearch-7-5-1-da-jian/","excerpt":"","text":"Es数据库（单节点） 1.1.1拉取ES docker 镜像 docker pull elasticsearch:7.5.1 1.1.2创建ES绑定数据卷 mkdir /root/ES/config/ mkdir /root/ES/data/ chmod 777 /root/ES/data 1.1.3创建ES主节点 es.yml vi /root/ES/config/es.yml cluster.name: elasticsearch-cluster node.name: master network.host: 0.0.0.0 network.publish_host: 192.168.2.124 #本机ip http.port: 9200 transport.tcp.port: 9300 http.cors.enabled: true http.cors.allow-origin: &quot;*&quot; node.master: true node.data: true discovery.seed_hosts: [&quot;192.168.2.124:9300&quot;] #所有主从节点ip:port cluster.initial_master_nodes: [&quot;master&quot;] 1.1.4 ES启动命令 docker run -e ES_JAVA_OPTS=&quot;-Xms256m -Xmx256m&quot; -d -p 9200:9200 -p 9300:9300 -v /root/ES/config/es.yml:/usr/share/elasticsearch/config/elasticsearch.yml -v /root/ES/data:/usr/share/elasticsearch/data --name ES 2bd69c322e98 1.1.5 验证安装成功 登录http://192.168.2.124:9200，若正常登录则证明es安装成功","categories":[],"tags":[],"author":"张存"},{"title":"Docker容器的重启策略及docker run的--restart选项详解","slug":"Docker容器的重启策略及docker-run的-restart选项详解","date":"2022-05-13T08:38:38.000Z","updated":"2022-05-13T08:45:58.467Z","comments":true,"path":"2022/05/13/docker-rong-qi-de-chong-qi-ce-lue-ji-docker-run-de-restart-xuan-xiang-xiang-jie/","link":"","permalink":"https://blog.zhangcun.store/2022/05/13/docker-rong-qi-de-chong-qi-ce-lue-ji-docker-run-de-restart-xuan-xiang-xiang-jie/","excerpt":"","text":"1.Docker容器的重启策略 Docker容器的重启策略是面向生产环境的一个启动策略，在开发过程中可以忽略该策略。 Docker容器的重启都是由Docker守护进程完成的，因此与守护进程息息相关。 Docker容器的重启策略如下： no，默认策略，在容器退出时不重启容器 on-failure，在容器非正常退出时（退出状态非0），才会重启容器 on-failure:3，在容器非正常退出时重启容器，最多重启3次 always，在容器退出时总是重启容器 unless-stopped，在容器退出时总是重启容器，但是不考虑在Docker守护进程启动时就已经停止了的容器 2.Docker容器的退出状态码 docker run的退出状态码如下： 0，表示正常退出 非0，表示异常退出（退出状态码采用chroot标准） 125，Docker守护进程本身的错误 126，容器启动后，要执行的默认命令无法调用 127，容器启动后，要执行的默认命令不存在 其他命令状态码，容器启动后正常执行命令，退出命令时该命令的返回状态码作为容器的退出状态码 3.docker run的--restart选项 通过–restart选项，可以设置容器的重启策略，以决定在容器退出时Docker守护进程是否重启刚刚退出的容器。 --restart选项通常只用于detached模式的容器。 --restart选项不能与–rm选项同时使用。显然，--restart选项适用于detached模式的容器，而–rm选项适用于foreground模式的容器。 在docker ps查看容器时，对于使用了--restart选项的容器，其可能的状态只有Up或Restarting两种状态。 示例： docker run -d --restart=always ba-208 docker run -d --restart=on-failure:10 ba-208 补充： 查看容器重启次数 docker inspect -f &quot;&#123;&#123; .RestartCount &#125;&#125;&quot; ba-208 查看容器最后一次的启动时间 docker inspect -f &quot;&#123;&#123; .State.StartedAt &#125;&#125;&quot; ba-208","categories":[],"tags":[],"author":"张存"},{"title":"redis怎么清除缓存","slug":"redis怎么清除缓存","date":"2022-05-13T08:20:23.000Z","updated":"2022-05-13T08:20:28.717Z","comments":true,"path":"2022/05/13/redis-zen-me-qing-chu-huan-cun/","link":"","permalink":"https://blog.zhangcun.store/2022/05/13/redis-zen-me-qing-chu-huan-cun/","excerpt":"","text":"Linux中redis清除缓存的方法 1、进入目录redis下src目录。 #cd redis-2.8.17/src 2、执行redis-cli文件 执行./redis-cli或者./redis-cli -h 127.0.0.1 -p 6379 3、执行dbsize命令 4、清除缓存 使用flushall命令可清除所有缓存。例： 5、查看所有key值 使用keys * 进行验证是否为空 6、执行exit命令，退出 注：redis清理缓存是一个很危险的动作，有可能会造成数据丢失 慎重操作","categories":[],"tags":[],"author":"张存"},{"title":"zabbix报错之：on host “x.x.x.x“ failed: first network error, wait for 15 seconds","slug":"zabbix报错之：on-host-“gdgwfx-cj01“-failed-first-network-error-wait-for-15-seconds","date":"2022-05-13T08:17:44.000Z","updated":"2022-05-13T08:18:01.032Z","comments":true,"path":"2022/05/13/zabbix-bao-cuo-zhi-on-host-gdgwfx-cj01-failed-first-network-error-wait-for-15-seconds/","link":"","permalink":"https://blog.zhangcun.store/2022/05/13/zabbix-bao-cuo-zhi-on-host-gdgwfx-cj01-failed-first-network-error-wait-for-15-seconds/","excerpt":"","text":"问题：zabbix服务端获取监控端信息超时，日志提示如下 on host &quot;x.x.x.x&quot; failed: first network error, wait for 15 seconds 原因：zabbix监控端的监控脚本执行时间过长（可能逻辑复杂，执行需要时间），返回到服务器的信息已超过服务端设定时间。 解决措施： 更改服务端配置文件，延长超时时间 # vi /etc/zabbix/zabbix_server.conf Timeout = 30 后重启服务端，解决","categories":[],"tags":[],"author":"张存"},{"title":"zabbix使用 zabbix监控 docker中运行的容器及docker进程","slug":"zabbix使用-zabbix监控-docker中运行的容器及docker进程","date":"2022-05-12T16:02:25.000Z","updated":"2022-05-12T16:04:27.513Z","comments":true,"path":"2022/05/13/zabbix-shi-yong-zabbix-jian-kong-docker-zhong-yun-xing-de-rong-qi-ji-docker-jin-cheng/","link":"","permalink":"https://blog.zhangcun.store/2022/05/13/zabbix-shi-yong-zabbix-jian-kong-docker-zhong-yun-xing-de-rong-qi-ji-docker-jin-cheng/","excerpt":"","text":"1、页面中导入zabbix模版 将这个文件通过 zabbix 页面导入； 2、服务器中存放监控脚本 [root@cest-3 ~]# cat /etc/zabbix/zabbix_agentd.d/docker_alarm.py #!/usr/bin/python import sys import os import json def discover(): d = &#123;&#125; d[&#39;data&#39;] = [] with os.popen(&quot;docker ps -a --format &#123;&#123;.Names&#125;&#125;&quot;) as pipe: for line in pipe: info = &#123;&#125; info[&#39;&#123;#CONTAINERNAME&#125;'] = line.replace(\"\\n\",\"\") d['data'].append(info) print json.dumps(d) def status(name,action): if action == \"ping\": cmd = 'docker inspect --format=\"&#123;&#123;.State.Running&#125;&#125;&quot; %s&#39; %name result = os.popen(cmd).read().replace(&quot;\\n&quot;,&quot;&quot;) if result == &quot;true&quot;: print 1 else: print 0 else: cmd = &#39;docker stats %s --no-stream --format &quot;&#123;&#123;.%s&#125;&#125;&quot;&#39; % (name,action) result = os.popen(cmd).read().replace(&quot;\\n&quot;,&quot;&quot;) if &quot;%&quot; in result: print float(result.replace(&quot;%&quot;,&quot;&quot;)) else: print result if __name__ == &#39;__main__&#39;: try: name, action = sys.argv[1], sys.argv[2] status(name,action) except IndexError: discover() docker 占位符说明： .Container 根据用户指定的名称显示容器的名称或 ID。 .Name 容器名称。 .ID 容器 ID。 .CPUPerc CPU 使用率。 .MemUsage 内存使用量。 .NetIO 网络 I/O。 .BlockIO 磁盘 I/O。 .MemPerc 内存使用率。 .PIDs PID 号。 3、服务器中配置运行的监控脚本 [root@cest-3 ~]# vim /etc/zabbix/zabbix_agentd.d/docker.conf UserParameter=docker.discovery,/etc/zabbix/zabbix_agentd.d/docker_alarm.py UserParameter=docker.[*],/etc/zabbix/zabbix_agentd.d/docker_alarm.py $1 $2 UserParameter=process.stats,ps -aux | grep $(cat /var/run/docker.pid) | grep -v grep | wc -l 4、zabbix-server 检测 zabbix_get -s 192.168.x.x -p 10050 -k docker.[xxx,ping] 5、常见问题 报错信息： Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Post http://%2Fvar%2Frun%2Fdocker.sock/v1.26/build? buildargs=%7B%7D&amp;buildbinds=null&amp;cachefrom=%5B%5D&amp;cgroupparent=&amp;cpuperiod=0&amp;cpuquota=0&amp;cpusetcpus=&amp;cpusetmems=&amp;cpushares=0&amp;dockerfile=Dockerfile&amp;labels=%7B%7 D&amp;memory=0&amp;memswap=0&amp;networkmode=default&amp;rm=1&amp;shmsize=0&amp;t=192.168.1.202%2Flibrary%2Ficp-service-interface%3Av2&amp;ulimits=null:dial unix /var/run/docker.sock: connect: permission denied 解决办法： 修改 /etc/zabbix/zabbix_agentd.conf 文件中的 EnableRemoteCommands 参数改为 1； 将 zabbix 用户添加到 docker 组中,并更新组信息； gpasswd -a zabbix docker newgrp docker","categories":[],"tags":[],"author":"张存"},{"title":"使用docker搭建frp服务器","slug":"使用docker搭建frp服务器","date":"2022-05-09T14:23:55.000Z","updated":"2022-05-09T14:24:32.606Z","comments":true,"path":"2022/05/09/shi-yong-docker-da-jian-frp-fu-wu-qi/","link":"","permalink":"https://blog.zhangcun.store/2022/05/09/shi-yong-docker-da-jian-frp-fu-wu-qi/","excerpt":"","text":"前言 把本地的开发环境映射到外网，这是我们经常会碰到的一个要求，比方说展示给别人看啦，临时测试啦。尤其在微信开发中，因为微信必须要求80端口，所以不转发的情况下，我们只能把代码部署到服务器之后才能验证测试，非常麻烦。 最早的时候是花生壳，不过这家公司贼恶心。。后面开始用ngrok，然后现在又有了frp，相比来说frp的配置要更简单一点。 因为没有找到合适的docker镜像，所以在参考很多之后，就有了如下自写的image及compose 准备工作 具有外网ip的服务器 域名 我这里是准备了一个子域名，*.frp.thyiad.top，把这这个域名解析到服务器，这样可以支持同时映射多个域名到外网，具体的子域名在frp客户端配置，服务端配置前缀域名为frp.thyiad.top docker需要注意的是，我这里是基于ngin-proxy镜像来解析域名的，此处不再赘述，可参照之前的文章：使用docker搭建wordpress docker file镜像已经上传到docker的hub上了，所以你也可以跳过docker file直接使用compose 创建工作目录： cd /usr mkdir frp &amp;&amp; cd frp mkdir frp_image &amp;&amp; cd frp_image 先创建一个frp的默认配置文件： mkdir conf &amp;&amp; vim conf/frps.ini 把以下内容填入 frps.ini： [common] bind_addr = 0.0.0.0 bind_port = 7000 kcp_bind_port = 7000 vhost_http_port = 80 vhost_https_port = 443 dashboard_addr = 0.0.0.0 dashboard_port = 7500 dashboard_user = admin dashboard_pwd = admin authentication_timeout = 0 subdomain_host = frp.thyiad.top 创建dockerfile： vim dockerfile 把以下内容填入dockerfile： FROM ubuntu MAINTAINER thyiad &lt;1520583107@qq.com&gt; ARG FRP_VERSION=0.16.0 RUN apt update \\ &amp;&amp; apt install -y wget WORKDIR /tmp RUN set -x \\ &amp;&amp; wget https://github.com/fatedier/frp/releases/download/v$&#123;FRP_VERSION&#125;/frp_$&#123;FRP_VERSION&#125;_linux_amd64.tar.gz \\ &amp;&amp; tar -zxf frp_$&#123;FRP_VERSION&#125;_linux_amd64.tar.gz \\ &amp;&amp; mv frp_$&#123;FRP_VERSION&#125;_linux_amd64 /var/frp \\ &amp;&amp; mkdir -p /var/frp/conf \\ &amp;&amp; apt remove -y wget \\ &amp;&amp; apt autoremove -y \\ &amp;&amp; rm -rf /var/lib/apt/lists/* COPY conf/frps.ini /var/frp/conf/frps.ini VOLUME /var/frp/conf # conf被配置成了卷，方便以后修改frps.ini WORKDIR /var/frp ENTRYPOINT ./frps -c ./conf/frps.ini 这个dockerfile执行了以下操作： 从github上下载frp的release版本 解压 从conf目录中读取替换默认的frps.ini 此时就可以使用docker build命令进行编译镜像了，命令为： docker build -t=&quot;thyiad/my-frp&quot; . docker compose 在镜像编译好后，我们就可以开始compose文件了，毕竟compose比直接docker run要方便的多 创建工作目录： mkdir /usr/frp/frp_compose &amp;&amp; cd /usr/frp/frp_compose vim docker-compose.yml 把以下内容填入docker-compose.yml： version: &#39;3&#39; services: frp: image: thyiad/my-frp:latest container_name: my-frp ports: - &quot;7000:7000&quot; - &quot;7500:7500&quot; expose: - 80 - 443 volumes: - frp_conf:/var/frp/conf restart: always environment: VIRTUAL_HOST: &#39;*.frp.thyiad.top,frp.thyiad.top&#39; # 指定需要绑定的域名 volumes: frp_conf: networks: default: external: name: nginx-proxy # 此处的nginx-proxy为之前创建的docker network 运行我们的compose： docker-compose up -d 此时，我们的frp服务器就已经OK了。 我们访问一下test.frp.thyiad.top试试： 显然，frp已经在运转了，只是该域名并没有绑定转发 frp客户端 服务端搭好之后，我们就可以下载客户端进行使用了。需要前往frp的github上下载对应的版本，我这里是16.0，windows x64。 下载解压后，我们修改frpc.ini为以下内容： [common] server_addr = 你的服务器ip server_port = 7000 # protocol = kcp [web] type = http local_port = 52485 subdomain = test 然后打开cmd，运行frpc： cd /d d:\\frp frpc 此时会出现以下界面： 说明已经连接成功了，我们再来访问test.frp.thyiad.top试试： 此时，我们的frp就已经搭建好了，很简单吧？","categories":[],"tags":[],"author":"张存"},{"title":"docker 设置国内镜像源","slug":"docker-设置国内镜像源","date":"2022-05-09T14:22:17.000Z","updated":"2022-05-09T14:22:23.751Z","comments":true,"path":"2022/05/09/docker-she-zhi-guo-nei-jing-xiang-yuan/","link":"","permalink":"https://blog.zhangcun.store/2022/05/09/docker-she-zhi-guo-nei-jing-xiang-yuan/","excerpt":"","text":"国内加速地址 1.Docker中国区官方镜像 https://registry.docker-cn.com 2.网易 http://hub-mirror.c.163.com 3.ustc https://docker.mirrors.ustc.edu.cn 4.中国科技大学 https://docker.mirrors.ustc.edu.cn 5.阿里云容器 生成自己的加速地址 登录：cr.console.aliyun.com 点击“创建我的容器镜像”，得到专属加速地址。 修改方法 创建或修改 /etc/docker/daemon.json 文件，修改为如下形式 &#123; &quot;registry-mirrors&quot;: [ &quot;http://hub-mirror.c.163.com&quot;, &quot;https://docker.mirrors.ustc.edu.cn&quot;, &quot;https://registry.docker-cn.com&quot; ] &#125; 加载重启docker service docker restart 查看是否成功 docker info","categories":[],"tags":[],"author":"张存"},{"title":"lsyncd自动同步配置","slug":"lsyncd自动同步配置","date":"2022-05-09T14:21:02.000Z","updated":"2022-05-09T14:21:10.056Z","comments":true,"path":"2022/05/09/lsyncd-zi-dong-tong-bu-pei-zhi/","link":"","permalink":"https://blog.zhangcun.store/2022/05/09/lsyncd-zi-dong-tong-bu-pei-zhi/","excerpt":"","text":"因生产环境需要，需要将2.60上的数据目录，备份到2.61上；计划利用lsyncd的实时同步功能来实现备份。 源：172.16.2.60 Ubuntu系统 备份：172.16.2.61 Ubuntu系统 主要的几个步骤是： 1.配置2.60到2.61上，实现无密码登录。 2.源机上安装lsyncd服务 3.源机上开启rsync服务 4.备份机上开启rsync服务 注意事项：ubuntu系统的root用户默认没有开启，需要先开启root用户的ssh登录权限。 具体如下： 1.配置源与备份主机之间的无密码登录 root@ubuntu-yangben01:~# ssh-keygen -t rsa root@ubuntu-yangben01:~# ssh-copy-id root@172.16.2.61 2.源机上安装lsyncd服务 root@ubuntu-yangben01:~# apt install lsyncd 安装成功后，你可以在：/usr/share/doc/lsyncd/examples，看到Lsyncd配置使用示例，你可以参考这些示例自己再编写配置。 手动创建日志文件和状态文件的目录： root@ubuntu-yangben01:~# mkdir -p /var/log/lsyncd root@ubuntu-yangben01:~# touch /var/log/lsyncd/lsyncd.log root@ubuntu-yangben01:~# touch /var/log/lsyncd/lsyncd.status 配置文件详情： root@ubuntu-yangben01:~# cat /etc/lsyncd/lsyncd.conf.lua ---- -- User configuration file for lsyncd. -- -- Simple example for default rsync, but executing moves through on the target. -- --sync&#123;default.rsyncssh, source=&quot;src&quot;, host=&quot;localhost&quot;, targetdir=&quot;dst/&quot;&#125; settings &#123; logfile =&quot;/var/log/lsyncd/lsyncd.log&quot;, statusFile =&quot;/var/log/lsyncd/lsyncd.status&quot;, inotifyMode = &quot;CloseWrite&quot;, maxProcesses = 8, &#125; -- rsync模式 + ssh shell -- 第一个同步目录 sync &#123; default.rsync, source = &quot;/data&quot;, target = &quot;root@172.16.2.61:/data&quot;, maxDelays = 5, delay = 30, rsync = &#123; binary = &quot;/usr/bin/rsync&quot;, archive = true, compress = true, bwlimit = 2000 &#125; &#125; --第二个同步目录 sync &#123; default.rsync, source = &quot;/yangben&quot;, target = &quot;root@172.16.2.61:/yangben&quot;, maxDelays = 5, delay = 30, rsync = &#123; binary = &quot;/usr/bin/rsync&quot;, archive = true, compress = true, bwlimit = 2000 &#125; &#125; 配置文件编辑完后，启动lsyncd，查看状态，并设置开机自启。 root@ubuntu-yangben01:~# systemctl start lsyncd root@ubuntu-yangben01:~# systemctl status lsyncd root@ubuntu-yangben01:~# systemctl enable lsyncd 3.ubuntu默认安装了rsync,但是默认是没有启动的，需要手动启用。 编辑vim /etc/default/rsync,将RSYNC_ENABLE=false改为true，保存； 然后重启lsyncd服务，systemctl restart lsyncd (这个地方卡了我很久，服务起来了，但就是不产生日志，后面排查了好久，才发现是rsync没有启用。当然，这一步也可以放到前面操作，就省去重启lsyncd服务这一步。) 4.备份机上开启rsync服务 5.验证同步效果","categories":[],"tags":[],"author":"张存"},{"title":"docker安装ldap+phpldapadmin","slug":"docker安装ldap-phpldapadmin","date":"2022-05-09T14:16:31.000Z","updated":"2022-05-09T14:17:04.990Z","comments":true,"path":"2022/05/09/docker-an-zhuang-ldap-phpldapadmin/","link":"","permalink":"https://blog.zhangcun.store/2022/05/09/docker-an-zhuang-ldap-phpldapadmin/","excerpt":"","text":"安装ladp之前，需要提前安装并启动docker。 安装ldap sudo docker run \\ -p 389:389\\ -p 636:636\\ --name youe_ldap\\ --network bridge\\ --hostname openldap-host\\ --env LDAP_ORGANISATION=&quot;youedata&quot;\\ --env LDAP_DOMAIN=&quot;youedata.com&quot;\\ --env LDAP_ADMIN_PASSWORD=&quot;youedata520&quot; \\ --detach osixia/openldap 配置LDAP组织者：--env LDAP_ORGANISATION=&quot;youedata&quot; 配置LDAP域：--env LDAP_DOMAIN=&quot;youedata.com&quot; 配置LDAP密码：--env LDAP_ADMIN_PASSWORD=&quot;youedata520&quot; 默认登录用户名：admin 上述密码是可以修改的 安装phpLdapAdmin docker run \\ -d --privileged \\ -p 18004:80 \\ --name you_pla \\ --env PHPLDAPADMIN_HTTPS=false \\ --env PHPLDAPADMIN_LDAP_HOSTS=192.168.1.169 \\ --detach osixia/phpldapadmin 注意更改为自己的IP地址 访问 IP:18004端口，出现登录界面，表示安装成功 Login DN： cn=admin,dc=youedata,dc=com Password: youedata520","categories":[],"tags":[],"author":"张存"},{"title":"docker安装目录迁移","slug":"docker安装目录迁移","date":"2022-05-09T14:10:00.000Z","updated":"2022-05-09T14:11:39.282Z","comments":true,"path":"2022/05/09/docker-an-zhuang-mu-lu-qian-yi/","link":"","permalink":"https://blog.zhangcun.store/2022/05/09/docker-an-zhuang-mu-lu-qian-yi/","excerpt":"","text":"在安装docker时通常是默认安装的系统盘目录/var/lib/docker，而该目录通常是比较小的，一旦镜像过多就可能出现docker无法运行的情况，这时进行docker目录的迁移就可以很好地解决问题。 docker目录的迁移其实非常简单，有以下两种方法可以实现。 方法一（推荐） 目录拷贝 docker镜像, 容器等信息通常是默认存储在/var/lib/docker目录下的，因此需要先将/var/lib/docker整个目录拷贝到需要迁移的目录中去 停掉docker服务： systemctl stop docker将docker存储目录拷贝到要迁移的目录中去(例如，此处为/home/docker/lib/)： rsync -r -avz /var/lib/docker /home/docker/lib/2) 链接迁移目录到原目录 mv /var/lib/docker /var/lib/docker-old ln -s /home/docker/lib/docker /var/lib/ 重启docker和验证重启docker： systemctl start docker验证镜像和容器可以正常运行，即可删除/var/lib/docker-old目录 方法二 目录拷贝和方法1一样进行目录拷贝迁移 停掉docker服务： systemctl stop docker将docker存储目录拷贝到要迁移的目录中去(例如，此处为/home/docker/lib/)： rsync -r -avz /var/lib/docker /home/docker/lib/2) 修改配置 如果不存在配置目录则创建，存在则忽略： mkdir -p /etc/systemd/system/docker.service.d/ 编辑devicemapper.conf： vi /etc/systemd/system/docker.service.d/devicemapper.conf , 内容如下： [Service] ExecStart= ExecStart=/usr/bin/dockerd --graph=/home/docker/lib/docker vi /etc/docker/daemon.json 添加 &#123;&quot;storage-driver&quot;: &quot;devicemapper&quot; &#125; , 此处不修改可能会出现Job for docker.service failed because the control process exited with error code. See &quot;systemctl status docker.service&quot; and &quot;journalctl -xe&quot; for details. 重启 docker和验证 重新加载systemd管理器配置：systemctl daemon-reload重启docker服务： systemctl restart docker看目录是否更改：docker info ； 显示Docker Root Dir: /home/docker/lib/docker 则表明修改成功验证镜像和容器是否可以正常运行，如果正常即可删除原来的/var/lib/docker目录","categories":[],"tags":[],"author":"张存"},{"title":"dockerfile和构建缓存","slug":"dockerfile和构建缓存","date":"2022-05-09T10:39:24.000Z","updated":"2022-05-09T10:41:33.175Z","comments":true,"path":"2022/05/09/dockerfile-he-gou-jian-huan-cun/","link":"","permalink":"https://blog.zhangcun.store/2022/05/09/dockerfile-he-gou-jian-huan-cun/","excerpt":"","text":"镜像缓存 1.镜像缓存：在构建或者下载镜像时候，当镜像层已经存在的时候，直接使用使用缓存， 不需要进行重新构建镜像，如果我们希望在构建镜像时不使用缓存，可以在 docker build 命令中加上 –no-cache 参数。如果我们改变 Dockerfile 指令的执行顺序，或者修改或添加指令，都会使缓存失效。 2.Dockerfile 在执行的时候，当有执行过相同的代码并且顺序也一致的情况下，就会使用缓存镜像层进行构建新的镜像。Dockerfile 中每一个指令都会创建一个镜像层，上层是依赖于下层的。注：镜像层只是存在一个ID，镜像的内容存在host文件系统上，当需要的时候就使用了缓存。 由于每一步的构建过程都将结果提交为镜像，所以docker的构建过程就显得非常聪明。它将之前得镜像层看做缓存。 比如。在我们的调试例子里，我们不需要再第一步到第三步之间记性任何修改。因此docker会将 之前构建时创建的镜像当做缓存并作为新的开始点。 参考链接https://www.pianshen.com/article/49531206577/ 如果想要略过缓存功能，可以使用docker build 的–no-cache标志 使用 Dockerfile 文件但是不使用缓存生成镜像 前一段时候使用 Dockerfile 重新部署 NetCore3.1 项目的时候很顺利，由来由于一些原因，我把以前的镜像删除，如果我们大家继续使用 docker build 命令去生成镜像的话就会报错，例如： 1 [root@localhost PatrickLiu.NetCore]# docker build -t core31v1.112 -f Dockerfile . 2 Sending build context to Docker daemon 4.425MB 3 Step 1/17 : FROM mcr.microsoft.com/dotnet/core/aspnet:3.1-buster-slim AS base 4 —&gt; e3559b2d50bb 5 Step 2/17 : WORKDIR /app 6 —&gt; Using cache 7 —&gt; 1c0ab1a505e2 8 Step 3/17 : EXPOSE 80 9 —&gt; Using cache10 —&gt; 49a72547d56711 Step 4/17 : EXPOSE 44312 unable to find image “sha256:c5ed536f38a6742b7c084fa87e6ac885d9697960a20860f7fd0299da578cf2c8” 这样肯定是不行的，我们肯定希望使用没有缓存的方式重新加载文件生成镜像，怎么做呢？ 问题 你想不用缓存重建Dockerfile。 解决方法 构建镜像时使用 –no-cache 参数。 讨论 为了强制docker构建镜像时不用缓存，执行带–no-cache参数的docker build命令。下面的示例是使用了–no-cache构建镜像。 效果如下： 1 [root@localhost PatrickLiu.NetCore]# docker build –no-cache -t core31v1.112 -f Dockerfile . 2 Sending build context to Docker daemon 4.425MB 3 Step 1/17 : FROM mcr.microsoft.com/dotnet/core/aspnet:3.1-buster-slim AS base 4 —&gt; e3559b2d50bb 5 Step 2/17 : WORKDIR /app 6 —&gt; Running in e8178063fe45 7 Removing intermediate container e8178063fe45 8 —&gt; 0a1d582b30d4 9 Step 3/17 : EXPOSE 8010 —&gt; Running in e7716f38816511 Removing intermediate container e7716f38816512 —&gt; fc54a6e3c0aa13 Step 4/17 : EXPOSE 44314 —&gt; Running in 449680497b7f15 Removing intermediate container 449680497b7f16 —&gt; acf106867ca017 Step 5/17 : FROM mcr.microsoft.com/dotnet/core/sdk:3.1-buster AS build18 3.1-buster: Pulling from dotnet/core/sdk19 e4c3d3e4f7b0: Pull complete 20 101c41d0463b: Pull complete 21 8275efcd805f: Pull complete 22 751620502a7a: Pull complete 23 8e306865fd07: Pull complete 24 9d2f53e752c2: Downloading [===========================&gt; ] 69.19MB/123.8MB25 143a93e01eba: Download complete 镜像文件重新生成，没有使用缓存，每天进步一点点，把问题记录下来，这就是成长了。继续努力。 镜像最后生成的胜利步骤。 1 [root@localhost PatrickLiu.NetCore]# docker build –no-cache -t core31v1.112 -f Dockerfile . 2 Sending build context to Docker daemon 4.425MB 3 Step 1/17 : FROM mcr.microsoft.com/dotnet/core/aspnet:3.1-buster-slim AS base 4 —&gt; e3559b2d50bb 5 Step 2/17 : WORKDIR /app 6 —&gt; Running in e8178063fe45 7 Removing intermediate container e8178063fe45 8 —&gt; 0a1d582b30d4 9 Step 3/17 : EXPOSE 8010 —&gt; Running in e7716f38816511 Removing intermediate container e7716f38816512 —&gt; fc54a6e3c0aa13 Step 4/17 : EXPOSE 44314 —&gt; Running in 449680497b7f15 Removing intermediate container 449680497b7f16 —&gt; acf106867ca017 Step 5/17 : FROM mcr.microsoft.com/dotnet/core/sdk:3.1-buster AS build18 3.1-buster: Pulling from dotnet/core/sdk19 e4c3d3e4f7b0: Pull complete 20 101c41d0463b: Pull complete 21 8275efcd805f: Pull complete 22 751620502a7a: Pull complete 23 8e306865fd07: Pull complete 24 9d2f53e752c2: Pull complete 25 143a93e01eba: Pull complete 26 Digest: sha256:bfd6083e9cd36b37b2a4e9f1722cc958b6654fa96cb3d84ef78492ecf00dcd3227 Status: Downloaded newer image for mcr.microsoft.com/dotnet/core/sdk:3.1-buster28 —&gt; 5fe503d5183029 Step 6/17 : WORKDIR /src30 —&gt; Running in 4312c5d63f3f31 Removing intermediate container 4312c5d63f3f32 —&gt; 31cfbe6739ec33 Step 7/17 : COPY [“PatrickLiu.NetCore.MvcDemo/PatrickLiu.NetCore.MvcDemo.csproj”, “PatrickLiu.NetCore.MvcDemo/“]34 —&gt; ba9ba79cc7d335 Step 8/17 : RUN dotnet restore “PatrickLiu.NetCore.MvcDemo/PatrickLiu.NetCore.MvcDemo.csproj”36 —&gt; Running in 8d2c9ee2461437 Determining projects to restore…38 Restored /src/PatrickLiu.NetCore.MvcDemo/PatrickLiu.NetCore.MvcDemo.csproj (in 4.64 sec).39 Removing intermediate container 8d2c9ee2461440 —&gt; 872cce51982141 Step 9/17 : COPY . .42 —&gt; 4fe062b14ab143 Step 10/17 : WORKDIR “/src/PatrickLiu.NetCore.MvcDemo”44 —&gt; Running in 431b1c2f495945 Removing intermediate container 431b1c2f495946 —&gt; b9dc3acf883c47 Step 11/17 : RUN dotnet build “PatrickLiu.NetCore.MvcDemo.csproj” -c Release -o /app/build48 —&gt; Running in 639b5e3d01df49 Microsoft (R) Build Engine version 16.7.0+7fb82e5b2 for .NET50 Copyright (C) Microsoft Corporation. All rights reserved.51 52 Determining projects to restore…53 All projects are up-to-date for restore.54 PatrickLiu.NetCore.MvcDemo -&gt; /app/build/PatrickLiu.NetCore.MvcDemo.dll55 PatrickLiu.NetCore.MvcDemo -&gt; /app/build/PatrickLiu.NetCore.MvcDemo.Views.dll56 57 Build succeeded.58 0 Warning(s)59 0 Error(s)60 61 Time Elapsed 00:00:19.2162 Removing intermediate container 639b5e3d01df63 —&gt; aeb1df18b3f664 Step 12/17 : FROM build AS publish65 —&gt; aeb1df18b3f666 Step 13/17 : RUN dotnet publish “PatrickLiu.NetCore.MvcDemo.csproj” -c Release -o /app/publish67 —&gt; Running in ac663a5be45568 Microsoft (R) Build Engine version 16.7.0+7fb82e5b2 for .NET69 Copyright (C) Microsoft Corporation. All rights reserved.70 71 Determining projects to restore…72 All projects are up-to-date for restore.73 PatrickLiu.NetCore.MvcDemo -&gt; /src/PatrickLiu.NetCore.MvcDemo/bin/Release/netcoreapp3.1/PatrickLiu.NetCore.MvcDemo.dll74 PatrickLiu.NetCore.MvcDemo -&gt; /src/PatrickLiu.NetCore.MvcDemo/bin/Release/netcoreapp3.1/PatrickLiu.NetCore.MvcDemo.Views.dll75 PatrickLiu.NetCore.MvcDemo -&gt; /app/publish/76 Removing intermediate container ac663a5be45577 —&gt; 6ffbf30a49af78 Step 14/17 : FROM base AS final79 —&gt; acf106867ca080 Step 15/17 : WORKDIR /app81 —&gt; Running in 3dca58d70bef82 Removing intermediate container 3dca58d70bef83 —&gt; 37d1ad5bb22b84 Step 16/17 : COPY –from=publish /app/publish .85 —&gt; 09de2a36645186 Step 17/17 : ENTRYPOINT [“dotnet”, “PatrickLiu.NetCore.MvcDemo.dll”]87 —&gt; Running in 2c41d28e90dc88 Removing intermediate container 2c41d28e90dc89 —&gt; 8bf4c94fbc0490 Successfully built 8bf4c94fbc0491 Successfully tagged core31v1.112:latest 结束了。","categories":[],"tags":[],"author":"张存"},{"title":"Docker-可视化管理工具总结-推荐使用Portainer","slug":"Docker-可视化管理工具总结-推荐使用Portainer","date":"2022-05-09T09:59:36.000Z","updated":"2022-05-09T10:07:49.665Z","comments":true,"path":"2022/05/09/docker-ke-shi-hua-guan-li-gong-ju-zong-jie-tui-jian-shi-yong-portainer/","link":"","permalink":"https://blog.zhangcun.store/2022/05/09/docker-ke-shi-hua-guan-li-gong-ju-zong-jie-tui-jian-shi-yong-portainer/","excerpt":"","text":"对于初学docker的小白，一款好的可视化工具有助于快速掌握docker基本形态和概念，下面针对docker可视化工具做些总结 ui-for-docker#UI For Docker是一个使用Docker Remote API的web接口，目的是提供一个简洁纯净的客户端实现，为了连接和管理Docker； 该工具目前已经无人维护，建议使用下面介绍的portainer docker run -it -d --name docker-web --restart always -p 9000:9000 -v /var/run/docker.sock:/var/run/docker.sock docker.io/uifd/ui-for-docker Portainer#https://www.portainer.io/installation/是一款Docker可视化管理工具，可让您轻松构建和管理 Docker、Docker Swarm、Kubernetes 和 Azure ACI 中的容器。 Portainer 将管理容器的复杂性隐藏在易于使用的 UI 后面。通过消除使用 CLI、编写 YAML 或理解清单的需要，Portainer 使部署应用程序和解决问题变得如此简单，任何人都可以做到 Portainer-架构#Portainer 由两个元素组成：Portainer 服务器和 Portainer 代理。两者都在您现有的容器化基础设施上作为轻量级容器运行。Portainer 代理应该部署到集群中的每个节点，并配置为向 Portainer 服务器容器报告。单个 Portainer 服务器将接受来自任意数量的 Portainer 代理的连接，从而提供从一个集中式界面管理多个集群的能力。为此，Portainer Server 容器需要数据持久性。Portainer 代理是无状态的，数据被传送回 Portainer 服务器容器。 Portainer-安装#运行下面两条命令即可。这些命令会创建一个Portainer专用的卷，然后在8000和9000端口创建容器并运行。 基于本地容器的部署 如果使用Portainer管理本地Docker主机的话，需要绑定/var/run/docker.sock(这里是个知识点，涉及docker 之间通信的问题，以及docker 里运行docker ) $ docker volume create portainer_data$ docker run –name portainer –restart always -d -p 8000:8000 -p 9000:9000 -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer然后在浏览器打开对应地址，就会发现成功运行了。第一次运行的时候需要设置账号，然后选择要管理的Docker主机。 注意：portainer/portainer 是 Portainer v1.24.x 的镜像名，现在已弃用；从 2022 年 1 月开始，Portainer 2.0 的所有新版本都将在 portainer/portainer-ce 中发布 docker run -d -p 8000:8000 -p 9443:9443 –name portainer –restart=always -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer-ce:2.11.1连接到远程容器的部署 docker run -d -p 9000:9000 –name portainer –restart always -v portainer_data:/data portainer/portainer -H tcp://:PS：-H 后面的remote是你想用portainert管理的docker 添加新的容器集群环境# 本机连接方式#只能在创建 Portainer Server 容器时添加本地环境。部署 Portainer 后，您无法添加本地环境 第一次登陆会让选择管理的容器环境，这里可以选择本机，通过挂载/var/run/docker.sock 和docker 守护进程通信（如图所示），关于这部分知识后面会总结分享出来。 之后就可以看到本机上运行的Docker容器了，点击它们还可以进行容器的管理。 左边的条目可以管理卷、创建容器、查看主机信息等等。基本上该有的功能都有了 Remote连接方式#通过该方式，可以将远程机器添加到Portainer服务端，统一管理远程机器上的容器环境 将 Docker Standalone 主机连接到 Portainer 时，可以使用两种方法。您可以通过 TCP 直接连接到 Docker API，也可以在 Docker Standalone 主机上安装 Portainer 代理并通过代理连接。 https://docs.portainer.io/v/ce-2.11/admin/environments/add/docker 1） 通过远程访问TCP：2375端口绑定环境 使用Remote要求被管理的主机开启docker守护线程监听端口可以在/etc/docker/daemon.json中添加如下配置 { “hosts”: [“tcp://0.0.0.0:2375”, “unix:///var/run/docker.sock”]}2） 通过Portainer Agent方式管理docker环境https://docs.portainer.io/v/ce-2.11/start/install/agent/docker/linux使用Agent需要在要监控的主机上创建一个portainer agent容器 docker run -d -p 9001:9001 –name portainer_agent –restart=always -v /var/run/docker.sock:/var/run/docker.sock -v /var/lib/docker/volumes:/var/lib/docker/volumes portainer/agent:2.11.1 3） 通过Portainer Agent方式管理k8s集群环境 在k8s集群上执行以下命令 curl -L https://downloads.portainer.io/portainer-agent-ce211-k8s-nodeport.yaml -o portainer-agent-k8s.yaml; kubectl apply -f portainer-agent-k8s.yaml 在远程k8s集群上部署agent后，在Portainer server 上通过nodeport 或者 targetport 进行服务配置，完成k8s集群的连接配置。 LazyDocker#https://github.com/jesseduffield/lazydocker LazyDocker是基于终端的一个可视化查询工具，支持键盘操作和鼠标点击。相比Portainer来说可能不那么专业，不过对于开发者来说可能反而更加好用了。因为一般开发者都是使用命令行来运行Docker，偶尔需要图形化查看的时候，就可以使用LazyDocker这个工具。 Lazydocker 的具体特性如下： 全视野查看 Docker 或 docker-compose 容器环境的状态 查看容器或服务的日志 查看容器指标的 ascii 图表，这样你会更像个开发者 自定义图表以测量不同指标 附加到容器/服务 重启、删除与重新构建容器/服务 查看给定镜像的祖先图层 修剪占用磁盘空间的容器、镜像或卷 安装LazyDocker也非常简单，运行下面的命令即可。 docker run –rm -it -v /var/run/docker.sock:/var/run/docker.sock -v ~/.config/lazydocker:/.config/jesseduffield/lazydocker \\lazyteam/lazydocker当然如果发现LazyDocker挺好用，准备经常使用的话，还可以把它做成缩写添加到shell配置文件中，这样就可以将它变成一个简单的命令。例如我用的是zsh，就将下面这样添加到.zshrc文件中。以后就可以直接用lzd来调用LazyDocker了。 echo “alias lzd=’docker run –rm -it -v /var/run/docker.sock:/var/run/docker.sock -v ~/.config/lazydocker:/.config/jesseduffield/lazydocker lazyteam/lazydocker’” &gt;&gt; ~/.zshrc 然后就可以在终端中查看Docker容器、镜像和卷的信息了。LazyDocker支持键盘操作和鼠标点击，直接用鼠标点击就可以查看对应信息了 Docker Desktop#Docker Desktop 是 Docker 官方自带的客户端。https://docs.docker.com/desktop/windows/； 如果是windows用户，想在Windows系统上运行docker容器，可以使用； 小结#Portainer 比较适合团队使用，因为他有访问控制。 Lazydocker 属于简单灵活的小工具，如果你不需要复杂的功能，他们比较合适，而且会让你更有程序员的感觉。 Docker Desktop 是 Windows/Mac 安装 Docker 时就有的，管理功能比较简单，在需要简单的集成 Kubernetes 时可以用他。","categories":[],"tags":[],"author":"张存"},{"title":"frp+openvpn+docker实现内网穿透","slug":"frp-openvpn-docker实现内网穿透","date":"2022-05-09T08:59:48.000Z","updated":"2022-05-09T09:00:33.082Z","comments":true,"path":"2022/05/09/frp-openvpn-docker-shi-xian-nei-wang-chuan-tou/","link":"","permalink":"https://blog.zhangcun.store/2022/05/09/frp-openvpn-docker-shi-xian-nei-wang-chuan-tou/","excerpt":"","text":"公网服务器上部署frp服务端假设我们的公网服务器的地址anywebsites.f3322.net，ubuntu 20.04系统，各个端口都可用。 首先准备好frp服务端的配置文件/opt/frps.ini，内容如下 [common] bind_addr = 0.0.0.0 bind_port = 7000 dashboard_addr = 0.0.0.0 # 管理端口 dashboard_port = 7500 dashboard_user = admin dashboard_pwd = admin log_file = ./frps.log log_level = info log_max_days = 3 disable_log_color = false # 客户端连接token token = 12345678 allow_ports = 2000-3000,3001,3003,4000-50000 max_pool_count = 5 max_ports_per_client = 0 subdomain_host = frps.com tcp_mux = true 然后，运行下面的命令，使用docker部署frps的服务端： docker run -d --name=frps \\ --restart=always \\ -v /opt/frps.ini:/etc/frp/frps.ini \\ -p 7000:7000 \\ -p 7001:7001/udp \\ -p 7500:7500 \\ snowdreamtech/frps 该容器暴露出来三个端口：7000端口为frp的服务端口；7500为frp服务端的控制面板，而7001/udp端口是为了接下来部署openvpn预留的端口。 内网机器部署openvpn Github上已经有一份说明非常详细的文档（点此查看），讲的非常简明扼要，接下来我只是简单翻译一下而已。 首先，找个文件夹，新建一份docker-compose.yml的配置文件： version: &#39;2&#39; services: openvpn: cap_add: - NET_ADMIN image: kylemanna/openvpn container_name: openvpn ports: - &quot;1194:1194/udp&quot; restart: always network_mode: &quot;host&quot; volumes: - ./openvpn-data/conf:/etc/openvpn 配置文件中，network_mode:&quot;host&quot; 让openvpn的容器共享宿主机的网络，而不是docker-compose自动创建的openven_default虚拟网络。加了这条命令，外面机器成功登录了openvpn，即可访问内部局域网中的其他机器（否则不可以），然而，也要留意内部局域网中的ip分配与docker-compose默认的网段冲突！！！ 进入该路径，依次运行下面的命令（若出现交互内容，则按照提示输入即可）： 配置文件和证书初始化 docker-compose run --rm openvpn ovpn_genconfig -u udp://VPN.SERVERNAME.COM docker-compose run --rm openvpn ovpn_initpki 修改文件所属权 sudo chown -R $(whoami): ./openvpn-data 启动openvpn服务 docker-compose up -d openvpn 产生客户端认证文件 export CLIENTNAME=&quot;your_client_name&quot; docker-compose run --rm openvpn easyrsa build-client-full $CLIENTNAME nopass docker-compose run --rm openvpn ovpn_getclient $CLIENTNAME &gt; $CLIENTNAME.ovpn 一切操作结束，最后得到一个 $CLIENTNAME.ovpn，拷贝到本地，但仍然需要修改部分内容。需要把文件中remote VPN.SERVERNAME.COM 1194 udp 修改为remote anywebsites.f3322.net 7001 udp。地址自然是我们的公网网址，而端口，需要接下来，在frp的客户端转发到7001/udp。 内网机器部署frp客户端 内网客户端服务器上，准备好配置文件/opt/frpc.ini，内容如下： [common] server_addr = anywebsites.f3322.net server_port = 7000 token = 12345678 [openvpn] type = udp local_ip = 0.0.0.0 local_port = 1194 remote_port = 7001 然后，运行下面的docker命令： docker run --restart=always -d \\ --network host \\ -v /opt/frpc.ini:/etc/frp/frpc.ini \\ --name frpc \\ snowdreamtech/frpc 然后，打开我们服务端的网页控制面板anywebsites.f3322.net:7500： 展开左侧Proxies栏，点中UDP，看到部署的openvpn服务已经成功连接： 此时，将修改后的ovpn配置文件导入本机的openvpn客户端，即可成功登录内网！","categories":[],"tags":[],"author":"张存"},{"title":"使用seccomp强化Docker和Kubernetes安全","slug":"使用seccomp强化Docker和Kubernetes安全","date":"2022-05-09T08:57:43.000Z","updated":"2022-05-09T08:57:51.308Z","comments":true,"path":"2022/05/09/shi-yong-seccomp-qiang-hua-docker-he-kubernetes-an-quan/","link":"","permalink":"https://blog.zhangcun.store/2022/05/09/shi-yong-seccomp-qiang-hua-docker-he-kubernetes-an-quan/","excerpt":"","text":"使用seccomp强化Docker和Kubernetes安全关于容器安全性存在很多误解-许多人认为容器默认情况下是安全的，不幸的是，这不是事实。有很多工具可以帮助您提高容器的安全性，从而也可以提高Docker和Kubernetes的安全性。强化它们的方法之一是应用适当的seccomp配置文件。如果您不知道seccomp它是什么，请继续阅读并了解它是什么以及如何使用它来保护您的Docker和Kubernetes免受安全威胁！ seccomp是什么？如果您使用Docker或Kubernetes已有一段时间，您可能会听说过term seccomp，但是有可能，您还没有真正深入研究这个晦涩的工具，对吗？ 最简单，最容易理解的定义seccomp可能是“系统调用防火墙”。seccomp本质上是一种限制进程可能进行的系统调用的机制，因此可以阻止来自某些IP的数据包，也可以阻止进程向CPU发送系统调用。 太酷了，但是这如何帮助我们使系统更安全？Linux内核有很多syscall（数百个），但是任何给定的进程都不需要它们。但是，如果进程可能受到危害并被诱骗使用其中一些系统调用，则可能会导致整个系统出现严重的安全问题。因此，限制哪个系统调用进程可以大大减少内核的攻击面。 现在，如果您正在运行任何最新的Docker版本（1.10或更高版本），那么您已经在使用seccomp。您可以使用docker info或通过查看来检查该内容/boot/config-*： ~ $ docker info ... Security Options: apparmor seccomp Profile: default # default seccomp profile applied by default ... ~ $ grep SECCOMP /boot/config-$(uname -r) CONFIG_HAVE_ARCH_SECCOMP_FILTER=y CONFIG_SECCOMP_FILTER=y CONFIG_SECCOMP=y 好吧，太好了！我们已经拥有了seccomp，一切都是安全的，我们不需要弄乱任何东西，对吧？嗯，不完全是-您可能有很多理由想要弄脏您的手并深入研究seccomp… 为什么要麻烦创建一个？seccompDocker中的默认配置文件通常可能“足够好”，如果您没有使用它的经验，那么“改进”或自定义它可能不是您时间的最佳选择。但是，出于某些原因，您可能有足够的动力来更改默认seccomp配置文件： 有时会发现安全漏洞。这是不可避免的，进一步限制默认seccomp配置文件可能会降低安全漏洞影响您的应用程序的机会。这样的事件之一是CVE 2016-0728，它允许用户使用keyctl()syscall提升特权。在此事件之后，此系统调用现在已被默认seccomp配置文件阻止，但将来可能会有更多此类漏洞利用… 限制seccomp配置文件的另一个原因是，如果某些子系统存在安全漏洞，攻击者将无法从您的容器中利用它，因为相关的系统调用已被阻止。该子系统可以是依赖项，库或您无法控制的系统的某些部分。您可能也没有办法解决该子系统中的问题，并防止问题被利用，您需要在不同的层（例如，seccomp配置文件）中将其阻止。 当您处理PII数据或构建关键任务应用程序（例如医疗保健或电网中使用的软件）时，潜在的利用和安全漏洞就变得更加重要。在这些情况下，任何一点安全改进措施和自定义seccomp配置文件都是值得的。 除了所有这些特定原因之外，限制容器可以使用的系统调用会限制可以使用的攻击媒介，例如Docker上游镜像中的后门或应用程序中的可利用错误。 自定义配置文件现在，如果我们确定有充分的理由来更改seccomp个人资料，那么我们将如何实际去做呢？编写seccomp过滤器的一种方法是使用Berkeley数据包过滤器（BPF）语言。使用这种语言并不是很简单或不方便。幸运的是，我们不必使用它，而是可以编写由编译为profile的JSON libseccomp。这种配置文件的简单/最小示例如下所示： &#123; &quot;defaultAction&quot;: &quot;SCMP_ACT_ERRNO&quot;, &quot;syscalls&quot;: [ &#123; &quot;names&quot;: [ &quot;accept&quot;, &quot;chown&quot;, &quot;kill&quot;, &quot;mmap&quot;, ... ], &quot;action&quot;: &quot;SCMP_ACT_ALLOW&quot;, &quot;args&quot;: [], &quot;comment&quot;: &quot;&quot;, &quot;includes&quot;: &#123;&#125;, &quot;excludes&quot;: &#123;&#125; &#125; ] &#125; 通常，首选使用白名单而不是黑名单，并明确列出允许系统调用的列表，并禁止其他任何调用。这正是上述配置文件的功能-默认情况下，它将使用「SCMP_ACT_ERRNO」导致「Permission denied」所有系统调用的操作。对于确实要允许的名称，我们列出了它们的名称并指定了「SCMP_ACT_ALLOW」操作。 这些JSON配置文件可以使用很多选项，并且可能变得非常复杂，因此上面的配置文件实际上已被精简到最低限度。要查看真实的配置文件看起来如何，可以在此处查看Dockers配置文件。 现在我们对seccomp配置文件有了更多的了解，让我们玩Docker。不过，在尝试应用任何自定义配置文件之前，让我们先做一点实验并覆盖seccomp默认值： #运行时不使用seccomp配置文件: ~ $ docker run --rm -it --security-opt seccomp=unconfined alpine sh / # 重新启动 工作 #运行默认的seccomp配置文件 ~ $ docker container run --rm -it alpine sh / #重启#不起作用 在上方，我们可以看到如果seccomp完全禁用-任何可用的syscall都会发生什么，这允许容器中的用户（除其他外）重新引导主机。在—security-opt seccomp=... 在此实例中用于禁用seccomp。这也是应用自定义配置文件的方式，因此让我们构建并应用我们自己的自定义配置文件。 这不是一个好主意，从头开始，所以我们将修改现有的docker的个人资料（上面提到的），我们将通过消除制约了一点chmod，fchmod和fchmodat系统调用，从而有效地拒绝向使用chmod命令。这可能不是最合理的更改或“改进”，但出于演示目的，它很好用： ＃使用自定义seccomp配置文件运行（禁止chmod） 〜 $ docker容器运行--rm -it --security-opt seccomp = no-chmod.json alpine sh / ＃ whoami 根 / ＃ chmod 777 -R / etc chmod：/ etc：不允许操作 在此代码段中，我们从中加载自定义配置文件，no-chmod.json然后尝试进行chmod整本/etc。我们可以看到这在容器中导致了什么-在中尝试运行任何chmod结果Operation not permitted。 使用这个简单的“ no chmod”配置文件，很容易选择应阻止的系统调用。但是，总的来说，选择可以阻止或不能阻止的内容并不是那么简单。您可以进行有根据的猜测，但是通过阻塞系统调用可能会阻塞过多而又没有足够的风险，这会阻止您的应用程序正确运行，但还会丢失一些可以并且应该被阻塞的系统调用。 选择阻止哪个系统调用的唯一可行方法是调用跟踪。跟踪系统调用的一种方法是使用strace： ~ $ strace -c -f -S name chmod 2&gt;&amp;1 1&gt;/dev/null | tail -n +3 | head -n -2 | awk &#39;&#123;print $(NF)&#125;&#39; syscall ---------------- access arch_prctl brk close execve fstat mmap mprotect munmap openat pread64 read write 上面的命令为我们提供了命令使用的所有系统调用的列表（chmod在本例中），我们可以从中选择阻止/允许的操作。如果这个strace命令对您来说太复杂了，那么它也strace -c ls将起作用，它会输出一些额外的信息，例如时间和呼叫次数。我们显然不能阻止所有这些操作，因为这会使我们的容器无法使用，因此最好查找所有这些操作，例如使用此syscall表。 那Kubernetes呢？ 在标题和介绍中，我还提到了Kubernetes，但到目前为止，我们仅谈论Docker。那么，seccompKubernetes世界的情况如何？不幸的seccomp是，默认情况下，默认情况下不使用Kubernetes ，因此除了一些非常危险的系统调用之外，系统调用未被过滤。因此，使用Docker，您可以不用配置任何配置文件而只使用默认值，但是在Kubernetes中，实际上并没有阻止某些安全问题被利用的方法。 我们如何“解决”这个问题？这取决于您所使用的Kubernetes的版本-对于1.19之前的版本，您将需要对Pod应用注释。看起来像这样： apiVersion: v1 kind: Pod metadata: name: some-pod labels: app: some-pod annotations: seccomp.security.alpha.kubernetes.io/pod: localhost/profiles/some-profile.json spec: ... 对于1.19（我们将在此处重点介绍）及更高版本，seccomp配置文件是GA功能，您可以使用pod中的seccompProfilesection in securityContext。这样的pod的定义如下所示： apiVersion: v1 kind: Pod metadata: name: some-pod labels: app: some-pod spec: securityContext: seccompProfile: type: Localhost localhostProfile: profiles/some-profile.json containers: ... 现在我们知道了如何在Kubernetes上解决它，现在该进行一些演示了。为此，我们将需要一个集群-在这里，我将使用KinD（Docker中的Kubernetes）来设置最小的本地集群。另外，seccomp在启动集群之前，我们还将需要所有配置文件，因为这些配置文件需要在集群节点上可用。因此，集群本身的定义如下： apiVersion: kind.x-k8s.io/v1alpha4 kind: Cluster nodes: - role: control-plane extraMounts: - hostPath: &quot;./profiles&quot; containerPath: &quot;/var/lib/kubelet/seccomp/profiles&quot; 这定义了单节点群集，该群集将本地profiles目录安装到位于的节点上/var/lib/kubelet/seccomp/profiles。那我们放在这个profiles目录里呢？就本示例而言，我们将使用3个配置文件：Dockers默认配置文件和先前使用的配置文件，另外还有一个所谓的“ audit” “ complain”配置文件。 我们将从审核配置文件开始。这个不允许/阻止任何系统调用，而只是syslog在某些命令/程序使用它们时将它们记录到日志中。这对于调试和探索应用程序的行为以及查找可能或无法阻止的系统调用都非常有用。此配置文件的定义实际上只是一行，看起来像这样： # ./profiles/audit.json &#123; &quot;defaultAction&quot;: &quot;SCMP_ACT_LOG&quot; &#125; 我们将需要做的另一件事是-显然是pod。该Pod将具有单个Ubuntu容器，该容器将运行ls以触发一些系统调用，然后进入睡眠状态，因此它不会终止并重新启动： # ./pods/audit.yaml apiVersion: v1 kind: Pod metadata: name: audit-seccomp labels: app: audit-seccomp spec: securityContext: seccompProfile: type: Localhost localhostProfile: profiles/audit.json containers: - name: test-container image: ubuntu command: [ &quot;/bin/bash&quot;, &quot;-c&quot;, &quot;--&quot; ] args: [ &quot;ls /; while true; do sleep 30; done;&quot; ] securityContext: allowPrivilegeEscalation: false 顺便说一句，让我们构建集群并应用第一个配置文件： ~ $ tree . . ├── kind.yaml ├── pods │ ├── audit.yaml │ ├── default.yaml │ └── no-chmod.yaml └── profiles ├── audit.json └── no-chmod.json ~ $ kind create cluster --image kindest/node:v1.19.4 --config=kind.yaml ~ $ kubectl apply -f pods/audit.yaml ~ $ tail /var/log/syslog Nov 25 19:38:18 kernel: [461698.749294] audit: ... syscall=21 compat=0 ip=0x7ff8f8412d5b code=0x7ffc0000 # access Nov 25 19:38:18 kernel: [461698.749306] audit: ... syscall=257 compat=0 ip=0x7ff8f8412ec8 code=0x7ffc0000 # openat Nov 25 19:38:18 kernel: [461698.749315] audit: ... syscall=5 compat=0 ip=0x7ff8f8412c99 code=0x7ffc0000 # fstat Nov 25 19:38:18 kernel: [461698.749317] audit: ... syscall=9 compat=0 ip=0x7ff8f84130e6 code=0x7ffc0000 # mmap Nov 25 19:38:18 kernel: [461698.749323] audit: ... syscall=3 compat=0 ip=0x7ff8f8412d8b code=0x7ffc0000 # close 我们在目录中使用KinD群集定义，pods目录和profiles目录执行上述示例。我们首先使用kind命令从定义中创建集群。然后，我们应用audit-seccomp使用audit.yaml配置文件的容器。最后，我们检查syslog消息以查看audit-seccomppod记录的审核消息。这些消息中的每一个都包含syscall=...，用于指定syscall ID（用于x86_64体系结构），可以将其转换为每行末尾注释中的名称。现在，我们确认它seccomp可以正常工作，我们可以应用真实配置文件（Dockers默认设置）。为此，我们将使用不同的pod： # pods/default.yaml apiVersion: v1 kind: Pod metadata: name: default-seccomp labels: app: default-seccomp spec: securityContext: seccompProfile: type: RuntimeDefault containers: - name: test-container image: r.j3ss.co/amicontained command: [ &quot;/bin/sh&quot;, &quot;-c&quot;, &quot;--&quot; ] args: [ &quot;amicontained&quot; ] securityContext: allowPrivilegeEscalation: false 我们在这里做了一些更改。即，我们更改了seccompProfile指定RuntimeDefault类型的部分，还将映像更改为amicontained，这是一个容器自检工具，它将告诉我们哪些系统调用被阻止，以及一些其他有趣的安全信息。应用此pod后，我们可以在日志中看到以下内容： ~ $ kubectl apply -f pods/default.yaml ~ $ kubectl logs default-seccomp Container Runtime: docker Has Namespaces: pid: true user: false AppArmor Profile: unconfined Capabilities: BOUNDING -&gt; chown dac_override fowner fsetid kill setgid setuid setpcap net_bind_service net_raw sys_chroot mknod audit_write setfcap Seccomp: filtering Blocked Syscalls (61): PTRACE SYSLOG SETPGID SETSID USELIB USTAT SYSFS VHANGUP PIVOT_ROOT _SYSCTL ACCT SETTIMEOFDAY MOUNT UMOUNT2 SWAPON SWAPOFF REBOOT SETHOSTNAME SETDOMAINNAME IOPL IOPERM CREATE_MODULE INIT_MODULE DELETE_MODULE GET_KERNEL_SYMS QUERY_MODULE QUOTACTL NFSSERVCTL GETPMSG PUTPMSG AFS_SYSCALL TUXCALL SECURITY LOOKUP_DCOOKIE CLOCK_SETTIME VSERVER MBIND SET_MEMPOLICY GET_MEMPOLICY KEXEC_LOAD ADD_KEY REQUEST_KEY KEYCTL MIGRATE_PAGES UNSHARE MOVE_PAGES PERF_EVENT_OPEN FANOTIFY_INIT NAME_TO_HANDLE_AT OPEN_BY_HANDLE_AT SETNS PROCESS_VM_READV PROCESS_VM_WRITEV KCMP FINIT_MODULE KEXEC_FILE_LOAD BPF USERFAULTFD PKEY_MPROTECT PKEY_ALLOC PKEY_FREE 这表明Dockers的默认配置文件将阻止上述61个系统调用。如果我们不包括该类型的seccompProfile部分，RuntimeDefault则只有22（如果您对此不信任我，可以自行测试）。我认为这是对安全性的极大改进，实际花费很少。如果我们确定默认值不够好或需要进行一些修改，则可以部署自定义配置文件。在这里，我们将使用“ no chmod”配置文件和以下窗格来证明这一点： # pods/no-chmod.yaml apiVersion: v1 kind: Pod metadata: name: no-chmod-seccomp labels: app: no-chmod-seccomp spec: securityContext: seccompProfile: type: Localhost localhostProfile: profiles/no-chmod.json containers: - name: test-container image: ubuntu command: [ &quot;/bin/bash&quot;, &quot;-c&quot;, &quot;--&quot; ] args: [ &quot;touch test; chmod +x test; while true; do sleep 30; done;&quot; ] securityContext: allowPrivilegeEscalation: false 该pod与之前显示的“审核”pod非常相似。我们只是切换localhostProfile到指向不同的文件，然后将容器args更改为包括chmod命令，以便我们可以看到并确认修改后的seccomp配置文件按预期工作： ~ $ kubectl apply -f pods/no-chmod.yaml ~ $ kubectl logs no-chmod-seccomp chmod: changing permissions of &#39;test&#39;: Operation not permitted 日志显示了预期的结果-seccomp配置文件阻止了chmod对测试文件的尝试并返回Operation not permitted。这表明根据个人喜好或需求调整配置文件非常简单。 不过，在修改这些默认配置文件时请务必小心-如果最终阻塞太多，而pod /容器无法启动，则pod会处于Error状态，但日志中将看不到任何东西，事件中也没有任何用处kubectl describe pod …，因此在调试seccomp相关问题时请记住这一点。 结论 即使在阅读本文之后，修改或创建自己的seccomp配置文件也可能不是您的重中之重。但是，重要的是要意识到这一强大的工具并能够在需要时使用它（例如，在Kubernetes中），因为默认情况下它没有默认实施，而这很容易成为大安全性问题。出于这个原因，我建议-至少-启用“审核”配置文件，以便您可以监视正在使用的syscall并使用该信息稍后创建自己的配置文件或验证默认设置是否适用于您的应用程序。 另外，如果您从本文中删除了任何内容，那么它应该seccomp是重要的安全层，并且永远不要运行容器uncontained。","categories":[],"tags":[],"author":"张存"},{"title":"Linux修改文件句柄数及vm.max_map_count、stack size的大小","slug":"Linux修改文件句柄数及vm-max-map-count、stack-size的大小","date":"2022-05-09T08:50:51.000Z","updated":"2022-05-09T08:50:53.812Z","comments":true,"path":"2022/05/09/linux-xiu-gai-wen-jian-ju-bing-shu-ji-vm-max-map-count-stack-size-de-da-xiao/","link":"","permalink":"https://blog.zhangcun.store/2022/05/09/linux-xiu-gai-wen-jian-ju-bing-shu-ji-vm-max-map-count-stack-size-de-da-xiao/","excerpt":"","text":"一、修改文件句柄数 1.1.查看当前大小 ulimit -a 1.2.临时修改 ulimit -n 4096 1.3.永久修改 vim /etc/security/limits.conf * soft nofile 65536 * hard nofile 65536 重新登录后生效 二、修改max user processes进程数 2.1.临时修改 ulimit -u 65536 2.1.永久修改 vim /etc/security/limits.conf * soft nproc 65536 * hard nproc 65536 三、调整vm.max_map_count的大小 max_map_count文件包含限制一个进程可以拥有的VMA(虚拟内存区域)的数量 报错“max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144]” 3.1.查看当前值 sysctl -a|grep vm.max_map_count 3.2.临时修改 sysctl -w vm.max_map_count=262144 3.3.永久修改 vim /etc/sysctl.conf vm.max_map_count=262144 sysctl -p 1 四、调整stack size的大小 查看：ulimit -a,默认是8192，即8M 临时修改 ulimit -s 1024 永久修改 vi /etc/security/limits.conf * soft stack 1024 * hard stack 1024 五、设置系统所有进程一共可以打开的文件数量 如果安装第一、第二点操作后还是提示文件数量不够，需要修改系统一共可以打开的文件数量 修改/etc/sysctl.conf, 加入 fs.file-max = 6553600 sysctl -p cat /proc/sys/fs/file-max #查看是否生效 六、关于/etc/security/limits.conf的介绍 参考文章： /etc/security/limits.conf 详解与配置 /etc/security/limits.d/的优先级高于/etc/security/limits.conf 用户A如果在/etc/security/limits.conf有配置，当/etc/security/limits.d子目录下配置文件也有用户A的配置时，那么A中某些配置会被覆盖。最终取值是 /etc/security/limits.d 下的配置文件的值 soft，hard和- soft指的是当前系统生效的设置值，软限制也可以理解为警告值。 hard表明系统中所能设定的最大值。soft的限制不能比hard限制高 -表名同时设置了soft和hard的值。 示例 * - nproc 655360 * - nofile 655360","categories":[],"tags":[],"author":"张存"},{"title":"docker容器创建指定网关和网段","slug":"docker容器创建指定网关和网段","date":"2022-05-09T08:44:43.000Z","updated":"2022-05-09T08:46:55.963Z","comments":true,"path":"2022/05/09/docker-rong-qi-chuang-jian-zhi-ding-wang-guan-he-wang-duan/","link":"","permalink":"https://blog.zhangcun.store/2022/05/09/docker-rong-qi-chuang-jian-zhi-ding-wang-guan-he-wang-duan/","excerpt":"","text":"docker容器创建指定网关和网段 创建bridge时手动指定ip $ docker network create -d bridge --gateway 172.200.0.1 --subnet 172.200.0.0/16 demo fb0df58fb29358d1dbe195bd4de97e3962051358da8af3e152c87e61b8852f99 $ docker network ls NETWORK ID NAME DRIVER SCOPE b5edf38686f0 bridge bridge local fb0df58fb293 demo bridge local 7fb13e23576d host host local a262e38c5a52 mybridge bridge local 2f0e239177a2 none null local 查看bridge $ docker network inspect demo [ &#123; &quot;Name&quot;: &quot;demo&quot;, &quot;Id&quot;: &quot;fb0df58fb29358d1dbe195bd4de97e3962051358da8af3e152c87e61b8852f99&quot;, &quot;Created&quot;: &quot;2022-01-19T00:28:51.246647318+08:00&quot;, &quot;Scope&quot;: &quot;local&quot;, &quot;Driver&quot;: &quot;bridge&quot;, &quot;EnableIPv6&quot;: false, &quot;IPAM&quot;: &#123; &quot;Driver&quot;: &quot;default&quot;, &quot;Options&quot;: &#123;&#125;, &quot;Config&quot;: [ &#123; &quot;Subnet&quot;: &quot;172.200.0.0/16&quot;, &quot;Gateway&quot;: &quot;172.200.0.1&quot; &#125; ] &#125;, &quot;Internal&quot;: false, &quot;Attachable&quot;: false, &quot;Ingress&quot;: false, &quot;ConfigFrom&quot;: &#123; &quot;Network&quot;: &quot;&quot; &#125;, &quot;ConfigOnly&quot;: false, &quot;Containers&quot;: &#123;&#125;, &quot;Options&quot;: &#123;&#125;, &quot;Labels&quot;: &#123;&#125; &#125; ] 创建容器 $ docker container run -d --rm --name box --network demo busybox /bin/sh -c &quot;while true; do sleep 3600;done&quot; 9e21176cccbba5a311adc9872202d373c98168c13cee119fd18e029216b81d89","categories":[],"tags":[],"author":"张存"},{"title":"dockerfile ubuntu镜像设置时区错误解决（ubuntu18.04）","slug":"dockerfile-ubuntu镜像设置时区错误解决","date":"2022-05-09T06:07:00.000Z","updated":"2022-05-17T14:26:36.777Z","comments":true,"path":"2022/05/09/dockerfile-ubuntu-jing-xiang-she-zhi-shi-qu-cuo-wu-jie-jue/","link":"","permalink":"https://blog.zhangcun.store/2022/05/09/dockerfile-ubuntu-jing-xiang-she-zhi-shi-qu-cuo-wu-jie-jue/","excerpt":"","text":"只针对ubuntu 之前打镜像时 都是直接在dockerfile 里进行设置 /etc/timezone and /etc/localtime, 打完镜像后，验证测试过业务服务，但是压根没有去验证时间是否正确，这是个不好的行为，还好也没有对业务影响太大，只是对产出日志的时间有2个小时的差距，算是不幸中的万幸吧。 之前的dockerfiel FROM ubuntu:18.04 RUN set -x \\ &amp;&amp; ln -sf /usr/share/zoneinfo/Europe/Amsterdam /etc/localtime \\ &amp;&amp; echo &quot;Europe/Amsterdam&quot; &gt; /etc/timezone \\ 问题发现 启动刚打好的镜像，登录镜像 发现 /etc/timezone 是已经修改对了 cat /etc/timezone Europe/Amsterdam 但是 /etc/localtime 显示的是红的 查看目录提示没有这个目录或文件 root@b033681f4cc2:~# ls /usr/share/zonifo ls: cannot access &#39;/usr/share/zonifo&#39;: No such file or directory 我郁闷了，发现ubuntu:18.04 镜像里压根没有安装 `tzdata`,只能自行安装哈。 解决问题 安装tzdata 有2种方式 tzdata 2018版本开始（如2018d），安装过程中默认采用交互式，即要求输入指定的Geographic area和Time zone，从而必须人工值守进行安装 这个我们在dockerfile 种肯定不想人工去选择赛，上网搜索了一下相关资料，发现挺简单的提前设置 export DEBIAN_FRONTEND=noninteractive 就好 新版 apt方式 FROM ubuntu:18.04 RUN set -x \\ &amp;&amp; export DEBIAN_FRONTEND=noninteractive \\ &amp;&amp; apt-get update \\ &amp;&amp; apt-get install -y tzdata \\ &amp;&amp; ln -sf /usr/share/zoneinfo/Europe/Amsterdam /etc/localtime \\ &amp;&amp; echo &quot;Europe/Amsterdam&quot; &gt; /etc/timezone \\ &amp;&amp; rm -rf /var/lib/apt/lists/* 新版 dpkg方式 需要提前准备 deb 软件包. 1 apt-get update #进行授权，不然下载*.deb 会报错 mkdir -p dpkg &amp;&amp; chown _apt dpkg apt-get download tzdata FROM ubuntu:18.04 COPY dpkg/tzdata_2021a-0ubuntu0.18.04_all.deb /opt RUN set -x \\ &amp;&amp; export DEBIAN_FRONTEND=noninteractive \\ &amp;&amp; dpkg -i /opt/tzdata_2021a-0ubuntu0.18.04_all.deb \\ &amp;&amp; ln -sf /usr/share/zoneinfo/Europe/Amsterdam /etc/localtime \\ &amp;&amp; echo &quot;Europe/Amsterdam&quot; &gt; /etc/timezone \\ &amp;&amp; dpkg-reconfigure --frontend noninteractive tzdata \\ 镜像build 完毕后，执行 run 和exec 进入容器,查看 /etc/localtime 问题解决.","categories":[],"tags":[],"author":"张存"},{"title":"docker 容器重启策略","slug":"docker-容器重启策略","date":"2022-05-09T06:04:06.000Z","updated":"2022-05-09T06:04:11.133Z","comments":true,"path":"2022/05/09/docker-rong-qi-chong-qi-ce-lue/","link":"","permalink":"https://blog.zhangcun.store/2022/05/09/docker-rong-qi-chong-qi-ce-lue/","excerpt":"","text":"--restart= ：参数指定当容器退出时，所采用的各个策略： Docker容器的重启策略如下： no，默认策略，在容器退出时不重启容器 on-failure，在容器非正常退出时（退出状态非0），才会重启容器 on-failure:3，在容器非正常退出时重启容器，最多重启3次 always，在容器退出时总是重启容器 unless-stopped，在容器退出时总是重启容器，但是不考虑在Docker守护进程启动时就已经停止了的容器 如果容器启动时没有设置--restart参数，则通过下面命令进行更新： docker update --restart=unless-stopped pgdb","categories":[],"tags":[],"author":"张存"},{"title":"Dockerfile 时区设置","slug":"Dockerfile-时区设置","date":"2022-05-09T06:02:40.000Z","updated":"2022-05-09T06:02:42.899Z","comments":true,"path":"2022/05/09/dockerfile-shi-qu-she-zhi/","link":"","permalink":"https://blog.zhangcun.store/2022/05/09/dockerfile-shi-qu-she-zhi/","excerpt":"","text":"Dockerfile 时区设置 RUN ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime RUN echo &#39;Asia/Shanghai&#39; &gt;/etc/timezone FROM fiadliel/java8-jre VOLUME /tmp ADD api_h5-0.1.jar app.jar RUN ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime RUN echo &#39;Asia/Shanghai&#39; &gt;/etc/timezone ENTRYPOINT [&quot;java&quot;,&quot;-Djava.security.egd=file:/dev/./urandom&quot;,&quot;-jar&quot;,&quot;/app.jar&quot;] docker已运行容器里的时区修改 ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime 或者 cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime 重启容器即可 # 创建并运行容器，通过 -e TZ=&quot;Asia/Shanghai&quot; 设置时区 docker run -e TZ=&quot;Asia/Shanghai&quot; -d -p 80:80 --name nginx nginx","categories":[],"tags":[],"author":"张存"},{"title":"Ubuntu下安装卸载python3.8的过程","slug":"Ubuntu下安装卸载python3-8的过程","date":"2022-05-09T06:00:26.000Z","updated":"2022-05-09T06:00:30.677Z","comments":true,"path":"2022/05/09/ubuntu-xia-an-zhuang-xie-zai-python3-8-de-guo-cheng/","link":"","permalink":"https://blog.zhangcun.store/2022/05/09/ubuntu-xia-an-zhuang-xie-zai-python3-8-de-guo-cheng/","excerpt":"","text":"一、Python 3.8 安装 在 Ubuntu 16.04 中，python3 的默认版本为 3.5： $ python3 -V Python 3.5.2 本文以在 Ubuntu 16.04 中安装为例，方法同样适用于 Ubuntu 18.04 。 1.通过 Apt 安装Python3.8 Ubuntu 官方 apt 库中还未收录 python 3.8，这里使用 deadsnakes PPA 库安装。 1.1. 安装依赖包 $ sudo apt-get update $ sudo apt-get install software-properties-common 1.2. 添加 deadsnakes PPA 源 $ sudo add-apt-repository ppa:deadsnakes/ppa Press [ENTER] to continue or Ctrl-c to cancel adding it. 1.3. 安装 python 3.8 $ sudo apt-get update $ sudo apt-get install python3.8 $ python3.8 -V Python 3.8.2 2.配置 python3.8 为系统默认 python3 修改默认 python3 会导致打不开 Terminal 等各种问题，建议不要修改。解决方法见 Ubuntu16.04TLS 中终端（Terminal）无法打开的解决办法 2.1. 将 python 各版本添加到 update-alternatives $ which python3.8 /usr/bin/python3.8 $ sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.8 1 $ which python3.5 /usr/bin/python3.5 $ sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.5 2 2.2. 配置 python3 默认指向 python3.8 $ sudo update-alternatives --config python3 There are 2 choices for the alternative python3 (providing /usr/bin/python3). Selection Path Priority Status ------------------------------------------------------------ * 0 /usr/bin/python3.5 2 auto mode 1 /usr/bin/python3.5 2 manual mode 2 /usr/bin/python3.8 1 manual mode Press &lt;enter&gt; to keep the current choice[*], or type selection number: 2 选择/输入 2, 回车。 Python客栈送红包、纸质书 2.3 测试 python 版本 $ python3 -V Python 3.8.2 二、卸载python3.8 1、卸载python3.8 sudo apt-get remove python3.8 2、卸载python3.8及其依赖 sudo apt-get remove --auto-remove python3.8 3、清除python3.8 sudo apt-get purge python3.8 or sudo apt-get purge --auto-remove python3.8 注释： 此方法卸载python比较彻底，所以适合更换python版本时使用。 ——对于既想完全卸载python，又无法接受完全卸载后某些python组件无法使用的童鞋，请慎重！","categories":[],"tags":[],"author":"张存"},{"title":"pip install --no-cache-dir ；pip install --no-cache；docker --no-cache","slug":"pip-install-no-cache-dir-；pip-install-no-cache；docker-no-cache","date":"2022-05-09T05:57:07.000Z","updated":"2022-05-09T05:57:18.454Z","comments":true,"path":"2022/05/09/pip-install-no-cache-dir-pip-install-no-cache-docker-no-cache/","link":"","permalink":"https://blog.zhangcun.store/2022/05/09/pip-install-no-cache-dir-pip-install-no-cache-docker-no-cache/","excerpt":"","text":"docker build -t testXXX . --no-cache可以重新拉取数据，不使用已经存在本地的缓存，数据源改变时有用。 pip的--no-cache-dir和--no-cache也是一样","categories":[],"tags":[],"author":"张存"},{"title":"Centos6.5部署openvpn账号密码方式登录","slug":"Centos6-5部署openvpn账号密码方式登录","date":"2022-05-09T05:55:17.000Z","updated":"2022-05-09T05:55:24.658Z","comments":true,"path":"2022/05/09/centos6-5-bu-shu-openvpn-zhang-hao-mi-ma-fang-shi-deng-lu/","link":"","permalink":"https://blog.zhangcun.store/2022/05/09/centos6-5-bu-shu-openvpn-zhang-hao-mi-ma-fang-shi-deng-lu/","excerpt":"","text":"server端（路由模式）： 一.网络设置 1.开启服务器端路由转发功能 # vi /etc/sysctl.conf net.ipv4.ip_forward = 1 # sysctl -p 2.设置nat转发: 注：保证×××地址池可路由出外网 # iptables -t nat -A POSTROUTING -s 10.8.0.0/24 -o eth0 -j MASQUERAD 3.时间同步： # ntpdate asia.pool.ntp.org 二.安装依赖库 # yum install -y openssl openssl-devel lzo lzo-devel pam pam-devel automake pkgconfig 三.安装openvpn: #yum install openvpn 这里我把我的配置贴出来 [root@localhost /etc/openvpn]$ cat /etc/openvpn/server.conf local 0.0.0.0 port 1194 proto tcp dev tun ca /etc/openvpn/easy-rsa-release-2.x/easy-rsa/2.0/keys/ca.crt cert /etc/openvpn/easy-rsa-release-2.x/easy-rsa/2.0/keys/server.crt key /etc/openvpn/easy-rsa-release-2.x/easy-rsa/2.0/keys/server.key dh /etc/openvpn/easy-rsa-release-2.x/easy-rsa/2.0/keys/dh2048.pem server 10.8.0.0 255.255.255.0 ifconfig-pool-persist /var/log/openvpn/ipp.txt push &quot;route 172.31.0.0 255.255.0.0&quot; client-to-client keepalive 10 120 comp-lzo persist-key persist-tun status openvpn-status.log log /var/log/openvpn.log log-append /var/log/openvpn.log verb 3 client-cert-not-required #不使用客户端证书，使用密码进行验证 username-as-common-name #使用认证用户名，不使用证书 script-security 3 auth-user-pass-verify /etc/openvpn/checkpsw.sh via-env #指定路径，允许登陆的用户名及密码 创建检查账号密码脚本 vim checkpsw.sh #!/bin/sh ########################################################### # checkpsw.sh (C) 2004 Mathias Sundman &lt;mathias@openvpn.se&gt; # # This script will authenticate Open××× users against # a plain text file. The passfile should simply contain # one row per user with the username first followed by # one or more space(s) or tab(s) and then the password. PASSFILE=&quot;/etc/openvpn/psw-file&quot; LOG_FILE=&quot;/var/log/openvpn-password.log&quot; TIME_STAMP=`date &quot;+%Y-%m-%d %T&quot;` ########################################################### if [ ! -r &quot;$&#123;PASSFILE&#125;&quot; ]; then echo &quot;$&#123;TIME_STAMP&#125;: Could not open password file \\&quot;$&#123;PASSFILE&#125;\\&quot; for reading.&quot; &gt;&gt; $&#123;LOG_FILE&#125; exit 1 fi CORRECT_PASSWORD=`awk &#39;!/^;/&amp;&amp;!/^#/&amp;&amp;$1==&quot;&#39;$&#123;username&#125;&#39;&quot;&#123;print $2;exit&#125;&#39; $&#123;PASSFILE&#125;` if [ &quot;$&#123;CORRECT_PASSWORD&#125;&quot; = &quot;&quot; ]; then echo &quot;$&#123;TIME_STAMP&#125;: User does not exist: username=\\&quot;$&#123;username&#125;\\&quot;, password=\\&quot;$&#123;password&#125;\\&quot;.&quot; &gt;&gt; $&#123;LOG_FILE&#125; exit 1 fi if [ &quot;$&#123;password&#125;&quot; = &quot;$&#123;CORRECT_PASSWORD&#125;&quot; ]; then echo &quot;$&#123;TIME_STAMP&#125;: Successful authentication: username=\\&quot;$&#123;username&#125;\\&quot;.&quot; &gt;&gt; $&#123;LOG_FILE&#125; exit 0 fi echo &quot;$&#123;TIME_STAMP&#125;: Incorrect password: username=\\&quot;$&#123;username&#125;\\&quot;, password=\\&quot;$&#123;password&#125;\\&quot;.&quot; &gt;&gt; $&#123;LOG_FILE&#125; exit 1 四.下载easy-rsa: easy-rsa-release-2.x.zip 网上找到资源，其他的有时候我没有试验成功。 unzip easy-rsa-release-2.x.zip -d /etc/openvpn cd /etc/openvpn/easy-rsa-release-2.x cp easy-rsa ../ cd 2.0/ 编辑 vars [root@localhost /etc/openvpn]$ grep -v &quot;^#&quot; easy-rsa-release-2.x/easy-rsa/2.0/vars| grep -v &quot;^$&quot; export EASY_RSA=&quot;`pwd`&quot; export OPENSSL=&quot;openssl&quot; export PKCS11TOOL=&quot;pkcs11-tool&quot; export GREP=&quot;grep&quot; export KEY_CONFIG=`$EASY_RSA/whichopensslcnf $EASY_RSA` export KEY_DIR=&quot;$EASY_RSA/keys&quot; echo NOTE: If you run ./clean-all, I will be doing a rm -rf on $KEY_DIR export PKCS11_MODULE_PATH=&quot;dummy&quot; export PKCS11_PIN=&quot;dummy&quot; export KEY_SIZE=2048 export CA_EXPIRE=3650 export KEY_EXPIRE=3650 export KEY_COUNTRY=&quot;US&quot; export KEY_PROVINCE=&quot;California&quot; export KEY_CITY=&quot;BJ&quot; export KEY_ORG=&quot;Fort-Funston&quot; export KEY_EMAIL=&quot;dachenc@test.com&quot; export KEY_OU=&quot;MyOrganizationalUnit&quot; export KEY_NAME=&quot;EasyRSA&quot; 保存推迟后给予x权限 chmod +x vars ./vars ./clean-all #清除文件 ./build-ca server #生成服务端 ./build-dh 以上生成文件时都可以一路回车过去 生成的文件在/etc/openvpn/easy-rsa-release-2.x/easy-rsa/2.0/keys文件夹中 将ca.crt拷贝到本地 chkconfig openvpn on /etc/init.d/openvpn restart client配置： https://openvpn.net/index.php/open-source/downloads.html 以上路径下载客户端 Windows版本 安装完毕后将路径中sample-config的client.ovpn拷贝到config文件夹中 编辑config文件夹中的client.ovpn client dev tun proto tcp remote 公网地址 公网端口 resolv-retry infinite nobind persist-key persist-tun ca ca.crt #cert user1.crt #key user1.key comp-lzo verb 3 auth-user-pass 编写密码文件： vi psw-file client1 123456 chmod 777 psw-file chown nobody.nobody psw-file 重新连接客户端 输入用户名密码即可登录","categories":[],"tags":[],"author":"张存"},{"title":"docker-compose环境变量配置","slug":"docker-compose环境变量配置","date":"2022-05-09T05:14:51.000Z","updated":"2022-05-09T05:15:00.871Z","comments":true,"path":"2022/05/09/docker-compose-huan-jing-bian-liang-pei-zhi/","link":"","permalink":"https://blog.zhangcun.store/2022/05/09/docker-compose-huan-jing-bian-liang-pei-zhi/","excerpt":"","text":"变量定义 docker-compose.yml文件中定义MSA_EXTERNAL_DNS_NAME_OR_IP identity-api: environment: - ASPNETCORE_ENVIRONMENT=Development - ASPNETCORE_URLS=http://0.0.0.0:80 - IdentityApiClient=http://$&#123;MSA_EXTERNAL_DNS_NAME_OR_IP&#125;:5105 ports: - &quot;5105:80&quot; 变量赋值 使用.env文件 MSA_EXTERNAL_DNS_NAME_OR_IP为变量名，localhost为具体的值 # docker-compose variable MSA_EXTERNAL_DNS_NAME_OR_IP=localhost 在运行docker-compose命令时，如docker-compose.yml与.env文件在同一目录下。无需指定.env文件路径。如 docker-compose run 如果docker-compose.yml与.env文件不在同一目录下。需要使用–env-file指定文件路径。如 docker run --env-file ./config/.env 如果路径不正确会包如下错误 docker run --env-file ./config/.env ERROR: Could‘t find env file: home/user/./config/.env 使用docker-compose命令 运行docker-compose时，将变量MSA_EXTERNAL_DNS_NAME_OR_IP设置为192.168.1.1 docker-compose run -e MSA_EXTERNAL_DNS_NAME_OR_IP=192.168.1.1","categories":[],"tags":[],"author":"张存"},{"title":"Docker 换国内源","slug":"Docker-换国内源","date":"2022-05-09T05:11:27.000Z","updated":"2022-05-09T05:11:55.174Z","comments":true,"path":"2022/05/09/docker-huan-guo-nei-yuan/","link":"","permalink":"https://blog.zhangcun.store/2022/05/09/docker-huan-guo-nei-yuan/","excerpt":"","text":"Docker 换国内源先创建daemon.json文件，系统默认是没有这个文件。 sudo vim /etc/docker/daemon.json 编辑daemon.json，填入以下内容。 &#123; &quot;registry-mirrors&quot;: [ &quot;https://kfwkfulq.mirror.aliyuncs.com&quot;, &quot;https://2lqq34jg.mirror.aliyuncs.com&quot;, &quot;https://pee6w651.mirror.aliyuncs.com&quot;, &quot;https://registry.docker-cn.com&quot;, &quot;http://hub-mirror.c.163.com&quot; ], &quot;dns&quot;: [&quot;8.8.8.8&quot;,&quot;8.8.4.4&quot;] &#125; 最后重启docker service docker restart","categories":[],"tags":[],"author":"张存"},{"title":"Ubuntu Docker 和 docker-compose安装","slug":"Ubuntu-Docker-和-docker-compose安装","date":"2022-05-09T05:07:38.000Z","updated":"2022-05-09T05:08:39.800Z","comments":true,"path":"2022/05/09/ubuntu-docker-he-docker-compose-an-zhuang/","link":"","permalink":"https://blog.zhangcun.store/2022/05/09/ubuntu-docker-he-docker-compose-an-zhuang/","excerpt":"","text":"一、Ubuntu Docker 1.首先确认Ubuntu已安装CURL 2.使用官方安装脚本自动安装 安装命令如下： curl -fsSL https://get.docker.com | bash -s docker --mirror Aliyun 也可以使用国内 daocloud 一键安装命令： curl -sSL https://get.daocloud.io/docker | sh 二、 Ubuntu docker-compose安装 1.不推荐git路径的下载，太慢了，可参考下列路径 sudo curl -L https://get.daocloud.io/docker/compose/releases/download/1.25.1 /docker-compose-`uname -s`-`uname -m` -o /usr/local/bin/docker-compose 2.添加可执行权限 sudo chmod +x /usr/local/bin/docker-compose","categories":[],"tags":[],"author":"张存"},{"title":"使用docker部署filebeat","slug":"使用docker部署filebeat","date":"2022-05-06T16:41:50.000Z","updated":"2022-05-06T16:42:10.149Z","comments":true,"path":"2022/05/07/shi-yong-docker-bu-shu-filebeat/","link":"","permalink":"https://blog.zhangcun.store/2022/05/07/shi-yong-docker-bu-shu-filebeat/","excerpt":"","text":"filebeat 是有官方docker镜像的，不过用docker search filebeat 无法搜索到 在elastic的官网可以找到下载地址 docker pull docker.elastic.co/beats/filebeat:5.5.1 运行时要把需要收集的日志，和filebeat.yml配置文件挂载到容器里面. filebeat.yml filebeat: prospectors: - input_type: log paths: # 这里是容器内的path - /var/log/command.log json.keys_under_root: true # 使Filebeat解码日志结构化为JSON消息，设置key为输出文档的顶级目录。 如果不需要json格式输出，可以删除这两个json参数 json.overwrite_keys: true # 覆盖其他字段 registry_file: /usr/share/filebeat/data/registry/registry # 这个文件记录日志读取的位置，如果容器重启，可以从记录的位置开始取日志 output: elasticsearch: # 我这里是输出到elasticsearch，也可以输出到logstash index: &quot;rocket&quot; # kibana中的索引 hosts: [&quot;192.168.0.2:9200&quot;] # elasticsearch地址 可以在容器中的 /usr/share/filebeat/filebeat.full.yml 找到yml配置文件的完整参数 配置完成之后启动docker docker run -d --restart=always --name=filebeat -v /var/log/command.log:/var/log/command.log:ro -v /data/filebeat/filebeat.yml:/usr/share/filebeat/filebeat.yml -v /data/filebeat/registry/:/usr/share/filebeat/data/registry/ docker.elastic.co/beats/filebeat:5.5.1 在kibana添加filebeat.yml中的index字段 成功收到数据","categories":[],"tags":[],"author":"张存"},{"title":"jenkins打包前端项目","slug":"jenkins打包前端项目","date":"2022-05-06T16:04:11.000Z","updated":"2022-05-06T16:35:15.968Z","comments":true,"path":"2022/05/07/jenkins-da-bao-qian-duan-xiang-mu/","link":"","permalink":"https://blog.zhangcun.store/2022/05/07/jenkins-da-bao-qian-duan-xiang-mu/","excerpt":"","text":"jenkins部署vue项目 准备工作 1.插件管理 安装插件nodejs 2.全局工具配置 在全局工具配置中找到NodeJS，因为第一次使用Nodejs，选择在jenkins上自动安装，版本可以自己选择 http://nodejs.cn/ 本文选择10.16.0，配置如下图：配置完毕后先选择应用，在选择保存 创建一个自由风格的项目web-test 1.源码管理 选择Git，填写gitlab的URL和秘钥还有对应的分支，配置如下图： 2.构建环境 选择勾选Provide Node &amp; npm bin/ folder to PATH 3.执行shell 在构建中选择执行shell 因为本文测试使用所以jenkins服务器和目标服务器是同一个所以直接执行shell就可以了，如果不是同一个服务器，也可以用rsync命令去传输，或者打包好之后再发送到目标服务器，命令如下图所示： echo $PATH node -v npm -v npm install chromedriver --chromedriver_cdnurl=http://cdn.npm.taobao.org/dist/chromedriver npm install npm run build 执行成功后可以看到控制台输出 我的配置如下 echo $PATH node -v npm -v npm config set proxy null npm cache clean --force npm config set registry https://registry.npm.taobao.org npm i node-sass --sass_binary_site=https://npm.taobao.org/mirrors/node-sass/ npm install npm run build","categories":[],"tags":[],"author":"张存"},{"title":"crontab运行python不生效，但是手动执行正常的问题和解决方案","slug":"crontab运行python不生效，但是手动执行正常的问题和解决方案","date":"2022-05-06T15:51:52.000Z","updated":"2022-05-06T15:51:55.415Z","comments":true,"path":"2022/05/06/crontab-yun-xing-python-bu-sheng-xiao-dan-shi-shou-dong-zhi-xing-zheng-chang-de-wen-ti-he-jie-jue-fang-an/","link":"","permalink":"https://blog.zhangcun.store/2022/05/06/crontab-yun-xing-python-bu-sheng-xiao-dan-shi-shou-dong-zhi-xing-zheng-chang-de-wen-ti-he-jie-jue-fang-an/","excerpt":"","text":"crontab运行python不生效，但是手动执行正常的问题和解决方案 linux默认装的是python2.7，安装了其他版本后直接执行没问题，但在crontab里执行不了，需要使用全路径。 使用 whereis python 可以查看python对应版本的执行全路径 ================ 实战示例： */1 * * * * /bin/bash /root/tf/hnffc/do_ffc_lstm_prob.sh ------------------- You have new mail in /var/spool/mail/root提示 查看邮件提示内容： # cat /var/spool/mail/root #!/bin/sh python3 /root/tf/hnffc/ffc_lstm_prob.py 用全路径的方法执行提示找不到模型文件 #!/bin/sh cd /root/tf/hnffc/ nohup python3 ffc_lstm_prob.py &gt;nohup.out 2&gt;&amp;1 &amp; 提示：/root/tf/hnffc/do_ffc_lstm_prob.sh: line 2: python3: command not found #!/bin/sh cd /root/tf/hnffc/ python3 ffc_lstm_prob.py 改成这样也不行，但直接在目录下执行./do_ffc_lstm_prob.sh 没问题的 #!/bin/sh cd /root/tf/hnffc/ /usr/local/bin/python3.6 ffc_lstm_prob.py 用这个python3.6的全路径的终于可以了（使用 whereis python 可以查看python对应版本的执行全路径） 虽然可以执行了，但还是会不断给root用户发邮件提醒 #!/bin/sh cd /root/tf/hnffc/ nohup /usr/local/bin/python3.6 ffc_lstm_prob.py &gt;nohup.out 2&gt;&amp;1 &amp; 改成这样终于不会发邮件提醒了 ------------------- 清除邮件提醒内容命令： cat /dev/null &gt; /var/spool/mail/root","categories":[],"tags":[],"author":"张存"},{"title":"Docker修改容器系统时区","slug":"Docker修改容器系统时区","date":"2022-05-06T15:13:25.000Z","updated":"2022-05-06T15:13:29.708Z","comments":true,"path":"2022/05/06/docker-xiu-gai-rong-qi-xi-tong-shi-qu/","link":"","permalink":"https://blog.zhangcun.store/2022/05/06/docker-xiu-gai-rong-qi-xi-tong-shi-qu/","excerpt":"","text":"下面给大家介绍两种修改容器系统时区的方法有： 1. 在Dockerfile里修改 #设置镜像的时区（不同操作系统命令不一样， 核心思想是在创建镜像时执行系统时区设定命令） ENV TZ=Asia/Shanghai RUN ln -snf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime &amp;&amp; \\ echo &#39;Asia/Shanghai&#39; &gt; /etc/timezone 2. 启动容器时修改 docker run -d \\ -v ~/jenkins_home:/var/jenkins_home \\ -e TZ=Asia/Shanghai \\ -p 7070:8080 \\ -p 5000:5000 \\ --name jenkins \\ jenkins","categories":[],"tags":[],"author":"张存"},{"title":"java.lang.OutOfMemoryError: Java heap space解决方法","slug":"java-lang-OutOfMemoryError-Java-heap-space解决方法","date":"2022-05-06T14:56:11.000Z","updated":"2022-05-06T14:56:13.699Z","comments":true,"path":"2022/05/06/java-lang-outofmemoryerror-java-heap-space-jie-jue-fang-fa/","link":"","permalink":"https://blog.zhangcun.store/2022/05/06/java-lang-outofmemoryerror-java-heap-space-jie-jue-fang-fa/","excerpt":"","text":"//首先检查程序有没有限入死循环 这个问题主要还是由这个问题 java.lang.OutOfMemoryError: Java heap space 引起的。第一次出现这样的的问题以后，引发了其他的问题。在网上一查可能是JAVA的堆栈设置太小的原因。 跟据网上的答案大致有这两种解决方法： 1、设置环境变量 解决方法：手动设置Heap size 修改TOMCAT_HOME/bin/catalina.sh set JAVA_OPTS= -Xms32m -Xmx512m 可以根据自己机器的内存进行更改。 2、java -Xms32m -Xmx800m className 就是在执行JAVA类文件时加上这个参数，其中className是需要执行的确类名。（包括包名） 这个解决问题了。而且执行的速度比没有设置的时候快很多。 如果在测试的时候可能会用Eclispe 这时候就需要在Eclipse -&gt;run -arguments 中的VM arguments 中输入-Xms32m -Xmx800m这个参数就可以了。 后来在Eclilpse中修改了启动参数，在VM arguments 加入了-Xms32m -Xmx800m，问题解决。 一、java.lang.OutOfMemoryError: PermGen space PermGen space的全称是Permanent Generation space,是指内存的永久保存区域, 这块内存主要是被JVM存放Class和Meta信息的,Class在被Loader时就会被放到PermGen space中, 它和存放类实例(Instance)的Heap区域不同,GC(Garbage Collection)不会在主程序运行期对 PermGen space进行清理，所以如果你的应用中有很多CLASS的话,就很可能出现PermGen space错误, 这种错误常见在web服务器对JSP进行pre compile的时候。如果你的WEB APP下都用了大量的第三方jar, 其大小 超过了jvm默认的大小(4M)那么就会产生此错误信息了。 解决方法： 手动设置MaxPermSize大小 修改TOMCAT_HOME/bin/catalina.sh 在“echo &quot;Using CATALINA_BASE: $CATALINA_BASE&quot;”上面加入以下行： JAVA_OPTS=&quot;-server -XX:PermSize=64M -XX:MaxPermSize=128m 建议：将相同的第三方jar文件移置到tomcat/shared/lib目录下，这样可以达到减少jar 文档重复占用内存的目的。 二、java.lang.OutOfMemoryError: Java heap space Heap size 设置 JVM堆的设置是指java程序运行过程中JVM可以调配使用的内存空间的设置.JVM在启动的时候会自动设置Heap size的值， 其初始空间(即-Xms)是物理内存的1/64，最大空间(-Xmx)是物理内存的1/4。可以利用JVM提供的-Xmn -Xms -Xmx等选项可 进行设置。Heap size 的大小是Young Generation 和Tenured Generaion 之和。 提示：在JVM中如果98％的时间是用于GC且可用的Heap size 不足2％的时候将抛出此异常信息。 提示：Heap Size 最大不要超过可用物理内存的80％，一般的要将-Xms和-Xmx选项设置为相同，而-Xmn为1/4的-Xmx值。 解决方法：手动设置Heap size 修改TOMCAT_HOME/bin/catalina.sh 在“echo &quot;Using CATALINA_BASE: $CATALINA_BASE&quot;”上面加入以下行： JAVA_OPTS=&quot;-server -Xms800m -Xmx800m -XX:MaxNewSize=256m&quot; 三、实例，以下给出1G内存环境下java jvm 的参数设置参考： JAVA_OPTS=&quot;-server -Xms800m -Xmx800m -XX:PermSize=64M -XX:MaxNewSize=256m -XX:MaxPermSize=128m -Djava.awt.headless=true &quot; 很大的web工程，用tomcat默认分配的内存空间无法启动，如果不是在myeclipse中启动tomcat可以对tomcat这样设置： TOMCAT_HOME/bin/catalina.bat 中添加这样一句话： set JAVA_OPTS= -Xmx1024M -Xms512M -XX:MaxPermSize=256m 如果要在myeclipse中启动，上述的修改就不起作用了，可如下设置： Myeclipse-&gt;preferences-&gt;myeclipse-&gt;servers-&gt;tomcat-&gt;tomcat×.×-&gt;JDK面板中的 Optional Java VM arguments中添加：-Xmx1024M -Xms512M -XX:MaxPermSize=256m 以上是转贴，但本人遇见的问题是：在myeclipse中启动Tomcat时，提示&quot;ava.lang.OutOfMemoryError: Java heap space&quot;，解决办法就是： Myeclipse-&gt;preferences-&gt;myeclipse-&gt;servers-&gt;tomcat-&gt;tomcat×.×-&gt;JDK面板中的 Optional Java VM arguments中添加：-Xmx1024M -Xms512M -XX:MaxPermSize=256m","categories":[],"tags":[],"author":"张存"},{"title":"mbr和gpt选哪个？","slug":"mbr和gpt选哪个？","date":"2022-05-06T14:52:40.000Z","updated":"2022-05-06T14:53:42.150Z","comments":true,"path":"2022/05/06/mbr-he-gpt-xuan-na-ge/","link":"","permalink":"https://blog.zhangcun.store/2022/05/06/mbr-he-gpt-xuan-na-ge/","excerpt":"","text":"首先不论是MBR还是GPT，都是文件系统的分区方式，只是表示文件在硬盘上的存储方式，这个都由操作系统管理，对用户是完全透明的，所以无论使用哪种，对硬盘都没有任何影响。不过对于总容量小于或等于2TB的硬盘，分区表可以选择MBR，也可以选择GPT。从兼容性考虑的话，一般建议使用MBR分区表就可以满足使用要求了。对于总容量大于2TB的硬盘，必须选择GPT分区表，才能识别所有的硬盘容量。MBR分区表由于自身设计的局限性，最大只能支持2TB的地址空间。对于超过2TB的大硬盘，如果使用MBR分区表，将无法识别和使用2TB后的空间。 MBR分区 MBR的意思是“主引导记录”，是IBM公司早年间提出的。它是存在于磁盘驱动器开始部分的一个特殊的启动扇区。这个扇区包含了已安装的操作系统系统信息，并用一小段代码来启动系统。如果你安装了Windows，其启动信息就放在这一段代码中——如果MBR的信息损坏或误删就不能正常启动Windows，这时候你就需要找一个引导修复软件工具来修复它就可以了。Linux系统中MBR通常会是GRUB加载器。MBR。当一台电脑启动时，它会先启动主板自带的BIOS系统，bios加载MBR，MBR再启动Windows，这就是mbr的启动过程。 GPT分区 GPT的意思是GUID Partition Table，即“全局唯一标识磁盘分区表”。他是另外一种更加先进新颖的磁盘组织方式，一种使用UEFI启动的磁盘组织方式。最开始是为了更好的兼容性，后来因为其更大的支持内存（mbr分区最多支持2T的磁盘），更多的兼容而被广泛使用，特别是苹果的MAC系统全部使用gpt分区。gtp不在有分区的概念，所有CDEF盘都在一段信息中存储。可以简单的理解为更先进但是使用不够广泛的技术。 两者区别 分区：mbr最多支持四个主分区，gpt没有限制。如果你想跑多系统，mbr最多4个而gpt没有限制。 系统：win7只能用mbr分区（也可以但是很麻烦，不建议，下篇文章教你GPT分区安装win7），从Win8开始微软建议你使用gpt。 其它：gpt是由uefi启动的，而uefi是后来才提出的概念，兼容性和稳定性不如bios+mbr。","categories":[],"tags":[],"author":"张存"},{"title":"警告：以“root”用户身份运行pip","slug":"警告：以“root”用户身份运行pip","date":"2022-05-06T11:36:34.000Z","updated":"2022-05-06T11:36:46.534Z","comments":true,"path":"2022/05/06/jing-gao-yi-root-yong-hu-shen-fen-yun-xing-pip/","link":"","permalink":"https://blog.zhangcun.store/2022/05/06/jing-gao-yi-root-yong-hu-shen-fen-yun-xing-pip/","excerpt":"","text":"我正在docker中制作我的pythondjango应用程序的简单图像。但是在构建容器的末尾，它抛出了下一个警告（我正在Ubuntu20.04)上构建它：WARNING: Running pip as the ‘root’ user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead。如果我在映像中的python上安装需求，它为什么会抛出这个警告呢。我正在用sudo docker build -t my_app:1 .建立我的形象。我是否应该担心pip抛出的警告，因为我知道它会破坏我的系统？。这是我的dockerfile FROM python:3.8-slim-buster WORKDIR /app COPY requirements.txt requirements.txt RUN pip install -r requirements.txt COPY . . CMD [&quot;python&quot;, &quot;manage.py&quot;, &quot;runserver&quot;, &quot;0.0.0.0:8000&quot;] 发布于 9 月前 回答 容器的构建方式并没有添加用户，所以一切都是以root用户的身份完成的。 您可以创建一个用户并安装到该用户的主目录，方法如下：； FROM python:3.8.3-alpine RUN pip install --upgrade pip RUN adduser -D myuser USER myuser WORKDIR /home/worker COPY --chown=myuser:myuser requirements.txt requirements.txt RUN pip install --user -r requirements.txt ENV PATH=&quot;/home/myuser/.local/bin:$&#123;PATH&#125;&quot; COPY --chown=myuser:myuser . . CMD [&quot;python&quot;, &quot;manage.py&quot;, &quot;runserver&quot;, &quot;0.0.0.0:8000&quot;]","categories":[],"tags":[],"author":"张存"},{"title":"Docker alpine 设置东八时区","slug":"Docker-alpine-设置东八时区","date":"2022-05-06T09:43:29.000Z","updated":"2022-05-06T09:48:06.129Z","comments":true,"path":"2022/05/06/docker-alpine-she-zhi-dong-ba-shi-qu/","link":"","permalink":"https://blog.zhangcun.store/2022/05/06/docker-alpine-she-zhi-dong-ba-shi-qu/","excerpt":"","text":"FROM alpine:3.8 RUN echo &#39;http://mirrors.ustc.edu.cn/alpine/v3.5/main&#39; &gt; /etc/apk/repositories &amp;&amp; echo &#39;http://mirrors.ustc.edu.cn/alpine/v3.5/community&#39; &gt;&gt;/etc/apk/repositories &amp;&amp; apk update &amp;&amp; apk add tzdata &amp;&amp; ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime &amp;&amp; echo &quot;Asia/Shanghai&quot; &gt; /etc/timezone build docker build --rm --no-cache -t chengloong/demo . run docker run -it chengloong/demo date output Thu Dec 20 20:16:40 CST 2018","categories":[],"tags":[],"author":"张存"},{"title":"docker中批量删除 tag为none的镜像","slug":"docker中批量删除-tag为none的镜像","date":"2022-05-06T09:31:23.000Z","updated":"2022-05-06T09:31:36.934Z","comments":true,"path":"2022/05/06/docker-zhong-pi-liang-shan-chu-tag-wei-none-de-jing-xiang/","link":"","permalink":"https://blog.zhangcun.store/2022/05/06/docker-zhong-pi-liang-shan-chu-tag-wei-none-de-jing-xiang/","excerpt":"","text":"添加定时任务，批量删除tag 为none 的镜像 ，释放磁盘空间 [root@weifeng]:~# crontab -l 00 */4 * * * /usr/bin/docker rmi `docker images|grep none| awk &#39;&#123;print $3&#125;&#39;`","categories":[],"tags":[],"author":"张存"},{"title":"Dockerfile设置时区","slug":"Dockerfile设置时区","date":"2022-05-06T09:30:05.000Z","updated":"2022-05-06T09:30:08.039Z","comments":true,"path":"2022/05/06/dockerfile-she-zhi-shi-qu/","link":"","permalink":"https://blog.zhangcun.store/2022/05/06/dockerfile-she-zhi-shi-qu/","excerpt":"","text":"在docker container 中不能自动识别宿主机的时区，可通过安装tzdata软件包，配置TZ环境变量识别正确时区． 使用tzdata设置时区dpkg-reconfigure tzdata # for ubuntu RUN apt-get update &amp;&amp; apt-get install -y --no-install-recommends tzdata &amp;&amp; rm -rf /var/lib/apt/lists/* ENV TZ Asia/Shanghai # for alpine RUN apk add --no-cache tzdata ENV TZ Asia/Shanghai 当在个性化需求是可在docker run命令或docker-compose文件增加环境变量 -e TZ=Asia/Shanghai(其他时区) 本人测试文件 ubuntu/Dockerfile FROM ubuntu RUN apt update &amp;&amp; apt install -y tzdata ENV TZ Asia/Shanghai WORKDIR /app COPY . /app ENV NAME World alpine/Dockerfile FROM python:3.6-alpine WORKDIR /app COPY . /app ENV NAME World RUN apk add --no-cache tzdata ENV TZ Asia/Shanghai CMD [&quot;python&quot;, &quot;app.py&quot;] 测试用的复制粘贴 docker build -t t-u study_days/docker/ubuntu docker build -t t-a study_days/docker/alpine docker run --entrypoint /bin/sh -it t-a docker run --entrypoint /bin/bash -it t-s # tzdata 设置时区 dpkg-reconfigure tzdata","categories":[],"tags":[],"author":"张存"},{"title":"acme生成通配符ssl证书","slug":"acme生成通配符ssl证书","date":"2022-05-06T09:08:48.000Z","updated":"2022-05-06T09:08:51.768Z","comments":true,"path":"2022/05/06/acme-sheng-cheng-tong-pei-fu-ssl-zheng-shu/","link":"","permalink":"https://blog.zhangcun.store/2022/05/06/acme-sheng-cheng-tong-pei-fu-ssl-zheng-shu/","excerpt":"","text":"acme生成通配符ssl证书 1.安装acme wget https://get.acme.sh | sh 安装完成后的目录在/root/.acme.sh/下面. 直接使用 cd /root/.acme.sh 命令 进入.acme.sh目录. 2.生成SSL证书 这里我们是用 DNS 验证方式。DNS 方式，需要手动在域名上添加一条 txt 解析记录，验证域名所有权。为了避免每次都需要手动解析验证域名所有权，我们使用域名解析商提供的 api 自动添加 txt 记录完成验证，acme.sh 目前支持数十种解析商的自动集成，其中包含阿里云。以阿里云为例，你需要先登录到阿里云账号，生成你自己的 api id 和 api key，它是免费的 (建议开启阿里云【RAM 访问控制】，只给 AliyunDNSFullAccess 权限策略，这样做更安全)。然后执行下面的命令： export Ali_Key=&quot;xxx&quot; &amp;&amp; export Ali_Secret=&quot;xxx&quot; # 因为生成的通配符域名证书中并不包含根域名证书，所以我们要指定根域名。 acme.sh --issue --dns dns_ali -d example.com -d *.example.com 注意：请将 example.com 改为你自己的域名。 3.安装到nginx ./acme.sh --installcert -d example.com \\ --keypath /etc/nginx/ssl/example.com.key \\ --fullchainpath /etc/nginx/ssl/example.com.cer 4.nginx配置 server &#123; listen 443 ssl; server_name example.com; ssl on; ssl_certificate ssl/abc.domain.com.cer; ssl_certificate_key ssl/abc.domain.com.key; location / &#123; proxy_pass http://127.0.0.1:8001; &#125; &#125; # 80端口直接转到443 server &#123; listen 80; server_name example.com; return 301 https://$server_name$request_uri; &#125; 5.更新证书 生成的证书只有30天有效期，所以需要自行更新 5.1手动更新 acme.sh --renew -d example.com --force 5.2自动更新 安装 acme.sh 时会自动创建一个 cronjob，每天定期检查所有证书，如果证书需要更新会自动更新证书。 通过 crontab -l 查看 crontab 任务: 25 0 * * * &quot;/root/.acme.sh&quot;/acme.sh --cron --home &quot;/root/.acme.sh&quot; &gt; /dev/null 如果有该定时任务，则不需要额外配置。 6.移除证书 查看所有证书 acme.sh --list 移除某个证书 acme.sh --remove -d example.com","categories":[],"tags":[],"author":"张存"},{"title":"ubuntu 安装Python2.7 和对应的pip2","slug":"ubuntu-安装Python2-7-和对应的pip2","date":"2022-05-06T09:05:48.000Z","updated":"2022-05-06T09:05:51.067Z","comments":true,"path":"2022/05/06/ubuntu-an-zhuang-python2-7-he-dui-ying-de-pip2/","link":"","permalink":"https://blog.zhangcun.store/2022/05/06/ubuntu-an-zhuang-python2-7-he-dui-ying-de-pip2/","excerpt":"","text":"1，先看看系统中是不是有python2 和pip2 命令 whereis python2.7 #查看系统中所有Python2.7所在的位置 whereis pip2 #查看系统中所有pip2所在的位置 which python2.7 #查看系统默认调用的是哪个位置的Python2.7 which pip2 #查看系统规模人调用的是哪个位置的pip2 2，想要重新安装可以先删除Python2.7 3，安装Python2.7 下载包，去官网，这边下载的是2.7.6版本，自己选就行了 wget http://www.python.org/ftp/python/2.7.6/Python-2.7.6.tar.gz 解压包，安装 tar -zxvf Python-2.7.6.tar.gz cd Python-2.7.6 /configure make &amp;&amp; make install 查看安装是否成功和默认调用的版本 python2 -V python2.7 -V python -V 4，安装pip（对应Python版本） 下载pip 包 https://pypi.org/project/pip/9.0.1/#files 解压，安装： tar -zxvf pip-9.0.1.tar.gz cd pip-9.0.1 python2.7 setup.py install 查看默认pip版本 pip -V pip2 -V 可能会缺少setuptools，让你安装 下载，解压，安装 setuptools工具包 wget http://pypi.python.org/packages/source/s/setuptools/setuptools-0.6c11.tar.gz tar -xvf setuptools-0.6c11.tar.gz cd setuptools-0.6c11 python setup.py build python setup.py install","categories":[],"tags":[],"author":"张存"},{"title":"docker mysql客户端：SSL connection error: error:1425F102:SSL routines: unsupported protocol","slug":"docker-mysql客户端：SSL-connection-error-error-1425F102-SSL-routines-unsupported-protocol","date":"2022-05-06T08:47:41.000Z","updated":"2022-05-06T08:47:48.386Z","comments":true,"path":"2022/05/06/docker-mysql-ke-hu-duan-ssl-connection-error-error-1425f102-ssl-routines-unsupported-protocol/","link":"","permalink":"https://blog.zhangcun.store/2022/05/06/docker-mysql-ke-hu-duan-ssl-connection-error-error-1425f102-ssl-routines-unsupported-protocol/","excerpt":"","text":"docker mysql 客户端报错 [root@1317c0f71d3d /]# mysql -h192.168.102.11 -P3306 -uroot -p123456 mysql: [Warning] Using a password on the command line interface can be insecure. ERROR 2026 (HY000): SSL connection error: error:1425F102:SSL routines:ssl_choose_client_version:unsupported protocol 加上 --ssl-mode=DISABLED 解决问题 [root@1317c0f71d3d /]# mysql -h192.168.102.11 -P3306 -uroot -p123456 --ssl-mode=DISABLED mysql: [Warning] Using a password on the command line interface can be insecure. Welcome to the MySQL monitor. Commands end with ; or \\g. Your MySQL connection id is 43913 Server version: 5.7.27-log MySQL Community Server (GPL) Copyright (c) 2000, 2019, Oracle and/or its affiliates. All rights reserved. Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners. Type &#39;help;&#39; or &#39;\\h&#39; for help. Type &#39;\\c&#39; to clear the current input statement. mysql&gt;","categories":[],"tags":[],"author":"张存"},{"title":"Mysql 进阶查询 (select 语句的高级用法)","slug":"Mysql-进阶查询-select-语句的高级用法","date":"2022-05-06T06:01:02.000Z","updated":"2022-05-06T06:14:34.763Z","comments":true,"path":"2022/05/06/mysql-jin-jie-cha-xun-select-yu-ju-de-gao-ji-yong-fa/","link":"","permalink":"https://blog.zhangcun.store/2022/05/06/mysql-jin-jie-cha-xun-select-yu-ju-de-gao-ji-yong-fa/","excerpt":"","text":"前言 在mysql 中，可以使用SELECT 语句来查询数据，查询数据是指从数据库中根据需求，使用不同的查询方式来获取不同的数据，是使用频率最高，最重要的操作。 今天给大家带来查询语句的高级语法 一、按关键字排序 1、使用order by语句来实现排序 2、排序可针对一个或多个字段 3、ASC：升序，默认排序方式 4、DESC：降序 5、order by的语法结构 select 字段1，字段2 from 表明 order by 字段1 desc|asc，字段2 desc|asc； 6、按单子段排序 按照成绩降序排序 +----------+----------+---------+ | id | name | chengji | +----------+----------+---------+ | 20201001 | lili | 80 | | 20201002 | zhangsan | 85 | | 20201003 | mazi | 90 | +----------+----------+---------+ mysql&gt; mysql&gt; select id,name,chengji from chengji where chengji&gt;50 ordhengji desc; +----------+----------+---------+ | id | name | chengji | +----------+----------+---------+ | 20201003 | mazi | 90 | | 20201002 | zhangsan | 85 | | 20201001 | lili | 80 | +----------+----------+---------+ 3 rows in set (0.01 sec) 按照chengji升序排列 且&gt;50 mysql&gt; select id,name,chengji from chengji where chengji&gt;50 order by chengji asc; +----------+----------+---------+ | id | name | chengji | +----------+----------+---------+ | 20201001 | lili | 80 | | 20201002 | zhangsan | 85 | | 20201003 | mazi | 90 | +----------+----------+---------+ 3 rows in set (0.00 sec) 多字段排序 主参考字段在前面，按照成绩降序，辅助参考字段写在后面，按照ID升序 先比较主参考字段，如果相同再按照辅助字段排序 mysql&gt; select id,name,chengji from chengji where chengji&gt;70 order by chengji desc,id asc; +----------+----------+---------+ | id | name | chengji | +----------+----------+---------+ | 20201003 | mazi | 90 | | 20201002 | zhangsan | 85 | | 20201004 | sisi | 85 | | 20201001 | lili | 80 | +----------+----------+---------+ 4 rows in set (0.00 sec) 二、对结果进行分组 1、使用group by 语句来实现分组 2、通常结合聚合函数一起使用 3、可以按照一个或多个字段对结果进行分组 4、group by 的语法结构 按照成绩进行分组，并进行计数。统计成绩相同的那么数量 mysql&gt; select count(name),chengji from chengji where chengji&gt;79 group by chengji; +-------------+---------+ | count(name) | chengji | +-------------+---------+ | 1 | 80 | | 2 | 85 | | 1 | 90 | +-------------+---------+ 3 rows in set (0.00 sec) 按照上面的排序 在按照降序排列 mysql&gt; select count(name),chengji from chengji where chengji&gt;79 group by chengji desc; +-------------+---------+ | count(name) | chengji | +-------------+---------+ | 1 | 90 | | 2 | 85 | | 1 | 80 | +-------------+---------+ 3 rows in set (0.00 sec) 三、限制结果条目 1、只返回select查询结果的第一行或前几行 2、使用limit 语句限制条目 3、limit 语法结构 select 字段1，字段2 from 表名 limit [offset,] number; offset: 位置偏移量，从0开始 number：返回记录行的最大数目 mysql&gt; select * from chengji; +----------+----------+---------+ | id | name | chengji | +----------+----------+---------+ | 20201001 | lili | 80 | | 20201002 | zhangsan | 85 | | 20201003 | mazi | 90 | | 20201004 | sisi | 85 | +----------+----------+---------+ 4 rows in set (0.00 sec) 只显示前两行 mysql&gt; select id,name,chengji from chengji limit 2; +----------+----------+---------+ | id | name | chengji | +----------+----------+---------+ | 20201001 | lili | 80 | | 20201002 | zhangsan | 85 | +----------+----------+---------+ 2 rows in set (0.00 sec) mysql&gt; select * from chengji; +----------+----------+---------+ | id | name | chengji | +----------+----------+---------+ | 20201001 | lili | 80 | | 20201002 | zhangsan | 85 | | 20201003 | mazi | 90 | | 20201004 | sisi | 85 | +----------+----------+---------+ 4 rows in set (0.00 sec) 限制显示结果，从第2行开始，显示两行 mysql&gt; select id,name,chengji from chengji limit 2,2; +----------+------+---------+ | id | name | chengji | +----------+------+---------+ | 20201003 | mazi | 90 | | 20201004 | sisi | 85 | +----------+------+---------+ 2 rows in set (0.00 sec) 显示前三行 mysql&gt; select id,name,chengji from chengji limit 3; +----------+----------+---------+ | id | name | chengji | +----------+----------+---------+ | 20201001 | lili | 80 | | 20201002 | zhangsan | 85 | | 20201003 | mazi | 90 | +----------+----------+---------+ 3 rows in set (0.00 sec) 四、设置别名 1、使用as语句设置别名，关键字as可shenglue 2、设置别名时，保证不能从库中其他表或字段名称冲突 3、别名的语法结构 字段别名： select 字段 from 表名 as 别名 设置字段的别名、 、mysql&gt; select count(*) as 总行数 from chengji; +-----------+ | 总行数 | +-----------+ | 4 | +-----------+ 1 row in set (0.00 sec) 五、通配符 1、用于替换字符串中的部分字符 2、通常配合like一起使用，并协同where完成查询 3、常用的通配符 %：表示零个，一个或多个即任意字符 _: 表示单个字符 name字段中以z开头的任意记录 mysql&gt; select id,name from chengji where name like &#39;z%&#39;; +----------+----------+ | id | name | +----------+----------+ | 20201002 | zhangsan | +----------+----------+ 1 row in set (0.00 sec) name字段中有‘mazi’，匹配最后的单个字符 mysql&gt; select id,name from chengji where name like &#39;maz_&#39;; +----------+------+ | id | name | +----------+------+ | 20201003 | mazi | +----------+------+ 1 row in set (0.00 sec) ‘hang‘前面一个字符，后面任意多个字符 mysql&gt; select id,name from chengji where name like &#39;_hang%&#39;; +----------+----------+ | id | name | +----------+----------+ | 20201002 | zhangsan | +----------+----------+ 1 row in set (0.00 sec） 六、子查询 1、也称作为内查询或者嵌套查询 2、先于主查询被执行，其结果将作为外层主查询的条件 3、在增删改查中都可以使用子查询 4、支持多层嵌套 5、in 语句用来判断某个值是否在给定的结果集中 查看chengji表的ID是否有（20201001,20201002） mysql&gt; select id,name from chengji where id in(20201001,20201002); +----------+----------+ | id | name | +----------+----------+ | 20201001 | lili | | 20201002 | zhangsan | +----------+----------+ 2 rows in set (0.00 sec) 先进行子查询 是否有chengji&gt;85 有则继续执行 mysql&gt; select id,name from chengji where id in(select id from chengji where chengji&gt;85); +----------+------+ | id | name | +----------+------+ | 20201003 | mazi | +----------+------+ 1 row in set (0.00 sec) 没有则输出无 mysql&gt; select id,name from chengji where id in(select id from chengji where chengji&gt;100); Empty set (0.01 sec) 多层嵌套 select、update、delete都支持多层嵌套 mysql&gt; select * from chengji where id in (select a.id from (select id from chengji where chengji=85) a); +----------+----------+---------+ | id | name | chengji | +----------+----------+---------+ | 20201002 | zhangsan | 85 | | 20201004 | sisi | 85 | +----------+----------+---------+ 2 rows in set (0.00 sec) mysql&gt; 讲chengji表中chengji低于90的赋给临时表a，选择a表中的成绩字段的值进行修改，自身chengji减5 mysql&gt; update chengji set chengji=chengji-5 where id in (select a.id from (select id from chengji where chengji&lt;90) a); Query OK, 3 rows affected (0.00 sec) Rows matched: 3 Changed: 3 Warnings: 0 mysql&gt; select * from chengji -&gt; ; +----------+----------+---------+ | id | name | chengji | +----------+----------+---------+ | 20201001 | lili | 75 | | 20201002 | zhangsan | 80 | | 20201003 | mazi | 90 | | 20201004 | sisi | 80 | +----------+----------+---------+ 4 rows in set (0.00 sec) mysql&gt; delete from chengji where id in(select a.id from (select id from chengji where chengji=90) a); Query OK, 1 row affected (0.01 sec) mysql&gt; select * from chengji; +----------+----------+---------+ | id | name | chengji | +----------+----------+---------+ | 20201001 | lili | 75 | | 20201002 | zhangsan | 80 | | 20201004 | sisi | 80 | +----------+----------+---------+ 3 rows in set (0.00 sec) exit的用法 exists类似于if 后面执行成功前面的语句才会执行 mysql&gt; select name from chengji where exists (select id from chengji where name=&#39;lili&#39;); +----------+ | name | +----------+ | lili | | zhangsan | | sisi | +----------+ 3 rows in set (0.00 sec) exists后面只能加select语句，执行成功前面的才执行，不成功前面不执行。 七、null值 null：真空（什么都没有） &#39;&#39;:还有空气 表示缺失的值 与数字0或空白（spaces）不同 使用is null 或者is not null 进行判断 null值和真空（&#39;&#39;）的区别 空值长度为零，不占空间，null值得长度为null，占用空间 is null无法判断空值 空值使用‘=’或者‘&lt;&gt;’ 来处理 count（）计算是，null会忽略，空值会加入计算 count（）计算时，null会被忽略 mysql&gt; select * from aa; +------+------+--------+ | id | name | fenshu | +------+------+--------+ | 1 | qiqi | 80 | | 2 | sisi | 85 | | 3 | lili | 85 | | 4 | didi | NULL | +------+------+--------+ 4 rows in set (0.00 sec) mysql&gt; select count(fenshu) from aa; +---------------+ | count(fenshu) | +---------------+ | 3 | +---------------+ 1 row in set (0.00 sec) 查询fenshu字段为null的记录 mysql&gt; select * from aa; +------+------+--------+ | id | name | fenshu | +------+------+--------+ | 1 | qiqi | 80 | | 2 | sisi | 85 | | 3 | lili | 85 | | 4 | didi | NULL | | 5 | titi | NULL | | 1 | qiqi | 80 | | 2 | sisi | 85 | | 3 | lili | 85 | | 4 | didi | NULL | | 1 | qiqi | 80 | | 2 | sisi | 85 | | 3 | lili | 85 | | 4 | didi | NULL | | 1 | qiqi | 80 | | 2 | sisi | 85 | | 3 | lili | 85 | | 4 | didi | NULL | | 1 | qiqi | 80 | | 2 | sisi | 85 | | 3 | lili | 85 | | 4 | didi | NULL | | 1 | qiqi | 80 | | 2 | sisi | 85 | | 3 | lili | 85 | | 4 | didi | NULL | | 1 | qiqi | 80 | | 2 | sisi | 85 | | 3 | lili | 85 | | 4 | didi | NULL | +------+------+--------+ 29 rows in set (0.00 sec) mysql&gt; select * from aa where fenshu is null; +------+------+--------+ | id | name | fenshu | +------+------+--------+ | 4 | didi | NULL | | 5 | titi | NULL | | 4 | didi | NULL | | 4 | didi | NULL | | 4 | didi | NULL | | 4 | didi | NULL | | 4 | didi | NULL | | 4 | didi | NULL | +------+------+--------+ 8 rows in set (0.00 sec) 查询fenshu字段不为null的记录 mysql&gt; select * from aa where fenshu is not null; +------+------+--------+ | id | name | fenshu | +------+------+--------+ | 1 | qiqi | 80 | | 2 | sisi | 85 | | 3 | lili | 85 | | 1 | qiqi | 80 | | 2 | sisi | 85 | | 3 | lili | 85 | | 1 | qiqi | 80 | | 2 | sisi | 85 | | 3 | lili | 85 | | 1 | qiqi | 80 | | 2 | sisi | 85 | | 3 | lili | 85 | | 1 | qiqi | 80 | | 2 | sisi | 85 | | 3 | lili | 85 | | 1 | qiqi | 80 | | 2 | sisi | 85 | | 3 | lili | 85 | | 1 | qiqi | 80 | | 2 | sisi | 85 | | 3 | lili | 85 | +------+------+--------+ 21 rows in set (0.00 sec) count计数时 空值也会加入计数 mysql&gt; select * from cc; +------+------+--------+ | id | name | fenshu | +------+------+--------+ | 1 | qiqi | 80 | | 2 | sisi | 85 | | 3 | lili | 85 | | 4 | didi | NULL | | 5 | didi | | +------+------+--------+ 5 rows in set (0.00 sec) mysql&gt; select count(fenshu) from cc; +---------------+ | count(fenshu) | +---------------+ | 4 | +---------------+ 1 row in set (0.00 sec) 八、正则表达式 1、根据指定的匹配模式匹配记录中符合要求的特殊字符 2、使用regexp关键字指定匹配模式 3、常用匹配模式 ①：以特定字符串开头的记录 mysql&gt; select id,name,fenshu from cc where name regexp ‘^z’; ②：以特定字符串结尾的记录 mysql&gt; select id,name,fenshu from cc where name regexp ‘u$’; ③：包含指定字符串的记录 mysql&gt; select id,name,fenshu from cc where name regexp &#39;lili&#39;; +------+------+--------+ | id | name | fenshu | +------+------+--------+ | 3 | lili | 85 | +------+------+--------+ 1 row in set (0.00 sec) mysql&gt; ④、 mysql&gt; select id,name,fenshu from cc where name regexp &#39;l..i&#39;; +------+------+--------+ | id | name | fenshu | +------+------+--------+ | 3 | lili | 85 | +------+------+--------+ 1 row in set (0.00 sec) ⑤、匹配包含或者关系的记录 mysql&gt; select id,name,fenshu from cc where name regexp &#39;li|qi&#39;; +------+------+--------+ | id | name | fenshu | +------+------+--------+ | 1 | qiqi | 80 | | 3 | lili | 85 | +------+------+--------+ 2 rows in set (0.00 sec) ⑥、“*”匹配前面字符的任意多次 正表达式中*代表匹配前面字符任意多次，只写一个*没意义 name字段中匹配l任意多次，则匹配所有 mysql&gt; select * from cc where name regexp &#39;*&#39;; ERROR 1139 (42000): Got error &#39;repetition-operator operand invalid&#39; from regexp mysql&gt; select * from cc where name regexp &#39;l*&#39;; +------+------+--------+ | id | name | fenshu | +------+------+--------+ | 1 | qiqi | 80 | | 2 | sisi | 85 | | 3 | lili | 85 | | 4 | didi | NULL | | 5 | didi | | +------+------+--------+ 5 rows in set (0.00 sec) ⑦、“+”匹配前面字符至少一次 mysql&gt; select * from cc where name regexp ‘z+’; ⑧、匹配指定字符集中的任意一个 mysql&gt; select * from cc where name regexp &#39;^[d-l]&#39;; +------+------+--------+ | id | name | fenshu | +------+------+--------+ | 3 | lili | 85 | | 4 | didi | NULL | | 5 | didi | | +------+------+--------+ 3 rows in set (0.00 sec) 方括号“[]”指定了一个字符集合，只匹配其中的一个字符。“”不仅可以放到左侧，也可以放到方括号内，放到左侧表示以这些字符集内的字符开头，而放到方括号内则表示不在指定的字符集合内的字符。例如“[d-f]”表示除 d、e、f 以外的任何字符。 九、运算符 用于对记录中的字段值进行运算 Mysql 的运算符共有四种，分别是：算术运算符、比较运算符、逻辑运算符和位运算符 1、算术运算符 以select命令来实现最基础的加减乘除运算，具体操作如下 mysql&gt; select 1+2,1-2,1*2,10/2,10%3; +-----+-----+-----+--------+------+ | 1+2 | 1-2 | 1*2 | 10/2 | 10%3 | +-----+-----+-----+--------+------+ | 3 | -1 | 2 | 5.0000 | 1 | +-----+-----+-----+--------+------+ 1 row in set (0.00 sec) 整数相除，出来的结果是浮点型的。 在除法运算和求余数运算中，除数不能为 0，若除数是 0，返回的结果则为 NULL。 需要注意的是，如果有多个运算符，按照先乘除后加减的优先级进行运算。 mysql&gt; select 10/0,10%0; +------+------+ | 10/0 | 10%0 | +------+------+ | NULL | NULL | +------+------+ 1 row in set (0.00 sec) mysql&gt; select 1+2*3; +-------+ | 1+2*3 | +-------+ | 7 | +-------+ 1 row in set (0.00 sec) mysql&gt; select (1+2)*3; +---------+ | (1+2)*3 | +---------+ | 9 | +---------+ 1 row in set (0.00 sec) 注意：某些字符串类型的字段存储的数字型字符串，这些字段在进行算术运算时将会被自动转换为数字的值。如果字符串的开始部分是数字，在转换时将被转换为这个数字。如果是既包含字符又包含数字得的混合字符串，无法转换为数字时，将被转换为 0。 mysql&gt; select 3*&#39;3i&#39; -&gt; ; +--------+ | 3*&#39;3i&#39; | +--------+ | 9 | +--------+ 1 row in set, 1 warning (0.00 sec) mysql&gt; select 3*&#39;i3i&#39;; +---------+ | 3*&#39;i3i&#39; | +---------+ | 0 | +---------+ 1 row in set, 1 warning (0.00 sec) 2、比较运算符 （1） 等于运算符 用来判断数字、字符串和表达式是否相等的，如果相等则返回 1，如果不相等则返回 0。其中字符的比较是根据 ASCII 码来判断的。 ASCII码表转换： 0-48，1-49，…9-57 A-65，B-66 a-97，b-98 mysql&gt; select 1=3,2=&#39;2&#39;,&#39;e&#39;=&#39;e&#39;,&#39;r&#39;=null; +-----+-------+---------+----------+ | 1=3 | 2=&#39;2&#39; | &#39;e&#39;=&#39;e&#39; | &#39;r&#39;=null | +-----+-------+---------+----------+ | 0 | 1 | 1 | NULL | +-----+-------+---------+----------+ 1 row in set (0.00 sec) 比较规则： 如果两者都是整数，则按照整数值进行比较。 如果一个整数一个字符串，则会自动将字符串转换为数字，再进行比较。 如果两者都是字符串，则按照字符串进行比较。 如果两者中至少有一个值是 NULL，则比较的结果是 NULL。 （2） 不等于运算符 不等于号有两种写法，分别是&lt;&gt;或者!=，用于针对数字、字符串和表达式不相等的比较。如果不相等则返回 1，如果相等则返回 0。 需要注意的是不等于运算符不能用于判断 NULL。 mysql&gt; select &#39;ta&#39;!=&#39;tat&#39;,1&lt;&gt;2,2.4&lt;&gt;2,&#39;r&#39;&lt;&gt;null; +-------------+------+--------+-----------+ | &#39;ta&#39;!=&#39;tat&#39; | 1&lt;&gt;2 | 2.4&lt;&gt;2 | &#39;r&#39;&lt;&gt;null | +-------------+------+--------+-----------+ | 1 | 1 | 1 | NULL | +-------------+------+--------+-----------+ 1 row in set (0.00 sec （3） 大于、大于等于、小于、小于等于运算符 注意：都不能用于判断NULL。 mysql&gt; select &#39;a&#39;&lt;&#39;b&#39;,(2+3)&gt;=(4+1),4&gt;4,&#39;p&#39;&gt;null; +---------+--------------+-----+----------+ | &#39;a&#39;&lt;&#39;b&#39; | (2+3)&gt;=(4+1) | 4&gt;4 | &#39;p&#39;&gt;null | +---------+--------------+-----+----------+ | 1 | 1 | 0 | NULL | +---------+--------------+-----+----------+ 1 row in set (0.00 sec) （4） IS NULL、IS NOT NULL IS NULL 判断一个值是否为 NULL，如果为 NULL 返回 1，否则返回 0。 IS NOT NULL 判断一个值是否不为 NULL，如果不为 NULL 返回 1，否则返回 0。 mysql&gt; select &#39;p&#39; is null,null is null,&#39;null&#39; is not null; +-------------+--------------+--------------------+ | &#39;p&#39; is null | null is null | &#39;null&#39; is not null | +-------------+--------------+--------------------+ | 0 | 1 | 1 | +-------------+--------------+--------------------+ 1 row in set (0.00 sec) &#39;null&#39;是字符串，不是null （5） between and 用于判断一个值是否落在某两个值之间 例如，判断某数字是否在另外两个数字之间，也可以判断某英文字母是否在另外两个字母之间 mysql&gt; select 15 between 8 and 20,&#39;c&#39; between &#39;d&#39; and &#39;z&#39;; +---------------------+-------------------------+ | 15 between 8 and 20 | &#39;c&#39; between &#39;d&#39; and &#39;z&#39; | +---------------------+-------------------------+ | 1 | 0 | +---------------------+-------------------------+ 1 row in set (0.00 sec) （6） least、greatest LEAST：当有两个或者多个参数时，返回其中的最小值。如果其中一个值为 NULL，则返回结果就为 NULL。 GREATEST：当有两个或者多个参数时，返回其中的最大值。如果其中一个值为 NULL， 则返回结果就为 NULL。 mysql&gt; select least(1,2,3) as zishu,greatest(&#39;j&#39;,&#39;d&#39;,&#39;z&#39;) as max; +-------+-----+ | zishu | max | +-------+-----+ | 1 | z | +-------+-----+ 1 row in set (0.00 sec) mysql&gt; select least(1,2,3,null) as zishu,greatest(&#39;j&#39;,&#39;d&#39;,&#39;z&#39;) as max; +-------+-----+ | zishu | max | +-------+-----+ | NULL | z | +-------+-----+ 1 row in set (0.00 sec) （7） in、not in IN 判断一个值是否在对应的列表中，如果是返回 1，否则返回 0。 NOT IN 判断一个值是否不在对应的列表中，如果不是返回 1，否则返回 0。 mysql&gt; select 3 in (1,3,4),&#39;c&#39; not in (&#39;c&#39;,&#39;d&#39;,&#39;b&#39;); +--------------+--------------------------+ | 3 in (1,3,4) | &#39;c&#39; not in (&#39;c&#39;,&#39;d&#39;,&#39;b&#39;) | +--------------+--------------------------+ | 1 | 0 | +--------------+--------------------------+ 1 row in set (0.00 sec) （8） like、not like LIKE 用来匹配字符串，如果匹配成功则返回 1，反之返回 0；NOT LIKE 正好跟 LIKE 相反。 LIKE 支持两种通配符：’%’ 用于匹配任意数目的字符，而’_’只能匹配一个字符。 mysql&gt; select &#39;zhangsan&#39; like &#39;zh%&#39;,&#39;lisi&#39; like &#39;lis_&#39;,&#39;asc&#39; not like &#39;_sc&#39;; +-----------------------+--------------------+----------------------+ | &#39;zhangsan&#39; like &#39;zh%&#39; | &#39;lisi&#39; like &#39;lis_&#39; | &#39;asc&#39; not like &#39;_sc&#39; | +-----------------------+--------------------+----------------------+ | 1 | 1 | 0 | +-----------------------+--------------------+----------------------+ 1 row in set (0.00 sec) 3.逻辑运算符 又被称为布尔运算符 用来判断表达式的真假 （1）逻辑非 逻辑非将跟在它后面的逻辑测试取反，把真变为假，把假变为真。 如果 NOT 后面的操作数为 0 时，所得值为 1；如果操作数为非 0 时，所得值为 0；如果操作数为 NULL 时，所得值为 NULL。 注意：非0值都是1 mysql&gt; select not 2,! 0,not (5-5),! null; +-------+-----+-----------+--------+ | not 2 | ! 0 | not (5-5) | ! null | +-------+-----+-----------+--------+ | 0 | 1 | 1 | NULL | +-------+-----+-----------+--------+ 1 row in set (0.00 sec) （2）逻辑与 如果所有值都是真返回 1，否则返回 0。 逻辑与运算只要遇到0就是0 mysql&gt; select 3 and 4,5 &amp;&amp; 0,0 &amp;&amp; null,2 and null; +---------+--------+-----------+------------+ | 3 and 4 | 5 &amp;&amp; 0 | 0 &amp;&amp; null | 2 and null | +---------+--------+-----------+------------+ | 1 | 0 | 0 | NULL | +---------+--------+-----------+------------+ 1 row in set (0.00 sec) （3）逻辑或（最好用or） 逻辑或表示包含的操作数，任意一个为非零值并且不是 NULL 值时，返回 1，否则返回0 mysql&gt; select 2 or 0,3 or 5,0 or 0,0 or null,2 or null; +--------+--------+--------+-----------+-----------+ | 2 or 0 | 3 or 5 | 0 or 0 | 0 or null | 2 or null | +--------+--------+--------+-----------+-----------+ | 1 | 1 | 0 | NULL | 1 | +--------+--------+--------+-----------+-----------+ 1 row in set (0.00 sec) （4）逻辑异或 两个非 NULL 值的操作数，如果两者都是 0 或者都是非 0，则返回 0；如果一个为 0， 另一个为非 0，则返回结果为 1； 当任意一个值为 NULL 时，返回值为 NULL。 mysql&gt; select 0 xor 0,0 xor 1,2 xor 3,3 xor null; +---------+---------+---------+------------+ | 0 xor 0 | 0 xor 1 | 2 xor 3 | 3 xor null | +---------+---------+---------+------------+ | 0 | 1 | 0 | NULL | +---------+---------+---------+------------+ 1 row in set (0.00 sec) 运算总结： and运算，只要碰到0就是0，（非0和null是null） or运算，只要碰到非0值就是1，（0和null是null） 异或运算，只要碰到null都是null 4.位运算符 位运算符实际上是对二进制数进行计算的运算符 mysql&gt; select 12&amp;13,11|12,10^15,3&amp;~1; +-------+-------+-------+------+ | 12&amp;13 | 11|12 | 10^15 | 3&amp;~1 | +-------+-------+-------+------+ | 12 | 15 | 5 | 2 | +-------+-------+-------+------+ 1 row in set (0.00 sec) 位运算方法： 按位与运算 10–》1010 15–》1111 1010 --》10 按位与运算（&amp;），是对应的二进制位都是 1 的，它们的运算结果为 1，否则为 0 按位或运算 10–》1010 15–》1111 1111–》15 按位或运算（|），是对应的二进制位只要是 1 的，它们的运算结果就为 1，否则为 0 按位异或运算 10–》1010 15–》1111 0101–》5 按位异或运算（^），是对应的二进制位不相同时，运算结果 1，否则为 0 按位取反运算 1–》0001 ~1–》1110 5–》0101 0100–》4 按位取反（~），是对应的二进制数逐位反转，即 1 取反后变为 0, 0 取反后变为 1 mysql&gt; select 1&lt;&lt;2,10&gt;&gt;2; +------+-------+ | 1&lt;&lt;2 | 10&gt;&gt;2 | +------+-------+ | 4 | 2 | +------+-------+ 1 row in set (0.00 sec) 按位左移运算 1&lt;&lt;2 1–》0001 按位左移2位，空缺处补0 0100–》4 10&lt;&lt;3 10–》1010 按位左移3位，空缺处补0 1010000–》80 按位右移运算 10&gt;&gt;2 10–》1010 按位右移2位，多余的位数直接删除 0010–》2 15&gt;&gt;2 15–》1111 按位右移2位，多余的位数直接删除 0011–》3 常用的运算符优先级 十、连接查询 通常都是将来自两个或多个表的行结合起来，基于这些表之间的共同字段，进行数据的拼接。 要先确定一个主表作为结果集，然后将其他表的行有选择性的连接到选定的主表结果集上。 使用较多的连接查询包括：内连接、左连接和右连接 1.内连接 在from子句中使用关键字 inner join 来连接多张表，并使用 on子句设置连接条件。 mysql&gt; select info.name,hob.hobbyname from info inner join hob on info.hobby=hob.id; ±---------±-------------+ | name | hobbyname | ±---------±-------------+ | zhangsan | 人工智能 | | zhaosi | 人工智能 | | wangwu | 云计算 | | zhaoliu | 人工智能 | | heiqi | 云计算 | ±---------±-------------+ 内连接是系统默认的表连接，所以在 FROM 子句后可以省略 INNER 关键字，只使用关键字 JOIN。同时有多个表时，也可以连续使用 INNER JOIN 来实现多表的内连接，不过为了更好的性能，建议最好不要超过三个表。 2.外连接 左连接，主表在左边，主表内容会全部显示出来，在从表中没匹配到的以NULL显示出来 右连接，主表在右边，主表内容会全部显示出来，在从表中没匹配到的以NULL显示出来 修改表的结构 alter table old_name rename new_name; --修改表名 alter table test add column add_name varchar(10); --添加表列 alter table test drop column del_name; --删除表列 alter table test modify address char(10) --修改表列类型 # alter table test change address address char(40) alter table test change column address address1 varchar(30)--修改表列名","categories":[],"tags":[],"author":"张存"},{"title":"Elasticsearch- 集群状态查询","slug":"Elasticsearch-集群状态查询","date":"2022-05-06T05:54:20.000Z","updated":"2022-05-06T05:54:22.784Z","comments":true,"path":"2022/05/06/elasticsearch-ji-qun-zhuang-tai-cha-xun/","link":"","permalink":"https://blog.zhangcun.store/2022/05/06/elasticsearch-ji-qun-zhuang-tai-cha-xun/","excerpt":"","text":"1. 查看ES集群健康状态 curl -XGET &#39;http://localhost:8200/_cluster/health?pretty&#39; 结果： &#123; &quot;cluster_name&quot; : &quot;if2c&quot;, &quot;status&quot; : &quot;yellow&quot;, //集群的状态红绿灯，绿：健康，黄：亚健康，红：病态 &quot;timed_out&quot; : false, &quot;number_of_nodes&quot; : 1, //节点数 &quot;number_of_data_nodes&quot; : 1, //数据节点数 &quot;active_primary_shards&quot; : 3, //分片数，3个Index库 &quot;active_shards&quot; : 3, &quot;relocating_shards&quot; : 0, &quot;initializing_shards&quot; : 0, &quot;unassigned_shards&quot; : 3 //未指定节点，配置了复本，仅使用一台机器部署会出现这种情况 &#125; 也可以对具体Index库（一个或者多个库）进行查看健康状态 curl -XGET &#39;http://localhost:8200/_cluster/health/zh?pretty&#39; 一个index库 curl -XGET &#39;http://localhost:8200/_cluster/health/zh,west?pretty&#39; 多个index库 也可以附加一些参数显示更加具体的内容 level=indices, shards, cluster curl -XGET &#39;http://localhost:8200/_cluster/health?level=indices&amp;pretty&#39; curl -XGET &#39;http://localhost:8200/_cluster/health?level=shards&amp;pretty&#39;","categories":[],"tags":[],"author":"张存"},{"title":"ansible 实战 之nginx代理tomcat集群","slug":"ansible-实战-之nginx代理tomcat集群","date":"2022-05-06T05:46:34.000Z","updated":"2022-05-06T05:46:37.954Z","comments":true,"path":"2022/05/06/ansible-shi-zhan-zhi-nginx-dai-li-tomcat-ji-qun/","link":"","permalink":"https://blog.zhangcun.store/2022/05/06/ansible-shi-zhan-zhi-nginx-dai-li-tomcat-ji-qun/","excerpt":"","text":"实验环境： 操作系统 contos7.4 node 192.168.137.130 ansible node1 192.168.137.131 nginx node2 192.168.137.132 tomcatA node3 192.168.137.133 tomcatB 开始 配置主机名解析 [root@node /]# vi /etc/hosts 192.168.137.130 node.cwf.com node 192.168.137.131 node1.cwf.com node1 192.168.137.132 node2.cwf.com node2 192.168.137.133 node3.cwf.com node3 配置主机将秘钥认证通信 ssh-keygen -t rsa -P &quot;&quot; ssh-copy-id -i ~/.ssh/id_rsa.pub node1 … 安装ansible yum -y install ansible -y 1 添加主机到主机清单文件中 [root@node /]# vi /etc/ansible/hosts [lb] node1 [tomcat] node2 node3 node3 查看主机清单主机的可用主机 [root@node /]# ansible all --list-hosts hosts (3): node1 node2 node3 [root@node /]# ansible lb --list-hosts hosts (1): node1 [root@node /]# ansible tomcat --list-hosts hosts (2): node2 node3 定义roles目录 [root@node /]# mkdir -pv /etc/ansible/roles/&#123;nginx,tomcat,jdk&#125;/&#123;files,templates,tasks,handlers,vars,meta,default&#125; mkdir: created directory ‘/etc/ansible/roles/nginx’ mkdir: created directory ‘/etc/ansible/roles/nginx/files’ mkdir: created directory ‘/etc/ansible/roles/nginx/templates’ mkdir: created directory ‘/etc/ansible/roles/nginx/tasks’ mkdir: created directory ‘/etc/ansible/roles/nginx/handlers’ mkdir: created directory ‘/etc/ansible/roles/nginx/vars’ mkdir: created directory ‘/etc/ansible/roles/nginx/meta’ mkdir: created directory ‘/etc/ansible/roles/nginx/default’ mkdir: created directory ‘/etc/ansible/roles/tomcat’ mkdir: created directory ‘/etc/ansible/roles/tomcat/files’ mkdir: created directory ‘/etc/ansible/roles/tomcat/templates’ mkdir: created directory ‘/etc/ansible/roles/tomcat/tasks’ mkdir: created directory ‘/etc/ansible/roles/tomcat/handlers’ mkdir: created directory ‘/etc/ansible/roles/tomcat/vars’ mkdir: created directory ‘/etc/ansible/roles/tomcat/meta’ mkdir: created directory ‘/etc/ansible/roles/tomcat/default’ mkdir: created directory ‘/etc/ansible/roles/jdk’ mkdir: created directory ‘/etc/ansible/roles/jdk/files’ mkdir: created directory ‘/etc/ansible/roles/jdk/templates’ mkdir: created directory ‘/etc/ansible/roles/jdk/tasks’ mkdir: created directory ‘/etc/ansible/roles/jdk/handlers’ mkdir: created directory ‘/etc/ansible/roles/jdk/vars’ mkdir: created directory ‘/etc/ansible/roles/jdk/meta’ mkdir: created directory ‘/etc/ansible/roles/jdk/default’ 编辑nginx角色的任务文件 [root@node /]# cd /etc/ansible/roles/nginx/ - name: install nginx yum: name=nginx state=latest - name: install conf copy: src=lb.conf dest=/etc/nginx/conf.d/ tags: conf notify: restart nginx - name: start nginx service: name=nginx state=started enabled=yes 编辑handlers触发文件 [root@node nginx]# vim handlers/main.yml - name: restart nginx service: name=nginx state=restarted 定义Nginx的虚拟主机文件 [root@node nginx]# vim files/lb.conf [root@node nginx]# cat files/lb.conf upstream tcsrvs &#123; server node2.cwf.com:8080; server node3.cwf.com:8080; &#125; server &#123; listen 80; server_name node1.cwf.com; location / &#123; proxy_pass http://tcsrvs; &#125; &#125; 配置jdk角色 配置jdk角色的任务文件 [root@node roles]# cd jdk/ [root@node jdk]# ls default files handlers meta tasks templates vars [root@node jdk]# vim tasks/main.yml [root@node jdk]# cat tasks/main.yml - name: install openjdk yum: name=java-&#123;&#123; version &#125;&#125;-openjdk-devel state=latest #&#123;&#123; version &#125;&#125;使用变量 - name: install env file #定义jdk程序的环境文件 copy: src=java.sh dest=/etc/profile.d/ 编辑jdk的程序环境文件 vim files/java.sh export JAVA_HOME=/usr 配置tomcat的角色 编辑tomcat的任务文件 [root@node tomcat]# vim tasks/main.yml - name: install package yum: name=&#123;&#123; item &#125;&#125; state=latest with_items: - tomcat - tomcat-admin-webapps - tomcat-webapps - tomcat-docs-webapp - name: start tomcat service: name=tomcat state=started enabled=yes 编辑playbook样本文件，调用nginx角色 [root@node roles]# vim nginx.yml - hosts: lb remote_user: root roles: - nginx - hosts: tomcat remote_user: root roles: - &#123; role: jdk,version: 1.8.0 &#125; #调用jdk角色及定义version变量 - tomcat 注意 配网络源 本地 源 可能没有 tomcat 的包 执行nginx.yml样本文件 [root@node roles]# ansible-playbook nginx.yml PLAY [lb] ******************************************************************************************************************************* TASK [Gathering Facts] ****************************************************************************************************************** ok: [node1] TASK [nginx : install nginx] ************************************************************************************************************ ok: [node1] TASK [nginx : install conf] ************************************************************************************************************* ok: [node1] TASK [nginx : start nginx] ************************************************************************************************************** ok: [node1] PLAY [tomcat] *************************************************************************************************************************** TASK [Gathering Facts] ****************************************************************************************************************** ok: [node3] ok: [node2] TASK [jdk : install openjdk] ************************************************************************************************************ changed: [node3] changed: [node2] TASK [jdk : install env file] *********************************************************************************************************** ok: [node2] ok: [node3] TASK [tomcat : install package] ********************************************************************************************************* [DEPRECATION WARNING]: Invoking &quot;yum&quot; only once while using a loop via squash_actions is deprecated. Instead of using a loop to supply multiple items and specifying `name: &quot;&#123;&#123; item &#125;&#125;&quot;`, please use `name: [&#39;tomcat&#39;, &#39;tomcat-admin-webapps&#39;, &#39;tomcat-webapps&#39;, &#39;tomcat-docs- webapp&#39;]` and remove the loop. This feature will be removed in version 2.11. Deprecation warnings can be disabled by setting deprecation_warnings=False in ansible.cfg. [DEPRECATION WARNING]: Invoking &quot;yum&quot; only once while using a loop via squash_actions is deprecated. Instead of using a loop to supply multiple items and specifying `name: &quot;&#123;&#123; item &#125;&#125;&quot;`, please use `name: [&#39;tomcat&#39;, &#39;tomcat-admin-webapps&#39;, &#39;tomcat-webapps&#39;, &#39;tomcat-docs- webapp&#39;]` and remove the loop. This feature will be removed in version 2.11. Deprecation warnings can be disabled by setting deprecation_warnings=False in ansible.cfg. changed: [node2] =&gt; (item=[u&#39;tomcat&#39;, u&#39;tomcat-admin-webapps&#39;, u&#39;tomcat-webapps&#39;, u&#39;tomcat-docs-webapp&#39;]) changed: [node3] =&gt; (item=[u&#39;tomcat&#39;, u&#39;tomcat-admin-webapps&#39;, u&#39;tomcat-webapps&#39;, u&#39;tomcat-docs-webapp&#39;]) TASK [tomcat : start tomcat] ************************************************************************************************************ changed: [node2] changed: [node3] PLAY RECAP ****************************************************************************************************************************** node1 : ok=4 changed=0 unreachable=0 failed=0 node2 : ok=5 changed=3 unreachable=0 failed=0 node3 : ok=5 changed=3 unreachable=0 failed=0 浏览器访问 可以 成功 ！！！！！！！！！！！","categories":[],"tags":[],"author":"张存"},{"title":"Ubuntu - 查看磁盘IO情况","slug":"Ubuntu-查看磁盘IO情况","date":"2022-05-06T04:24:19.000Z","updated":"2022-05-06T04:24:53.843Z","comments":true,"path":"2022/05/06/ubuntu-cha-kan-ci-pan-io-qing-kuang/","link":"","permalink":"https://blog.zhangcun.store/2022/05/06/ubuntu-cha-kan-ci-pan-io-qing-kuang/","excerpt":"","text":"安装: sudo apt install sysstat sudo apt install iotop 参考：centos 7 查看磁盘io ，找出占用io读写很高的进程 1. iostat 终端输入： iostat 输出如： 用 iostat 查看磁盘 IO，确认读写负载： iostat -x 1 10 iostat -x 1 10 如图，红色框如果 %util 接近100%，表明I/O请求太多，I/O系统已经满负荷，磁盘可能存在瓶颈. 一般 %util 大于 70，I/O压力就比较大，读取速度有较多的wait，然后再看其他的参数. [1] - rrqm/s: 每秒进行merge的读操作数目，即delta/s [2] - wrqm/s: 每秒进行merge的写操作数目，即delta/s [3] - r/s: 每秒完成的读I/O设备次数，即delta/s [4] - w/s: 每秒完成的写I/0设备次数，即delta/s [5] - rsec/s: 每秒读扇区数，即delta/s [6] - wsec/s: 每秒写扇区数，即delta/s [7] - rKB/s: 每秒读K字节数，是rsec/s的一半，因为每扇区大小为512字节 [8] - wKB/s: 每秒写K字节数，是wsec/s的一半 [9] - avgrq-sz: 平均每次设备I/O操作的数据大小扇区，即delta/delta [10] - avgqu-sz: 平均I/O队列长度，即delta/s/1000因为的单位为毫秒 [11] - await: 平均每次设备I/O操作的等待时间毫秒，即delta/delta [12] - svctm:平均每次设备I/O操作的服务时间毫秒，即delta/delta [13] - %util:一秒中有百分之多少的时间用于I/O操作,或者说一秒中有多少时间I/O队列是非空的 2. iotop 使用 iotop 找出 IO 高的进程： iotop 如： 注： [1] - iotop 可能需要 sudo 运行. [2] - 如果运行出现提示： To run an uninstalled copy of iotop, launch iotop.py in the top directory 解决办法： which iotop #/usr/sbin/iotop vim /usr/sbin/iotop 进行如下编辑： #!/usr/bin/python - old #!/usr/bin/python2 - new","categories":[],"tags":[],"author":"张存"},{"title":"Docker管理面板Portainer中文汉化项目","slug":"Docker管理面板Portainer中文汉化项目","date":"2022-05-06T04:18:14.000Z","updated":"2022-05-06T04:20:14.809Z","comments":true,"path":"2022/05/06/docker-guan-li-mian-ban-portainer-zhong-wen-han-hua-xiang-mu/","link":"","permalink":"https://blog.zhangcun.store/2022/05/06/docker-guan-li-mian-ban-portainer-zhong-wen-han-hua-xiang-mu/","excerpt":"","text":"前言Docker接触了一段时间了，批量操作过程中感觉太繁琐，所以找到了好评率比较高的Portainer面板，使用后感觉的确不错所以准备拿出来精力来做个汉化版，过程中发现词条非常多，所以暂时先汉化部分常用的功能，后面有精力继续汉化完，汉化版本是在1.20.2的基础上做的请熟知。 什么是PortainerPortainer是Docker的图形化管理工具，提供状态显示面板、应用模板快速部署、容器镜像网络数据卷的基本操作（包括上传下载镜像，创建容器等操作）、事件日志显示、容器控制台操作、Swarm集群和服务等集中管理和操作、登录用户管理和控制等功能。功能十分全面，基本能满足中小型单位对容器管理的全部需求。 汉化界面Portainer汉化中文 安装Docker如果已经安装了Docker环境直接跳过本步骤即可 #CentOS 6 rpm -iUvh http://dl.fedoraproject.org/pub/epel/6/x86_64/epel-release-6-8.noarch.rpm yum update -y yum -y install docker-io service docker start chkconfig docker on #CentOS 7、Debian、Ubuntu curl -sSL https://get.docker.com/ | sh systemctl start docker systemctl enable docker.service Portainer中文汉化下载汉化文件 1、新建文件夹命名为 public ，把 Portainer-CN.zip 解压至里面。 2、public 文件夹传输至系统根目录 3、然后按需执行以下命令 x86-64系统使用 docker volume create portainer_data docker run -d -p 9000:9000 -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data -v /public:/public portainer/portainer:1.20.2 ARM64系统使用 docker volume create portainer_data docker run -d -p 9000:9000 -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data -v /public:/public portainer/portainer:linux-arm64-1.20.2 您只需要使用浏览器访问运行Portainer的Docker引擎的端口9000官方安装文档详见 https://www.portainer.io/installation/ 如果遇到错误或者汉化不成功，请停止或者删除Portainer容器，重新覆盖public中的文件，再执行一次RUN命令。","categories":[],"tags":[],"author":"张存"},{"title":"rabbitmq: Management API returned status code 500","slug":"rabbitmq-Management-API-returned-status-code-500","date":"2022-05-06T02:27:20.000Z","updated":"2022-05-06T02:27:59.005Z","comments":true,"path":"2022/05/06/rabbitmq-management-api-returned-status-code-500/","link":"","permalink":"https://blog.zhangcun.store/2022/05/06/rabbitmq-management-api-returned-status-code-500/","excerpt":"","text":"docker启动rabbitmq，浏览器可以正常访问。 打开channel与Exchange模块提示信息： Management API returned status code 500 解决办法： docker进入容器，修改配置，重启容器 docker exec -it [containerId] /bin/bash cd /etc/rabbitmq/conf.d/ ###rabbitmq配置文件 echo management_agent.disable_metrics_collector = false &gt; management_agent.disable_metrics_collector.conf exit docker restart [containerId] 刷新rabbitmq页面","categories":[],"tags":[],"author":"张存"},{"title":"OpenVPN客户端证书合并到配置文件中","slug":"OpenVPN客户端证书合并到配置文件中","date":"2022-05-06T02:19:11.000Z","updated":"2022-05-06T02:22:49.416Z","comments":true,"path":"2022/05/06/openvpn-ke-hu-duan-zheng-shu-he-bing-dao-pei-zhi-wen-jian-zhong/","link":"","permalink":"https://blog.zhangcun.store/2022/05/06/openvpn-ke-hu-duan-zheng-shu-he-bing-dao-pei-zhi-wen-jian-zhong/","excerpt":"","text":"这里只讲OpenVPN客户端证书合并到配置文件中，避免文件太多，管理不便！ 生成的客户端证书和配置文件，客户端需要的一共有5个文件：ca.crt、client.crt、client.key、ta.key(如果不开启tls-auth，则无需该文件)、client.ovpn。 此方法在Linux、Windows、Mac OS下都通用！！ 正式进入主题，合并证书到配置文件中，很简单： 编辑client.ovpn客户端配置文件： vim client.ovpn删除或者注释掉以下几行内容： 在这里我把它们注释掉： ca ca.crt 改为：#ca ca.crt cert client.crt 改为：#cert client.crt key client.key 改为：#key client.key tls-auth ta.key 1 改为：#tls-auth ta.key 1 在最后面添加以下内容： &lt;ca&gt; ca.crt文件内容 &lt;/ca&gt; &lt;cert&gt; client.crt文件内容 &lt;/cert&gt; &lt;key&gt; client.key文件内容 &lt;/key&gt; key-direction 1 &lt;tls-auth&gt; ta.key文件内容 &lt;/tls-auth&gt; 复制各文件里的内容到相应的位置即可！保存退出！！ 然后可以删掉那4个证书文件了，只需要客户端的配置文件这一个即可，到此操作完毕！可以去启动客户端加载配置文件了，一切正常！！","categories":[],"tags":[],"author":"张存"},{"title":"Docker部署rabbitmq遇到的问题","slug":"Docker部署rabbitmq遇到的问题","date":"2022-05-06T02:16:44.000Z","updated":"2022-05-06T02:16:49.744Z","comments":true,"path":"2022/05/06/docker-bu-shu-rabbitmq-yu-dao-de-wen-ti/","link":"","permalink":"https://blog.zhangcun.store/2022/05/06/docker-bu-shu-rabbitmq-yu-dao-de-wen-ti/","excerpt":"","text":"1.背景Docker部署rabbitmq遇到的如下两个问题 问题一：访问交换机时报错 Management API returned status code 500 问题二：访问channel时报错 Stats in management UI are disabled on this node 2.解决方案 [root@ldp03host ~]# clear [root@ldp03host ~]# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES adc292b90f88 rabbitmq &quot;docker-entrypoint.s…&quot; 6 days ago Up 18 hours 4369/tcp, 0.0.0.0:5672-&gt;5672/tcp, :::5672-&gt;5672/tcp, 5671/tcp, 15691-15692/tcp, 25672/tcp, 0.0.0.0:15672-&gt;15672/tcp, :::15672-&gt;15672/tcp rabbit [root@ldp03host ~]# docker exec -it adc292b90f88 /bin/bash root@my-rabbit:/# cd /etc/rabbitmq/conf.d/ root@my-rabbit:/etc/rabbitmq/conf.d# echo management_agent.disable_metrics_collector = false &gt; management_agent.disable_metrics_collector.conf root@my-rabbit:/etc/rabbitmq/conf.d# exit exit [root@ldp03host ~]# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES adc292b90f88 rabbitmq &quot;docker-entrypoint.s…&quot; 6 days ago Up 19 hours 4369/tcp, 0.0.0.0:5672-&gt;5672/tcp, :::5672-&gt;5672/tcp, 5671/tcp, 15691-15692/tcp, 25672/tcp, 0.0.0.0:15672-&gt;15672/tcp, :::15672-&gt;15672/tcp rabbit [root@ldp03host ~]# docker restart adc292b90f88 adc292b90f88 [root@ldp03host ~]# 完美！","categories":[],"tags":[],"author":"张存"},{"title":"Dockerfile使用OracleJDK创建自定义tomcat8镜像","slug":"Dockerfile使用OracleJDK创建自定义tomcat8镜像","date":"2022-05-05T09:27:28.000Z","updated":"2022-05-05T09:29:18.247Z","comments":true,"path":"2022/05/05/dockerfile-shi-yong-oraclejdk-chuang-jian-zi-ding-yi-tomcat8-jing-xiang/","link":"","permalink":"https://blog.zhangcun.store/2022/05/05/dockerfile-shi-yong-oraclejdk-chuang-jian-zi-ding-yi-tomcat8-jing-xiang/","excerpt":"","text":"我们默认下载的tomcat镜像是用的openjdk ，但是我们有些项目必须使用oraclejdk 那就不能使用官方的tomcat镜像，只能重新自定义一个镜像 Dockerfile文件 复制代码 FROM centos:7 #把java与tomcat添加到容器中 ADD jdk-8u161-linux-x64.tar.gz /usr/local/ ADD apache-tomcat-8.5.59.tar.gz /usr/local/ #安装 vim编辑器 RUN yum -y install vim # 设置工作访问时候的WORKDIR路径， 登录落脚点 ENV MYPATH /usr/local/ WORKDIR $MYPATH #配置java与tomcat环境变量 ENV JAVA_HOME /usr/local/jdk1.8.0_161 ENV CLASSPATH $JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar ENV CATALINA_HOME /usr/local/apache-tomcat-8.5.59 ENV CATALINA_BASE /usr/local/apache-tomcat-8.5.59 ENV PATH $PATH:$JAVA_HOME/bin:$CATALINA_HOME/lib:$CATALINA_HOME/bin #容器运行时监听的端口 EXPOSE 8080 # 启动时运行tomcat # ENTRPOINT [&quot;/usr/local/apache-tomcat-8.5.59/bin/startup.sh&quot;] # CMD [&quot;/usr/local/apache-tomcat-8.5.59/bin/catalina.sh&quot;,&quot;run&quot;] CMD /usr/local/apache-tomcat-8.5.59/bin/startup.sh &amp;&amp; tail -f /usr/local/apache-tomcat-8.5.59/logs/catalina.out 复制代码 jdk-8u161-linux-x64.tar.gz 这是jdk1.8的压缩包 apache-tomcat-8.5.59.tar.gz 这是tomcat8的压缩包 下载地址：https://yvioo.lanzoui.com/i851wtevfqf （使用ADD命令会自动解压） 这个可以根据自己的来 但是文件对应的名称也要改 配置完之后 当前目录执行 docker build -t mytomcat8 . 然后启动 docker run -itd -p 9090:8080 --name=&quot;mytomcat8&quot; -v /data/tomcat8/webapps:/usr/local/apache-tomcat-8.5.59/webapps -v /data/tomcat8/logs:/usr/local/apache-tomcat-8.5.59/logs --privileged=true mytomcat8 然后把项目放到 /data/tomcat8/webapps 中 然后访问9090端口 docker-compose.yml写法 复制代码 version: &#39;3&#39; services: tomcat8: build: context: ./tomcat8 #Dockerfile 所在目录 dockerfile: Dockerfile image: tomcat8 container_name: tomcat8 ports: - 9090:8080 network_mode: &quot;host&quot; restart: always privileged: true volumes: - /data/tomcat/webapps:/usr/local/tomcat/webapps - /data/tomcat/logs:/usr/local/tomcat/logs - /data/tomcat/conf:/usr/local/tomcat/conf","categories":[],"tags":[],"author":"张存"},{"title":"Ubuntu20.04安装Mysql","slug":"Ubuntu20-04安装Mysql","date":"2022-05-05T09:15:41.000Z","updated":"2022-05-05T09:18:42.331Z","comments":true,"path":"2022/05/05/ubuntu20-04-an-zhuang-mysql/","link":"","permalink":"https://blog.zhangcun.store/2022/05/05/ubuntu20-04-an-zhuang-mysql/","excerpt":"","text":"如何在Ubuntu 20.04上安装 Mysql 1. Mysql安装 # update the package index on your server if you’ve not done so recently sudo apt update # Then install the mysql-server package sudo apt install mysql-server 2. Mysql配置 sudo mysql_secure_installation 按提示配置root密码，密码等级... ~$ sudo mysql_secure_installation Securing the MySQL server deployment. Connecting to MySQL using a blank password. VALIDATE PASSWORD COMPONENT can be used to test passwords and improve security. It checks the strength of password and allows the users to set only those passwords which are secure enough. Would you like to setup VALIDATE PASSWORD component? Press y|Y for Yes, any other key for No: Please set the password for root here. New password: Re-enter new password: By default, a MySQL installation has an anonymous user, allowing anyone to log into MySQL without having to have a user account created for them. This is intended only for testing, and to make the installation go a bit smoother. You should remove them before moving into a production environment. Remove anonymous users? (Press y|Y for Yes, any other key for No) : ... skipping. Normally, root should only be allowed to connect from &#39;localhost&#39;. This ensures that someone cannot guess at the root password from the network. Disallow root login remotely? (Press y|Y for Yes, any other key for No) : y Success. By default, MySQL comes with a database named &#39;test&#39; that anyone can access. This is also intended only for testing, and should be removed before moving into a production environment. Remove test database and access to it? (Press y|Y for Yes, any other key for No) : ... skipping. Reloading the privilege tables will ensure that all changes made so far will take effect immediately. Reload privilege tables now? (Press y|Y for Yes, any other key for No) : y Success. All done! 3. 创建用户并给权限 以root用户登录mysql sudo mysql 修改密码等级，使能设置简单6位数密码 # 显示当前mysql 密码策略 mysql&gt; SHOW VARIABLES LIKE &#39;validate_password%&#39;; # 设置密码的强度验证等级为LOW mysql&gt; set global validate_password.policy=LOW; # 设置密码长度为6 mysql&gt; set global validate_password.length=6; 创建新用户 # 创建新用户 # 用户名: my_user # Host: %表示支持任意连接，localhost表示只允许本地连接 # 密码: my_password mysql&gt; CREATE USER &#39;my_user&#39;@&#39;%&#39; IDENTIFIED BY &#39;my_password&#39;; # 查询用户 mysql&gt; SELECT user,host FROM mysql.user; #删除用户, 注意默认删除的是&#39;XXX&#39;@&#39;%&#39;这个用户。如果要删除&#39;XXX&#39;@&#39;localhost&#39;， 使用drop删除时需要加上host即drop user &#39;XXX&#39;@&#39;localhost&#39; mysql&gt; drop user my_user; 创建数据库 # 显示现有数据库 mysql&gt; show databases; # 创建数据库 mysql&gt; CREATE DATABASE my_database; 将新创建的数据库与新用户关联，并赋权限 mysql&gt; GRANT ALL PRIVILEGES ON my_database.* to my_user@&#39;%&#39;; # 如果需要给用户创建数据库的权限，则可以这样设置 mysql&gt; GRANT ALL PRIVILEGES ON *.* to my_user@&#39;%&#39;; 保存退出 mysql&gt; FLUSH PRIVILEGES; mysql&gt; exit 新用户登录 # 登录 mysql -u my_user -p # 使用对应数据库 mysql&gt; use my_database; # 显示所有表 mysql&gt; show tables; 3. 遇到的问题 1. ERROR 2003 (HY000): Can&#39;t connect to MySQL server on &#39;127.0.0.1&#39; (111) 解决： 修改配置文件：/etc/mysql/mysql.conf.d/mysqld.cnf， 注释掉 bind-address = 127.0.0.1 #bind-address = 127.0.0.1 重启mysql即可 # 重启mysql sudo service mysql restart # 验证修改是否生效 sudo netstat -tnlp | grep mysqld 4. 其他 免密登录设置 如果需要不用密码直接登录，则需修改/etc/mysql/mysql.conf.d/mysqld.cnf， 添加skip-grant-tables, 重启mysql skip-grant-tables 重启mysql # 重启mysql sudo service mysql restart 验证 mysql -u root -p # 不用输入密码，直接回车（出现Enter Password 也一样直接回车，即可登陆成功","categories":[],"tags":[],"author":"张存"},{"title":"Linux Shell查看物理CPU个数、核数、逻辑CPU个数","slug":"Linux-Shell查看物理CPU个数、核数、逻辑CPU个数","date":"2022-05-05T09:11:14.000Z","updated":"2022-05-05T09:12:14.960Z","comments":true,"path":"2022/05/05/linux-shell-cha-kan-wu-li-cpu-ge-shu-he-shu-luo-ji-cpu-ge-shu/","link":"","permalink":"https://blog.zhangcun.store/2022/05/05/linux-shell-cha-kan-wu-li-cpu-ge-shu-he-shu-luo-ji-cpu-ge-shu/","excerpt":"","text":"Linux Shell常用命令： ====================================== 复制代码#总核数 = 物理CPU个数 X 每颗物理CPU的核数#总逻辑CPU数 = 物理CPU个数 X 每颗物理CPU的核数 X 超线程数 #查看物理CPU个数 cat /proc/cpuinfo| grep &quot;physical id&quot;| sort| uniq| wc -l #查看每个物理CPU中core的个数(即核数) cat /proc/cpuinfo| grep &quot;cpu cores&quot;| uniq #查看逻辑CPU的个数 cat /proc/cpuinfo| grep &quot;processor&quot;| wc -l #查看CPU信息（型号） cat /proc/cpuinfo | grep name | cut -f2 -d: | uniq -c #查看内 存信息 cat /proc/meminfo","categories":[],"tags":[],"author":"张存"},{"title":"set -o vi","slug":"set-o-vi","date":"2022-05-05T09:06:24.000Z","updated":"2022-05-05T09:06:55.994Z","comments":true,"path":"2022/05/05/set-o-vi/","link":"","permalink":"https://blog.zhangcun.store/2022/05/05/set-o-vi/","excerpt":"","text":"大家都知道，shell命令行有两种编辑模式emacs-mode和vi-mode。我个人比较喜欢用vi-mode。这样在敲命令的时候就不用把手移到方向键上去。非常方便。使用 “set -o vi” 启用vi-mode，使用 “set -o emacs” 启用emacs-mode。 但是我今天发现了一件非常奇怪的事情。应该是bash的一个bug。我把 “set -o vi” 写在 /.bashrc 里面（为什么？你懂的），当我打开新的shell时，发现vi-mode不起作用。然后我把 “set -o vi” 从 ~/.bashrc 中注释掉，在开启一个新的shell，手动输入 “set -o vi”，这时候一切正常。经过长时间的反复尝试，最后发现只要是在 ~/.bashrc 里面加上 “set -o vi” 就会让vi-mode永久失效。而emacs-mode总是正常的。汗 莫非bash的开发者和vi的开发者有深仇大恨？？ 后来上网查了下，发现是和 /etc/inputrc 冲突了。具体原因不详。貌似是INPUTRC机制和vi-mode冲突了。欢迎知道的同学解释一下。最后找到两种解决方法。 1. 创建一个空文件 “/.inputrc”，这样能够覆盖 /etc/inputrc 的配置，在 ~/.bashrc 中加入 “set -o vi”。 2. 把 ~/.bashrc 中的 “set -o vi” 注释掉，在 “/.inputrc” 中加入 “set editing-mode vi”。 第一种方法是直接去掉了inputrc的配置，这样可能无法在命令行中输入双字节（如汉字），第二种方法就能完美的保留inputrc的配置并且是bash默认使用vi-mode，方法是复制 /etc/inputrc 到 ~/.inputrc 在执行方法2。 补充：我的操作系统内核是Linux 2.4.30。不知道其他版本的有没有这个问题。 2011/5/27 - 后记：今天好像发现了这个问题的原因了。情况可能是这样的。inputrc中通过其他机制（和”set -o vi”不同的机制，而且这个机制有bug）默认设置了emacs-mode，并覆盖了bashrc中的”set -o vi”。现在看来应该是inputrc机制的开发人员和vi有仇了。下面步骤是比较官方的解决方法： 1. 在bashrc中加入以下代码 set -o vi 2. 在inputrc中加入以下代码 $if mode=vi set editing-mode vi set keymap vi $endif","categories":[],"tags":[],"author":"张存"},{"title":"Linux系统里的加密压缩方式","slug":"Linux系统里的加密压缩方式","date":"2022-05-05T09:04:41.000Z","updated":"2022-05-05T09:04:45.126Z","comments":true,"path":"2022/05/05/linux-xi-tong-li-de-jia-mi-ya-suo-fang-shi/","link":"","permalink":"https://blog.zhangcun.store/2022/05/05/linux-xi-tong-li-de-jia-mi-ya-suo-fang-shi/","excerpt":"","text":"Linux下zip加密压缩 zip -q -r -P password zipfile.zip sourcefiles.txt password 是加密密码 zipfile.zip 是生成的压缩文件 sourcefiles.txt 是被压缩的文件 zip [参数] &lt;压缩包&gt; &lt;源文件&gt; 使用zip格式打包文件 -r 递归，将指定目录下的所有文件和子目录一并处理 -S 包含系统和隐藏文件 -y 直接保存符号连接，而非该连接所指向的文件 -X 不保存额外的文件属性 -m 将文件压缩并加入压缩文件后，删除源文件 -&lt;压缩级别&gt; 1~9，数字越大，压缩率越高 -F 尝试修复已损坏的压缩文件 -T 检查备份文件内的每个文件是否正确无误 -q 不显示指令执行过程 -g 将文件压缩后附加在既有的压缩文件之后，而非另行建立新的压缩文件 -u 更新压缩包内文件 -f 更新压缩包内文件。如果符合条件的文件没有包含在压缩包中，则压缩后添加 -$ 保存第一个被压缩文件所在磁盘的卷标 -j 只保存文件名称及其内容 -D 压缩文件内不建立目录名称 -i &lt;表达式&gt; 压缩目录时，只压缩符合条件的文件 -x &lt;表达式&gt; 排除符合条件的文件 -n &lt;文件名后缀&gt; 排除指定文件名后缀的文件 -b &lt;缓存路径&gt; 指定临时文件目录 -d &lt;表达式&gt; 从压缩文件内删除指定的文件 -t &lt;日期时间&gt; 把压缩文件的日期设成指定的日期 -o 以压缩文件内拥有最新更改时间的文件为准，将压缩文件的更改时间设成和该文件相同 -A 调整可执行的自动解压缩文件 -c 替每个被压缩的文件加上注释 -z 替压缩文件加上注释 -k 使用MS-DOS兼容格式的文件名称。 -l 压缩文件时，把LF字符置换成LF+CR字符。 -ll 压缩文件时，把LF+CR字符置换成LF字符。 举例： 将/home/B linux /html/ 这个目录下所有文件和文件夹打包为当前目录下的html.zip zip -q -r html.zip /home/B linux /html 1 unzip [参数] &lt;压缩文件&gt; [压缩包中将被释放的文件] 解压zip压缩包文件 -P &lt;密码&gt; zip压缩包的密码 -d &lt;路径&gt; 指定解压路径 -n 解压缩时不覆盖原有文件 -f 覆盖原有文件 -o 不经询问，直接覆盖原有文件 -u 覆盖原有文件，并将压缩文件中的其他文件解压缩到目录中 -l 显示压缩文件内所包含的文件 -t 检查压缩文件是否正确 -z 显示压缩包注释 -Z unzip -Z等于执行zipinfo指令 -j 不处理压缩文件中原有的目录路径 -C 压缩文件中的文件名称区分大小写 -L 将压缩文件中的全部文件名改为小写 -s 将文件名中的空格转换下划线 -X 解压缩时保留文件原来的UID/GID -q 执行时不显示任何信息 -v 执行是时显示详细的信息 -c 将解压缩的结果显示到屏幕上，并对字符做适当的转换 -p 与-c参数类似，会将解压缩的结果显示到屏幕上，但不会执行任何的转换 -a 对文本文件进行必要的字符转换 -b 不要对文本文件进行字符转换 -x &lt;表达式&gt; 处理里排除压缩包中的指定文件 -M 将输出结果送到more程序处理","categories":[],"tags":[],"author":"张存"},{"title":"Linux下vm.overcommit_memory的内存分配参数解释（主要是redis服务——redis服务的日志：/var/log/redis_6379.log）","slug":"Linux下vm-overcommit-memory的内存分配参数解释（主要是redis服务——redis服务的日志：-var-log-redis-6379-log）","date":"2022-05-05T09:01:48.000Z","updated":"2022-05-05T09:02:59.527Z","comments":true,"path":"2022/05/05/linux-xia-vm-overcommit-memory-de-nei-cun-fen-pei-can-shu-jie-shi-zhu-yao-shi-redis-fu-wu-redis-fu-wu-de-ri-zhi-var-log-redis-6379-log/","link":"","permalink":"https://blog.zhangcun.store/2022/05/05/linux-xia-vm-overcommit-memory-de-nei-cun-fen-pei-can-shu-jie-shi-zhu-yao-shi-redis-fu-wu-redis-fu-wu-de-ri-zhi-var-log-redis-6379-log/","excerpt":"","text":"背景 公司的redis有时background save db不成功，通过log发现下面的告警，很可能由它引起的： 内核参数overcommit_memory它是 内存分配策略 可选值：0，1，2。 0，：表示内核将检查是否有足够的可用内存供应用进程使用；如果有足够的可用内存，内存申请允许；否则，内存申请失败，并把错误返回给应用进程。1：表示内核允许分配所有的物理内存，而不管当前的内存状态如何。2： 表示内核允许分配超过所有物理内存和交换空间总和的内存。 什么是Overcommit和OOM Linux对大部分申请内存的请求都回复”yes”，以便能跑更多更大的程序。因为申请内存后，并不会马上使用内存。这种技术叫做 Overcommit。当linux发现内存不足时，会发生OOM killer(OOM=out-of-memory)。它会选择杀死一些进程(用户态进程，不是内核线程)，以便释放内存。 当oom-killer发生时，linux会选择杀死哪些进程？选择进程的函数是oom_badness函数(在mm/oom_kill.c中)，该 函数会计算每个进程的点数(0~1000)。点数越高，这个进程越有可能被杀死。每个进程的点数跟oom_score_adj有关，而且 oom_score_adj可以被设置(-1000最低，1000最高)。 解决方法： 很简单，按提示的操作（将vm.overcommit_memory 设为1）即可： 有三种方式修改内核参数，但要有root权限： （1）编辑/etc/sysctl.conf ，改vm.overcommit_memory=1，然后sysctl -p使配置文件生效 #永久的，重启之后，仍然生效 （2）sysctl vm.overcommit_memory=1 或sysctl -w vm.overcommit_memory=1 #临时的，重启之后，又恢复为原来的样子 （3）echo 1 &gt; /proc/sys/vm/overcommit_memory #临时的，重启之后，又恢复为原来的样子","categories":[],"tags":[],"author":"张存"},{"title":"Linux查看物理CPU个数、核数、逻辑CPU个数","slug":"Linux查看物理CPU个数、核数、逻辑CPU个数","date":"2022-05-01T13:58:47.000Z","updated":"2022-05-01T13:59:57.695Z","comments":true,"path":"2022/05/01/linux-cha-kan-wu-li-cpu-ge-shu-he-shu-luo-ji-cpu-ge-shu/","link":"","permalink":"https://blog.zhangcun.store/2022/05/01/linux-cha-kan-wu-li-cpu-ge-shu-he-shu-luo-ji-cpu-ge-shu/","excerpt":"","text":"Linux查看物理CPU个数、核数、逻辑CPU个数#一般情况下使用root或者oracle用户查都可以。 # 总核数 = 物理CPU个数 X 每颗物理CPU的核数 # 总逻辑CPU数 = 物理CPU个数 X 每颗物理CPU的核数 X 超线程数 --查看物理CPU个数 [oracle@enmo ~]$ cat /proc/cpuinfo| grep &quot;physical id&quot;| sort| uniq| wc -l 0 --查看每个物理CPU中core的个数(即核数) cat /proc/cpuinfo| grep &quot;cpu cores&quot;| uniq --查看逻辑CPU的个数 [oracle@enmo ~]$ cat /proc/cpuinfo| grep &quot;processor&quot;| wc -l 1 [oracle@enmo ~]$ --查看CPU信息（型号） [oracle@enmo ~]$ cat /proc/cpuinfo | grep name | cut -f2 -d: | uniq -c 1 Intel(R) Core(TM) i5-5200U CPU @ 2.20GHz [oracle@enmo ~]$ --查看内 存信息 [oracle@enmo ~]$ cat /proc/meminfo MemTotal: 2035908 kB MemFree: 1544564 kB Buffers: 31728 kB Cached: 299544 kB SwapCached: 0 kB Active: 89152 kB Inactive: 293792 kB Active(anon): 54944 kB Inactive(anon): 396 kB Active(file): 34208 kB Inactive(file): 293396 kB Unevictable: 4444 kB Mlocked: 4444 kB SwapTotal: 4192956 kB SwapFree: 4192956 kB Dirty: 0 kB Writeback: 0 kB AnonPages: 56116 kB Mapped: 30028 kB Shmem: 528 kB Slab: 75504 kB SReclaimable: 29204 kB SUnreclaim: 46300 kB KernelStack: 992 kB PageTables: 6800 kB NFS_Unstable: 0 kB Bounce: 0 kB WritebackTmp: 0 kB CommitLimit: 5210908 kB Committed_AS: 180624 kB VmallocTotal: 34359738367 kB VmallocUsed: 157976 kB VmallocChunk: 34359574176 kB HugePages_Total: 0 HugePages_Free: 0 HugePages_Rsvd: 0 HugePages_Surp: 0 Hugepagesize: 2048 kB DirectMap4k: 8192 kB DirectMap2M: 2088960 kB DirectMap1G: 0 kB [oracle@enmo ~]$","categories":[],"tags":[],"author":"张存"},{"title":"Jenkins ：其他项目构建完成后，自动触发我的项目构建","slug":"Jenkins-：其他项目构建完成后，自动触发我的项目构建","date":"2022-04-30T11:40:30.000Z","updated":"2022-04-30T12:05:44.073Z","comments":true,"path":"2022/04/30/jenkins-qi-ta-xiang-mu-gou-jian-wan-cheng-hou-zi-dong-hong-fa-wo-de-xiang-mu-gou-jian/","link":"","permalink":"https://blog.zhangcun.store/2022/04/30/jenkins-qi-ta-xiang-mu-gou-jian-wan-cheng-hou-zi-dong-hong-fa-wo-de-xiang-mu-gou-jian/","excerpt":"","text":"1、先新建一个JOB 2、编辑配置 3、勾选「其他工程构建后触发」 4、填写你的项目名 5、去构建你自己的项目，试试；看看老徐的这个项目是否自动构建","categories":[],"tags":[],"author":"张存"},{"title":"pip install cupy安装缓慢，安装cupy-cuda101 (for CUDA 10.1)代替","slug":"pip-install-cupy安装缓慢，安装cupy-cuda101-for-CUDA-10-1-代替","date":"2022-04-30T11:37:43.000Z","updated":"2022-04-30T11:38:18.524Z","comments":true,"path":"2022/04/30/pip-install-cupy-an-zhuang-huan-man-an-zhuang-cupy-cuda101-for-cuda-10-1-dai-ti/","link":"","permalink":"https://blog.zhangcun.store/2022/04/30/pip-install-cupy-an-zhuang-huan-man-an-zhuang-cupy-cuda101-for-cuda-10-1-dai-ti/","excerpt":"","text":"直接安装cupy会特别的慢，甚至以为卡死了 直接安装对应的cupy-cuda包即可 cupy-cuda101 (for CUDA 10.1) cupy-cuda100 (for CUDA 10.0) cupy-cuda92 (for CUDA 9.2) cupy-cuda91 (for CUDA 9.1) cupy-cuda90 (for CUDA 9.0) cupy-cuda80 (for CUDA 8.0) 比如我用的cuda10.1则直接 pip install cupy-cuda101","categories":[],"tags":[],"author":"张存"},{"title":"linux shell 用sed命令在文本的行尾或行首添加字符","slug":"linux-shell-用sed命令在文本的行尾或行首添加字符","date":"2022-04-29T11:32:36.000Z","updated":"2022-04-29T11:32:48.999Z","comments":true,"path":"2022/04/29/linux-shell-yong-sed-ming-ling-zai-wen-ben-de-xing-wei-huo-xing-shou-tian-jia-zi-fu/","link":"","permalink":"https://blog.zhangcun.store/2022/04/29/linux-shell-yong-sed-ming-ling-zai-wen-ben-de-xing-wei-huo-xing-shou-tian-jia-zi-fu/","excerpt":"","text":"用sed命令在行首或行尾添加字符的命令有以下几种： 假设处理的文本为test.file 在每行的头添加字符，比如&quot;HEAD&quot;，命令如下： sed &#39;s/^/HEAD&amp;/g&#39; test.file 在每行的行尾添加字符，比如“TAIL”，命令如下： sed &#39;s/$/&amp;TAIL/g&#39; test.file 运行结果如下图： 几点说明： 1.&quot;^&quot;代表行首，&quot;$&quot;代表行尾 2.&#39;s/$/&amp;TAIL/g&#39;中的字符g代表每行出现的字符全部替换，如果想在特定字符处添加，g就有用了，否则只会替换每行第一个，而不继续往后找了 例： 3.如果想导出文件，在命令末尾加&quot;&gt; outfile_name&quot;；如果想在原文件上更改，添加选项&quot;-i&quot;，如（这里的-i，可以理解为其他命令执行后的结果重定向到原文件，所以-n p等参数会影响-i的效果） 4.也可以把两条命令和在一起，在test.file的每一行的行头和行尾分别添加字符&quot;HEAD&quot;、“TAIL”，命令：sed &#39;/./&#123;s/^/HEAD&amp;/;s/$/&amp;TAIL/&#125;&#39; test.file 以上其实都还OK，昨天花太多时间，主要因为被处理的文件是用Mysql从数据库提取的结果导出来的，别人给我之后我就直接处理，太脑残了= -我一直有点怀疑之所以结果不对，有可能是windows和linux换行的问题，可是因为对sed不熟，就一直在搞sed。。。。。。。 众所周知（= -），window和linux的回车换行之云云，如果你知道了，跳过这一段，不知道，读一下呗： Unix系统里，每行结尾只有“&lt;换行&gt;”，即“\\n”；Windows系统里面，每行结尾是“&lt;换行&gt;&lt;回 车&gt;”，即“\\n\\r”。一个直接后果是，Unix系统下的文件在Windows里打开的话，所有文字会变成一行；而Windows里的文件在Unix下打开的话，在每行的结尾可能会多出一个^M符号。 好了，所以我的问题就出在被处理的文件的每行末尾都有^M符号，而这通常是看不出来的。可以用&quot;cat -A test.file&quot;命令查看。因此当我想在行尾添加字符的时候，它总是添加在行首且会覆盖掉原来行首的字符。 要把文件转换一下，有两种方法： 1.命令dos2unix test.file 2.去掉&quot;\\r&quot; ，用命令sed -i &#39;s/\\r//&#39; test.file","categories":[],"tags":[],"author":"张存"},{"title":"Linux sed 输出指定行","slug":"Linux-sed-输出指定行","date":"2022-04-29T11:31:29.000Z","updated":"2022-04-29T11:31:30.440Z","comments":true,"path":"2022/04/29/linux-sed-shu-chu-zhi-ding-xing/","link":"","permalink":"https://blog.zhangcun.store/2022/04/29/linux-sed-shu-chu-zhi-ding-xing/","excerpt":"","text":"n,m 表示 n 到m行，这里用 4p;5p 也行，从指定行输出到末尾使用$ test.txt 是输入文件 sed -n &#39;4,5p&#39; test.txt sed -n &#39;4,$p&#39; test.txt","categories":[],"tags":[],"author":"张存"},{"title":"搭建轻量级日志系统Loki","slug":"搭建轻量级日志系统Loki","date":"2022-04-29T11:30:18.000Z","updated":"2022-04-29T11:30:20.976Z","comments":true,"path":"2022/04/29/da-jian-qing-liang-ji-ri-zhi-xi-tong-loki/","link":"","permalink":"https://blog.zhangcun.store/2022/04/29/da-jian-qing-liang-ji-ri-zhi-xi-tong-loki/","excerpt":"","text":"Loki 是一个水平可扩展，高可用性，多租户日志聚合系统,灵感来自 Prometheus ，其设计非常经济高效，易于操作。它不索引日志的内容，而是为每个日志流设置一组标签。 与其他日志聚合系统相比，Loki： 不对日志进行全文本索引。通过存储压缩的，非结构化的日志以及仅索引元数据，Loki更加易于操作且运行成本更低。使用与Prometheus相同的标签对日志流进行索引和分组，从而使您能够使用与Prometheus相同的标签在指标和日志之间无缝切换。特别适合存储Kubernetes Pod日志。诸如Pod标签之类的元数据会自动被抓取并建立索引。在Grafana中原生支持（需要Grafana v6.0及以上）。基于Loki的日志记录堆栈包含3个组件： promtail是代理，负责收集日志并将其发送给Loki。loki是主服务器，负责存储日志和处理查询。Grafana用于查询和显示日志。开始大部分文章都是基于 k8s 、docker-compose去安装的，这里我们用二进制安装 Loki类似 elasticsearch 安装 curl -O -L &quot;https://github.com/grafana/loki/releases/download/v1.5.0/loki-linux-amd64.zip&quot; unzip loki-linux-amd64.zip chmod a+x loki-linux-amd64 ./loki-linux-amd64 配置文件 config.yaml auth_enabled: false server: http_listen_port: 3100 ingester: lifecycler: address: 127.0.0.1 ring: kvstore: store: inmemory replication_factor: 1 final_sleep: 0s chunk_idle_period: 5m chunk_retain_period: 30s schema_config: configs: - from: 2018-04-15 store: boltdb object_store: filesystem schema: v9 index: prefix: index_ period: 168h storage_config: boltdb: directory: /tmp/loki/index filesystem: directory: /tmp/loki/chunks limits_config: enforce_metric_name: false reject_old_samples: true reject_old_samples_max_age: 168h chunk_store_config: max_look_back_period: 0 table_manager: chunk_tables_provisioning: inactive_read_throughput: 0 inactive_write_throughput: 0 provisioned_read_throughput: 0 provisioned_write_throughput: 0 index_tables_provisioning: inactive_read_throughput: 0 inactive_write_throughput: 0 provisioned_read_throughput: 0 provisioned_write_throughput: 0 retention_deletes_enabled: false retention_period: 0 Promtail 比如你要收集Nginx的错误日志，那就要在Nginx那台服务器部署 Promtail，类似 fluentd 安装 curl -O -l &quot;https://github.com/grafana/loki/releases/download/v1.5.0/promtail-linux-amd64.zip&quot; unzip promtail-linux-amd64.zip chmod a+x promtail-linux-amd64 ./promtail-linux-amd64 配置文件 config.yaml # Promtail Server Config server: http_listen_port: 9080 grpc_listen_port: 0 # Positions positions: filename: /tmp/positions.yaml # Loki服务器的地址 clients: - url: http://172.18.11.161:3100/loki/api/v1/push scrape_configs: - job_name: nginx static_configs: - targets: - localhost labels: job: nginx-error host: localhost __path__: /usr/local/nginx/logs/error.log Grafana 打开Grafana，添加数据源，选 使用 打开 Grafana，点击 Explore , Log labels 输入 &#123;job=&quot;nginx-error&quot;&#125;","categories":[],"tags":[],"author":"张存"},{"title":"cronsun 单机部署","slug":"cronsun-单机部署","date":"2022-04-29T11:28:01.000Z","updated":"2022-04-29T11:28:03.190Z","comments":true,"path":"2022/04/29/cronsun-dan-ji-bu-shu/","link":"","permalink":"https://blog.zhangcun.store/2022/04/29/cronsun-dan-ji-bu-shu/","excerpt":"","text":"cronsun: 是一个分布式任务系统,单个节点和 Linux 机器上的 crontab 近似.是为了解决多台 Linux 机器上 crontab 任务管理不方便的问题,同时提供任务高可用的支持（当某个节点死机的时候可以自动调度到正常的节点执行）.支持界面管理机器上的任务,支持任务失败邮件提醒,安装简单,使用方便,是替换 crontab 一个不错的选择. 环境： VM centos7 etcd 3.3.5 mongodb 3.6.5 资源： etcd: https://github.com/coreos/etcd/releases mongodb https://www.mongodb.com/download-center#atlas cronsun https://github.com/shunfei/cronsun/releases etcd 0x01. 下载etcd curl -L https://github.com/coreos/etcd/releases/download/v3.3.5/etcd-v3.3.5-linux-amd64.tar.gz -o etcd-v3.3.5-linux-amd64.tar.gz 0x02. 解压后,会看到etcd,etcdctl,将它们复制到/usr/local/bin或/usr/bin下 etcd 是服务端 etcdctl 是客户端 运行 etcd,将默认组建一个两个节点的集群.数据库服务端默认监听在 2379 和 4001 端口,etcd 实例监 听在 2380 和 7001 端口 0x03. 检查etcd是否正常了,看看READ-etcdctl.ME和READv2-etcdctl.ME文件,其中READ-etcdctl.ME开头有句话 export ETCDCTL_API=3 0x04. env 检查环境变量 0x05. 通过命令检查是否成功 etcdctl put testkey &#39;hello word&#39; etcdctl get testkey mongdb 0x01. 下载mongdb curl -L https://fastdl.mongodb.org/linux/mongodb-linux-x86_64-amazon-3.6.5.tgz -o mongodb-linux-x86_64-amazon-3.6.5.tgz 0x02. 解压 tar -zxvf mongodb-linux-x86_64-amazon-3.6.5.tgz 移动到指定目录 mv mongodb-linux-x86_64-3.0.6/ /usr/local/mongodb 注册环境目录 export PATH=/usr/local/mongodb/bin:$PATH 创建数据库目录 mkdir -p /data/db 0x03. 运行mongdb服务端 cd /usr/local/mongodb/bin ./mongo cronsun 0x01. 下载cronsun https://github.com/shunfei/cronsun/releases/download/v0.3.2/cronsun-v0.3.2-linux-amd64.zip -o cronsun-v0.3.2-linux-amd64.zip 0x02. conf 目录下的配置文件：db.json 和 etcd.json,分别修改 MongoDB 和 etcd 的实际地址 0x03. 启动 web：./cronweb -conf conf/base.json 启动 node：./cronnode -conf conf/base.json 0x04. 访问前台：http://x.x.x.x:7079/ui/ 参考文献: https://www.mongodb.com/download-center#community https://blog.csdn.net/dream_broken/article/details/52671344 https://zhangge.net/5129.html","categories":[],"tags":[],"author":"张存"},{"title":"关于history两个变量：HISTFILESIZE和HISTSIZE的区别","slug":"关于history两个变量：HISTFILESIZE和HISTSIZE的区别","date":"2022-04-29T11:23:24.000Z","updated":"2022-04-29T11:24:29.673Z","comments":true,"path":"2022/04/29/guan-yu-history-liang-ge-bian-liang-histfilesize-he-histsize-de-qu-bie/","link":"","permalink":"https://blog.zhangcun.store/2022/04/29/guan-yu-history-liang-ge-bian-liang-histfilesize-he-histsize-de-qu-bie/","excerpt":"","text":"HISTSIZE：history命令显示的行数 [root@localhost ~]# export HISTSIZE=&quot;5&quot; #显示最近5行历史记录 [root@localhost ~]# history 110 history 111 man history 112 vi .bash_history 113 export HISTSIZE=&quot;5&quot; 114 history HISTFILESIZE：.bash_history文件中最大能记录的行数","categories":[],"tags":[],"author":"张存"},{"title":"在Portainer上添加其他主机上的docker","slug":"在Portainer上添加其他主机上的docker","date":"2022-04-29T11:21:33.000Z","updated":"2022-04-29T11:21:37.941Z","comments":true,"path":"2022/04/29/zai-portainer-shang-tian-jia-qi-ta-zhu-ji-shang-de-docker/","link":"","permalink":"https://blog.zhangcun.store/2022/04/29/zai-portainer-shang-tian-jia-qi-ta-zhu-ji-shang-de-docker/","excerpt":"","text":"其他主机开启远程连接docker端口 需要设置一下2375端口的监听。通过修改docker配置文件方式进行监听。 修改配置文件修改监听端口 使用Centos7安装的docker，所以下面的配置是适用于Centos7的。 打开配置文件 /usr/lib/systemd/system/docker.service 或者通过 systemctl status docker.service 命令查看docker.service文件所在路径 修改配置项ExecStart中的值，若ExecStart中没有值，则直接添加 -H tcp://0.0.0.0:2375 ，否则在已有参数后面添加，比如下面这样： ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2375 -H fd:// --containerd=/run/containerd/containerd.sock 修改完之后保存文件，然后重启docker服务 systemctl daemon-reload systemctl restart docker","categories":[],"tags":[],"author":"张存"},{"title":"Hexo部署出现错误err: Error: Spawn failed解决方式","slug":"Hexo部署出现错误err-Error-Spawn-failed解决方式","date":"2022-04-29T11:17:35.000Z","updated":"2022-04-29T11:18:43.195Z","comments":true,"path":"2022/04/29/hexo-bu-shu-chu-xian-cuo-wu-err-error-spawn-failed-jie-jue-fang-shi/","link":"","permalink":"https://blog.zhangcun.store/2022/04/29/hexo-bu-shu-chu-xian-cuo-wu-err-error-spawn-failed-jie-jue-fang-shi/","excerpt":"","text":"部署过程中可能会出现错误 fatal: unable to access &#39;https://github.com/a956551943/a956551943.github.io/&#39;: Encountered end of file FATAL &#123; err: Error: Spawn failed at ChildProcess.&lt;anonymous&gt; (/usr/local/src/hexo/hanyubolg/node_modules/hexo-util/lib/spawn.js:51:21) at ChildProcess.emit (events.js:376:20) at Process.ChildProcess._handle.onexit (internal/child_process.js:277:12) &#123; code: 128 &#125; &#125; Something&#39;s wrong. Maybe you can find the solution here: %s https://hexo.io/docs/troubleshooting.html 解决方式一： ##进入站点根目录 cd /usr/local/src/hexo/hanyubolg/ ##删除git提交内容文件夹 rm -rf .deploy_git/ ##执行 git config --global core.autocrlf false ##最后 hexo clean &amp;&amp; hexo g &amp;&amp; hexo d 解决方式二：有可能是你的git repo配置地址不正确,可以将http方式变更为ssh方式 ##进入站点根目录 cd /usr/local/src/hexo/hanyubolg/ ##删除git提交内容文件夹 vim _config.yml ##修改 deploy: type: git repo: https://github.com/yourname/yourname.github.io.git -&gt; git@github.com:a956551943/weixiaohui.github.io.git branch: master ##最后 hexo clean &amp;&amp; hexo g &amp;&amp; hexo d 解决方式三：不建议 ##进入站点根目录 cd /usr/local/src/hexo/hanyubolg/ ##进入depoly文件夹 cd .deploy_git/ ##强制推送 git push -f","categories":[],"tags":[],"author":"张存"},{"title":"【rsync+ssh】rsync远程同步备份数据","slug":"【rsync-ssh】rsync远程同步备份数据","date":"2022-04-29T11:13:34.000Z","updated":"2022-04-29T11:13:38.632Z","comments":true,"path":"2022/04/29/rsync-ssh-rsync-yuan-cheng-tong-bu-bei-fen-shu-ju/","link":"","permalink":"https://blog.zhangcun.store/2022/04/29/rsync-ssh-rsync-yuan-cheng-tong-bu-bei-fen-shu-ju/","excerpt":"","text":"rsync连接远程主机进行同步或备份时有两种途径：1.使用远程shell程序（如ssh或rsh）进行连接2.使用TCP直接连接rsync daemon rsync daemon是”rsync –daemon”或再加上其他一些选项启动的，它会读取配置文件，默认是/etc/rsyncd.conf，并默认监听在873端口上，当外界有客户端对此端口发起连接请求，通过这个网络套接字就可以完成连接，以后与该客户端通信的所有数据都通过该网络套接字传输。 rsync daemon的通信方式和传输通道与远程shell不同。 远程shell连接的两端是通过管道完成通信和数据传输的，即使连接的一端是远程主机，当连接到目标端时，将在目标端上根据远程shell进程fork出rsync进程使其成为rsync server。 rsync daemon是事先在server端上运行好的rsync后台进程(根据启动选项，也可以设置为非后台进程)，它监听套接字等待client端的连接，连接建立后所有通信方式都是通过套接字完成的。 注意:rsync中的server的概念从来就不代表是rsync daemon，server在rsync中只是一种通用称呼，只要不是发起rsync请求的client端，就是server端，你可以认为rsync daemon是一种特殊的server，其实daemon更应该称之为service。 当源路径或目的路径的主机名后面包含一个冒号分隔符时，rsync使用远程shell传输； 当源路径或目的路径的主机名后面包含两个冒号，或使用rsync://URL时，rsync使用TCP直接连接rsync daemon。 特别的，如果只指定了源路径，而没有指定目的路径，rsync将会显示源路径中的文件列表，类似于使用命令ls -l。 rsync把本地端看作client，把远程端当成server。 rsync有两种常用的认证方式，一种为rsync-daemon方式，另外一种则是ssh。 在一些场合，使用rsync-daemon方式会比较缺乏灵活性，ssh方式则成为首选。 1、从本地同步到远程 # rsync -avz -e ssh /local/dir/ root@xx.xx.xx.xx:/remote/dir # rsync -avz -e &#39;ssh -p 2222&#39; /local/dir/ root@xx.xx.xx.xx:/remote/dir 两种方式的区别就是远程的ssh默认端口换了 2、从远程同步到本地 # rsync -avzP -e ssh root@xx.xx.xx.xx:/remote/dir/ /local/dir # rsync -avzP -e &#39;ssh -p 2222&#39; root@xx.xx.xx.xx:/remote/dir/ /local/dir 3. 从目的目录中删除不必要的文件（在server端没有的文件） # rsync -avzP --delete -e ssh root@xx.xx.xx.xx:/remote/dir/ /local/dir # rsync -avzP --delete -e &#39;ssh -p 2222&#39; root@xx.xx.xx.xx:/remote/dir/ /local/dir 注意： 源路径的最后是否有斜杠有不同的含义： 有斜杠，只是复制目录中的文件；没有斜杠的话，不但要复制目录中的文件，还要复制目录本身! 目的路径的最后有没有斜杠，对传输没有影响! rsync参数 http://einverne.github.io/post/2017/07/rsync-introduction.html rsync基本命令和用法 https://www.cnblogs.com/f-ck-need-u/p/7220009.html How to Securely Transfer Files via rsync and SSH on Linux https://www.liquidweb.com/kb/how-to-securely-transfer-files-via-rsync-and-ssh-on-linux How To Copy Files With Rsync Over SSH https://www.digitalocean.com/community/tutorials/how-to-copy-files-with-rsync-over-ssh","categories":[],"tags":[],"author":"张存"},{"title":"rsync命令详解","slug":"rsync命令详解","date":"2022-04-29T10:53:36.000Z","updated":"2022-04-29T10:54:12.059Z","comments":true,"path":"2022/04/29/rsync-ming-ling-xiang-jie/","link":"","permalink":"https://blog.zhangcun.store/2022/04/29/rsync-ming-ling-xiang-jie/","excerpt":"","text":"rsync 简介rsync（remote synchronize）是一个远程数据同步工具，可通过 LAN/WAN 快速同步多台主机之间的文件。也可以使用 rsync 同步本地硬盘中的不同目录。rsync 是用于替代 rcp 的一个工具，rsync 使用所谓的 rsync算法 进行数据同步，这种算法只传送两个文件的不同部分，而不是每次都整份传送，因此速度相当快。 您可以参考 How Rsync Works A Practical Overview 进一步了解 rsync 的运作机制。 rsync 的初始作者是 Andrew Tridgell 和 Paul Mackerras，目前由 http://rsync.samba.org 维护。 rsync 支持大多数的类 Unix 系统，无论是 Linux、Solaris 还是 BSD上 都经过了良好的测试。 CentOS系统默认就安装了 rsync 软件包。 此外，在 windows 平台下也有相应的版本，如 cwrsync 和DeltaCopy 等。rsync 具有如下的基本特性： 可以镜像保存整个目录树和文件系统 可以很容易做到保持原来文件的权限、时间、软硬链接等无须特殊权限即可安装 优化的流程，文件传输效率高 可以使用 rsh、ssh 方式来传输文件，当然也可以通过直接的 socket 连接 支持匿名传输，以方便进行网站镜象 在使用 rsync 进行远程同步时，可以使用两种方式：远程 Shell 方式（建议使用 ssh，用户验证由 ssh 负责）和 C/S 方式（即客户连接远程 rsync 服务器，用户验证由 rsync 服务器负责）。 无论本地同步目录还是远程同步数据，首次运行时将会把全部文件拷贝一次，以后再运行时将只拷贝有变化的文件（对于新文件）或文件的变化部分（对于原有文件）。本节重点介绍 rsync 客户命令的使用，有关 rsync 服务器的配置和使用请参见下节。 rsync 在首次复制时没有速度优势，速度不如 tar，因此当数据量很大时您可以考虑先使用 tar 进行首次复制，然后再使用 rsync 进行数据同步。 镜像、备份和归档 实施备份的两种情况： 需保留备份历史归档：在备份时保留历史的备份归档，是为了在系统出现错误后能恢复到从前正确的状态。这可以使用完全备份和增量备份来完成。 可以使用 tar 命令保存归档文件。 为了提高备份效率，也可以使用 rsync 结合 tar 来完成。 无需保留备份历史归档：若无需从历史备份恢复到正确状态，则只备份系统最“新鲜”的状态即可。这可以简单地使用 rsync 同步来完成。此时通常称为镜像。镜像可以分为两种： 被镜像的目录在各个主机上保持相同的位置。此时一般是为了实施负载均衡而对多个主机进行同步镜像。例如：将主机 A 的 /srv/www 目录同步到主机 B 的 /srv/www 目录等。 被镜像的目录在各个主机上不保持相同的位置。例如：主机 A 和主机 B 都运行着各自的业务，同时又互为镜像备份。此时主机 A 的 /srv/www 目录同步到主机 B 的 /backups/hosta/www 目录；主机 B 的 /srv/www 目录同步到主机 A 的 /backups/hostb/www 目录等。 rsync 命令rsync 是一个功能非常强大的工具，其命令也有很多功能选项。rsync 的命令格式为： 1）本地使用： rsync [OPTION...] SRC... [DEST] 2）通过远程 Shell 使用： 拉: rsync [OPTION...] [USER@]HOST:SRC... [DEST] 推: rsync [OPTION...] SRC... [USER@]HOST:DEST 3）访问 rsync 服务器: 拉: rsync [OPTION...] [USER@]HOST::SRC... [DEST] 推: rsync [OPTION...] SRC... [USER@]HOST::DEST 拉: rsync [OPTION...] rsync://[USER@]HOST[:PORT]/SRC... [DEST] 推: rsync [OPTION...] SRC... rsync://[USER@]HOST[:PORT]/DEST 其中： SRC: 是要复制的源位置 DEST: 是复制目标位置 若本地登录用户与远程主机上的用户一致，可以省略 USER@ 使用远程 shell 同步时，主机名与资源之间使用单个冒号“:”作为分隔符 使用 rsync 服务器同步时，主机名与资源之间使用两个冒号“::”作为分隔符 当访问 rsync 服务器时也可以使用 rsync:// URL “拉”复制是指从远程主机复制文件到本地主机 “推”复制是指从本地主机复制文件到远程主机 当进行“拉”复制时，若指定一个 SRC 且省略 DEST，则只列出资源而不进行复制 下面列出常用选项： 选项 说明 -a, ––archive 归档模式，表示以递归方式传输文件，并保持所有文件属性，等价于 -rlptgoD (注意不包括 -H) -r, ––recursive 对子目录以递归模式处理 -l, ––links 保持符号链接文件 -H, ––hard-links 保持硬链接文件 -p, ––perms 保持文件权限 -t, ––times 保持文件时间信息 -g, ––group 保持文件属组信息 -o, ––owner 保持文件属主信息 (super-user only) -D 保持设备文件和特殊文件 (super-user only) -z, ––compress 在传输文件时进行压缩处理 ––exclude=PATTERN 指定排除一个不需要传输的文件匹配模式 ––exclude-from=FILE 从 FILE 中读取排除规则 ––include=PATTERN 指定需要传输的文件匹配模式 ––include-from=FILE 从 FILE 中读取包含规则 ––copy-unsafe-links 拷贝指向SRC路径目录树以外的链接文件 ––safe-links 忽略指向SRC路径目录树以外的链接文件（默认） ––existing 仅仅更新那些已经存在于接收端的文件，而不备份那些新创建的文件 ––ignore-existing 忽略那些已经存在于接收端的文件，仅备份那些新创建的文件 -b, ––backup 当有变化时，对目标目录中的旧版文件进行备份 ––backup-dir=DIR 与 -b 结合使用，将备份的文件存到 DIR 目录中 ––link-dest=DIR 当文件未改变时基于 DIR 创建硬链接文件 ––delete 删除那些接收端还有而发送端已经不存在的文件 ––delete-before 接收者在传输之前进行删除操作 (默认) ––delete-during 接收者在传输过程中进行删除操作 ––delete-after 接收者在传输之后进行删除操作 ––delete-excluded 在接收方同时删除被排除的文件 -e, ––rsh=COMMAND 指定替代 rsh 的 shell 程序 ––ignore-errors 即使出现 I/O 错误也进行删除 ––partial 保留那些因故没有完全传输的文件，以是加快随后的再次传输 ––progress 在传输时显示传输过程 -P 等价于 ––partial ––progress ––delay-updates 将正在更新的文件先保存到一个临时目录（默认为 “.~tmp~”），待传输完毕再更新目标文件 -v, ––verbose 详细输出模式 -q, ––quiet 精简输出模式 -h, ––human-readable 输出文件大小使用易读的单位（如，K，M等） -n, ––dry-run 显示哪些文件将被传输 ––list-only 仅仅列出文件而不进行复制 ––rsyncpath=PROGRAM 指定远程服务器上的 rsync 命令所在路径 ––password-file=FILE 从 FILE 中读取口令，以避免在终端上输入口令，通常在 cron 中连接 rsync 服务器时使用 -4, ––ipv4 使用 IPv4 -6, ––ipv6 使用 IPv6 ––version 打印版本信息 ––help 显示帮助信息 若使用普通用户身份运行 rsync 命令，同步后的文件的属主将改变为这个普通用户身份。 若使用超级用户身份运行 rsync 命令，同步后的文件的属主将保持原来的用户身份。 rsync 的基本使用 在本地磁盘同步数据 # rsync -a --delete /home /backups # rsync -a --delete /home/ /backups/home.0 在指定复制源时，路径是否有最后的 “/” 有不同的含义，例如： /home ： 表示将整个 /home 目录复制到目标目录 /home/ ： 表示将 /home 目录中的所有内容复制到目标目录 使用基于 ssh 的 rsync 远程同步数据 同步静态主机表文件 # 执行“推”复制同步（centos5 是可解析的远程主机名） [root@soho ~]# rsync /etc/hosts centos5:/etc/hosts # 执行“拉”复制同步（soho 是可解析的远程主机名） [root@centos5 ~]# rsync soho:/etc/hosts /etc/hosts 同步用户的环境文件 # 执行“推”复制同步 [osmond@soho ~]$ rsync ~/.bash* centos5: # 执行“拉”复制同步 [osmond@cnetos5 ~]$ rsync soho:~/.bash* . 同步站点根目录 # 执行“推”复制同步 [osmond@soho ~]$ rsync -avz --delete /var/www root@192.168.0.101:/var/www # 执行“拉”复制同步 [osmond@cnetos5 ~]$ rsync -avz --delete root@192.168.0.55:/var/www /var/www 使用基于 ssh 的 rsync 同步数据可以使用 -e ssh 参数，当前的 CentOS 默认指定使用 ssh 作为远程Shell。若您在其他系统上执行 rsync 命令，为确保使用 ssh 作为远程 Shell，请添加 -e ssh 参数。 通常 rsync 命令在后台以 cron 任务形式执行，为了避免从终端上输入口令需要设置 ssh。ssh 的设置方法请参考 安全登录守护进程。 使用 rsync 从远程 rsync 服务器同步数据 下面以镜像 CentOS 和 Ubuntu 的软件库为例来说明。 您可以到如下站点查找离自己最近的提供 rsync 服务的镜像站点 CentOS — http://www.centos.org/modules/tinycontent/index.php?id=13 Ubuntu — https://launchpad.net/ubuntu/+archivemirrors 然后执行类似如下命令： rsync -aqzH --delete --delay-updates \\ rsync://mirror.centos.net.cn/centos /var/www/mirror/centos rsync -azH --progress --delete --delay-updates \\ rsync://ubuntu.org.cn/ubuntu /var/www/mirror/ubuntu/ rsync -azH --progress --delete --delay-updates \\ rsync://ubuntu.org.cn/ubuntu-cn /var/www/mirror/ubuntu-cn/ 为了每天不断更新，可以安排一个 cron 任务： # crontab -e # mirror centos at 0:10AM everyday 10 0 * * * rsync -aqzH --delete --delay-updates rsync://mirror.centos.net.cn/centos /var/www/mirror/centos/ # mirror ubuntu at 2:10AM everyday 10 2 * * * rsync -azH --progress --delete --delay-updates rsync://ubuntu.org.cn/ubuntu /var/www/mirror/ubuntu/ # mirror ubuntu-cn at 4:10AM everyday 10 4 * * * rsync -azH --progress --delete --delay-updates rsync://ubuntu.org.cn/ubuntu-cn /var/www/mirror/ubuntu-cn/ 如果您安装了自己的匿名 rsync 服务器请相应地更改 rsync URL。有关如何配置匿名 rsync 服务器的内容请参见下节。 筛选 rsync 的传输目标 使用 --exclude/--include 选项 可以使用 ––exclude 选项排除源目录中要传输的文件；同样地，也可以使用 ––include 选项指定要传输的文件。 例如：下面的 rsync 命令将 192.168.0.101 主机上的 /www 目录（不包含 /www/logs 和 /www/conf子目录）复制到本地的 /backup/www/ 。 # rsync -vzrtopg --delete --exclude &quot;logs/&quot; --exclude &quot;conf/&quot; --progress \\ backup@192.168.0.101:/www/ /backup/www/ 又如：下面的 rsync 命令仅复制目录结构而忽略掉目录中的文件。 # rsync -av --include &#39;*/&#39; --exclude &#39;*&#39; \\ backup@192.168.0.101:/www/ /backup/www-tree/ 选项 ––include 和 ––exclude 都不能使用间隔符。例如： --exclude &quot;logs/&quot; --exclude &quot;conf/&quot; 不能写成 --exclude &quot;logs/ conf/&quot; 使用 --exclude-from/--include-from 选项 当 include/exclude 的规则较复杂时，可以将规则写入规则文件。使用规则文件可以灵活地选择传输哪些文件（include）以及忽略哪些文件（exclude）。 若文件/目录在剔除列表中，则忽略传输 若文件/目录在包含列表中，则传输之 若文件/目录未被提及，也传输之 在 rsync 的命令行中使用 ––exclude-from=FILE 或 ––include-from=FILE 读取规则文件。 规则文件 FILE 的书写约定： 每行书写一条规则 RULE 以 # 或 ; 开始的行为注释行 包含（include）和排除（exclude）规则的语法如下： include PATTERN 或简写为 + PATTERN exclude PATTERN 或简写为 - PATTERN PATTERN 的书写规则如下： 以 / 开头：匹配被传输的跟路径上的文件或目录 以 / 结尾：匹配目录而非普通文件、链接文件或设备文件 使用通配符 *：匹配非空目录或文件（遇到 / 截止） **：匹配任何路径（包含 / ） ?：匹配除了 / 的任意单个字符 [：匹配字符集中的任意一个字符，如 [a-z] 或 [[:alpha:]] 可以使用转义字符 \\ 将上述通配符还原为字符本身含义 下面给出几个使用规则的例子： 例1： # 不传输所有后缀为 .o 的文件 - *.o # 不传输传输根目录下名为 foo 的文件或目录 - /foo # 不传输名为 foo 的目录 - foo/ # 不传输 /foo 目录下的名为 bar 的文件或目录 - /foo/bar 例2： # 传输所有目录和C语言源文件并禁止传输其他文件 + */ + *.c - * 例3： # 仅传输 foo 目录和其下的 bar.c 文件 + foo/ + foo/bar.c - * 将规则写入规则文件之后，如何在命令行上使用它呢？下面给出一个例子： 首先将下面的规则存入名为 www-rsync-rules 的文件 # 不传输 logs 目录 - logs/ # 不传输后缀为 .tmp 的文件 - *.tmp # 传输 Apache 虚拟主机文档目录（/*/ 匹配域名） + /srv/www/ + /srv/www/*/ + /srv/www/*/htdocs/ + /srv/www/*/htdocs/** # 传输每个用户的 public_html 目录（/*/ 匹配用户名） + /home/ + /home/*/ + /home/*/public_html/ + /home/*/public_html/** # 禁止传输其他 - * 然后即可使用类似如下的 rsync 命令： rsync -av --delete --exclude-from=www-rsync-rules / remotehost:/dest/dir rsync 应用示例 使用 rsync 镜像 使用 rsync 对目录做镜像实际上就是做无历史归档的完全备份。下面给出一个镜像远程 Web 站点例子。 笔者在 dreamhost 上维护了3个 Dokuwiki 站点。为了备份这3个站点笔者使用 rsync 进行镜像。远程站点的目录结构如下： ~ |-- sinosmond.com | `-- dokuwiki |-- smartraining.cn | `-- dokuwiki `-- symfony-project.cn `-- dokuwiki 每个 Dokuwiki 的目录结构如下： dokuwiki |-- bin |-- inc |-- conf --- 存放配置文件的目录 | |-- acl.auth.php --- 访问控制配置文件 ★ | |-- local.php --- 本地配置文件 ★ | |-- users.auth.php --- 用户口令文件 ★ | `-- ……………… |-- data --- 存放数据的目录 | |-- attic --- 存放WIKI版本信息 ★ | |-- cache --- 存放数据缓存 | |-- index --- 存放站内索引 | |-- locks --- 存放编辑页面时的锁定文件 | |-- media --- 存放图片等 ★ | |-- meta --- 存放 meta 以便系统读取这些信息生成页面 ★ | `-- pages --- 存放 wiki 页面 ★ `-- lib |-- plugins --- 存放插件的目录 ☆ |-- tpl --- 存放模版的目录 ☆ `-- ……………… 为了减少网络流量，只同步标有 ★ 的目录或文件。若在站点运行过程中新安装了插件或更换了模板，也应该同步标有 ☆ 的目录。为此编写如下的规则文件 /root/bin/backup/dw-exclude.txt： - dokuwiki/bin/ - dokuwiki/inc/ - dokuwiki/data/cache/ - dokuwiki/data/locks/ - dokuwiki/data/index/ + dokuwiki/conf/acl.auth.php + dokuwiki/conf/local.php + dokuwiki/conf/users.auth.php - dokuwiki/conf/* + dokuwiki/lib/plugins/ # 不同步系统默认安装的插件 - dokuwiki/lib/plugins/acl/ - dokuwiki/lib/plugins/config/ - dokuwiki/lib/plugins/importoldchangelog/ - dokuwiki/lib/plugins/importoldindex/ - dokuwiki/lib/plugins/info/ - dokuwiki/lib/plugins/plugin/ - dokuwiki/lib/plugins/revert/ - dokuwiki/lib/plugins/usermanager/ - dokuwiki/lib/plugins/action.php - dokuwiki/lib/plugins/admin.php - dokuwiki/lib/plugins/syntax.php + dokuwiki/lib/tpl # 不同步系统默认安装的模板 - dokuwiki/lib/tpl/default/ - dokuwiki/lib/* - dokuwiki/COPYING - dokuwiki/doku.php - dokuwiki/feed.php - dokuwiki/index.php - dokuwiki/install* - dokuwiki/README - dokuwiki/VERSION 下面是同步脚本 /root/bin/backup/rsync-dw.sh #!/bin/bash ##################################### # mirror dokuwiki website # $1 --- domain (ex: smartraining.cn) # $2 --- full or update ##################################### # declare some variable RmtUser=osmond RmtIP=208.113.163.110 RmtPath=$1/dokuwiki BackupRoot=/backups/$1 Excludes=&quot;--exclude-from=/root/bin/backup/dw-exclude.txt&quot; # use rsync for mirror if [ &quot;$2&quot; == &quot;full&quot; ] then [ -d /backups/$1 ] || mkdir -p /backups/$1 excludesfile=&quot;/tmp/first-excludes&quot; cat &gt; $&#123;excludesfile&#125; &lt;&lt; EOF + dokuwiki/data/cache/_dummy - dokuwiki/data/cache/* + dokuwiki/data/locks/_dummy - dokuwiki/data/locks/* + dokuwiki/data/index/_dummy - dokuwiki/data/index/* EOF /usr/bin/rsync -avzP --exclude-from=$&#123;excludesfile&#125; \\ $RmtUser@$RmtIP:$RmtPath $BackupRoot else /usr/bin/rsync -avzP --delete $Excludes \\ $RmtUser@$RmtIP:$RmtPath $BackupRoot fi 首次备份可以使用类似如下的命令（为了在本地保留一个完整复本）： # /root/bin/backup/rsync-dw.sh smartraining.cn full # /root/bin/backup/rsync-dw.sh sinosmond.com full # /root/bin/backup/rsync-dw.sh symfony-project.cn full 可以安排 cron 任务以便日后更新： # crontab -e 05 1 * * * /root/bin/backup/rsync-dw.sh smartraining.cn 25 1 * * * /root/bin/backup/rsync-dw.sh sinosmond.com 45 1 * * * /root/bin/backup/rsync-dw.sh symfony-project.cn 普通型增量备份 使用 rsync 可以做增量备份。rsync 提供了 -b ––backup-dir 选项，使用这个选项可以将有变化的文件进行更新同时将其旧版本保存在指定的目录中，从而实现增量备份。 下面是对 /home 进行增量备份的步骤说明： # 第0次备份 # 首先复制 /home 目录的内容到备份目录 /backups/daily/home.0， # rsync -a /home/ /backups/daily/home.0 # /backups/daily/home.0 总是同步到最新的状态，可以每隔一段时间（如一周） # 对其内容进行打包压缩生成归档文件（完全备份）存在 /backups/archive/。 # 第1次备份（此为核心操作） # 将 /home 目录的内容同步到目录 /backups/daily/home.0， # 并将有变化的文件的旧版本保存到 /backups/daily/home.1， # 若每天执行一次，则目录 /backups/daily/home.1 保存了有变化文件一天前的状态。 # rsync -a --delete -b --backup-dir=/backups/daily/home.1 /home/ /backups/daily/home.0 # 第2次备份 # 将备份目录 /backups/daily/home.1 更名为 /backups/daily/home.2 # mv /backups/daily/home.1 /backups/daily/home.2 # 执行第1次备份的核心操作 # 第n次备份 # 将早先的备份目录 /backups/daily/home.n 到 /backups/daily/home.1 # 依次更名为 /backups/daily/home.(n+1) 到 /backups/daily/home.2 # 执行第1次备份的核心操作 下面给出一个增量备份示例脚本。 #!/bin/bash #======================== # 您可以安排 cron 任务执行本脚本 # &gt; crontab -e # # daily : 1 1 * * * /path/to/script/rsync-backup.sh #======================== mydate=&quot;`date &#39;+%Y%m%d.%H%M&#39;`&quot; # Define rmt location RmtUser=root RmtHost=192.168.0.55 RmtPath=/home/ BackupSource=&quot;$&#123;RmtUser&#125;@$&#123;RmtHost&#125;:$&#123;RmtPath&#125;&quot; #BackupSource=&quot;/home/&quot; # 若进行本地备份则用本地路径替换上面的行 # Define location of backup BackupRoot=&quot;/backups/$RmtHost/&quot; # BackupRoot=&quot;/backups/localhost/&quot; # 若进行本地备份则用本地路径替换上面的行 LogFile=&quot;$&#123;BackupRoot&#125;/backup.log&quot; ExcludeList=&quot;/root/backup/backup-exclude-list.txt&quot; BackupName=&#39;home&#39; BackupNum=&quot;7&quot; # 指定保留多少个增量备份（适用于每周生成归档文件） #BackupNum=&quot;31&quot; # 指定保留多少个增量备份（适用于每月生成归档文件） # 定义函数检查目录 $1 是否存在，若不存在创建之 checkDir() &#123; if [ ! -d &quot;$&#123;BackupRoot&#125;/$1&quot; ] ; then mkdir -p &quot;$&#123;BackupRoot&#125;/$1&quot; fi &#125; # 定义函数实现目录滚动 # $1 -&gt; 备份路径 # $2 -&gt; 备份名称 # $3 -&gt; 增量备份的数量 rotateDir() &#123; for i in `seq $(($3 - 1)) -1 1` do if [ -d &quot;$1/$2.$i&quot; ] ; then /bin/rm -rf &quot;$1/$2.$((i + 1))&quot; mv &quot;$1/$2.$i&quot; &quot;$1/$2.$((i + 1))&quot; fi done &#125; # 调用函数 checkDir ，确保目录存在 checkDir &quot;archive&quot; checkDir &quot;daily&quot; #======= Backup Begin ================= # S1: Rotate daily. rotateDir &quot;$&#123;BackupRoot&#125;/daily&quot; &quot;$BackupName&quot; &quot;$BackupNum&quot; checkDir &quot;daily/$&#123;BackupName&#125;.0/&quot; checkDir &quot;daily/$&#123;BackupName&#125;.1/&quot; mv $&#123;LogFile&#125; $&#123;BackupRoot&#125;/daily/$&#123;BackupName&#125;.1/ cat &gt;&gt; $&#123;LogFile&#125; &lt;&lt;_EOF =========================================== Backup done on: $mydate =========================================== _EOF # S2: Do the backup and save difference in $&#123;BackupName&#125;.1 rsync -av --delete \\ -b --backup-dir=$&#123;BackupRoot&#125;/daily/$&#123;BackupName&#125;.1 \\ --exclude-from=$&#123;ExcludeList&#125; \\ $BackupSource $&#123;BackupRoot&#125;/daily/$&#123;BackupName&#125;.0 \\ 1&gt;&gt; $&#123;LogFile&#125; 2&gt;&amp;1 # S3: Create an archive backup every week if [ `date +%w` == &quot;0&quot; ] # 每周日做归档 # if [ `date +%d` == &quot;01&quot; ] # 每月1日做归档 then tar -cjf $&#123;BackupRoot&#125;/archive/$&#123;BackupName&#125;-$&#123;mydate&#125;.tar.bz2 \\ -C $&#123;BackupRoot&#125;/daily/$&#123;BackupName&#125;.0 . fi 您可以适当修该上述脚本中变量： RmtPath=&quot;$1/&quot; #BackupSource=&quot;$1/&quot; BackupName=&quot;$1&quot; 然后传递脚本参数备份其他目录，例如要备份 /www 可以使用如下命令： ./rsync-backup.sh /www 快照型增量备份 使用 rsync 可以做快照（Snapshot）型增量备份。每一个快照都相当于一个完全备份。其核心思想是：对有变化的文件进行复制；对无变化的文件创建硬链接以减少磁盘占用。 下面是对 /home 进行快照型增量备份的步骤说明： # 第0次备份 # 首先复制 /home 目录的内容到备份目录 /backups/home.0 # rsync -a /home/ /backups/home.0 # 第1次备份（此为核心操作） # 以硬链接形式复制 /backups/home.0 到 /backups/home.1 # cp -al /backups/home.0 /backups/home.1 # 将 /home 目录的内容同步到目录 /backups/home.0 # （rsync 在发现变化的文件时，先删除之，然后在创建该文件） # rsync -a --delete /home/ /backups/home.0 # 第2次备份 # 将备份目录 /backups/home.1 更名为 /backups/home.2 # mv /backups/home.1 /backups/home.2 # 执行第1次备份的核心操作 # 第n次备份 # 将早先的备份目录 /backups/home.n 到 /backups/home.1 # 依次更名为 /backups/home.(n+1) 到 /backups/home.2 # 执行第1次备份的核心操作 rsync 2.5.6 版本之后提供了 ––link-dest 选项，如下两条核心操作命令： cp -al /backups/home.0 /backups/home.1 rsync -a --delete /home/ /backups/home.0 可以简化为如下的一条命令： rsync -a --delete --link-dest=/backups/home.1 /home/ /backups/home.0 下面给出一个快照型增量备份示例脚本，该脚本来自http://www.mikerubel.org/computers/rsync_snapshots/contributed/peter_schneider-kamp #!/bin/bash # ---------------------------------------------------------------------- # mikes handy rotating-filesystem-snapshot utility # ---------------------------------------------------------------------- # RCS info: $Id: make_snapshot.sh,v 1.6 2002/04/06 04:20:00 mrubel Exp $ # ---------------------------------------------------------------------- # this needs to be a lot more general, but the basic idea is it makes # rotating backup-snapshots of /home whenever called # ---------------------------------------------------------------------- # ------------- system commands used by this script -------------------- ID=&#39;/usr/bin/id&#39;; ECHO=&#39;/bin/echo&#39;; MOUNT=&#39;/bin/mount&#39;; RM=&#39;/bin/rm&#39;; MV=&#39;/bin/mv&#39;; CP=&#39;/bin/cp&#39;; TOUCH=&#39;/usr/bin/touch&#39;; RSYNC=&#39;/usr/bin/rsync&#39;; # ------------- file locations ----------------------------------------- MOUNT_DEVICE=/dev/hdb1; SNAPSHOT_RW=/root/snapshots; EXCLUDES=/etc/snapshot_exclude; # ------------- backup configuration------------------------------------ BACKUP_DIRS=&quot;/etc /home&quot; NUM_OF_SNAPSHOTS=3 BACKUP_INTERVAL=hourly # ------------- the script itself -------------------------------------- # make sure we&#39;re running as root if (( `$ID -u` != 0 )); then &#123; $ECHO &quot;Sorry, must be root. Exiting...&quot;; exit; &#125; fi echo &quot;Starting snapshot on &quot;`date` # attempt to remount the RW mount point as RW; else abort $MOUNT -o remount,rw $MOUNT_DEVICE $SNAPSHOT_RW ; if (( $? )); then &#123; $ECHO &quot;snapshot: could not remount $SNAPSHOT_RW readwrite&quot;; exit; &#125; fi; # rotating snapshots for BACKUP_DIR in $BACKUP_DIRS do NUM=$NUM_OF_SNAPSHOTS # step 1: delete the oldest snapshot, if it exists: if [ -d $&#123;SNAPSHOT_RW&#125;$&#123;BACKUP_DIR&#125;/$&#123;BACKUP_INTERVAL&#125;.$NUM ] ; then \\ $RM -rf $&#123;SNAPSHOT_RW&#125;$&#123;BACKUP_DIR&#125;/$&#123;BACKUP_INTERVAL&#125;.$NUM ; \\ fi ; NUM=$(($NUM-1)) # step 2: shift the middle snapshots(s) back by one, if they exist while [[ $NUM -ge 1 ]] do if [ -d $&#123;SNAPSHOT_RW&#125;$&#123;BACKUP_DIR&#125;/$&#123;BACKUP_INTERVAL&#125;.$NUM ] ; then \\ $MV $&#123;SNAPSHOT_RW&#125;$&#123;BACKUP_DIR&#125;/$&#123;BACKUP_INTERVAL&#125;.$NUM $&#123;SNAPSHOT_RW&#125;$&#123;BACKUP_DIR&#125;/$&#123;BACKUP_IN&#125; fi; NUM=$(($NUM-1)) done # step 3: make a hard-link-only (except for dirs) copy of the latest snapshot, # if that exists if [ -d $&#123;SNAPSHOT_RW&#125;$&#123;BACKUP_DIR&#125;/$&#123;BACKUP_INTERVAL&#125;.0 ] ; then \\ $CP -al $&#123;SNAPSHOT_RW&#125;$&#123;BACKUP_DIR&#125;/$&#123;BACKUP_INTERVAL&#125;.0 $&#123;SNAPSHOT_RW&#125;$&#123;BACKUP_DIR&#125;/$&#123;BACKUP_INTERVAL&#125; fi; # step 4: rsync from the system into the latest snapshot (notice that # rsync behaves like cp --remove-destination by default, so the destination # is unlinked first. If it were not so, this would copy over the other # snapshot(s) too! $RSYNC \\ -va --delete --delete-excluded \\ --exclude-from=&quot;$EXCLUDES&quot; \\ $&#123;BACKUP_DIR&#125;/ $&#123;SNAPSHOT_RW&#125;$&#123;BACKUP_DIR&#125;/$&#123;BACKUP_INTERVAL&#125;.0 ; # step 5: update the mtime of $&#123;BACKUP_INTERVAL&#125;.0 to reflect the snapshot time $TOUCH $&#123;SNAPSHOT_RW&#125;$&#123;BACKUP_DIR&#125;/$&#123;BACKUP_INTERVAL&#125;.0 ; done # now remount the RW snapshot mountpoint as readonly $MOUNT -o remount,ro $MOUNT_DEVICE $SNAPSHOT_RW ; if (( $? )); then &#123; $ECHO &quot;snapshot: could not remount $SNAPSHOT_RW readonly&quot;; exit; &#125; fi;","categories":[],"tags":[],"author":"张存"},{"title":"docker部署实用的小工具","slug":"docker部署实用的小工具","date":"2022-04-29T05:40:05.000Z","updated":"2022-04-29T09:25:39.769Z","comments":true,"path":"2022/04/29/docker-bu-shu-shi-yong-de-xiao-gong-ju/","link":"","permalink":"https://blog.zhangcun.store/2022/04/29/docker-bu-shu-shi-yong-de-xiao-gong-ju/","excerpt":"","text":"1、Portainer 容器页面管理工具，初次访问需要设置密码，浏览器访问端口是9000 docker run --itd --restart=always -p 8000:8000 -p 9000:9000 --name=portainer -v /var/run/docker.sock:/var/run/docker.sock -v /data/portainer_data:/data portainer/portainer-ce 2、pdf转中文 由于看的pdf是英文，阅读起来比较慢，可以把pdf转为html再通过谷歌翻译可以直接看 pdf转html方法：需要有linux系统并且安装了docker docker pull bwits/pdf2htmlex alias pdf2htmlEX=&#39;docker run -ti --rm -v `pwd`:/pdf bwits/pdf2htmlex pdf2htmlEX&#39; pdf2htmlEX name.pdf 3、部署磁力下载工具 docker run -itd --restart=always --name=cloud-torrent -p 80:3000 -v /data/downloads:/downloads registry.baidubce.com/tools/cloud-torrent:latest 4、私人搜索引擎 docker run -itd --restart=always --name=searx -p8888:8888 registry.baidubce.com/tools/searx:latest 5、runlike打印出容器创建时参数 输出运行它所需要的命令行以及所有选项（端口，链接，卷等）。对于那些通常通过某些CM工具（如Ansible / Chef）部署Docker容器，然后发现自己需要手动重新运行某些容器的人来说，这是一个实时节省程序。 通过docker安装runlike命令（比pip安装方便） alias runlike=&quot;docker run --rm -v /var/run/docker.sock:/var/run/docker.sock assaflavie/runlike&quot; 如果dockerhub的镜像下载失败可以替换为国内镜像仓库的镜像。 alias runlike=&quot;docker run --rm -v /var/run/docker.sock:/var/run/docker.sock registry.baidubce.com/tools/runlike:latest&quot; 验证： 6、将 docker 镜像反向工程到创建它的 Dockerfile 中 通过docker安装whaler命令（比pip安装方便） alias whaler=&quot;docker run -t --rm -v /var/run/docker.sock:/var/run/docker.sock:ro pegleg/whaler&quot;``` 如果dockerhub的镜像下载失败可以替换为国内镜像仓库的镜像。 ```bash alias whaler=&quot;docker run -t --rm -v /var/run/docker.sock:/var/run/docker.sock:ro registry.baidubce.com/tools/pegleg/whaler:latest&quot;``` 5 验证： whaler -sV=1.36 download-prometheus-operator:v0.38.1 7、minio(本次部署仅测试使用，生产环境建议高可用方式部署) mkdir -p /data/minio docker run -itd --name minio --restart=always -p 9000:9000 -p 9001:9001 -e &quot;MINIO_ACCESS_KEY=admin&quot; -e &quot;MINIO_SECRET_KEY=admin123456&quot; -v /data/minio/data:/data -v /data/minio/config:/root/.minio minio/minio server /data --console-address &quot;:9001&quot; 8、一个简易web服务器 mkdir -p /data/nginx/iso/centos mkdir -p /data/nginx/conf cp nginx.conf /data/nginx/conf docker run -itd --restart=always --name nginx-iso -p 80:80 -v /data/nginx/conf/nginx.conf:/etc/nginx/nginx.conf -v /data/nginx/iso/centos:/opt/iso/centos nginx:latest nginx.conf文件 worker_processes auto; worker_rlimit_nofile 65535; events &#123; worker_connections 20480; &#125; http &#123; include mime.types; default_type application/octet-stream; sendfile on; server &#123; listen 80; server_name localhost; location / &#123; root /opt/iso; autoindex on; autoindex_exact_size off; autoindex_localtime on; &#125; location /opt/iso/centos &#123; autoindex on; autoindex_exact_size off; autoindex_localtime on; &#125; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125; &#125; &#125;","categories":[],"tags":[],"author":"张存"},{"title":"Ubuntu系统安装中文支持，中文UTF-8","slug":"Ubuntu系统安装中文支持，中文UTF-8","date":"2022-04-29T05:07:21.000Z","updated":"2022-04-29T05:07:23.544Z","comments":true,"path":"2022/04/29/ubuntu-xi-tong-an-zhuang-zhong-wen-zhi-chi-zhong-wen-utf-8/","link":"","permalink":"https://blog.zhangcun.store/2022/04/29/ubuntu-xi-tong-an-zhuang-zhong-wen-zhi-chi-zhong-wen-utf-8/","excerpt":"","text":"第一步，安装中文包： sudo apt-get install language-pack-zh* 第二步，配置相关环境变量： sudo vim /etc/environment 在文件中增加语言和编码的设置： LANG=&quot;zh_CN.UTF-8&quot; LANGUAGE=&quot;zh_CN:zh:en_US:en&quot; 第三步，重新设置本地配置： sudo dpkg-reconfigure locales","categories":[],"tags":[],"author":"张存"},{"title":"docker批量重启容器服务","slug":"docker批量重启容器服务","date":"2022-04-29T04:13:45.000Z","updated":"2022-04-29T04:13:47.434Z","comments":true,"path":"2022/04/29/docker-pi-liang-chong-qi-rong-qi-fu-wu/","link":"","permalink":"https://blog.zhangcun.store/2022/04/29/docker-pi-liang-chong-qi-rong-qi-fu-wu/","excerpt":"","text":"docker中 启动所有的容器命令： docker start $(docker ps -a | awk &#39;&#123; print $1&#125;&#39; | tail -n +2) docker中 关闭所有的容器命令： docker stop $(docker ps -a | awk &#39;&#123; print $1&#125;&#39; | tail -n +2) 批量删除容器与镜像： docker ps -a | awk &#39;&#123;print $1&#125;&#39; | xargs docker rm docker images | grep none | awk &#39;&#123;print $3&#125;&#39; | xargs docker rmi 批量重启容器： docker restart $(docker ps | grep test | awk ‘{ print $1}’)","categories":[],"tags":[],"author":"张存"},{"title":"Ubuntu驱动nvidia更新与说明","slug":"Ubuntu驱动nvidia更新与说明","date":"2022-04-27T09:13:36.000Z","updated":"2022-04-27T09:31:12.458Z","comments":true,"path":"2022/04/27/ubuntu-qu-dong-nvidia-geng-xin-yu-shuo-ming/","link":"","permalink":"https://blog.zhangcun.store/2022/04/27/ubuntu-qu-dong-nvidia-geng-xin-yu-shuo-ming/","excerpt":"","text":"ubuntu18.04 nvidia-smi是nvidia 的系统管理界面 ，其中smi是System management interface的缩写， 它可以收集各种级别的信息，查看显存使用情况。此外, 可以启用和禁用 GPU 配置选项 (如 ECC 内存功能)。 查看GPU信息报错如下： root@iZ2zeiflf48wp1ved7nnnmZ:~# nvidia-smi Failed to initialize NVML: Driver/library version mismatch 查找本机内核版本： cat /proc/driver/nvidia/version 查看客户端驱动版本： cat /var/log/dpkg.log | grep nvidia #发现明显不一样，一个是400.82，一个是400.100，内核版本低于客户端版本。 再查看系统日志： 直接提示原因是：NVIDIA 内核驱动版本与系统驱动不一致导致 解决方法： 卸载驱动： root@iZ2zeiflf48wp1ved7nnnmZ:~# sudo rmmod nvidia rmmod: ERROR: Module nvidia is in use by: nvidia_uvm nvidia_modeset 卸载失败，提示要先卸载依赖： root@iZ2zeiflf48wp1ved7nnnmZ:~# sudo rmmod nvidia_uvm root@iZ2zeiflf48wp1ved7nnnmZ:~# sudo rmmod nvidia_modeset rmmod: ERROR: Module nvidia_modeset is in use by: nvidia_drm 继续根据提示卸载依赖： root@iZ2zeiflf48wp1ved7nnnmZ:~# sudo rmmod nvidia_drm root@iZ2zeiflf48wp1ved7nnnmZ:~# sudo rmmod nvidia_modeset root@iZ2zeiflf48wp1ved7nnnmZ:~# sudo rmmod nvidia 最后重新查看GPU信息： root@iZ2zeiflf48wp1ved7nnnmZ:~# nvidia-smi 重新查看驱动内核版本和客户端版本已经一致： 这是服务器上Ubuntu18.04的信息。 上面的表格中： 第一栏的Fan：0表示只有一块GPU,0下面的N/A是风扇转速，从0到100%之间变动，这个速度是计算机期望的风扇转速，实际情况下如果风扇堵转，可能打不到显示的转速。有的设备不会返回转速，因为它不依赖风扇冷却而是通过其他外设保持低温（比如云主机）。 第二栏的Temp：是温度，单位摄氏度。 第三栏的Perf：是性能状态，从P0到P12，P0表示最大性能，P12表示状态最小性能。 第四栏下方的Pwr：是能耗，28W / 250W表示当前功率和总功率；上方的Persistence-M：是GPU常驻持续模式，持续模式虽然耗能大，但是在新的GPU应用启动时，花费的时间更少，这里显示的是off的状态。 第五栏的Bus-Id：00000000:00:09.0是GPU总线相关的东西，domain:bus:device.function（域：总线:设备.功能） 第六栏的Disp.A是Display Active（显示活动），表示GPU的显示是否初始化。 第五第六栏下方的Memory Usage是显存使用率，0MiB / 16280MiB表示：系统占用显存数量/显存总大小。 第七栏是浮动的GPU利用率。 第八栏上方是关于ECC的东西，这是显示off(关闭)。 第八栏下方Compute M：默认模式是计算。 下面如果有进程的化会显示一格：表示每个进程占用的显存使用率。","categories":[],"tags":[],"author":"张存"},{"title":"解决Driver/library version mismatch","slug":"解决Driver-library-version-mismatch","date":"2022-04-27T09:05:43.000Z","updated":"2022-04-27T09:05:45.917Z","comments":true,"path":"2022/04/27/jie-jue-driver-library-version-mismatch/","link":"","permalink":"https://blog.zhangcun.store/2022/04/27/jie-jue-driver-library-version-mismatch/","excerpt":"","text":"概述 服务器更新nvidia driver 版本之后，经常会出现 Failed to initialize NVML: Driver/library version mismatch 这个问题出现的原因是kernel mod 的 Nvidia driver 的版本没有更新： 1. 一般情况下，重启机器就能够解决。 2. 如果因为某些原因不能够重启的话，也有办法reload kernel mod 服务器更新nvidia driver 版本之后，经常会出现 Failed to initialize NVML: Driver/library version mismatch 这个问题出现的原因是kernel mod 的 Nvidiadriver 的版本没有更新： 1. 一般情况下，重启机器就能够解决。 2. 如果因为某些原因不能够重启的话，也有办法reload kernel mod。 简单来看，就两步 unload nvidiakernel mod reload nvidia kernel mod 执行起来就是 sudo rmmod nvidia sudo nvidia-smi nvidia-smi 发现没有 kernel mod 会将其自动装载。 但是事情远远不是这么简单，一般情况下都会遇到卸载失败。 $ sudo rmmod nvidia rmmod: ERROR: Module nvidia is in use by: nvidia_modeset nvidia_uvm 这时，就要一点一点的卸载整个驱动了，首先要知道现在kernel mod 的依赖情况， 首先我们从错误信息中知道，nvidia_modeset nvidia_uvm 这两个 mod 依赖于 nvidia,所以要先卸载他们 $lsmod | grep nvidia nvidia_uvm 647168 0 nvidia_drm 53248 0 nvidia_modeset 790528 1 nvidia_drm nvidia 12144640 152 nvidia_modeset,nvidia_uvm 12144640 152 nvidia_modeset,nvidia_uvm 可以看到 nvidia 被使用了152词，我们可以先卸载 nvidia_uvm 和 nvidia_modeset 先查看下有哪些进程使用了 nvidia* sudo lsof -n -w /dev/nvidia* 对这些进程有个了解，如果一会卸载失败，记得关闭相关进程。 卸载 nvidia_uvm,nvidia_modeset sudo rmmod nvidia_uvm sudo rmmod nvidia_modeset 然后在losf 一遍， 如果nvidia 的使用 Used by 还没有降到0,kill 相关的进程。然后在执行相关卸载操作 最后 sudo rmmod nvidia nvidia-smi","categories":[],"tags":[],"author":"张存"},{"title":"docker删除状态为Exited的容器","slug":"docker删除状态为Exited的容器","date":"2022-04-27T08:06:15.000Z","updated":"2022-04-27T08:08:19.978Z","comments":true,"path":"2022/04/27/docker-shan-chu-zhuang-tai-wei-exited-de-rong-qi/","link":"","permalink":"https://blog.zhangcun.store/2022/04/27/docker-shan-chu-zhuang-tai-wei-exited-de-rong-qi/","excerpt":"","text":"docker rm $(docker ps -qf status=exited)","categories":[],"tags":[],"author":"张存"},{"title":"Nginx中如何限制某个IP同一时间段的访问次数和并发数","slug":"Nginx中如何限制某个IP同一时间段的访问次数和并发数","date":"2022-04-26T11:42:57.000Z","updated":"2022-04-26T11:42:59.301Z","comments":true,"path":"2022/04/26/nginx-zhong-ru-he-xian-zhi-mou-ge-ip-tong-yi-shi-jian-duan-de-fang-wen-ci-shu-he-bing-fa-shu/","link":"","permalink":"https://blog.zhangcun.store/2022/04/26/nginx-zhong-ru-he-xian-zhi-mou-ge-ip-tong-yi-shi-jian-duan-de-fang-wen-ci-shu-he-bing-fa-shu/","excerpt":"","text":"最近一个项目为了防止刷票，需要对nginx 设置能限制某个IP某一时间段的访问次数 具体修改如下： nginx.conf 配置修改 在 http &#123; &#125; 里面加上 limit_req_zone $binary_remote_addr zone=allips:10m rate=30r/s; limit_req zone=allips burst=5 nodelay; 下面为注释 #定义一个名为allips的limit_req_zone用来存储session，大小是10M内存， #以$binary_remote_addr 为key,限制平均每秒的请求为30个， #1M能存储16000个状态，rete的值必须为整数， #如果限制两秒钟一个请求，可以设置成30r/m 下面为注释 #定义一个名为allips的limit_req_zone用来存储session，大小是10M内存， #以$binary_remote_addr 为key,限制平均每秒的请求为30个， #1M能存储16000个状态，rete的值必须为整数， #如果限制两秒钟一个请求，可以设置成30r/m 在需要限制并发数和下载带宽的网站配置文件中 server&#123; &#125; 里加上如下代码 limit_conn one 5; #并发连接数为5 limit_rate 100k; #限速为 100KB/秒 在server 上面加上如下代码 limit_conn_zone $binary_remote_addr zone=one:10m;","categories":[],"tags":[],"author":"张存"},{"title":"mysql修改最大连接数&wait_timeout时间","slug":"mysql修改最大连接数-wait-timeout时间","date":"2022-04-26T11:29:37.000Z","updated":"2022-04-26T11:30:34.408Z","comments":true,"path":"2022/04/26/mysql-xiu-gai-zui-da-lian-jie-shu-wait-timeout-shi-jian/","link":"","permalink":"https://blog.zhangcun.store/2022/04/26/mysql-xiu-gai-zui-da-lian-jie-shu-wait-timeout-shi-jian/","excerpt":"","text":"show processlist; 查看连接数，可以发现有很多连接处于sleep状态，这些其实是暂时没有用的，所以可以kill掉 show variables like &quot;max_connections&quot;; 查看最大连接数，应该是与上面查询到的连接数相同，才会出现too many connections的情况 set GLOBAL max_connections=1000; 修改最大连接数，但是这不是一劳永逸的方法，应该要让它自动杀死那些sleep的进程。 show global variables like &#39;wait_timeout&#39;; 这个数值指的是mysql在关闭一个非交互的连接之前要等待的秒数，默认是28800s set global wait_timeout=300; 修改这个数值，这里可以随意，最好控制在几分钟内 set global interactive_timeout=500; 修改这个数值，表示mysql在关闭一个连接之前要等待的秒数，至此可以让mysql自动关闭那些没用的连接，但要注意的是，正在使用的连接到了时间也会被关闭，因此这个时间值要合适 show status like &#39;Threads%&#39;; 查询线程数","categories":[],"tags":[],"author":"张存"},{"title":"zabbix监控docker容器","slug":"zabbix监控docker容器","date":"2022-04-26T11:02:58.000Z","updated":"2022-04-26T11:03:02.388Z","comments":true,"path":"2022/04/26/zabbix-jian-kong-docker-rong-qi/","link":"","permalink":"https://blog.zhangcun.store/2022/04/26/zabbix-jian-kong-docker-rong-qi/","excerpt":"","text":"1、环境说明 由于最近zabbix进行过一次迁移，所以zabbix-server系列采用docker方式安装，参考zabbix官网：https://github.com/zabbix/zabbix-docker。为适应本地环境和需求，docker-compose.yml文件有改动，具体内容如下： docker-compose.yml文件 复制代码 version: &#39;3.5&#39; services: zabbix-server: image: zabbix/zabbix-server-mysql:centos-4.2-latest ports: - &quot;10051:10051&quot; volumes: - /etc/localtime:/etc/localtime:ro - /etc/timezone:/etc/timezone:ro - ./zbx_env/usr/lib/zabbix/alertscripts:/usr/lib/zabbix/alertscripts:ro - ./zbx_env/usr/lib/zabbix/externalscripts:/usr/lib/zabbix/externalscripts:ro - ./zbx_env/var/lib/zabbix/modules:/var/lib/zabbix/modules:ro - ./zbx_env/var/lib/zabbix/enc:/var/lib/zabbix/enc:ro - ./zbx_env/var/lib/zabbix/ssh_keys:/var/lib/zabbix/ssh_keys:ro - ./zbx_env/var/lib/zabbix/mibs:/var/lib/zabbix/mibs:ro links: - mysql-server:mysql-server container_name: zabbix-server restart: unless-stopped ulimits: nproc: 65535 nofile: soft: 20000 hard: 40000 env_file: - .env_db_mysql - .env_srv secrets: - MYSQL_USER - MYSQL_PASSWORD - MYSQL_ROOT_PASSWORD user: root depends_on: - mysql-server stop_grace_period: 30s sysctls: - net.ipv4.ip_local_port_range=1024 65000 - net.ipv4.conf.all.accept_redirects=0 - net.ipv4.conf.all.secure_redirects=0 - net.ipv4.conf.all.send_redirects=0 zabbix-web-nginx-mysql: image: zabbix/zabbix-web-nginx-mysql:centos-4.2-latest ports: - &quot;8081:80&quot; - &quot;8443:443&quot; links: - mysql-server:mysql-server - zabbix-server:zabbix-server container_name: zabbix-web-nginx-mysql restart: unless-stopped volumes: - /etc/localtime:/etc/localtime:ro - /etc/timezone:/etc/timezone:ro - ./zbx_env/etc/ssl/nginx:/etc/ssl/nginx:ro env_file: - .env_db_mysql - .env_web secrets: - MYSQL_USER - MYSQL_PASSWORD user: root depends_on: - mysql-server - zabbix-server healthcheck: test: [&quot;CMD&quot;, &quot;curl&quot;, &quot;-f&quot;, &quot;http://localhost&quot;] interval: 10s timeout: 5s retries: 3 start_period: 30s stop_grace_period: 10s sysctls: - net.core.somaxconn=65535 zabbix-agent: image: zabbix/zabbix-agent:centos-4.2-latest ports: - &quot;10050:10050&quot; volumes: - /etc/localtime:/etc/localtime:ro - /etc/timezone:/etc/timezone:ro - ./zbx_env/etc/zabbix/zabbix_agentd.d:/etc/zabbix/zabbix_agentd.d:ro - ./zbx_env/usr/lib/zabbix/alertscripts:/usr/lib/zabbix/alertscripts:ro - ./zbx_env/usr/lib/zabbix/externalscripts:/usr/lib/zabbix/externalscripts:ro - ./zbx_env/var/lib/zabbix/modules:/var/lib/zabbix/modules:ro - ./zbx_env/var/lib/zabbix/enc:/var/lib/zabbix/enc:ro - ./zbx_env/var/lib/zabbix/ssh_keys:/var/lib/zabbix/ssh_keys:ro links: - zabbix-server:zabbix-server restart: unless-stopped container_name: zabbix-agent env_file: - .env_agent user: root privileged: true pid: &quot;host&quot; stop_grace_period: 5s mysql-server: image: mysql:8.0 ports: - &quot;33060:3306&quot; command: [mysqld, --character-set-server=utf8, --collation-server=utf8_bin, --default-authentication-plugin=mysql_native_password] volumes: - ./zbx_env/var/lib/mysql:/var/lib/mysql:rw restart: unless-stopped container_name: mysql-server env_file: - .env_db_mysql secrets: - MYSQL_USER - MYSQL_PASSWORD - MYSQL_ROOT_PASSWORD user: root stop_grace_period: 1m secrets: MYSQL_USER: file: ./.MYSQL_USER MYSQL_PASSWORD: file: ./.MYSQL_PASSWORD MYSQL_ROOT_PASSWORD: file: ./.MYSQL_ROOT_PASSWORD 复制代码 2、zabbix添加自定义监控 （1）zabbix_server.conf配置 #脚本路径 AlertScriptsPath=/usr/lib/zabbix/alertscripts ExternalScripts=/usr/lib/zabbix/externalscripts （2）zabbix_agent.conf配置 ##允许使用用户自定义参数 UnsafeUserParameters=1 ##导入该文件下的配置 Include=/etc/zabbix/zabbix_agentd.d/*.conf （3）自定义监控脚本 /usr/lib/zabbix/externalscripts/docker_discovery.py，搜集正在运行的容器的名称 复制代码 #!/usr/bin/env python # -*- coding: utf-8 -* import os import simplejson as json t=os.popen(&quot;&quot;&quot;docker ps |grep -v &#39;CONTAINER ID&#39;|awk &#123;&#39;print $NF&#39;&#125; &quot;&quot;&quot;) container_name = [] for container in t.readlines(): r = os.path.basename(container.strip()) container_name += [&#123;&#39;&#123;#CONTAINERNAME&#125;':r&#125;] print(json.dumps(&#123;'data':container_name&#125;,sort_keys=True,indent=4,separators=(',',':'))) 复制代码 安装python3 所需要的包 pip3 install simplejson docker_discovery.py执行结果 复制代码 python3 docker_discovery.py &#123; \"data\":[ &#123; \"&#123;#CONTAINERNAME&#125;\":\"nginx\" &#125;, &#123; \"&#123;#CONTAINERNAME&#125;\":\"fortune\" &#125; ] &#125; 复制代码 /usr/lib/zabbix/externalscripts/docker_monitor.py，输入容器名称以及监控项，输出数据 复制代码 #!/usr/bin/env python import docker import sys import subprocess import os def check_container_stats(container_name,collect_item): if collect_item == \"ping\": cmd = 'docker inspect --format=\"&#123;&#123;.State.Running&#125;&#125;&quot; %s&#39; % container_name result = os.popen(cmd).read().replace(&quot;\\n&quot;,&quot;&quot;) if result == &quot;true&quot;: return 1 else: return 0 #:docker_client = docker_client.containers.get(container_name) container_collect=docker_client.containers.get(container_name).stats(stream=True) old_result=eval(next(container_collect)) new_result=eval(next(container_collect)) print(new_result) container_collect.close() if collect_item == &#39;cpu_total_usage&#39;: result=new_result[&#39;cpu_stats&#39;][&#39;cpu_usage&#39;][&#39;total_usage&#39;] - old_result[&#39;cpu_stats&#39;][&#39;cpu_usage&#39;][&#39;total_usage&#39;] elif collect_item == &#39;cpu_system_usage&#39;: result=new_result[&#39;cpu_stats&#39;][&#39;system_cpu_usage&#39;] - old_result[&#39;cpu_stats&#39;][&#39;system_cpu_usage&#39;] elif collect_item == &#39;cpu_percent&#39;: cpu_total_usage=new_result[&#39;cpu_stats&#39;][&#39;cpu_usage&#39;][&#39;total_usage&#39;] - old_result[&#39;cpu_stats&#39;][&#39;cpu_usage&#39;][&#39;total_usage&#39;] cpu_system_uasge=new_result[&#39;cpu_stats&#39;][&#39;system_cpu_usage&#39;] - old_result[&#39;cpu_stats&#39;][&#39;system_cpu_usage&#39;] cpu_num=len(old_result[&#39;cpu_stats&#39;][&#39;cpu_usage&#39;][&#39;percpu_usage&#39;]) result=round((float(cpu_total_usage)/float(cpu_system_uasge))*cpu_num*100.0,2) elif collect_item == &#39;mem_usage&#39;: result=new_result[&#39;memory_stats&#39;][&#39;usage&#39;] elif collect_item == &#39;mem_limit&#39;: result=new_result[&#39;memory_stats&#39;][&#39;limit&#39;] elif collect_item == &#39;network_rx_bytes&#39;: result=new_result[&#39;networks&#39;][&#39;eth0&#39;][&#39;rx_bytes&#39;] elif collect_item == &#39;network_tx_bytes&#39;: result=new_result[&#39;networks&#39;][&#39;eth0&#39;][&#39;tx_bytes&#39;] elif collect_item == &#39;mem_percent&#39;: mem_usage=new_result[&#39;memory_stats&#39;][&#39;usage&#39;] mem_limit=new_result[&#39;memory_stats&#39;][&#39;limit&#39;] result=round(float(mem_usage)/float(mem_limit)*100.0,2) return result if __name__ == &quot;__main__&quot;: docker_client = docker.DockerClient(base_url=&#39;unix://var/run/docker.sock&#39;) container_name=sys.argv[1] collect_item=sys.argv[2] print(check_container_stats(container_name,collect_item) 复制代码 安装python3依赖的包 pip3 install docker docker_monitor.py执行结果 python3 docker_monitor.py nginx mem_percent 0.49 （4）脚本赋执行权限 chmod +x docker_discovery.py chmod +x docker_monitor.py （5）自定义监控配置文件 /etc/zabbix/zabbix_agentd.d/docker_discovery.conf UserParameter=docker_discovery,/usr/bin/python3 /usr/lib/zabbix/externalscripts/docker_discovery.py UserParameter=docker_status[*],/usr/bin/python3 /usr/lib/zabbix/externalscripts/docker_monitor.py $1 $2 （6）导入模板 复制代码 &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;zabbix_export&gt; &lt;version&gt;4.2&lt;/version&gt; &lt;date&gt;2019-09-27T06:35:12Z&lt;/date&gt; &lt;groups&gt; &lt;group&gt; &lt;name&gt;Templates&lt;/name&gt; &lt;/group&gt; &lt;/groups&gt; &lt;templates&gt; &lt;template&gt; &lt;template&gt;Template Discovery Docker&lt;/template&gt; &lt;name&gt;Template Discovery Docker&lt;/name&gt; &lt;description/&gt; &lt;groups&gt; &lt;group&gt; &lt;name&gt;Templates&lt;/name&gt; &lt;/group&gt; &lt;/groups&gt; &lt;applications/&gt; &lt;items/&gt; &lt;discovery_rules&gt; &lt;discovery_rule&gt; &lt;name&gt;collect docker container use resource&lt;/name&gt; &lt;type&gt;0&lt;/type&gt; &lt;snmp_community/&gt; &lt;snmp_oid/&gt; &lt;key&gt;docker_discovery&lt;/key&gt; &lt;delay&gt;30s&lt;/delay&gt; &lt;status&gt;0&lt;/status&gt; &lt;allowed_hosts/&gt; &lt;snmpv3_contextname/&gt; &lt;snmpv3_securityname/&gt; &lt;snmpv3_securitylevel&gt;0&lt;/snmpv3_securitylevel&gt; &lt;snmpv3_authprotocol&gt;0&lt;/snmpv3_authprotocol&gt; &lt;snmpv3_authpassphrase/&gt; &lt;snmpv3_privprotocol&gt;0&lt;/snmpv3_privprotocol&gt; &lt;snmpv3_privpassphrase/&gt; &lt;params/&gt; &lt;ipmi_sensor/&gt; &lt;authtype&gt;0&lt;/authtype&gt; &lt;username/&gt; &lt;password/&gt; &lt;publickey/&gt; &lt;privatekey/&gt; &lt;port/&gt; &lt;filter&gt; &lt;evaltype&gt;0&lt;/evaltype&gt; &lt;formula/&gt; &lt;conditions&gt; &lt;condition&gt; &lt;macro&gt;&#123;#CONTAINERNAME&#125;&lt;/macro&gt; &lt;value/&gt; &lt;operator&gt;8&lt;/operator&gt; &lt;formulaid&gt;A&lt;/formulaid&gt; &lt;/condition&gt; &lt;/conditions&gt; &lt;/filter&gt; &lt;lifetime&gt;30d&lt;/lifetime&gt; &lt;description/&gt; &lt;item_prototypes&gt; &lt;item_prototype&gt; &lt;name&gt;docker:&#123;#CONTAINERNAME&#125;:cpu_percent&lt;/name&gt; &lt;type&gt;0&lt;/type&gt; &lt;snmp_community/&gt; &lt;snmp_oid/&gt; &lt;key&gt;docker_status[&#123;#CONTAINERNAME&#125;,cpu_percent]&lt;/key&gt; &lt;delay&gt;30s&lt;/delay&gt; &lt;history&gt;90d&lt;/history&gt; &lt;trends&gt;365d&lt;/trends&gt; &lt;status&gt;0&lt;/status&gt; &lt;value_type&gt;0&lt;/value_type&gt; &lt;allowed_hosts/&gt; &lt;units&gt;%&lt;/units&gt; &lt;snmpv3_contextname/&gt; &lt;snmpv3_securityname/&gt; &lt;snmpv3_securitylevel&gt;0&lt;/snmpv3_securitylevel&gt; &lt;snmpv3_authprotocol&gt;0&lt;/snmpv3_authprotocol&gt; &lt;snmpv3_authpassphrase/&gt; &lt;snmpv3_privprotocol&gt;0&lt;/snmpv3_privprotocol&gt; &lt;snmpv3_privpassphrase/&gt; &lt;params/&gt; &lt;ipmi_sensor/&gt; &lt;authtype&gt;0&lt;/authtype&gt; &lt;username/&gt; &lt;password/&gt; &lt;publickey/&gt; &lt;privatekey/&gt; &lt;port/&gt; &lt;description/&gt; &lt;inventory_link&gt;0&lt;/inventory_link&gt; &lt;applications/&gt; &lt;valuemap/&gt; &lt;logtimefmt/&gt; &lt;preprocessing/&gt; &lt;jmx_endpoint/&gt; &lt;timeout&gt;3s&lt;/timeout&gt; &lt;url/&gt; &lt;query_fields/&gt; &lt;posts/&gt; &lt;status_codes&gt;200&lt;/status_codes&gt; &lt;follow_redirects&gt;1&lt;/follow_redirects&gt; &lt;post_type&gt;0&lt;/post_type&gt; &lt;http_proxy/&gt; &lt;headers/&gt; &lt;retrieve_mode&gt;0&lt;/retrieve_mode&gt; &lt;request_method&gt;0&lt;/request_method&gt; &lt;output_format&gt;0&lt;/output_format&gt; &lt;allow_traps&gt;0&lt;/allow_traps&gt; &lt;ssl_cert_file/&gt; &lt;ssl_key_file/&gt; &lt;ssl_key_password/&gt; &lt;verify_peer&gt;0&lt;/verify_peer&gt; &lt;verify_host&gt;0&lt;/verify_host&gt; &lt;application_prototypes/&gt; &lt;master_item/&gt; &lt;/item_prototype&gt; &lt;item_prototype&gt; &lt;name&gt;docker:&#123;#CONTAINERNAME&#125;:cpu_total_usage&lt;/name&gt; &lt;type&gt;0&lt;/type&gt; &lt;snmp_community/&gt; &lt;snmp_oid/&gt; &lt;key&gt;docker_status[&#123;#CONTAINERNAME&#125;,cpu_total_usage]&lt;/key&gt; &lt;delay&gt;30s&lt;/delay&gt; &lt;history&gt;90d&lt;/history&gt; &lt;trends&gt;365d&lt;/trends&gt; &lt;status&gt;0&lt;/status&gt; &lt;value_type&gt;3&lt;/value_type&gt; &lt;allowed_hosts/&gt; &lt;units/&gt; &lt;snmpv3_contextname/&gt; &lt;snmpv3_securityname/&gt; &lt;snmpv3_securitylevel&gt;0&lt;/snmpv3_securitylevel&gt; &lt;snmpv3_authprotocol&gt;0&lt;/snmpv3_authprotocol&gt; &lt;snmpv3_authpassphrase/&gt; &lt;snmpv3_privprotocol&gt;0&lt;/snmpv3_privprotocol&gt; &lt;snmpv3_privpassphrase/&gt; &lt;params/&gt; &lt;ipmi_sensor/&gt; &lt;authtype&gt;0&lt;/authtype&gt; &lt;username/&gt; &lt;password/&gt; &lt;publickey/&gt; &lt;privatekey/&gt; &lt;port/&gt; &lt;description/&gt; &lt;inventory_link&gt;0&lt;/inventory_link&gt; &lt;applications/&gt; &lt;valuemap/&gt; &lt;logtimefmt/&gt; &lt;preprocessing/&gt; &lt;jmx_endpoint/&gt; &lt;timeout&gt;3s&lt;/timeout&gt; &lt;url/&gt; &lt;query_fields/&gt; &lt;posts/&gt; &lt;status_codes&gt;200&lt;/status_codes&gt; &lt;follow_redirects&gt;1&lt;/follow_redirects&gt; &lt;post_type&gt;0&lt;/post_type&gt; &lt;http_proxy/&gt; &lt;headers/&gt; &lt;retrieve_mode&gt;0&lt;/retrieve_mode&gt; &lt;request_method&gt;0&lt;/request_method&gt; &lt;output_format&gt;0&lt;/output_format&gt; &lt;allow_traps&gt;0&lt;/allow_traps&gt; &lt;ssl_cert_file/&gt; &lt;ssl_key_file/&gt; &lt;ssl_key_password/&gt; &lt;verify_peer&gt;0&lt;/verify_peer&gt; &lt;verify_host&gt;0&lt;/verify_host&gt; &lt;application_prototypes/&gt; &lt;master_item/&gt; &lt;/item_prototype&gt; &lt;item_prototype&gt; &lt;name&gt;docker:&#123;#CONTAINERNAME&#125;:men_percent&lt;/name&gt; &lt;type&gt;0&lt;/type&gt; &lt;snmp_community/&gt; &lt;snmp_oid/&gt; &lt;key&gt;docker_status[&#123;#CONTAINERNAME&#125;,mem_percent]&lt;/key&gt; &lt;delay&gt;30s&lt;/delay&gt; &lt;history&gt;90d&lt;/history&gt; &lt;trends&gt;365d&lt;/trends&gt; &lt;status&gt;0&lt;/status&gt; &lt;value_type&gt;0&lt;/value_type&gt; &lt;allowed_hosts/&gt; &lt;units&gt;%&lt;/units&gt; &lt;snmpv3_contextname/&gt; &lt;snmpv3_securityname/&gt; &lt;snmpv3_securitylevel&gt;0&lt;/snmpv3_securitylevel&gt; &lt;snmpv3_authprotocol&gt;0&lt;/snmpv3_authprotocol&gt; &lt;snmpv3_authpassphrase/&gt; &lt;snmpv3_privprotocol&gt;0&lt;/snmpv3_privprotocol&gt; &lt;snmpv3_privpassphrase/&gt; &lt;params/&gt; &lt;ipmi_sensor/&gt; &lt;authtype&gt;0&lt;/authtype&gt; &lt;username/&gt; &lt;password/&gt; &lt;publickey/&gt; &lt;privatekey/&gt; &lt;port/&gt; &lt;description/&gt; &lt;inventory_link&gt;0&lt;/inventory_link&gt; &lt;applications/&gt; &lt;valuemap/&gt; &lt;logtimefmt/&gt; &lt;preprocessing/&gt; &lt;jmx_endpoint/&gt; &lt;timeout&gt;3s&lt;/timeout&gt; &lt;url/&gt; &lt;query_fields/&gt; &lt;posts/&gt; &lt;status_codes&gt;200&lt;/status_codes&gt; &lt;follow_redirects&gt;1&lt;/follow_redirects&gt; &lt;post_type&gt;0&lt;/post_type&gt; &lt;http_proxy/&gt; &lt;headers/&gt; &lt;retrieve_mode&gt;0&lt;/retrieve_mode&gt; &lt;request_method&gt;0&lt;/request_method&gt; &lt;output_format&gt;0&lt;/output_format&gt; &lt;allow_traps&gt;0&lt;/allow_traps&gt; &lt;ssl_cert_file/&gt; &lt;ssl_key_file/&gt; &lt;ssl_key_password/&gt; &lt;verify_peer&gt;0&lt;/verify_peer&gt; &lt;verify_host&gt;0&lt;/verify_host&gt; &lt;application_prototypes/&gt; &lt;master_item/&gt; &lt;/item_prototype&gt; &lt;item_prototype&gt; &lt;name&gt;docker:&#123;#CONTAINERNAME&#125;:men_usage&lt;/name&gt; &lt;type&gt;0&lt;/type&gt; &lt;snmp_community/&gt; &lt;snmp_oid/&gt; &lt;key&gt;docker_status[&#123;#CONTAINERNAME&#125;,mem_usage]&lt;/key&gt; &lt;delay&gt;30s&lt;/delay&gt; &lt;history&gt;90d&lt;/history&gt; &lt;trends&gt;365d&lt;/trends&gt; &lt;status&gt;0&lt;/status&gt; &lt;value_type&gt;0&lt;/value_type&gt; &lt;allowed_hosts/&gt; &lt;units&gt;%&lt;/units&gt; &lt;snmpv3_contextname/&gt; &lt;snmpv3_securityname/&gt; &lt;snmpv3_securitylevel&gt;0&lt;/snmpv3_securitylevel&gt; &lt;snmpv3_authprotocol&gt;0&lt;/snmpv3_authprotocol&gt; &lt;snmpv3_authpassphrase/&gt; &lt;snmpv3_privprotocol&gt;0&lt;/snmpv3_privprotocol&gt; &lt;snmpv3_privpassphrase/&gt; &lt;params/&gt; &lt;ipmi_sensor/&gt; &lt;authtype&gt;0&lt;/authtype&gt; &lt;username/&gt; &lt;password/&gt; &lt;publickey/&gt; &lt;privatekey/&gt; &lt;port/&gt; &lt;description/&gt; &lt;inventory_link&gt;0&lt;/inventory_link&gt; &lt;applications/&gt; &lt;valuemap/&gt; &lt;logtimefmt/&gt; &lt;preprocessing/&gt; &lt;jmx_endpoint/&gt; &lt;timeout&gt;3s&lt;/timeout&gt; &lt;url/&gt; &lt;query_fields/&gt; &lt;posts/&gt; &lt;status_codes&gt;200&lt;/status_codes&gt; &lt;follow_redirects&gt;1&lt;/follow_redirects&gt; &lt;post_type&gt;0&lt;/post_type&gt; &lt;http_proxy/&gt; &lt;headers/&gt; &lt;retrieve_mode&gt;0&lt;/retrieve_mode&gt; &lt;request_method&gt;0&lt;/request_method&gt; &lt;output_format&gt;0&lt;/output_format&gt; &lt;allow_traps&gt;0&lt;/allow_traps&gt; &lt;ssl_cert_file/&gt; &lt;ssl_key_file/&gt; &lt;ssl_key_password/&gt; &lt;verify_peer&gt;0&lt;/verify_peer&gt; &lt;verify_host&gt;0&lt;/verify_host&gt; &lt;application_prototypes/&gt; &lt;master_item/&gt; &lt;/item_prototype&gt; &lt;item_prototype&gt; &lt;name&gt;docker:&#123;#CONTAINERNAME&#125;:network_rx_bytes&lt;/name&gt; &lt;type&gt;0&lt;/type&gt; &lt;snmp_community/&gt; &lt;snmp_oid/&gt; &lt;key&gt;docker_status[&#123;#CONTAINERNAME&#125;,network_rx_bytes]&lt;/key&gt; &lt;delay&gt;30s&lt;/delay&gt; &lt;history&gt;90d&lt;/history&gt; &lt;trends&gt;365d&lt;/trends&gt; &lt;status&gt;0&lt;/status&gt; &lt;value_type&gt;0&lt;/value_type&gt; &lt;allowed_hosts/&gt; &lt;units&gt;%&lt;/units&gt; &lt;snmpv3_contextname/&gt; &lt;snmpv3_securityname/&gt; &lt;snmpv3_securitylevel&gt;0&lt;/snmpv3_securitylevel&gt; &lt;snmpv3_authprotocol&gt;0&lt;/snmpv3_authprotocol&gt; &lt;snmpv3_authpassphrase/&gt; &lt;snmpv3_privprotocol&gt;0&lt;/snmpv3_privprotocol&gt; &lt;snmpv3_privpassphrase/&gt; &lt;params/&gt; &lt;ipmi_sensor/&gt; &lt;authtype&gt;0&lt;/authtype&gt; &lt;username/&gt; &lt;password/&gt; &lt;publickey/&gt; &lt;privatekey/&gt; &lt;port/&gt; &lt;description/&gt; &lt;inventory_link&gt;0&lt;/inventory_link&gt; &lt;applications/&gt; &lt;valuemap/&gt; &lt;logtimefmt/&gt; &lt;preprocessing/&gt; &lt;jmx_endpoint/&gt; &lt;timeout&gt;3s&lt;/timeout&gt; &lt;url/&gt; &lt;query_fields/&gt; &lt;posts/&gt; &lt;status_codes&gt;200&lt;/status_codes&gt; &lt;follow_redirects&gt;1&lt;/follow_redirects&gt; &lt;post_type&gt;0&lt;/post_type&gt; &lt;http_proxy/&gt; &lt;headers/&gt; &lt;retrieve_mode&gt;0&lt;/retrieve_mode&gt; &lt;request_method&gt;0&lt;/request_method&gt; &lt;output_format&gt;0&lt;/output_format&gt; &lt;allow_traps&gt;0&lt;/allow_traps&gt; &lt;ssl_cert_file/&gt; &lt;ssl_key_file/&gt; &lt;ssl_key_password/&gt; &lt;verify_peer&gt;0&lt;/verify_peer&gt; &lt;verify_host&gt;0&lt;/verify_host&gt; &lt;application_prototypes/&gt; &lt;master_item/&gt; &lt;/item_prototype&gt; &lt;item_prototype&gt; &lt;name&gt;docker:&#123;#CONTAINERNAME&#125;:network_tx_bytes&lt;/name&gt; &lt;type&gt;0&lt;/type&gt; &lt;snmp_community/&gt; &lt;snmp_oid/&gt; &lt;key&gt;docker_status[&#123;#CONTAINERNAME&#125;,network_tx_bytes]&lt;/key&gt; &lt;delay&gt;30s&lt;/delay&gt; &lt;history&gt;90d&lt;/history&gt; &lt;trends&gt;365d&lt;/trends&gt; &lt;status&gt;0&lt;/status&gt; &lt;value_type&gt;0&lt;/value_type&gt; &lt;allowed_hosts/&gt; &lt;units&gt;%&lt;/units&gt; &lt;snmpv3_contextname/&gt; &lt;snmpv3_securityname/&gt; &lt;snmpv3_securitylevel&gt;0&lt;/snmpv3_securitylevel&gt; &lt;snmpv3_authprotocol&gt;0&lt;/snmpv3_authprotocol&gt; &lt;snmpv3_authpassphrase/&gt; &lt;snmpv3_privprotocol&gt;0&lt;/snmpv3_privprotocol&gt; &lt;snmpv3_privpassphrase/&gt; &lt;params/&gt; &lt;ipmi_sensor/&gt; &lt;authtype&gt;0&lt;/authtype&gt; &lt;username/&gt; &lt;password/&gt; &lt;publickey/&gt; &lt;privatekey/&gt; &lt;port/&gt; &lt;description/&gt; &lt;inventory_link&gt;0&lt;/inventory_link&gt; &lt;applications/&gt; &lt;valuemap/&gt; &lt;logtimefmt/&gt; &lt;preprocessing/&gt; &lt;jmx_endpoint/&gt; &lt;timeout&gt;3s&lt;/timeout&gt; &lt;url/&gt; &lt;query_fields/&gt; &lt;posts/&gt; &lt;status_codes&gt;200&lt;/status_codes&gt; &lt;follow_redirects&gt;1&lt;/follow_redirects&gt; &lt;post_type&gt;0&lt;/post_type&gt; &lt;http_proxy/&gt; &lt;headers/&gt; &lt;retrieve_mode&gt;0&lt;/retrieve_mode&gt; &lt;request_method&gt;0&lt;/request_method&gt; &lt;output_format&gt;0&lt;/output_format&gt; &lt;allow_traps&gt;0&lt;/allow_traps&gt; &lt;ssl_cert_file/&gt; &lt;ssl_key_file/&gt; &lt;ssl_key_password/&gt; &lt;verify_peer&gt;0&lt;/verify_peer&gt; &lt;verify_host&gt;0&lt;/verify_host&gt; &lt;application_prototypes/&gt; &lt;master_item/&gt; &lt;/item_prototype&gt; &lt;item_prototype&gt; &lt;name&gt;docker:&#123;#CONTAINERNAME&#125;:is run&lt;/name&gt; &lt;type&gt;0&lt;/type&gt; &lt;snmp_community/&gt; &lt;snmp_oid/&gt; &lt;key&gt;docker_status[&#123;#CONTAINERNAME&#125;,ping]&lt;/key&gt; &lt;delay&gt;30s&lt;/delay&gt; &lt;history&gt;90d&lt;/history&gt; &lt;trends&gt;365d&lt;/trends&gt; &lt;status&gt;0&lt;/status&gt; &lt;value_type&gt;0&lt;/value_type&gt; &lt;allowed_hosts/&gt; &lt;units&gt;%&lt;/units&gt; &lt;snmpv3_contextname/&gt; &lt;snmpv3_securityname/&gt; &lt;snmpv3_securitylevel&gt;0&lt;/snmpv3_securitylevel&gt; &lt;snmpv3_authprotocol&gt;0&lt;/snmpv3_authprotocol&gt; &lt;snmpv3_authpassphrase/&gt; &lt;snmpv3_privprotocol&gt;0&lt;/snmpv3_privprotocol&gt; &lt;snmpv3_privpassphrase/&gt; &lt;params/&gt; &lt;ipmi_sensor/&gt; &lt;authtype&gt;0&lt;/authtype&gt; &lt;username/&gt; &lt;password/&gt; &lt;publickey/&gt; &lt;privatekey/&gt; &lt;port/&gt; &lt;description/&gt; &lt;inventory_link&gt;0&lt;/inventory_link&gt; &lt;applications/&gt; &lt;valuemap/&gt; &lt;logtimefmt/&gt; &lt;preprocessing/&gt; &lt;jmx_endpoint/&gt; &lt;timeout&gt;3s&lt;/timeout&gt; &lt;url/&gt; &lt;query_fields/&gt; &lt;posts/&gt; &lt;status_codes&gt;200&lt;/status_codes&gt; &lt;follow_redirects&gt;1&lt;/follow_redirects&gt; &lt;post_type&gt;0&lt;/post_type&gt; &lt;http_proxy/&gt; &lt;headers/&gt; &lt;retrieve_mode&gt;0&lt;/retrieve_mode&gt; &lt;request_method&gt;0&lt;/request_method&gt; &lt;output_format&gt;0&lt;/output_format&gt; &lt;allow_traps&gt;0&lt;/allow_traps&gt; &lt;ssl_cert_file/&gt; &lt;ssl_key_file/&gt; &lt;ssl_key_password/&gt; &lt;verify_peer&gt;0&lt;/verify_peer&gt; &lt;verify_host&gt;0&lt;/verify_host&gt; &lt;application_prototypes/&gt; &lt;master_item/&gt; &lt;/item_prototype&gt; &lt;item_prototype&gt; &lt;name&gt;docker:&#123;#CONTAINERNAME&#125;:cpu_system_usage&lt;/name&gt; &lt;type&gt;0&lt;/type&gt; &lt;snmp_community/&gt; &lt;snmp_oid/&gt; &lt;key&gt;docker_status[&#123;#CONTAINERNAME&#125;,system_cpu_usage]&lt;/key&gt; &lt;delay&gt;30s&lt;/delay&gt; &lt;history&gt;90d&lt;/history&gt; &lt;trends&gt;365d&lt;/trends&gt; &lt;status&gt;0&lt;/status&gt; &lt;value_type&gt;0&lt;/value_type&gt; &lt;allowed_hosts/&gt; &lt;units&gt;%&lt;/units&gt; &lt;snmpv3_contextname/&gt; &lt;snmpv3_securityname/&gt; &lt;snmpv3_securitylevel&gt;0&lt;/snmpv3_securitylevel&gt; &lt;snmpv3_authprotocol&gt;0&lt;/snmpv3_authprotocol&gt; &lt;snmpv3_authpassphrase/&gt; &lt;snmpv3_privprotocol&gt;0&lt;/snmpv3_privprotocol&gt; &lt;snmpv3_privpassphrase/&gt; &lt;params/&gt; &lt;ipmi_sensor/&gt; &lt;authtype&gt;0&lt;/authtype&gt; &lt;username/&gt; &lt;password/&gt; &lt;publickey/&gt; &lt;privatekey/&gt; &lt;port/&gt; &lt;description/&gt; &lt;inventory_link&gt;0&lt;/inventory_link&gt; &lt;applications/&gt; &lt;valuemap/&gt; &lt;logtimefmt/&gt; &lt;preprocessing/&gt; &lt;jmx_endpoint/&gt; &lt;timeout&gt;3s&lt;/timeout&gt; &lt;url/&gt; &lt;query_fields/&gt; &lt;posts/&gt; &lt;status_codes&gt;200&lt;/status_codes&gt; &lt;follow_redirects&gt;1&lt;/follow_redirects&gt; &lt;post_type&gt;0&lt;/post_type&gt; &lt;http_proxy/&gt; &lt;headers/&gt; &lt;retrieve_mode&gt;0&lt;/retrieve_mode&gt; &lt;request_method&gt;0&lt;/request_method&gt; &lt;output_format&gt;0&lt;/output_format&gt; &lt;allow_traps&gt;0&lt;/allow_traps&gt; &lt;ssl_cert_file/&gt; &lt;ssl_key_file/&gt; &lt;ssl_key_password/&gt; &lt;verify_peer&gt;0&lt;/verify_peer&gt; &lt;verify_host&gt;0&lt;/verify_host&gt; &lt;application_prototypes/&gt; &lt;master_item/&gt; &lt;/item_prototype&gt; &lt;/item_prototypes&gt; &lt;trigger_prototypes/&gt; &lt;graph_prototypes&gt; &lt;graph_prototype&gt; &lt;name&gt;docker:&#123;#CONTAINERNAME&#125;:cpu&lt;/name&gt; &lt;width&gt;900&lt;/width&gt; &lt;height&gt;200&lt;/height&gt; &lt;yaxismin&gt;0.0000&lt;/yaxismin&gt; &lt;yaxismax&gt;100.0000&lt;/yaxismax&gt; &lt;show_work_period&gt;1&lt;/show_work_period&gt; &lt;show_triggers&gt;1&lt;/show_triggers&gt; &lt;type&gt;0&lt;/type&gt; &lt;show_legend&gt;1&lt;/show_legend&gt; &lt;show_3d&gt;0&lt;/show_3d&gt; &lt;percent_left&gt;0.0000&lt;/percent_left&gt; &lt;percent_right&gt;0.0000&lt;/percent_right&gt; &lt;ymin_type_1&gt;0&lt;/ymin_type_1&gt; &lt;ymax_type_1&gt;0&lt;/ymax_type_1&gt; &lt;ymin_item_1&gt;0&lt;/ymin_item_1&gt; &lt;ymax_item_1&gt;0&lt;/ymax_item_1&gt; &lt;graph_items&gt; &lt;graph_item&gt; &lt;sortorder&gt;0&lt;/sortorder&gt; &lt;drawtype&gt;0&lt;/drawtype&gt; &lt;color&gt;1A7C11&lt;/color&gt; &lt;yaxisside&gt;0&lt;/yaxisside&gt; &lt;calc_fnc&gt;2&lt;/calc_fnc&gt; &lt;type&gt;0&lt;/type&gt; &lt;item&gt; &lt;host&gt;Template Discovery Docker&lt;/host&gt; &lt;key&gt;docker_status[&#123;#CONTAINERNAME&#125;,cpu_percent]&lt;/key&gt; &lt;/item&gt; &lt;/graph_item&gt; &lt;graph_item&gt; &lt;sortorder&gt;1&lt;/sortorder&gt; &lt;drawtype&gt;0&lt;/drawtype&gt; &lt;color&gt;F63100&lt;/color&gt; &lt;yaxisside&gt;0&lt;/yaxisside&gt; &lt;calc_fnc&gt;2&lt;/calc_fnc&gt; &lt;type&gt;0&lt;/type&gt; &lt;item&gt; &lt;host&gt;Template Discovery Docker&lt;/host&gt; &lt;key&gt;docker_status[&#123;#CONTAINERNAME&#125;,system_cpu_usage]&lt;/key&gt; &lt;/item&gt; &lt;/graph_item&gt; &lt;graph_item&gt; &lt;sortorder&gt;2&lt;/sortorder&gt; &lt;drawtype&gt;0&lt;/drawtype&gt; &lt;color&gt;2774A4&lt;/color&gt; &lt;yaxisside&gt;0&lt;/yaxisside&gt; &lt;calc_fnc&gt;2&lt;/calc_fnc&gt; &lt;type&gt;0&lt;/type&gt; &lt;item&gt; &lt;host&gt;Template Discovery Docker&lt;/host&gt; &lt;key&gt;docker_status[&#123;#CONTAINERNAME&#125;,cpu_total_usage]&lt;/key&gt; &lt;/item&gt; &lt;/graph_item&gt; &lt;/graph_items&gt; &lt;/graph_prototype&gt; &lt;graph_prototype&gt; &lt;name&gt;docker:&#123;#CONTAINERNAME&#125;:menory&lt;/name&gt; &lt;width&gt;900&lt;/width&gt; &lt;height&gt;200&lt;/height&gt; &lt;yaxismin&gt;0.0000&lt;/yaxismin&gt; &lt;yaxismax&gt;100.0000&lt;/yaxismax&gt; &lt;show_work_period&gt;1&lt;/show_work_period&gt; &lt;show_triggers&gt;1&lt;/show_triggers&gt; &lt;type&gt;0&lt;/type&gt; &lt;show_legend&gt;1&lt;/show_legend&gt; &lt;show_3d&gt;0&lt;/show_3d&gt; &lt;percent_left&gt;0.0000&lt;/percent_left&gt; &lt;percent_right&gt;0.0000&lt;/percent_right&gt; &lt;ymin_type_1&gt;0&lt;/ymin_type_1&gt; &lt;ymax_type_1&gt;0&lt;/ymax_type_1&gt; &lt;ymin_item_1&gt;0&lt;/ymin_item_1&gt; &lt;ymax_item_1&gt;0&lt;/ymax_item_1&gt; &lt;graph_items&gt; &lt;graph_item&gt; &lt;sortorder&gt;0&lt;/sortorder&gt; &lt;drawtype&gt;0&lt;/drawtype&gt; &lt;color&gt;1A7C11&lt;/color&gt; &lt;yaxisside&gt;0&lt;/yaxisside&gt; &lt;calc_fnc&gt;2&lt;/calc_fnc&gt; &lt;type&gt;0&lt;/type&gt; &lt;item&gt; &lt;host&gt;Template Discovery Docker&lt;/host&gt; &lt;key&gt;docker_status[&#123;#CONTAINERNAME&#125;,mem_percent]&lt;/key&gt; &lt;/item&gt; &lt;/graph_item&gt; &lt;graph_item&gt; &lt;sortorder&gt;1&lt;/sortorder&gt; &lt;drawtype&gt;0&lt;/drawtype&gt; &lt;color&gt;F63100&lt;/color&gt; &lt;yaxisside&gt;0&lt;/yaxisside&gt; &lt;calc_fnc&gt;2&lt;/calc_fnc&gt; &lt;type&gt;0&lt;/type&gt; &lt;item&gt; &lt;host&gt;Template Discovery Docker&lt;/host&gt; &lt;key&gt;docker_status[&#123;#CONTAINERNAME&#125;,mem_usage]&lt;/key&gt; &lt;/item&gt; &lt;/graph_item&gt; &lt;/graph_items&gt; &lt;/graph_prototype&gt; &lt;graph_prototype&gt; &lt;name&gt;docker:&#123;#CONTAINERNAME&#125;:network&lt;/name&gt; &lt;width&gt;900&lt;/width&gt; &lt;height&gt;200&lt;/height&gt; &lt;yaxismin&gt;0.0000&lt;/yaxismin&gt; &lt;yaxismax&gt;100.0000&lt;/yaxismax&gt; &lt;show_work_period&gt;1&lt;/show_work_period&gt; &lt;show_triggers&gt;1&lt;/show_triggers&gt; &lt;type&gt;0&lt;/type&gt; &lt;show_legend&gt;1&lt;/show_legend&gt; &lt;show_3d&gt;0&lt;/show_3d&gt; &lt;percent_left&gt;0.0000&lt;/percent_left&gt; &lt;percent_right&gt;0.0000&lt;/percent_right&gt; &lt;ymin_type_1&gt;0&lt;/ymin_type_1&gt; &lt;ymax_type_1&gt;0&lt;/ymax_type_1&gt; &lt;ymin_item_1&gt;0&lt;/ymin_item_1&gt; &lt;ymax_item_1&gt;0&lt;/ymax_item_1&gt; &lt;graph_items&gt; &lt;graph_item&gt; &lt;sortorder&gt;0&lt;/sortorder&gt; &lt;drawtype&gt;0&lt;/drawtype&gt; &lt;color&gt;1A7C11&lt;/color&gt; &lt;yaxisside&gt;0&lt;/yaxisside&gt; &lt;calc_fnc&gt;2&lt;/calc_fnc&gt; &lt;type&gt;0&lt;/type&gt; &lt;item&gt; &lt;host&gt;Template Discovery Docker&lt;/host&gt; &lt;key&gt;docker_status[&#123;#CONTAINERNAME&#125;,network_rx_bytes]&lt;/key&gt; &lt;/item&gt; &lt;/graph_item&gt; &lt;graph_item&gt; &lt;sortorder&gt;1&lt;/sortorder&gt; &lt;drawtype&gt;0&lt;/drawtype&gt; &lt;color&gt;F63100&lt;/color&gt; &lt;yaxisside&gt;0&lt;/yaxisside&gt; &lt;calc_fnc&gt;2&lt;/calc_fnc&gt; &lt;type&gt;0&lt;/type&gt; &lt;item&gt; &lt;host&gt;Template Discovery Docker&lt;/host&gt; &lt;key&gt;docker_status[&#123;#CONTAINERNAME&#125;,network_tx_bytes]&lt;/key&gt; &lt;/item&gt; &lt;/graph_item&gt; &lt;/graph_items&gt; &lt;/graph_prototype&gt; &lt;/graph_prototypes&gt; &lt;host_prototypes/&gt; &lt;jmx_endpoint/&gt; &lt;timeout&gt;3s&lt;/timeout&gt; &lt;url/&gt; &lt;query_fields/&gt; &lt;posts/&gt; &lt;status_codes&gt;200&lt;/status_codes&gt; &lt;follow_redirects&gt;1&lt;/follow_redirects&gt; &lt;post_type&gt;0&lt;/post_type&gt; &lt;http_proxy/&gt; &lt;headers/&gt; &lt;retrieve_mode&gt;0&lt;/retrieve_mode&gt; &lt;request_method&gt;0&lt;/request_method&gt; &lt;allow_traps&gt;0&lt;/allow_traps&gt; &lt;ssl_cert_file/&gt; &lt;ssl_key_file/&gt; &lt;ssl_key_password/&gt; &lt;verify_peer&gt;0&lt;/verify_peer&gt; &lt;verify_host&gt;0&lt;/verify_host&gt; &lt;lld_macro_paths/&gt; &lt;preprocessing/&gt; &lt;master_item/&gt; &lt;/discovery_rule&gt; &lt;/discovery_rules&gt; &lt;httptests/&gt; &lt;macros/&gt; &lt;templates/&gt; &lt;screens/&gt; &lt;tags/&gt; &lt;/template&gt; &lt;/templates&gt; &lt;/zabbix_export&gt; 复制代码 模板导入成功后，查看监控项是否可用，注意客户端版本是否和文章一致，这里的zabbix所有版本均为4.2，若有问题可留言讨论。 3、问题整理 由于原本客户端python是2.7版本，在执行docker_monitor.py时有如下报错，后来知道是python版本问题，升级python3以后执行成功。 # python docker_monitor.py Traceback (most recent call last): File &quot;docker_monitor.py&quot;, line 36, in &lt;module&gt; docker_client = docker.DockerClient(base_url=&#39;unix://var/run/docker.sock&#39;) AttributeError: &#39;module&#39; object has no attribute &#39;DockerClient&#39; （1）python2升级步骤 复制代码 #安装python3.6 yum -y install epel-release yum install https://centos7.iuscommunity.org/ius-release.rpm ##安装centos7的ius源 yum install python36u -y ln -s /usr/bin/python3.6 /bin/python3 #安装pip3 yum install python36u-pip -y ln -s /usr/bin/pip3.6 /bin/pip3 pip3 install --upgrade pip ##有些情况安装完python3之后就不需要再安装pip3 复制代码 （2）升级python3后，simplejson和docker-py需要重装 pip3 install simplejson #docker-py最新版改名为docker pip3 install docker （3）zabbix-serve端测试时报错 复制代码 zabbix_get -s 10.8.0.22 -p 10050 -k docker_status[reids,cpu_percent] Traceback (most recent call last): File &quot;/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py&quot;, line 672, in urlopen chunked=chunked, File &quot;/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py&quot;, line 387, in _make_request conn.request(method, url, **httplib_request_kw) File &quot;/usr/lib64/python3.6/http/client.py&quot;, line 1254, in request self._send_request(method, url, body, headers, encode_chunked) File &quot;/usr/lib64/python3.6/http/client.py&quot;, line 1300, in _send_request self.endheaders(body, encode_chunked=encode_chunked) File &quot;/usr/lib64/python3.6/http/client.py&quot;, line 1249, in endheaders self._send_output(message_body, encode_chunked=encode_chunked) File &quot;/usr/lib64/python3.6/http/client.py&quot;, line 1036, in _send_output self.send(msg) File &quot;/usr/lib64/python3.6/http/client.py&quot;, line 974, in send self.connect() File &quot;/usr/local/lib/python3.6/site-packages/docker/transport/unixconn.py&quot;, line 43, in connect sock.connect(self.unix_socket) PermissionError: [Errno 13] Permission denied During handling of the above exception, another exception occurred: Traceback (most recent call last): File &quot;/usr/local/lib/python3.6/site-packages/requests/adapters.py&quot;, line 449, in send timeout=timeout File &quot;/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py&quot;, line 720, in urlopen method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2] File &quot;/usr/local/lib/python3.6/site-packages/urllib3/util/retry.py&quot;, line 400, in increment raise six.reraise(type(error), error, _stacktrace) File &quot;/usr/local/lib/python3.6/site-packages/urllib3/packages/six.py&quot;, line 734, in reraise raise value.with_traceback(tb) File &quot;/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py&quot;, line 672, in urlopen chunked=chunked, File &quot;/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py&quot;, line 387, in _make_request conn.request(method, url, **httplib_request_kw) File &quot;/usr/lib64/python3.6/http/client.py&quot;, line 1254, in request self._send_request(method, url, body, headers, encode_chunked) File &quot;/usr/lib64/python3.6/http/client.py&quot;, line 1300, in _send_request self.endheaders(body, encode_chunked=encode_chunked) File &quot;/usr/lib64/python3.6/http/client.py&quot;, line 1249, in endheaders self._send_output(message_body, encode_chunked=encode_chunked) File &quot;/usr/lib64/python3.6/http/client.py&quot;, line 1036, in _send_output self.send(msg) File &quot;/usr/lib64/python3.6/http/client.py&quot;, line 974, in send self.connect() File &quot;/usr/local/lib/python3.6/site-packages/docker/transport/unixconn.py&quot;, line 43, in connect sock.connect(self.unix_socket) urllib3.exceptions.ProtocolError: (&#39;Connection aborted.&#39;, PermissionError(13, &#39;Permission denied&#39;)) During handling of the above exception, another exception occurred: Traceback (most recent call last): File &quot;/usr/lib/zabbix/externalscripts/docker_monitor.py&quot;, line 39, in &lt;module&gt; print(check_container_stats(container_name,collect_item)) File &quot;/usr/lib/zabbix/externalscripts/docker_monitor.py&quot;, line 9, in check_container_stats container_collect=docker_client.containers.get(container_name).stats(stream=True) File &quot;/usr/local/lib/python3.6/site-packages/docker/models/containers.py&quot;, line 880, in get resp = self.client.api.inspect_container(container_id) File &quot;/usr/local/lib/python3.6/site-packages/docker/utils/decorators.py&quot;, line 19, in wrapped return f(self, resource_id, *args, **kwargs) File &quot;/usr/local/lib/python3.6/site-packages/docker/api/container.py&quot;, line 756, in inspect_container self._get(self._url(&quot;/containers/&#123;0&#125;/json&quot;, container)), True File &quot;/usr/local/lib/python3.6/site-packages/docker/utils/decorators.py&quot;, line 46, in inner return f(self, *args, **kwargs) File &quot;/usr/local/lib/python3.6/site-packages/docker/api/client.py&quot;, line 230, in _get return self.get(url, **self._set_request_timeout(kwargs)) File &quot;/usr/local/lib/python3.6/site-packages/requests/sessions.py&quot;, line 546, in get return self.request(&#39;GET&#39;, url, **kwargs) File &quot;/usr/local/lib/python3.6/site-packages/requests/sessions.py&quot;, line 533, in request resp = self.send(prep, **send_kwargs) File &quot;/usr/local/lib/python3.6/site-packages/requests/sessions.py&quot;, line 646, in send r = adapter.send(request, **kwargs) File &quot;/usr/local/lib/python3.6/site-packages/requests/adapters.py&quot;, line 498, in send raise ConnectionError(err, request=request) requests.exceptions.ConnectionError: (&#39;Connection aborted.&#39;, PermissionError(13, &#39;Permission denied&#39;)) 复制代码 从错误可以看出是权限问题，解决办法： #查看docker.sock用户权限 ls /var/run/docker.sock -lh srw-rw---- 1 root docker 0 9月 2 17:04 /var/run/docker.sock #将zabbix用户加入docker所在组 gpasswd -a zabbix docker zabbix_get测试连接 zabbix_get -s 10.8.0.22 -p 10050 -k docker_status[redis,mem_percent] 0.3 以上所有内容均为亲自测试成功后才写的，那些踩的最深的坑都已经都修改，大可放心使用。","categories":[],"tags":[],"author":"张存"},{"title":"zabbix自发现实时监控docker容器及容器中各个服务的状态线上业务展示","slug":"zabbix自发现实时监控docker容器及容器中各个服务的状态线上业务展示","date":"2022-04-26T10:25:23.000Z","updated":"2022-04-29T09:41:39.678Z","comments":true,"path":"2022/04/26/zabbix-zi-fa-xian-shi-shi-jian-kong-docker-rong-qi-ji-rong-qi-zhong-ge-ge-fu-wu-de-zhuang-tai-xian-shang-ye-wu-zhan-shi/","link":"","permalink":"https://blog.zhangcun.store/2022/04/26/zabbix-zi-fa-xian-shi-shi-jian-kong-docker-rong-qi-ji-rong-qi-zhong-ge-ge-fu-wu-de-zhuang-tai-xian-shang-ye-wu-zhan-shi/","excerpt":"","text":"1.查看自己的环境变量以及自己的服务路径 （1）jdk环境： jdk1.8 （2）zabbix版本：zabbix3.4.5 （3）zabbix脚本存放路径：/data/zabbix/scripts/ ( 4 ) .conf文件存放路径：/data/zabbix/etc/zabbix_agentd.conf.d/ 2.配置脚本、key、模板 ###UnsafeUserParameters=1 首选，zabbix_agentd 配置 vim/data/zabbix/etc/zabbix_agentd.conf.d/docker.conf UserParameter=docker.discovery,/data/zabbix/scripts/docker.py UserParameter=docker.[*],/data/zabbix/script/docker.py $1 $2 下面是docker.py 脚本，采用自动发现规则来发现容器，然后指定容器获取状态信息： #!/usr/bin/python import sys import os import json def discover(): d = &#123;&#125; d[&#39;data&#39;] = [] with os.popen(&quot;docker ps -a --format &#123;&#123;.Names&#125;&#125;&quot;) as pipe: for line in pipe: info = &#123;&#125; info[&#39;&#123;#CONTAINERNAME&#125;'] = line.replace(\"\\n\",\"\") d['data'].append(info) print json.dumps(d) def status(name,action): if action == \"ping\": cmd = 'docker inspect --format=\"&#123;&#123;.State.Running&#125;&#125;&quot; %s&#39; %name result = os.popen(cmd).read().replace(&quot;\\n&quot;,&quot;&quot;) if result == &quot;true&quot;: print 1 else: print 0 else: cmd = &#39;docker stats %s --no-stream --format &quot;&#123;&#123;.%s&#125;&#125;&quot;&#39; % (name,action) result = os.popen(cmd).read().replace(&quot;\\n&quot;,&quot;&quot;) if &quot;%&quot; in result: print float(result.replace(&quot;%&quot;,&quot;&quot;)) else: print result if name == &#39;main&#39;: try: name, action = sys.argv[1], sys.argv[2] status(name,action) except IndexError: discover() 这里说一下自动发现规则的坑。。。我被坑了好久才找出来.....一是必须返回json格式内容，二是 info[&#39;&#123;#CONTAINERNAME&#125;&#39; ] 这个key一定要这么写&#123;#CONTAINERNAME&#125; 返回结果如下，一定要是这样的层级关系 &#123;&quot;data&quot;: [&#123;&quot;&#123;#CONTAINERNAME&#125;&quot;: &quot;node-3&quot;&#125;, &#123;&quot;&#123;#CONTAINERNAME&#125;&quot;: &quot;node-2&quot;&#125;, &#123;&quot;&#123;#CONTAINERNAME&#125;&quot;: &quot;node-1&quot;&#125;, &#123;&quot;&#123;#CONTAINERNAME&#125;&quot;: &quot;web&quot;&#125;, &#123;&quot;&#123;#CONTAINERNAME&#125;&quot;: &quot;cadvisor&quot;&#125;, &#123;&quot;&#123;#CONTAINERNAME&#125;&quot;: &quot;updatol&quot;&#125;, &#123;&quot;&#123;#CONTAINERNAME&#125;&quot;: &quot;research&quot;&#125;, &#123;&quot;&#123;#CONTAINERNAME&#125;&quot;: &quot;services&quot;&#125;, &#123;&quot;&#123;#CONTAINERNAME&#125;&quot;: &quot;data&quot;&#125;, &#123;&quot;&#123;#CONTAINERNAME&#125;&quot;: &quot;rabbitmq&quot;&#125;, &#123;&quot;&#123;#CONTAINERNAME&#125;&quot;: &quot;redis&quot;&#125;, &#123;&quot;&#123;#CONTAINERNAME&#125;&quot;: &quot;mysql&quot;&#125;, &#123;&quot;&#123;#CONTAINERNAME&#125;&quot;: &quot;ssdb&quot;&#125;]&#125; 另外那个函数的很简单了，就是调用docker 命令在获取数据的。 然后导入模板： 模板如下： &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;zabbix_export&gt; &lt;version&gt;3.2&lt;/version&gt; &lt;date&gt;2018-06-04T04:12:36Z&lt;/date&gt; &lt;groups&gt; &lt;group&gt; &lt;name&gt;Templates&lt;/name&gt; &lt;/group&gt; &lt;/groups&gt; &lt;templates&gt; &lt;template&gt; &lt;template&gt;docker-status&lt;/template&gt; &lt;name&gt;docker-status&lt;/name&gt; &lt;description/&gt; &lt;groups&gt; &lt;group&gt; &lt;name&gt;Templates&lt;/name&gt; &lt;/group&gt; &lt;/groups&gt; &lt;applications&gt; &lt;application&gt; &lt;name&gt;docker_test&lt;/name&gt; &lt;/application&gt; &lt;/applications&gt; &lt;items/&gt; &lt;discovery_rules&gt; &lt;discovery_rule&gt; &lt;name&gt;docker.discovery&lt;/name&gt; &lt;type&gt;0&lt;/type&gt; &lt;snmp_community/&gt; &lt;snmp_oid/&gt; &lt;key&gt;docker.discovery&lt;/key&gt; &lt;delay&gt;60&lt;/delay&gt; &lt;status&gt;0&lt;/status&gt; &lt;allowed_hosts/&gt; &lt;snmpv3_contextname/&gt; &lt;snmpv3_securityname/&gt; &lt;snmpv3_securitylevel&gt;0&lt;/snmpv3_securitylevel&gt; &lt;snmpv3_authprotocol&gt;0&lt;/snmpv3_authprotocol&gt; &lt;snmpv3_authpassphrase/&gt; &lt;snmpv3_privprotocol&gt;0&lt;/snmpv3_privprotocol&gt; &lt;snmpv3_privpassphrase/&gt; &lt;delay_flex/&gt; &lt;params/&gt; &lt;ipmi_sensor/&gt; &lt;authtype&gt;0&lt;/authtype&gt; &lt;username/&gt; &lt;password/&gt; &lt;publickey/&gt; &lt;privatekey/&gt; &lt;port/&gt; &lt;filter&gt; &lt;evaltype&gt;0&lt;/evaltype&gt; &lt;formula/&gt; &lt;conditions&gt; &lt;condition&gt; &lt;macro&gt;&#123;#CONTAINERNAME&#125;&lt;/macro&gt; &lt;value&gt;@ CONTAINER NAME&lt;/value&gt; &lt;operator&gt;8&lt;/operator&gt; &lt;formulaid&gt;A&lt;/formulaid&gt; &lt;/condition&gt; &lt;/conditions&gt; &lt;/filter&gt; &lt;lifetime&gt;30&lt;/lifetime&gt; &lt;description/&gt; &lt;item_prototypes&gt; &lt;item_prototype&gt; &lt;name&gt;Container &#123;#CONTAINERNAME&#125; Diskio usage:&lt;/name&gt; &lt;type&gt;0&lt;/type&gt; &lt;snmp_community/&gt; &lt;multiplier&gt;0&lt;/multiplier&gt; &lt;snmp_oid/&gt; &lt;key&gt;docker.[&#123;#CONTAINERNAME&#125; ,BlockIO]&lt;/key&gt; &lt;delay&gt;60&lt;/delay&gt; &lt;history&gt;90&lt;/history&gt; &lt;trends&gt;0&lt;/trends&gt; &lt;status&gt;0&lt;/status&gt; &lt;value_type&gt;1&lt;/value_type&gt; &lt;allowed_hosts/&gt; &lt;units/&gt; &lt;delta&gt;0&lt;/delta&gt; &lt;snmpv3_contextname/&gt; &lt;snmpv3_securityname/&gt; &lt;snmpv3_securitylevel&gt;0&lt;/snmpv3_securitylevel&gt; &lt;snmpv3_authprotocol&gt;0&lt;/snmpv3_authprotocol&gt; &lt;snmpv3_authpassphrase/&gt; &lt;snmpv3_privprotocol&gt;0&lt;/snmpv3_privprotocol&gt; &lt;snmpv3_privpassphrase/&gt; &lt;formula&gt;1&lt;/formula&gt; &lt;delay_flex/&gt; &lt;params/&gt; &lt;ipmi_sensor/&gt; &lt;data_type&gt;0&lt;/data_type&gt; &lt;authtype&gt;0&lt;/authtype&gt; &lt;username/&gt; &lt;password/&gt; &lt;publickey/&gt; &lt;privatekey/&gt; &lt;port/&gt; &lt;description/&gt; &lt;inventory_link&gt;0&lt;/inventory_link&gt; &lt;applications&gt; &lt;application&gt; &lt;name&gt;docker_test&lt;/name&gt; &lt;/application&gt; &lt;/applications&gt; &lt;valuemap/&gt; &lt;logtimefmt/&gt; &lt;application_prototypes/&gt; &lt;/item_prototype&gt; &lt;item_prototype&gt; &lt;name&gt;Container&#123;#CONTAINERNAME&#125; CPU usage:&lt;/name&gt; &lt;type&gt;0&lt;/type&gt; &lt;snmp_community/&gt; &lt;multiplier&gt;0&lt;/multiplier&gt; &lt;snmp_oid/&gt; &lt;key&gt;docker.[&#123;#CONTAINERNAME&#125;,CPUPerc]&lt;/key&gt; &lt;delay&gt;60&lt;/delay&gt; &lt;history&gt;90&lt;/history&gt; &lt;trends&gt;365&lt;/trends&gt; &lt;status&gt;0&lt;/status&gt; &lt;value_type&gt;0&lt;/value_type&gt; &lt;allowed_hosts/&gt; &lt;units&gt;%&lt;/units&gt; &lt;delta&gt;0&lt;/delta&gt; &lt;snmpv3_contextname/&gt; &lt;snmpv3_securityname/&gt; &lt;snmpv3_securitylevel&gt;0&lt;/snmpv3_securitylevel&gt; &lt;snmpv3_authprotocol&gt;0&lt;/snmpv3_authprotocol&gt; &lt;snmpv3_authpassphrase/&gt; &lt;snmpv3_privprotocol&gt;0&lt;/snmpv3_privprotocol&gt; &lt;snmpv3_privpassphrase/&gt; &lt;formula&gt;1&lt;/formula&gt; &lt;delay_flex/&gt; &lt;params/&gt; &lt;ipmi_sensor/&gt; &lt;data_type&gt;0&lt;/data_type&gt; &lt;authtype&gt;0&lt;/authtype&gt; &lt;username/&gt; &lt;password/&gt; &lt;publickey/&gt; &lt;privatekey/&gt; &lt;port/&gt; &lt;description/&gt; &lt;inventory_link&gt;0&lt;/inventory_link&gt; &lt;applications&gt; &lt;application&gt; &lt;name&gt;docker_test&lt;/name&gt; &lt;/application&gt; &lt;/applications&gt; &lt;valuemap/&gt; &lt;logtimefmt/&gt; &lt;application_prototypes/&gt; &lt;/item_prototype&gt; &lt;item_prototype&gt; &lt;name&gt;Container &#123;#CONTAINERNAME&#125; mem usage:&lt;/name&gt; &lt;type&gt;0&lt;/type&gt; &lt;snmp_community/&gt; &lt;multiplier&gt;0&lt;/multiplier&gt; &lt;snmp_oid/&gt; &lt;key&gt;docker.[&#123;#CONTAINERNAME&#125;,MemPerc]&lt;/key&gt; &lt;delay&gt;60&lt;/delay&gt; &lt;history&gt;90&lt;/history&gt; &lt;trends&gt;365&lt;/trends&gt; &lt;status&gt;0&lt;/status&gt; &lt;value_type&gt;0&lt;/value_type&gt; &lt;allowed_hosts/&gt; &lt;units&gt;%&lt;/units&gt; &lt;delta&gt;0&lt;/delta&gt; &lt;snmpv3_contextname/&gt; &lt;snmpv3_securityname/&gt; &lt;snmpv3_securitylevel&gt;0&lt;/snmpv3_securitylevel&gt; &lt;snmpv3_authprotocol&gt;0&lt;/snmpv3_authprotocol&gt; &lt;snmpv3_authpassphrase/&gt; &lt;snmpv3_privprotocol&gt;0&lt;/snmpv3_privprotocol&gt; &lt;snmpv3_privpassphrase/&gt; &lt;formula&gt;1&lt;/formula&gt; &lt;delay_flex/&gt; &lt;params/&gt; &lt;ipmi_sensor/&gt; &lt;data_type&gt;0&lt;/data_type&gt; &lt;authtype&gt;0&lt;/authtype&gt; &lt;username/&gt; &lt;password/&gt; &lt;publickey/&gt; &lt;privatekey/&gt; &lt;port/&gt; &lt;description/&gt; &lt;inventory_link&gt;0&lt;/inventory_link&gt; &lt;applications&gt; &lt;application&gt; &lt;name&gt;docker_test&lt;/name&gt; &lt;/application&gt; &lt;/applications&gt; &lt;valuemap/&gt; &lt;logtimefmt/&gt; &lt;application_prototypes/&gt; &lt;/item_prototype&gt; &lt;item_prototype&gt; &lt;name&gt;Container &#123;#CONTAINERNAME&#125; NETio usage:&lt;/name&gt; &lt;type&gt;0&lt;/type&gt; &lt;snmp_community/&gt; &lt;multiplier&gt;0&lt;/multiplier&gt; &lt;snmp_oid/&gt; &lt;key&gt;docker.[&#123;#CONTAINERNAME&#125;,NetIO]&lt;/key&gt; &lt;delay&gt;60&lt;/delay&gt; &lt;history&gt;90&lt;/history&gt; &lt;trends&gt;0&lt;/trends&gt; &lt;status&gt;0&lt;/status&gt; &lt;value_type&gt;1&lt;/value_type&gt; &lt;allowed_hosts/&gt; &lt;units/&gt; &lt;delta&gt;0&lt;/delta&gt; &lt;snmpv3_contextname/&gt; &lt;snmpv3_securityname/&gt; &lt;snmpv3_securitylevel&gt;0&lt;/snmpv3_securitylevel&gt; &lt;snmpv3_authprotocol&gt;0&lt;/snmpv3_authprotocol&gt; &lt;snmpv3_authpassphrase/&gt; &lt;snmpv3_privprotocol&gt;0&lt;/snmpv3_privprotocol&gt; &lt;snmpv3_privpassphrase/&gt; &lt;formula&gt;1&lt;/formula&gt; &lt;delay_flex/&gt; &lt;params/&gt; &lt;ipmi_sensor/&gt; &lt;data_type&gt;0&lt;/data_type&gt; &lt;authtype&gt;0&lt;/authtype&gt; &lt;username/&gt; &lt;password/&gt; &lt;publickey/&gt; &lt;privatekey/&gt; &lt;port/&gt; &lt;description/&gt; &lt;inventory_link&gt;0&lt;/inventory_link&gt; &lt;applications&gt; &lt;application&gt; &lt;name&gt;docker_test&lt;/name&gt; &lt;/application&gt; &lt;/applications&gt; &lt;valuemap/&gt; &lt;logtimefmt/&gt; &lt;application_prototypes/&gt; &lt;/item_prototype&gt; &lt;item_prototype&gt; &lt;name&gt;Container&#123;#CONTAINERNAME&#125; is_run :&lt;/name&gt; &lt;type&gt;0&lt;/type&gt; &lt;snmp_community/&gt; &lt;multiplier&gt;0&lt;/multiplier&gt; &lt;snmp_oid/&gt; &lt;key&gt;docker.[&#123;#CONTAINERNAME&#125; ,ping]&lt;/key&gt; &lt;delay&gt;30&lt;/delay&gt; &lt;history&gt;90&lt;/history&gt; &lt;trends&gt;365&lt;/trends&gt; &lt;status&gt;0&lt;/status&gt; &lt;value_type&gt;3&lt;/value_type&gt; &lt;allowed_hosts/&gt; &lt;units/&gt; &lt;delta&gt;0&lt;/delta&gt; &lt;snmpv3_contextname/&gt; &lt;snmpv3_securityname/&gt; &lt;snmpv3_securitylevel&gt;0&lt;/snmpv3_securitylevel&gt; &lt;snmpv3_authprotocol&gt;0&lt;/snmpv3_authprotocol&gt; &lt;snmpv3_authpassphrase/&gt; &lt;snmpv3_privprotocol&gt;0&lt;/snmpv3_privprotocol&gt; &lt;snmpv3_privpassphrase/&gt; &lt;formula&gt;1&lt;/formula&gt; &lt;delay_flex/&gt; &lt;params/&gt; &lt;ipmi_sensor/&gt; &lt;data_type&gt;0&lt;/data_type&gt; &lt;authtype&gt;0&lt;/authtype&gt; &lt;username/&gt; &lt;password/&gt; &lt;publickey/&gt; &lt;privatekey/&gt; &lt;port/&gt; &lt;description/&gt; &lt;inventory_link&gt;0&lt;/inventory_link&gt; &lt;applications&gt; &lt;application&gt; &lt;name&gt;docker_test&lt;/name&gt; &lt;/application&gt; &lt;/applications&gt; &lt;valuemap/&gt; &lt;logtimefmt/&gt; &lt;application_prototypes/&gt; &lt;/item_prototype&gt; &lt;/item_prototypes&gt; &lt;trigger_prototypes&gt; &lt;trigger_prototype&gt; &lt;expression&gt;&#123;docker-status:docker.[&#123;#CONTAINERNAME&#125; ,ping].last()&#125;=0&lt;/expression&gt; &lt;recovery_mode&gt;0&lt;/recovery_mode&gt; &lt;recoveryexpression/&gt; &lt;name&gt;docker&#123;#CONTAINERNAME&#125;_down&lt;/name&gt; &lt;correlation_mode&gt;0&lt;/correlation_mode&gt; &lt;correlation_tag/&gt; &lt;url/&gt; &lt;status&gt;0&lt;/status&gt; &lt;priority&gt;5&lt;/priority&gt; &lt;description/&gt; &lt;type&gt;0&lt;/type&gt; &lt;manual_close&gt;0&lt;/manual_close&gt; &lt;dependencies/&gt; &lt;tags/&gt; &lt;/trigger_prototype&gt; &lt;/trigger_prototypes&gt; &lt;graph_prototypes/&gt; &lt;host_prototypes/&gt; &lt;/discovery_rule&gt; &lt;/discovery_rules&gt; &lt;httptests/&gt; &lt;macros/&gt; &lt;templates/&gt; &lt;screens/&gt; &lt;/template&gt; &lt;/templates&gt; &lt;/zabbix_export&gt;~~ 3.web端操作 导入模板后 可能有的人在这导入模板后会出现这个问题： zabbixGlobal regular expression &quot; CONTAINER NAME&quot; does not exist. 出现这个问题，证明：问题不大。 去这个地方把这个去掉 如果你要了解这个时什么意思：请参考官网：zabbix正则表达式写法，大体意思如下： 去管理 、一般，里边点开正则 自己先去了解这个怎么用，去添加就好了 接下来我们看一下模板中都监控了什么 触发器有一个 都没问题之后我们看一下最新数据 我们看到了各个容器状态已经添加上去了，","categories":[],"tags":[],"author":"张存"},{"title":"启动Docker“Got permission denied while trying to connect to the Docker daemon socket“","slug":"启动Docker“Got-permission-denied-while-trying-to-connect-to-the-Docker-daemon-socket“","date":"2022-04-26T10:10:37.000Z","updated":"2022-04-26T10:10:39.777Z","comments":true,"path":"2022/04/26/qi-dong-docker-got-permission-denied-while-trying-to-connect-to-the-docker-daemon-socket/","link":"","permalink":"https://blog.zhangcun.store/2022/04/26/qi-dong-docker-got-permission-denied-while-trying-to-connect-to-the-docker-daemon-socket/","excerpt":"","text":"1 问题描述 在终端执行&quot;docker version&quot;命令，出现如下报错： ”Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.26/images/json: dial unix /var/run/docker.sock: connect: permission denied“ 2 原因分析 来自docker mannual： Manage Docker as a non-root user The docker daemon binds to a Unix socket instead of a TCP port. By default that Unix socket is owned by the user root and other users can only access it using sudo. The docker daemon always runs as the root user. If you don’t want to use sudo when you use the docker command, create a Unix group called docker and add users to it. When the docker daemon starts, it makes the ownership of the Unix socket read/writable by the docker group. docker进程使用 Unix Socket 而不是 TCP 端口。而默认情况下，Unix socket 属于 root 用户，因此需要 root权限 才能访问。 3 解决方法 sudo groupadd docker #添加docker用户组 sudo gpasswd -a $XXX docker #检测当前用户是否已经在docker用户组中，其中XXX为用户名，例如我的，liangll sudo gpasswd -a $USER docker #将当前用户添加至docker用户组 newgrp docker #更新docker用户组 4 检查是否更新成功 再次执行&quot;docker version&quot;命令，发现不再出现&quot;Got permission denied&quot;权限报错","categories":[],"tags":[],"author":"张存"},{"title":"Ubuntu20更换软件源","slug":"Ubuntu20更换软件源","date":"2022-04-26T10:08:33.000Z","updated":"2022-04-26T10:08:36.277Z","comments":true,"path":"2022/04/26/ubuntu20-geng-huan-ruan-jian-yuan/","link":"","permalink":"https://blog.zhangcun.store/2022/04/26/ubuntu20-geng-huan-ruan-jian-yuan/","excerpt":"","text":"1.备份原来的源(可省略) sudo cp /etc/apt/sources.list&#123;,.bak&#125; 2.将/etc/apt/sources.list里的源改为自己需要的源,可在以下源任选一条： #添加阿里源 deb http://mirrors.aliyun.com/ubuntu/ focal main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ focal main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ focal-security main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ focal-security main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ focal-updates main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ focal-updates main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ focal-proposed main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ focal-proposed main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ focal-backports main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ focal-backports main restricted universe multiverse #添加清华源 deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-updates main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-updates main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-backports main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-backports main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-security main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-security main restricted universe multiverse multiverse 具体操作如下： vim /etc/apt/sources.list image.png 3.更新软件源 apt-get update","categories":[],"tags":[],"author":"张存"},{"title":"find命令结合cp的使用","slug":"find命令结合cp的使用","date":"2022-04-26T03:52:10.000Z","updated":"2022-04-26T03:59:12.400Z","comments":true,"path":"2022/04/26/find-ming-ling-jie-he-cp-de-shi-yong/","link":"","permalink":"https://blog.zhangcun.store/2022/04/26/find-ming-ling-jie-he-cp-de-shi-yong/","excerpt":"","text":"用find查找/data目录下，以.txt文件结尾的文件并复制到/tmp下 方法一 find与|xargs是黄金搭档，-t参数指定目标目录 [root@linuxidc ~]# find /data/ -type f -name&quot;*.txt&quot; | xargs cp -t /tmp 方法二 &#123;&#125;大括号里的内容为find命令找到的结果 [root@linuxidc ~]# find /data/ -type f -name&quot;*.txt&quot; -exec cp &#123;&#125; /tmp \\; 方法三 $()=` ` 存放命令的执行结果 [root@linuxidc ~]# cp $(find /data/ -type f -name&quot;*.txt&quot;) /tmp 方法四 -i参数指定找到的结果放到&#123;&#125;中 [root@linuxidc ~]# find/data/ -type f -name &quot;*.txt&quot; | xargs -i cp&#123;&#125; /tmp","categories":[],"tags":[],"author":"张存"},{"title":"mysql查看当前实时连接数","slug":"mysql查看当前实时连接数","date":"2022-04-26T03:49:09.000Z","updated":"2022-04-26T03:49:11.319Z","comments":true,"path":"2022/04/26/mysql-cha-kan-dang-qian-shi-shi-lian-jie-shu/","link":"","permalink":"https://blog.zhangcun.store/2022/04/26/mysql-cha-kan-dang-qian-shi-shi-lian-jie-shu/","excerpt":"","text":"静态查看: SHOW PROCESSLIST; SHOW FULL PROCESSLIST; SHOW VARIABLES LIKE &#39;%max_connections%&#39;; SHOW STATUS LIKE &#39;%Connection%&#39;; 实时查看： mysql&gt; show status like &#39;Threads%&#39;; +-------------------+-------+ | Variable_name | Value | +-------------------+-------+ | Threads_cached | 58 | | Threads_connected | 57 | ###这个数值指的是打开的连接数 | Threads_created | 3676 | ###threads_created表示创建过的线程数，如果发现threads_created值过大的话，表明mysql服务器一直在创建线程，这也是比较耗资源 | Threads_running | 4 | ###这个数值指的是激活的连接数，这个数值一般远低于connected数值 +-------------------+-------+ Threads_connected 跟show processlist结果相同，表示当前连接数。准确的来说，Threads_running是代表当前并发数 这是是查询数据库当前设置的最大连接数 mysql&gt; show variables like &#39;%max_connections%&#39;; +-----------------+-------+ | Variable_name | Value | +-----------------+-------+ | max_connections | 100 | +-----------------+-------+ 可以在/etc/my.cnf里面设置数据库的最大连接数 max_connections = 1000","categories":[],"tags":[],"author":"张存"},{"title":"动态修改docker容器环境变量env","slug":"动态修改docker容器环境变量env","date":"2022-04-26T03:44:56.000Z","updated":"2022-04-26T03:45:25.353Z","comments":true,"path":"2022/04/26/dong-tai-xiu-gai-docker-rong-qi-huan-jing-bian-liang-env/","link":"","permalink":"https://blog.zhangcun.store/2022/04/26/dong-tai-xiu-gai-docker-rong-qi-huan-jing-bian-liang-env/","excerpt":"","text":"1、停止容器 docker stop congtainer id 2、停止容器服务 service docker stop 3、修改 /var/lib/docker/containers/ID/config.v2.json 中的参数 4、重启容器服务 service docker start 5、重启容器镜像 docker start container id","categories":[],"tags":[],"author":"张存"},{"title":"jenkins:配置密钥时报错的解决：Failed to add SSH key. Message invalid privatekey","slug":"jenkins-配置密钥时报错的解决：Failed","date":"2022-04-26T03:38:15.000Z","updated":"2022-04-26T03:46:12.823Z","comments":true,"path":"2022/04/26/jenkins-pei-zhi-mi-yao-shi-bao-cuo-de-jie-jue-failed/","link":"","permalink":"https://blog.zhangcun.store/2022/04/26/jenkins-pei-zhi-mi-yao-shi-bao-cuo-de-jie-jue-failed/","excerpt":"","text":"一，报错的现象: 1,提示信息: jenkins.plugins.publish_over.BapPublisherException: Failed to add SSH key. Message [invalid privatekey: [B@60373f7] 如图: 2,系统环境: fedora 30 [root@localhost ~]# more /etc/redhat-release Fedora release 30 (Thirty) 内核 ： [root@localhost ~]# uname -r 5.6.13-100.fc30.x86_64 ssh [root@localhost ~]# ssh -V OpenSSH_8.0p1, OpenSSL 1.1.1g FIPS 21 Apr 2020 jenkins的版本是2.257 说明：刘宏缔的架构森林是一个专注架构的博客，地址：https://www.cnblogs.com/architectforest 对应的源码可以访问这里获取： https://github.com/liuhongdi/ 说明：作者:刘宏缔 邮箱: 371125307@qq.com 二，问题的原因 因为我们生成密钥的openssh的版本过高的原因 看例子：先生成密钥 [root@localhost ~]# ssh-keygen -t rsa 查看所生成私钥的格式: [root@localhost ~]$ more .ssh/id_rsa -----BEGIN OPENSSH PRIVATE KEY----- b3BlbnNzaC1rZXktdjEAAAAABG5vbmUAAAAEbm9uZQAAAAAAAAABAAABlwAAAAdzc2gtcn … 可以看到密钥的首行是: -----BEGIN OPENSSH PRIVATE KEY—— 而jenkins 2.2.57 版本在检验密钥时还不支持这种格式， 三，问题的解决: 1，指定格式 [root@localhost ~]# ssh-keygen -m PEM -t rsa -b 4096 说明： -m 参数指定密钥的格式，PEM是rsa之前使用的旧格式 -b 指定密钥长度。对于RSA密钥，最小要求768位，默认是2048位。 附man手册的说明: 复制代码 -m key_format Specify a key format for key generation, the -i (import), -e (export) conversion options, and the -p change passphrase oper‐ ation. The latter may be used to convert between OpenSSH private key and PEM private key formats. The supported key for‐ mats are: “RFC4716” (RFC 4716/SSH2 public or private key), “PKCS8” (PKCS8 public or private key) or “PEM” (PEM public key). By default OpenSSH will write newly-generated private keys in its own format, but when converting public keys for export the default format is “RFC4716”. Setting a format of “PEM” when generating or updating a supported private key type will cause the key to be stored in the legacy PEM private key format. 复制代码 2,查看密钥格式: [root@localhost ~]# more /root/.ssh/id_rsa -----BEGIN RSA PRIVATE KEY----- MIIJKAIBAAKCAgEA44rzAenw3N7Tpjy5KXJpVia5oSTV/HrRg7d8PdCeJ3N1AiZU ... 可以看到密钥的首行是: -----BEGIN RSA PRIVATE KEY----- 这样改动后可以通过jenkins对密钥格式的验证 四，测试: 点击 test configuration 后，提示 success,表示密钥无问题 五，查看Jenkins版本 在登录后首页的右下角，可以看到当前的版本:2.257","categories":[],"tags":[],"author":"张存"},{"title":"docker镜像常用操作的基本命令","slug":"docker镜像常用操作的基本命令-1","date":"2022-04-26T03:35:00.000Z","updated":"2022-04-26T03:35:26.995Z","comments":true,"path":"2022/04/26/docker-jing-xiang-chang-yong-cao-zuo-de-ji-ben-ming-ling-1/","link":"","permalink":"https://blog.zhangcun.store/2022/04/26/docker-jing-xiang-chang-yong-cao-zuo-de-ji-ben-ming-ling-1/","excerpt":"","text":"1.拉取/下载镜像 docker pull 镜像名称 （可以从网易云镜像中心获取要下载的镜像） 2.查看已经下载的镜像 docker images 3.删除本地镜像 docker rmi 镜像标识 （docker images可以看到镜像标识） 4.镜像导入/导出 导出 docker save -o 导出路径 镜像id 加载本地镜像 docker load -i 镜像文件 修改镜像名称（加载后的镜像文件名称为null 需要修改镜像名称和版本） docker tag 镜像id 新镜像名称:版本 ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ 对容器操作 1.运行容器 docker run 镜像标识|镜像名称 例子：docker run -d -p 宿机端口:容器端口 --name 容器名称 镜像标识|镜像名称 -d表示后台运行 -p表示宿机与容器间的映射端口 --name表示给容器指定的命名 2.查看正在运行的容器 docker ps 查看运行中的容器 docker ps -a 查看所有容器 包括未运行的 docker ps -q 查看容器的标识 3.查看容器日志 docker logs -f 容器id -f表示查看最后几行 4.进入容器 docker exec -it 容器id bash 若报错则用： docker exec -it 容器id sh exit 退出容器 5.启动容器 docker start 容器id //启动容器 docker stop 容器id //关闭容器 docker rm 容器id //删除容器 6.将主机中的文件放入容器中的方式 docker cp 文件名称 容器id:容器内部的路径 7.修改已启动docker的容器启动方式 在你关掉docker之前，先把你想增加端口号的容器添加上这条命令:docker update container_name --restart=always 来设置重启docker之后自动启动该容器。设置完成后再修改hostconfig.json文件 在linux下可以修改/var/lib/docker/containers/容器下的hostconfig.json,即可 但在mac下是使用linux虚拟机实现的，而且还找不到入口的那种 进入linux虚拟机办法如下： cd ~/Library/Containers/com.docker.docker/Data/vms/0 screen tty 这样就可以进入linux下操作了 容器的目录在/var/lib/docker/containers下，找到对应的目录，修改完hostconfig.json,重启docker服务即可","categories":[],"tags":[],"author":"张存"},{"title":"Linux设置history命令显示行数以及时间","slug":"Linux设置history命令显示行数以及时间","date":"2022-04-25T12:15:04.000Z","updated":"2022-04-25T12:18:22.649Z","comments":true,"path":"2022/04/25/linux-she-zhi-history-ming-ling-xian-shi-xing-shu-yi-ji-shi-jian/","link":"","permalink":"https://blog.zhangcun.store/2022/04/25/linux-she-zhi-history-ming-ling-xian-shi-xing-shu-yi-ji-shi-jian/","excerpt":"","text":"Linux和unix上都提供了history命令，可以查询以前执行的命令历史记录 但是，这个记录并不包含时间项目 因此只能看到命令，但是不知道什么时间执行的 如何让history记录时间呢？ 解决方案 注意：本方法只对bash-3.0以上版本有效 执行rpm -q bash即可显示bash的版本 对于常见的linux AS4、AS5，都是有效的 --------------------------------------------- 编辑/etc/bashrc文件，加入如下三行： HISTFILESIZE=2000 HISTSIZE=2000 HISTTIMEFORMAT=&quot;%Y%m%d-%H%M%S: &quot; 或者HISTTIMEFORMAT=&quot;%Y%m%d %T &quot;或者HISTTIMEFORMAT=&quot;%F %T &quot; export HISTTIMEFORMAT 或者一句话： echo -e &#39;export HISTFILESIZE=99999\\nexport HISTSIZE=99999\\nexport HISTTIMEFORMAT=&quot;%F %T &quot;&#39; &gt;&gt; /etc/bashrc echo &quot;HISTFILESIZE=99999&quot; &gt;&gt; /etc/bashrc &amp;&amp; echo &quot;HISTSIZE=99999&quot; &gt;&gt; /etc/bashrc &amp;&amp; echo &#39;HISTTIMEFORMAT=&quot;%F %T &quot;&#39;&gt;&gt; /etc/bashrc &amp;&amp; export HISTTIMEFORMAT 保存后退出，关闭当前shell，并重新登录 这个时候，在~/.bash_history文件中，就有记录命令执行的时间了 用cat命令显示这个文件，但是却会看到这个时间不是年月日显示的 而是按照unix time来显示： [root@vz ~]# cat ~/.bash_history #1184649982 touch 3 #1184649984 exit #1184650148 history [root@vz ~]# 这个时间叫做unix time，是从1970年1月1日临时起，到现在一共经过了多少秒 因为1969年是unix系统诞生，因此1970年1月1日被规定为unix系统诞生的时间的初始 linux系统因为和unix系统的相似性，也完全采用这种方式来记录时间 为了按照人类的年月日方式来显示时间，执行history命令来查看，就可以了，例如： [root@vz ~]# history | more 20070717-132935: ll 20070717-132935: w 20070717-132935: rm -rf * 20070717-132935: ll 20070717-132935: w 20070717-132935: cat /etc/redhat-release 20070717-132935: rpm -ivh expect-5.42.1-1.i386.rpm 20070717-132935: ll 20070717-132935: vi /etc/sysconfig/i18n 20070717-132935: ll 20070717-132935: rpm -q expect [root@vz ~]# 这样即可查看到在什么时间执行了什么命令。 注意：本方法必须在服务器刚刚新安装好时候，就设置这个参数。 如果是已经运行了很久的服务器才添加这个参数，则以前的那些命令历史记录是不显示时间的。","categories":[],"tags":[],"author":"张存"},{"title":"解决Ubuntu系统设置打不开","slug":"解决Ubuntu系统设置打不开","date":"2022-04-25T12:11:43.000Z","updated":"2022-04-25T12:11:48.705Z","comments":true,"path":"2022/04/25/jie-jue-ubuntu-xi-tong-she-zhi-da-bu-kai/","link":"","permalink":"https://blog.zhangcun.store/2022/04/25/jie-jue-ubuntu-xi-tong-she-zhi-da-bu-kai/","excerpt":"","text":"今天把Ubuntu从16.04更新到16.10之后卸载了些软件，之后蛋疼的发现系统设置打不开了，真是欲哭无泪。去网上搜了下发现是我之前由于卸载了iBus导致的，虽然我不懂为什么iBus和Ubuntu之间的关系为什么会如此紧密，但是既然发生了这种事情我也很绝望啊，只能按照网上的方法 sudo apt-get install ubuntu-desktop #这个会把Ubuntu预装的软件office还有Amazon什么的装回来，装完自己再慢慢卸载吧或者他也提供了一次性的安装办法 sudo apt-get install ibus-pinyin unity-control-center unity-control-center-signon webaccounts-extension-common xul-ext-webaccounts但是我眉头一皱，发现事情并不简单，我继续搜了下去，也有很多人遇到这种问题，发现还有更简单的办法 sudo apt-get install gnome-control-center #如果系统设置打不开，请重新安装gnome-control-centersudo apt-get install unity-control-center #如果设置里只有很少的几个图标请重新安装unity-control-center","categories":[],"tags":[],"author":"张存"},{"title":"Linux下命令行连接wifi","slug":"Linux下命令行连接wifi","date":"2022-04-25T12:08:01.000Z","updated":"2022-04-25T12:08:03.368Z","comments":true,"path":"2022/04/25/linux-xia-ming-ling-xing-lian-jie-wifi/","link":"","permalink":"https://blog.zhangcun.store/2022/04/25/linux-xia-ming-ling-xing-lian-jie-wifi/","excerpt":"","text":"查看网络设备 $ iw dev phy#0 Unnamed/non-netdev interface wdev 0x2 addr bc:a8:a6:dc:b0:ea type P2P-device txpower 0.00 dBm Interface wlp1s0 ifindex 3 wdev 0x1 addr bc:a8:a6:dc:b0:ea ssid AndroidAP1f05 type managed channel 11 (2462 MHz), width: 20 MHz, center1: 2462 MHz txpower 0.00 dBm multicast TXQ: qsz-byt qsz-pkt flows drops marks overlmt hashcoltx-bytes tx-packets 0 0 0 0 0 0 0 00 查看wifi连接状态 $ iw wlp1s0 link 打开网络设备 $ sudo ip link set wlp1s0 up 扫描可用的wifi $ sudo iw wlp1s0 scan | grep SSID SSID: AndroidAP1f05 * Multiple BSSID SSID: @PHICOMM_E0 SSID: \\xe5\\xbc\\xa0\\xe5\\x9d\\xa4wifi SSID: TP-LINK_EC92 SSID: \\xe5\\xbc\\xa0\\xe5\\x9d\\xa4wifi-5G SSID: @PHICOMM_F3 SSID: FAST_9C10 SSID: Tenda_CD2868 SSID: PHICOMM_6F1764 SSID: TP-LINK_1D30 SSID: SSID: @PHICOMM_18 输入SSID+密码连接wifi $ nmcli dev wifi connect wifi的ssid password wifi的密码","categories":[],"tags":[],"author":"张存"},{"title":"docker build走代理!","slug":"docker-build走代理","date":"2022-04-25T12:05:34.000Z","updated":"2022-04-25T12:06:01.623Z","comments":true,"path":"2022/04/25/docker-build-zou-dai-li/","link":"","permalink":"https://blog.zhangcun.store/2022/04/25/docker-build-zou-dai-li/","excerpt":"","text":"docker build -t haha . --build-arg https_proxy=http://192.168.31.16:1013 --build-arg http_proxy=http://192.168.31.16:1013","categories":[],"tags":[],"author":"张存"},{"title":"linux:有效使用docker logs查看日志","slug":"linux-有效使用docker-logs查看日志","date":"2022-04-25T11:58:24.000Z","updated":"2022-04-25T11:58:26.864Z","comments":true,"path":"2022/04/25/linux-you-xiao-shi-yong-docker-logs-cha-kan-ri-zhi/","link":"","permalink":"https://blog.zhangcun.store/2022/04/25/linux-you-xiao-shi-yong-docker-logs-cha-kan-ri-zhi/","excerpt":"","text":"在开发基于Docker的应用程序时，能够在日志中查找特定信息并将此数据保存到文件中可以加快故障排除和调试过程。以下是使用日志选项，tail和grep在docker容器的日志数据中查找所需内容的一些提示。 关于开始使用Docker的帖子 新手docker cli指令和docker run十个选项和其他docker帖子 I. 显示所有日志 在启动Docker容器（例如with）时docker-compose up，它将自动显示日志。如果你在后台运行它们，例如使用docker-compose up -d或从不同的终端运行它们，则可以使用以下方式显示日志： docker logs [OPTIONS] CONTAINER docker-compose logs （所有容器） 但是，这将为你提供大量信息。 II. 跟踪容器日志 使用docker-compose，你可以指定要使用的容器日志(在位于docker-compose文件的当前目录执行)： docker-compose logs [options] [SERVICE...] 调试特定应用程序时，一个有用的选项是持续实时查看日志输出。这意味着你可以启动容器，测试功能并查看在使用时发送到日志的内容。 --follow , -f 另一种方法是测试你的应用程序，然后在日志中搜索特定信息，以向你显示它的工作情况（或不是!!!）。有两个基于Unix命令的命令可用于此目的。 III. 使用tail和grep切片和搜索日志 该tail命令输出n文件末尾的最后一行数。例如： [root@LinuxEA-172_25_50_250 /data/mirrors]# tail -n5 docker-compose.yaml - FTPPASSWD=123 - FTPDATA=/data/wwwroot - SERVER_NAME=meftp.ds.com - NGINX_PORT=80 - WELCOME=&quot;welome to www.linuxea.com&quot; 要查看docker日志中的最新输出，你可以直接在日志文件中使用它，也可以使用docker --tail选项。 --tail 从日志末尾显示的行数 [root@LinuxEA-172_25_50_250 /data/mirrors]# docker-compose logs --tail 5 nginx_repo Attaching to nginx_repo nginx_repo | 2019-01-29 17:45:58,689 INFO spawned: &#39;vsftpd&#39; with pid 26 nginx_repo | 2019-01-29 17:45:58,738 INFO exited: vsftpd (exit status 0; not expected) nginx_repo | 2019-01-29 17:45:59,739 INFO success: nginx entered RUNNING state, process has stayed up for &gt; than 1 seconds (startsecs) nginx_repo | 2019-01-29 17:45:59,740 INFO success: createrepo entered RUNNING state, process has stayed up for &gt; than 1 seconds (startsecs) nginx_repo | 2019-01-29 17:45:59,740 INFO gave up: vsftpd entered FATAL state, too many start retries too quickly 这仅仅只是一个示例，其他选项如，-f, -t ,--tail docker官网也有说明 另外，可以与日志一起使用的另一个Bash命令是grep返回包含指定字符串的行。例如： docker-compose logs | grep success 这将显示docker容器记录的所有想要的信息。非常有用，可以看到你需要关注开发的重点。 [root@LinuxEA-172_25_50_250 /data/mirrors]# docker-compose logs --tail 5 nginx_repo|grep success nginx_repo | 2019-01-29 17:45:59,739 INFO success: nginx entered RUNNING state, process has stayed up for &gt; than 1 seconds (startsecs) nginx_repo | 2019-01-29 17:45:59,740 INFO success: createrepo entered RUNNING state, process has stayed up for &gt; than 1 seconds (startsecs) 按时间记录 如果你知道要关注的时间段，例如你知道存在问题的时间，则可以告诉docker使用时间戳显示时间戳 --timestamps , -t [root@LinuxEA-172_25_50_250 /data/mirrors]# docker-compose logs -t nginx_repo Attaching to nginx_repo nginx_repo | 2019-01-29T09:45:57.110408403Z useradd: warning: the home directory already exists. nginx_repo | 2019-01-29T09:45:57.110441950Z Not copying any file from skel directory into it. nginx_repo | 2019-01-29T09:45:57.136689405Z Changing password for user marksugar. nginx_repo | 2019-01-29T09:45:57.136748778Z passwd: all authentication tokens updated successfully. nginx_repo | 2019-01-29T09:45:57.593741281Z Saving Primary metadata nginx_repo | 2019-01-29T09:45:57.593832853Z Saving file lists metadata nginx_repo | 2019-01-29T09:45:57.593854286Z Saving other metadata nginx_repo | 2019-01-29T09:45:57.593862151Z Generating sqlite DBs nginx_repo | 2019-01-29T09:45:57.593869092Z Sqlite DBs complete nginx_repo | 2019-01-29T09:45:57.672214250Z 2019-01-29 17:45:57,671 CRIT Supervisor is running as root. Privileges were not dropped because no user is specified in the config file. If you intend to run as root, you can set user=root in the config file to avoid this message. nginx_repo | 2019-01-29T09:45:57.679619865Z 2019-01-29 17:45:57,679 INFO RPC interface &#39;supervisor&#39; initialized nginx_repo | 2019-01-29T09:45:57.679661466Z 2019-01-29 17:45:57,679 CRIT Server &#39;unix_http_server&#39; running without any HTTP authentication checking nginx_repo | 2019-01-29T09:45:57.679740900Z 2019-01-29 17:45:57,679 INFO supervisord started with pid 1 nginx_repo | 2019-01-29T09:45:58.683866045Z 2019-01-29 17:45:58,683 INFO spawned: &#39;nginx&#39; with pid 24 nginx_repo | 2019-01-29T09:45:58.687228502Z 2019-01-29 17:45:58,686 INFO spawned: &#39;createrepo&#39; with pid 25 nginx_repo | 2019-01-29T09:45:58.690025433Z 2019-01-29 17:45:58,689 INFO spawned: &#39;vsftpd&#39; with pid 26 nginx_repo | 2019-01-29T09:45:58.738620050Z 2019-01-29 17:45:58,738 INFO exited: vsftpd (exit status 0; not expected) nginx_repo | 2019-01-29T09:45:59.740406128Z 2019-01-29 17:45:59,739 INFO success: nginx entered RUNNING state, process has stayed up for &gt; than 1 seconds (startsecs) nginx_repo | 2019-01-29T09:45:59.740444435Z 2019-01-29 17:45:59,740 INFO success: createrepo entered RUNNING state, process has stayed up for &gt; than 1 seconds (startsecs) nginx_repo | 2019-01-29T09:45:59.740540049Z 2019-01-29 17:45:59,740 INFO gave up: vsftpd entered FATAL state, too many start retries too quickly 选择一个特定的时间段--since和--until选项（仅适用于docker logs，不是docker-compose logs）： --since从时间戳（例如2013-01-02T13：23：37）或相对（例如42分钟42米）显示日志 --until在时间戳（例如2013-01-02T13：23：37）或相对之前显示日志（例如42分钟42米） 例如，如果我想在前面的示例中看到日志接近info的消息，我将执行： [root@LinuxEA-172_25_50_250 /data/mirrors]# docker logs -t --since 2019-01-29T09:45:57.679661466Z --until 2019-01-29T09:45:59.740540049Z nginx_repo 2019-01-29T09:45:57.679661466Z 2019-01-29 17:45:57,679 CRIT Server &#39;unix_http_server&#39; running without any HTTP authentication checking 2019-01-29T09:45:57.679740900Z 2019-01-29 17:45:57,679 INFO supervisord started with pid 1 2019-01-29T09:45:58.683866045Z 2019-01-29 17:45:58,683 INFO spawned: &#39;nginx&#39; with pid 24 2019-01-29T09:45:58.687228502Z 2019-01-29 17:45:58,686 INFO spawned: &#39;createrepo&#39; with pid 25 2019-01-29T09:45:58.690025433Z 2019-01-29 17:45:58,689 INFO spawned: &#39;vsftpd&#39; with pid 26 2019-01-29T09:45:58.738620050Z 2019-01-29 17:45:58,738 INFO exited: vsftpd (exit status 0; not expected) 2019-01-29T09:45:59.740406128Z 2019-01-29 17:45:59,739 INFO success: nginx entered RUNNING state, process has stayed up for &gt; than 1 seconds (startsecs) 2019-01-29T09:45:59.740444435Z 2019-01-29 17:45:59,740 INFO success: createrepo entered RUNNING state, process has stayed up for &gt; than 1 seconds (startsecs) 2019-01-29T09:45:59.740540049Z 2019-01-29 17:45:59,740 INFO gave up: vsftpd entered FATAL state, too many start retries too quickly 组合命令 你可以将这些选项和命令组合在一起，以使用你需要的信息来定位日志的特定区域。在下面的示例中，我们将-t timestamps选项与--tail容器日志的最后5行组合nginx_repo，然后在这些行中搜索包含INFO仅查看INFO级别记录的行的行。 [root@LinuxEA-172_25_50_250 /data/mirrors]# docker-compose logs --tail 5 nginx_repo|grep INFO nginx_repo | 2019-01-29 17:45:58,689 INFO spawned: &#39;vsftpd&#39; with pid 26 nginx_repo | 2019-01-29 17:45:58,738 INFO exited: vsftpd (exit status 0; not expected) nginx_repo | 2019-01-29 17:45:59,739 INFO success: nginx entered RUNNING state, process has stayed up for &gt; than 1 seconds (startsecs) nginx_repo | 2019-01-29 17:45:59,740 INFO success: createrepo entered RUNNING state, process has stayed up for &gt; than 1 seconds (startsecs) nginx_repo | 2019-01-29 17:45:59,740 INFO gave up: vsftpd entered FATAL state, too many start retries too quickly 如果要在所有内容中查找，这里可以替换成all [root@LinuxEA-172_25_50_250 /data/mirrors]# docker-compose logs --tail all nginx_repo|grep INFO nginx_repo | 2019-01-29 17:45:57,679 INFO RPC interface &#39;supervisor&#39; initialized nginx_repo | 2019-01-29 17:45:57,679 INFO supervisord started with pid 1 nginx_repo | 2019-01-29 17:45:58,683 INFO spawned: &#39;nginx&#39; with pid 24 nginx_repo | 2019-01-29 17:45:58,686 INFO spawned: &#39;createrepo&#39; with pid 25 nginx_repo | 2019-01-29 17:45:58,689 INFO spawned: &#39;vsftpd&#39; with pid 26 nginx_repo | 2019-01-29 17:45:58,738 INFO exited: vsftpd (exit status 0; not expected) nginx_repo | 2019-01-29 17:45:59,739 INFO success: nginx entered RUNNING state, process has stayed up for &gt; than 1 seconds (startsecs) nginx_repo | 2019-01-29 17:45:59,740 INFO success: createrepo entered RUNNING state, process has stayed up for &gt; than 1 seconds (startsecs) nginx_repo | 2019-01-29 17:45:59,740 INFO gave up: vsftpd entered FATAL state, too many start retries too quickly 将日志写入文件 现在你已掌握了docker logs命令以及如何准确找到所需内容，请使用此命令将数据发送到日志文件。使用Bash或替代shell（如Zsh），&gt;&gt;命令后跟文件名输出并将数据保存到该文件。 docker-compose logs --tail all nginx_repo|grep INFO &gt;&gt; ./nginx_repo.log 你可能希望使用它来为特定日志数据创建日志文件。例如，在调试时，你可以创建警告或错误。 docker-compose logs --tail all nginx_repo| grep warning &gt;&gt; logs_warnings.log 现在我的nginx_repo.log文件内容包含： nginx_repo | 2019-01-29 17:45:57,679 INFO RPC interface &#39;supervisor&#39; initialized nginx_repo | 2019-01-29 17:45:57,679 INFO supervisord started with pid 1 nginx_repo | 2019-01-29 17:45:58,683 INFO spawned: &#39;nginx&#39; with pid 24 nginx_repo | 2019-01-29 17:45:58,686 INFO spawned: &#39;createrepo&#39; with pid 25 nginx_repo | 2019-01-29 17:45:58,689 INFO spawned: &#39;vsftpd&#39; with pid 26 nginx_repo | 2019-01-29 17:45:58,738 INFO exited: vsftpd (exit status 0; not expected) nginx_repo | 2019-01-29 17:45:59,739 INFO success: nginx entered RUNNING state, process has stayed up for &gt; than 1 seconds (startsecs) nginx_repo | 2019-01-29 17:45:59,740 INFO success: createrepo entered RUNNING state, process has stayed up for &gt; than 1 seconds (startsecs) nginx_repo | 2019-01-29 17:45:59,740 INFO gave up: vsftpd entered FATAL state, too many start retries too quickly 这意味着你可以使用与文本文件一起使用的所有其他应用程序和命令，并将它们应用于此日志数据。","categories":[],"tags":[],"author":"张存"},{"title":"ELK：收集Docker容器日志","slug":"ELK：收集Docker容器日志","date":"2022-04-25T06:24:12.000Z","updated":"2022-04-25T12:04:36.100Z","comments":true,"path":"2022/04/25/elk-shou-ji-docker-rong-qi-ri-zhi/","link":"","permalink":"https://blog.zhangcun.store/2022/04/25/elk-shou-ji-docker-rong-qi-ri-zhi/","excerpt":"","text":"简介 之前写过一篇博客 ELK：日志收集分析平台，介绍了在Centos7系统上部署配置使用ELK的方法，随着容器化时代的到来，容器化部署成为一种很方便的部署方式，收集容器日志也成为刚需。本篇文档从 容器化部署ELK系统，收集容器日志，自动建立项目索引，ElastAlert日志监控报警，定时删除过期日志索引文件 这几个方面来介绍ELK。 大部分配置方法多是看官方文档，理解很辛苦，查了很多文章，走了很多弯路，分享出来，希望让有此需求的朋友少走弯路，如有错误或理解不当的地方，请批评指正。 逻辑结构如下图 ELK之容器日志收集及索引建立 Docker环境下，拉取官方镜像，官方镜像地址 Docker @ Elastic docker pull docker.elastic.co/elasticsearch/elasticsearch:6.6.2 docker pull docker.elastic.co/kibana/kibana:6.6.2 docker pull docker.elastic.co/beats/filebeat:6.6.2 docker pull docker.elastic.co/logstash/logstash:6.6.2 Elasticsearch 容器部署 Elasticsearch 启动命令说明 启动两个端口，9200为数据查询和写入端口，也即是业务端口，9300为集群端口，同步集群数据，此处我单节点部署 指定日志输出格式为json格式，默认情况下也为json格式，默认输出路径 /var/lib/docker/containers/*/*.log 日志文件最多保留三个，每个最多10M 容器开机自启 传递参数为单节点部署 数据存储映射至宿主机 需要给 /data/elasticsearch 赋予权限，否则报权限不足的错误 docker run -d \\ --user root \\ -p 127.0.0.1:9200:9200 \\ -p 9300:9300 \\ --log-driver json-file \\ --log-opt max-size=10m \\ --log-opt max-file=3 \\ --name elasticsearch \\ --restart=always \\ -e &quot;discovery.type=single-node&quot; \\ -v /data/elasticsearch:/usr/share/elasticsearch/data \\ docker.elastic.co/elasticsearch/elasticsearch:6.6.2 chmod 777 -R /data/elasticsearch Logstash 容器部署 Logstash 配置文件说明 配置文件映射至至宿主机 match =&gt; &#123; &quot;message&quot; =&gt; &quot;%&#123;TIMESTAMP_ISO8601:log-timestamp&#125; %&#123;LOGLEVEL:log-level&#125; %&#123;JAVALOGMESSAGE:log-msg&#125;&quot; &#125; 将日志做简单拆分, 时间戳重命名为 log-timestamp，日志级别重命名为 log-msg，如果拆分成功输出日志中就会产生这两个字段 通过 remove_field =&gt; [&quot;beat&quot;] 移除无用字段 输出到elasticsearch 索引通过 容器名称-时间 建立 mkdir -pv /data/conf cat &gt; /data/conf/logstash.conf &lt;&lt; &quot;EOF&quot; input &#123; beats &#123; host =&gt; &quot;0.0.0.0&quot; port =&gt; &quot;5043&quot; &#125; &#125; filter &#123; grok &#123; match =&gt; &#123; &quot;message&quot; =&gt; &quot;%&#123;TIMESTAMP_ISO8601:log-timestamp&#125; %&#123;LOGLEVEL:log-level&#125; %&#123;JAVALOGMESSAGE:log-msg&#125;&quot; &#125; &#125; mutate &#123; # remove_field =&gt; [&quot;message&quot;] remove_field =&gt; [&quot;beat&quot;] &#125; &#125; output &#123; stdout &#123; codec =&gt; rubydebug &#125; elasticsearch &#123; hosts =&gt; [ &quot;elasticsearch:9200&quot; ] index =&gt; &quot;%&#123;containername&#125;-%&#123;+YYYY.MM.dd&#125;&quot; &#125; &#125; EOF Logstash 启动命令说明 通过 --link elasticsearch 连接 elasticsearch 容器，并生成环境变量在容器中使用 配置文件映射如容器 docker run -p 5043:5043 -d \\ --user root \\ --log-driver json-file \\ --log-opt max-size=10m \\ --log-opt max-file=3 \\ --name logstash \\ --link elasticsearch \\ --restart=always \\ -v /data/conf/logstash.conf:/usr/share/logstash/pipeline/logstash.conf \\ docker.elastic.co/logstash/logstash:6.6.2 Kibana容器部署 启动参数参考上述组件 docker run -p 5601:5601 -d \\ --user root \\ --log-driver json-file \\ --log-opt max-size=10m \\ --log-opt max-file=3 \\ --name kibana \\ --link elasticsearch \\ --restart=always \\ -e ELASTICSEARCH_URL=http://elasticsearch:9200 \\ -v /data/conf/kibana.yml:/usr/share/kibana/config/kibana.yml \\ -v /data/elastalert-kibana-plugin:/usr/share/kibana/plugins/elastalert-kibana-plugin \\ docker.elastic.co/kibana/kibana:6.6.2 通过服务器IP地址即可访问Kibana web http://IP:5601 Filebeat 容器部署 Filebeat 配置文件说明 Filebeat是一个轻量级的日志收集工具，是Elastic的Beat组成员，默认情况下，docker输出的日志格式为json格式，需要解码才方便查看日志的路径为 /var/lib/docker/containers/*/*.log - type: log 选择filebeat输入类型选择log，之后通过解码json的配置将docker输出的日志解码，输入类型也可选择docker，但是我试过目前版本该数据类型有些功能受限，比如后面rename时，只能rename一个 json解码： 必须至少指定设置其中之一来启用JSON解析模式，建议三行都加上，不然，有些功能会有问题 json.overwrite_keys #如果启用了keys_under_root和此设置，那么来自解码的JSON对象的值将覆盖Filebeat通常添加的字段（type, source, offset,等）以防冲突。 json.add_error_key #如果启用此设置，则在出现JSON解组错误或配置中定义了message_key但无法使用的情况下，Filebeat将添加“error.message”和“error.type：json”键。 json.message_key #一个可选的配置设置，用于指定应用行筛选和多行设置的JSON密钥。 如果指定，键必须位于JSON对象的顶层，且与键关联的值必须是字符串，否则不会发生过滤或多行聚合。 多行合并： 将多行日志合并成一条，比如java的报错日志，规则为，如果不是以四个数字，即年份开头的日志合并到上一条日志当中 排除或删除通配符行： 即排除含有相关关键字的行，或只收集含有相关关键字的行 排除通配文件： 即不读取该含该字符的文件的日志 添加docker元数据： 将docker容器的相关数据收集起来，方便作为索引的字段， match_source_index: 4 为获取docker数据的索引，其数据为json格式，索引太低可能无法获取关键docker数据 处理器重命名和删除无用字段： - rename: 将上面收集的元数据重命名来提升其索引等级，以便交给logstash来处理，其中 docker.container.name 为docker容器的名字，重命名为 containername字段， - drop_fields: 清除掉无用索引数据，不输出到 output 日志输出：日志输出的几种方式 output.file 输出到文件，output.console 输出到标准输出，通过 docker logs containName 查看，该两种输出方便调试 cat &gt; /data/conf/filebeat.yml &lt;&lt; &quot;EOF&quot; filebeat.inputs: - type: log paths: - &#39;/var/lib/docker/containers/*/*.log&#39; # json解码 json.add_error_key: true json.overwrite_keys: true json.message_key: log # 多行合并 # multiline: # pattern: ^\\d&#123;4&#125; # negate: true # match: after # # 排除或删除通配符行 # exclude_lines: [&#39;^DBG&#39;] # include_lines: [&#39;ERROR&#39;, &#39;WARN&#39;, &#39;INFO&#39;] # 排除通配文件 # exclude_files: [&#39;\\.gz$&#39;] # # 添加docker元数据 processors: - add_docker_metadata: match_source: true # 选取添加docker元数据的层级 match_source_index: 4 # 处理器重命名和删除无用字段 processors: - rename: fields: - from: &quot;json.log&quot; to: &quot;message&quot; - from: &quot;docker.container.name&quot; to: &quot;containername&quot; - from: &quot;log.file.path&quot; to: &quot;filepath&quot; - drop_fields: fields: [&quot;docker&quot;,&quot;metadata&quot;,&quot;beat&quot;,&quot;input&quot;,&quot;prospector&quot;,&quot;host&quot;,&quot;source&quot;,&quot;offset&quot;] # 日志输出 output.logstash: # 输出地址 hosts: [&quot;192.168.30.42:5043&quot;] #output.elasticsearch: # hosts: [&quot;192.168.30.42:9200&quot;] # protocol: &quot;http&quot; #output.file: # path: &quot;/tmp&quot; # filename: filebeat.out #output.console: # pretty: true EOF Filebeat 启动命令 -v /var/lib/docker/containers/:/var/lib/docker/containers/ 映射日志目录 -v /var/run/docker.sock:/var/run/docker.sock:ro 映射docker套接字文件，来收集docker信息，添加docker元数据 docker run -d \\ --name filebeat \\ --user root \\ --log-driver json-file \\ --log-opt max-size=10m \\ --log-opt max-file=3 \\ --restart=always \\ -v /data/conf/filebeat.yml:/usr/share/filebeat/filebeat.yml:ro \\ -v /var/lib/docker/containers/:/var/lib/docker/containers/ \\ -v /var/run/docker.sock:/var/run/docker.sock:ro \\ docker.elastic.co/beats/filebeat:6.6.2 Filebeat是日志收集客户端，正常情况下其部署在需要收集日志的主机上 添加kibana索引 通过服务器IP地址访问Kibana web http://IP:5601 同时添加索引 img-w500 如此便可查看相关日志 img-w500 ELK之ElastAlert日志告警 ElastAlert分为两部分，后端程序，项目地址 https://github.com/bitsensor/elastalert，Kibana前端页面插件地址 https://github.com/bitsensor/elastalert-kibana-plugin ElastAlert目前支持的报警类型： any：只要有匹配就报警； blacklist：compare_key字段的内容匹配上 blacklist数组里任意内容； whitelist：compare_key字段的内容一个都没能匹配上whitelist数组里内容； change：在相同query_key条件下，compare_key字段的内容，在 timeframe范围内发送变化； frequency：在相同 query_key条件下，timeframe 范围内有num_events个被过滤出来的异常； spike：在相同query_key条件下，前后两个timeframe范围内数据量相差比例超过spike_height。其中可以通过spike_type设置具体涨跌方向是up,down,both 。还可以通过threshold_ref设置要求上一个周期数据量的下限，threshold_cur设置要求当前周期数据量的下限，如果数据量不到下限，也不触发； flatline：timeframe 范围内，数据量小于threshold阈值； new_term：fields字段新出现之前terms_window_size(默认30天)范围内最多的terms_size (默认50)个结果以外的数据； cardinality：在相同 query_key条件下，timeframe范围内cardinality_field的值超过 max_cardinality 或者低于min_cardinality Percentage Match: 在buffer_time 中匹配所设置的字段的百分比高于或低于阈值时，此规则将匹配。默认情况下为全局的buffer_time ElastAlert容器启动 -p 3030:3030 指定映射端口，该端口需要kibana调用 -v config/elastalert.yaml:/opt/elastalert/config.yaml 映射ElastAlert的配置文件 -v rules:/opt/elastalert/rules 映射报警规则文件目录 --link elasticsearch ElastAlert需要连接ElasticSearch 进行数据的查询 rule_templates:/opt/elastalert/rule_templates 该目录下为报警规则的模版，可使用其配置并放入 rules 使其生效，具体配置规则参考 https://elastalert.readthedocs.io/en/latest/ruletypes.html git clone https://github.com/bitsensor/elastalert.git; cd elastalert sed -i -e &#39;s/localhost/elasticsearch/g&#39; `pwd`/config/elastalert.yaml docker run -d \\ -p 3030:3030 \\ -v `pwd`/config/elastalert.yaml:/opt/elastalert/config.yaml \\ -v `pwd`/config/config.json:/opt/elastalert-server/config/config.json \\ -v `pwd`/rules:/opt/elastalert/rules \\ -v `pwd`/rule_templates:/opt/elastalert/rule_templates \\ --link elasticsearch \\ --name elastalert \\ bitsensor/elastalert:latest 可通过 elastalert-test-rule rules/rule1.yaml 在 elastalert 容器内测试报警规则 Kibana 需要更改配置 添加 elastalert 相关的配置，包括主机名和端口 cat &gt; /data/conf/kibana.yml &lt;&lt; &quot;EOF&quot; # Default Kibana configuration from kibana-docker. server.name: kibana server.host: &quot;0&quot; elasticsearch.hosts: http://elasticsearch:9200 xpack.monitoring.ui.container.elasticsearch.enabled: true elastalert-kibana-plugin.serverHost: elastalert elastalert-kibana-plugin.serverPort: 3030 Kibana 启动参数更改 配置 Kibana的插件 elastalert-kibana-plugin 需要注意的是，插件的下载地址 https://github.com/bitsensor/elastalert-kibana-plugin/releases 需要找到对应自己 kibana 版本，否则插件无法安装成功 从目前版本来看，插件的使用不是很方便，其相当于在 ElasticAlert 启动时 -v rules:/opt/elastalert/rules 目录下写文件 -v /data/kibana/elastalert-kibana-plugin:/usr/share/kibana/plugins/elastalert-kibana-plugin 映射插件目录 cd /data wget https://github.com/bitsensor/elastalert-kibana-plugin/releases/download/1.0.2/elastalert-kibana-plugin-1.0.2-6.6.2.zip unzip elastalert-kibana-plugin-1.0.2-6.6.2.zip docker run -p 5601:5601 -d \\ --user root \\ --log-driver json-file \\ --log-opt max-size=10m \\ --log-opt max-file=3 \\ --name kibana \\ --link elasticsearch \\ --link elastalert \\ --restart=always \\ -e ELASTICSEARCH_URL=http://elasticsearch:9200 \\ -v /data/conf/kibana.yml:/usr/share/kibana/config/kibana.yml \\ -v /data/kibana/elastalert-kibana-plugin:/usr/share/kibana/plugins/elastalert-kibana-plugin \\ docker.elastic.co/kibana/kibana:6.6.2 启动后，可查看 http://IP:5601，可通过此来创建报警规则 报警规则配置 这里给出一个报警规则的示例，更多请查看文档 https://elastalert.readthedocs.io/en/latest/ruletypes.html es_host: elasticsearch 该配置会使用docker容器中的变量 name: filebeat info frequency rule 报警规则的名称，需要唯一 timeframe: 设定查询的时间尺度，这里指定为5分钟 filter 指定报警条件，示例为日志中message字段还有INFO信息就示作匹配 alert 指定报警方式，报警方式有很多，这里使用slack，可查看文档配置 # Alert when the rate of events exceeds a threshold # (Optional) # Elasticsearch host # es_host: elasticsearch.example.com es_host: elasticsearch # (Optional) # Elasticsearch port # es_port: 14900 es_port: 9200 # (OptionaL) Connect with SSL to Elasticsearch #use_ssl: True # (Optional) basic-auth username and password for Elasticsearch #es_username: someusername #es_password: somepassword # (Required) # Rule name, must be unique name: filebeat info frequency rule # (Required) # Type of alert. # the frequency rule type alerts when num_events events occur with timeframe time type: frequency # (Required) # Index to search, wildcard supported index: filebeat-* # (Required, frequency specific) # Alert when this many documents matching the query occur within a timeframe num_events: 1 # (Required, frequency specific) # num_events must occur within this amount of time to trigger an alert timeframe: # hours: 1 minutes: 5 # (Required) # A list of Elasticsearch filters used for find events # These filters are joined with AND and nested in a filtered query # For more info: http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/query-dsl.html filter: - query: query_string: query: &quot;message:INFO&quot; # (Required) # The alert is use when a match is found alert: - &quot;slack&quot; alert_subject: &quot;&#123;&#125; @&#123;&#125;&quot; alert_subject_args: - containername - log-timestamp alert_text_type: alert_text_only alert_text: | &gt; 【Name】: &#123;&#125; &gt; 【Log-Msg】: &#123;&#125; alert_text_args: - containername - message slack_webhook_url: &quot;https://hooks.slack.com/services/xxxx/xxxx/xxxxxx&quot; slack_title_link: &quot;https://elk.glinux.top&quot; slack_title: &quot;ELK URL&quot; slack_username_override: &quot;ELK Alert&quot; slack_channel_override: &quot;#filebeat-test&quot; 定时删除过期日志索引文件 该脚本用于删除7天以前的索引文件（过月日志清除），脚本为参考他人作品，做了少许更改，可查看参考文档 curl -s &quot;http://127.0.0.1:9200/_cat/indices?v&quot; 该命令可以查看es中的索引 curl -XDELETE -s &quot;http://127.0.0.1:9200/filebeat-2019.04.27&quot; 该命令用于删除es中的 filebeat-2019.04.27 索引 cat &gt; /data/delete_index.sh &lt;&lt; &quot;EOF&quot; #!/bin/bash elastic_url=127.0.0.1 elastic_port=9200 user=&quot;username&quot; pass=&quot;password&quot; log=&quot;/data/log/delete_index.log&quot; # 当前日期时间戳减去索引名时间转化时间戳是否大于1 dateDiff ()&#123; dte1=$1 dte2=$2 diffSec=$((dte1-dte2)) if ((diffSec &gt; 6)); then echo &quot;1&quot; else echo &quot;0&quot; fi &#125; # 循环获取索引文件，通过正则匹配过滤 for index in $(curl -s &quot;$&#123;elastic_url&#125;:$&#123;elastic_port&#125;/_cat/indices?v&quot; | awk -F&#39; &#39; &#39;&#123;print $3&#125;&#39; | grep -E &quot;[0-9]&#123;4&#125;.[0-9]&#123;2&#125;.[0-9]&#123;2&#125;$&quot;); do # 获取索引文件日期，并转化格式 date=$(echo $index | awk -F&#39;-&#39; &#39;&#123;print $NF&#125;&#39; | sed -n &#39;s/\\.//p&#39; | sed -n &#39;s/\\.//p&#39;) # 获取当前日期 cond=$(date &#39;+%Y%m%d&#39;) # 根据不同服务器，计算不同数值 diff=$(dateDiff &quot;$&#123;cond&#125;&quot; &quot;$&#123;date&#125;&quot;) # 打印索引名和结果数值 #echo -n &quot;$&#123;index&#125; ($&#123;diff&#125;)&quot; # 判断结果值是否大于等于1 if [ $diff -eq 1 ]; then curl -XDELETE -s &quot;$&#123;elastic_url&#125;:$&#123;elastic_port&#125;/$&#123;index&#125;&quot; &amp;&amp; echo &quot;$&#123;index&#125; 删除成功&quot; &gt;&gt; $log || echo &quot;$&#123;index&#125; 删除失败&quot; &gt;&gt; $log fi done EOF 该脚本可以做成定时任务，每天都执行一次，来删除过期数据","categories":[],"tags":[],"author":"张存"},{"title":"通过镜像反推Dockerfile命令","slug":"通过镜像反推Dockerfile命令","date":"2022-04-25T06:17:17.000Z","updated":"2022-04-25T06:17:30.712Z","comments":true,"path":"2022/04/25/tong-guo-jing-xiang-fan-tui-dockerfile-ming-ling/","link":"","permalink":"https://blog.zhangcun.store/2022/04/25/tong-guo-jing-xiang-fan-tui-dockerfile-ming-ling/","excerpt":"","text":"命令为： docker history --format &#123;&#123;.CreatedBy&#125;&#125; --no-trunc=true imagesName:V|sed &quot;s?/bin/sh\\ -c\\ \\#(nop)\\ ??g&quot;|sed &quot;s?/bin/sh\\ -c?RUN?g&quot; | tac","categories":[],"tags":[],"author":"张存"},{"title":"zabbix-get命令使用及zabbix内置的一些参数","slug":"zabbix-get命令使用及zabbix内置的一些参数","date":"2022-04-25T06:12:08.000Z","updated":"2022-04-25T06:12:12.850Z","comments":true,"path":"2022/04/25/zabbix-get-ming-ling-shi-yong-ji-zabbix-nei-zhi-de-yi-xie-can-shu/","link":"","permalink":"https://blog.zhangcun.store/2022/04/25/zabbix-get-ming-ling-shi-yong-ji-zabbix-nei-zhi-de-yi-xie-can-shu/","excerpt":"","text":"一、内置key说明： Zabbix 内置了很多丰富的key，使得咱们再添加linux os模板的时候，已经帮我们把key给定义好，这样我们就能够直接链接模板就可以使用了。 我们这边的话列举一些内置key，然后进行一些简单的说明:当我们内置key可以采集到数据的时候我们最好是不用去写自定义key再去采集的：(我见过一篇51 CTO的写监控用户登录数，还用w去监控，没有直接取调用内置key)： 二、详情可以查看官方文档： https://www.zabbix.com/documentation/3.0/manual/config/items/itemtypes/zabbix_agent#supported_item_keys 三、内置监控项key列表： agent.hostname 返回被监控端名称(字符串) 使用方式列举：后面使用的方式是一样的： [root@BJ-monitor-h-01 bin]# ./zabbix_get -s 192.168.10.100 -k agent.hostname Zabbix server agent.ping 检测被监控端是否存活(1:运行中 其他:未运行)-使用函数 nodata()检测客户端是否正在运行 agent.version zabbix agent版本字符串 kernel.maxfiles 系统支持最大的open files整数 kernel.maxproc 系统支持最大的进程数量整数 log[file, 监控日志文件 file - 文件详细路径 regexp - 正则 encoding - 编码 maxlines - zabbix agent向server或者proxy发送最大的行数。 这个参数覆盖配置文件zabbxi_agentd.conf中的’MaxLinesPerSecond’ mode - 可选值:all (默认), skip (跳过处理老数据).mode参数从2.0版本开始支持 output - 可选项，输出格式模板. 示例: log[/var/log/syslog] log[/var/log/syslog,error] log[/home/zabbix/logs/logfile,,,100] logrt[file_pattern, Monitoring of log file with log rotation support. file_pattern - 文件绝对路径 net.if.discovery 列出网卡.通常用于低级别的discovery.JSON对象 net.if.in[if, 网卡入口流量整数. if - 网卡名称 mode - 可用值: bytes - 字节数 (默认) packets - 包数量 errors - 错误数量 dropped - 丢包数量 示例keys: net.if.in[eth0,errors] net.if.in[eth0] net.if.out[if, 网卡出口流量（参数参见net.if.in） net.if.total[if, 网卡进/出流量的总和（参数参见net.if.in） net.tcp.listen[port] 检测端口是否开启0 – （not listen） 1 – in LISTEN stateport 示例: net.tcp.listen[80] net.tcp.port[ 是否可以连接到指定的TCP端口0 – cannot connect 1 – can connect ip - IP地址(默认是 127.0.0.1) port - 端口 范例: net.tcp.port[,80] 检测web服务器端口是否运行中 net.tcp.service[service, 检测服务是否开启，并且端口可用0 – 服务挂了 1 – 服务运行中 service - 如下:ssh, ntp, ldap, smtp, ftp, http, pop, nntp,imap, tcp, https, telnet ip - IP地址 (默认127.0.0.1) port - 端口 (默认情况为标准端口号) 示例key: net.tcp.service[ftp,,45] net.tcp.service.perf[service, 检测服务器性能0 – 服务挂了; seconds – 链接到服务器端口消耗的时间 service - 如下:ssh, ntp, ldap, smtp, ftp, http, pop, nntp,imap, tcp, https, telnet ip - IP地址 (默认127.0.0.1) port - 端口 (默认情况为标准端口号) 示例key: net.tcp.service.perf[ssh] proc.mem[ 用户进程消耗的内存内存使用量 (字节单位). name - 进程名 (默认值 “all processes”) user - 用户名 (默认值“all users”) mode - 可选值: avg, max, min, sum (默认) cmdline - 命令行过滤(正则表达时) 示例keys: proc.mem[,root] – root的进程消耗了多少内存 proc.mem[zabbix_server,zabbix] – zabbix用户运行的zabbix_server使用了多少内存 proc.mem[,oracle,max,oracleZABBIX] proc.num[ 某用户某些状态的进程的数量进程数量 name - 进程名称 (默认“all processes”) user - 用户名 (默认 “all users”) state - 可用值: all (默认), run,sleep, zomb cmdline - 命令行过滤(正则表达时) 示例keys: proc.num[,mysql] – MySQL用户运行的进程数量 proc.num[apache2,www-data] – www-data运行了多少个apache2进程 proc.num[,oracle,sleep,oracleZABBIX] 备注：Windows系统只支持name和user两个参数 system.boottime 系统启动的时间戳整数.unix时间戳 system.cpu.intr 设备中断整数 system.cpu.load[ CPU负载浮点数 cpu - 可用值: all (默认), percpu (所有在线cpu的负载) mode - 可用值:avg1 (1分钟 默认值), avg5(5分钟平均), avg15 (15分钟平均值) 范例key: system.cpu.load[,avg5] system.cpu.num[ CPU数量处理器个数type - 可用值: online (默认值), max范例: system.cpu.num system.cpu.switches 上下文交换交换次数老命名方式: system[switches] system.cpu.util[ CPU利用率百分比 cpu - cpu数量 (默认是所有cpu) type - 可用值: idle, nice, user (默认), system (windows系统默认值）, iowait, interrupt, softirq,steal mode - 可用值: avg1 (一分钟平均，默认值), avg5(5分钟平均, avg15 (15分钟平均值) 范例key: system.cpu.util[0,user,avg5] system.hostname[ 返回主机名字符串 type (仅用于windows系统) – 可用值: netbios(默认) or host system.hw.cpu[ 返回CPU信息字符/数字 cpu - cpu数量或者all (默认) info - full (默认), curfreq, maxfreq, model 或者vendor 例如: system.hw.cpu[0,vendor] AuthenticAMD 从/proc/cpuinfo、 /sys/devices/system/cpu/[cpunum]/cpufreq/cpuinfo_max_freq获取信息. 如果指定了CPU数量和 curfreq或者maxfreq, 将会返回数值(Hz). system.hw.devices[ 列出PCI或者USB文本值 type - pci (默认) or usb 范例: system.hw.devices[pci] 00:00.0 Host bridge: Advanced Micro Devices [AMD] RS780 Host Bridge [..] 返回lspci或者lsusb (不带参数) system.hw.macaddr[ 列出MAC地址字符串 interface - all (默认) 或者正则表达式 format - full (默认) 、short 范例: system.hw.macaddr[&quot;eth0$&quot;,full] [eth0] 00:11:22:33:44:55 列出指定接口mac地址 如果format指定为short，MAC地址相同的将会被忽略掉 system.localtime[ 系统时间.数字或者字符串 system.run[command, 在制定的主机上运行命令文本 command - 命令 mode - wait (默认值, 执行超时时间), nowait (不等待)最大可用返回512KB数据，包含空白数据。 命令输出数据必须是文本 例如: system.run[“ls -l /”] – 列出/的文件和目录. Note: 启用这个方法, agent配置文件必须配置 EnableRemoteCommands=1选项 system.sw.arch 返回软件信息字符串 范例: system.sw.arch system.sw.os[ 返回系统信息字符串 info - full (default), short ,name 范例: system.sw.os[short] Ubuntu 2.6.35-28.50-generic 2.6.35.11 信息来自如下文件： /proc/version [short] /proc/version_signature [name] /etc/issue.net system.sw.packages[ 已安装软件列表文本值 package - all (默认)或者正则表达式 manager - all (默认) or a package manager format - full (默认) ，short 范例: system.sw.packages[http] system.swap.in[ 交换分区IN（磁盘交换到内存）数字 device - 交换分区设备 (默认all) type - 可选值: count (swapins数量), sectors(sectors swapped in), pages (pages swapped in). 示例key: system.swap.in[,pages] 数据采集自: Linux 2.4: /proc/swaps, /proc/partitions, /proc/stat Linux 2.6: /proc/swaps, /proc/diskstats, /proc/vmstat system.swap.out[ Swap out (f内存到磁盘) .数字 device - swap设备 (默认all) type - count (number of swapouts), sectors(sectors swapped out), pages (pages swapped out). 示 例key: system.swap.out[,pages] 数据采集自: Linux 2.4: /proc/swaps, /proc/partitions, /proc/stat Linux 2.6: /proc/swaps, /proc/diskstats, /proc/vmstat system.swap.size[ 交换分区大小字节或者百分比 device - 交换分区 (默认值 all) type - free (free swap space, default), pfree (free swap space, in percent), pused (used swap space, in percent), total (total swap space), used (used swap space) 示例 system.swap.size[,pfree] – 空闲swap百分比 system.uname 返回主机相信信息.字符串 system.uptime 系统运行时长(秒)多少秒使用s/uptime来获取 system.users.num 登陆用户数量多少用户agent使用who命令获取 vfs.dev.read[ 磁盘读取状态整数，浮点数（如果type为如下） device - 磁盘设备 (默认值 “all”) type - 可选值:sectors, operations, bytes, sps, ops, bps(必须指定, 不同操作系统下不同). sps, ops, bps stand for: sectors, operations, bytes per second, respectively mode - 可选值: avg1, avg5, avg15. 备注: 只有type为sps, ops, bps的时候，第三个参数才被支持。 不同操作系统的TYPE参数： FreeBSD – bps Linux – sps OpenBSD – operations Solaris – bytes 示例key: vfs.dev.read[,operations] vfs.dev.write[ 磁盘写入状态整数， device - 磁盘设备 (默认 all) type - sectors, operations, bytes, sps, ops, bps mode - one of avg1 (default),avg5 , avg15. example: vfs.dev.write[,operations] Old naming: io vfs.file.cksum[file] 计算文件校验 UNIX cksum. file - 文件完整路径 vfs.file.contents[file, 获取文本内容若为空，只返回 LF/CR characters. file - 文件完整路径 例如: vfs.file.contents[/etc/passwd] 文件不可以超过64KB. vfs.file.exists[file] 检测文件是否存在1 – 存在 0 – 不存在 file - 文件完整路径 vfs.file.md5sum[file] 文件MD5校验码文件MD5哈希值 file - 完整路径 vfs.file.regexp[file,regexp, 文件中搜索字符串包含字符串的行，或者为空 file - 文件完整路径 regexp - GNU正则表达式 encoding - 编码 start line - 从哪一行开始，默认第一行 end line - 从哪一行结束，默认最后一行 如: vfs.file.regexp[/etc/passwd,zabbix] vfs.file.regexp[/path/to/some/file,”([0-9]+)$”,,3,5,\\1] vfs.file.regexp[/etc/passwd,^zabbix:.:([0-9]+),,,,\\1] vfs.file.regmatch[file,regexp, 文件中搜索字符串0 – 未找到 1 – 找到 file - 文件完整路径 regexp - GNU 正则表达式 encoding - 编码 start line - 哪行开始，默认第一行 end line - 哪行结束，默认最后一行 例如: vfs.file.regmatch[/var/log/app.log,error] vfs.file.size[file] 文件大小字节fzabbix必须有可读此文件的权限 vfs.file.time[file, 文件时间信息Unix 时间戳. mode - modify (默认, 修改时间), access – 最后访问时间, change – 最后改变时间 例如: vfs.file.time[/etc/passwd,modify] 备注：文件大小有限制 vfs.fs.discovery 列出挂载的文件系统 用于lld.JSON对象 vfs.fs.inode[fs, inodes数量数字 fs - 文件系统 mode - total (默认), free, used, pfree (空闲百分比), pused (使用百分比) 例如: vfs.fs.inode[/,pfree] vfs.fs.size[fs, 磁盘空间，返回本地文件系统的使用量字节 fs - 文件系统 mode - total (默认), free, used, pfree (空闲百分比), pused (使用百分比). 例如: vfs.fs.size[/tmp,free] vm.memory.size[ 内存大小字节或百分比 mode - total (默认), active, anon, buffers, cached, exec, file, free, inactive, pinned, shared, wired, used, pused, available 监控项vm.memory.size[] 允许三种类型的参数： 第一类：包含total - 总内存 第二类： 系统指定内存类型:active, anon, buffers, cached, exec, file, free, inactive,pinned, shared, wired. 第三类：用户级别，一共使用了多少内存，还有多少内存可用: used, pused, available,pavailable. web.page.get[host, 获取网页内容网页源代码 host - 主机名/域名 path - 文件地址，默认/ port - 端口，默认80返回空字符串表示失败. 例如: web.page.get[ web.page.perf[host, 获取完全加载网页消耗的时长秒，返回0表示失败 host - 主机名/域名 path - html地址，默认是/ port - 端口,默认80 [root@BJ-monitor-h-01 bin]# ./zabbix_get -s 192.168.10.100 -k web.page.perf[www.baidu.com] web.page.regexp[host, 在网页中搜索字符串 失败则返回空字符 (不匹配). host - 主机名 path - html文件路径 (默认值 /) port - 端口 (默认80) regexp - GNU正则表达式 length - 返回的最大的字符串数量 output - 输出格式模板可选项. -----------------------------------","categories":[],"tags":[],"author":"张存"},{"title":"Jenkins Publish over SSH Exec command 不打印输出","slug":"Jenkins-Publish-over-SSH-Exec-command-不打印输出","date":"2022-04-25T05:59:55.000Z","updated":"2022-04-25T06:05:38.151Z","comments":true,"path":"2022/04/25/jenkins-publish-over-ssh-exec-command-bu-da-yin-shu-chu/","link":"","permalink":"https://blog.zhangcun.store/2022/04/25/jenkins-publish-over-ssh-exec-command-bu-da-yin-shu-chu/","excerpt":"","text":"勾选：Verbose output in console 根据自身项目情况适当勾选：Exec in pty(模拟一个终端执行脚步)我遇到的问题：勾选Exec in pty ，项目发布结束后，Exec command 中的java -jar进程结束","categories":[],"tags":[],"author":"张存"},{"title":"mysql备份并自动压缩命令","slug":"mysql备份并自动压缩命令","date":"2022-04-25T05:56:10.000Z","updated":"2022-04-25T05:56:17.934Z","comments":true,"path":"2022/04/25/mysql-bei-fen-bing-zi-dong-ya-suo-ming-ling/","link":"","permalink":"https://blog.zhangcun.store/2022/04/25/mysql-bei-fen-bing-zi-dong-ya-suo-ming-ling/","excerpt":"","text":"#! /bin/bash mysqldump -uroot -p&#39;password&#39; databasename | gzip &gt; /home/backup/database_`date +%Y%m%d%H%M`.sql.gz","categories":[],"tags":[],"author":"张存"},{"title":"基于docker-compose的ELK环境搭建","slug":"基于docker-compose的ELK环境搭建","date":"2022-04-25T05:54:17.000Z","updated":"2022-04-25T05:54:27.580Z","comments":true,"path":"2022/04/25/ji-yu-docker-compose-de-elk-huan-jing-da-jian/","link":"","permalink":"https://blog.zhangcun.store/2022/04/25/ji-yu-docker-compose-de-elk-huan-jing-da-jian/","excerpt":"","text":"基于docker-compose的ELK环境搭建因为最近学习到了需要利用到ELK的环境，因为昨天自己不小心踩了坑，在这里跟大家分享一下快速搭建的方法。简单易上手。也是记录自己的学习过程，以后也可以用到。 1、安装Docker具体可参照 https://docs.docker.com/engine/install/centos/ 官方文档，linux下的docker安装我这里做简单介绍 1、安装Docker所需要的包： yum install -y yum-utils \\ device-mapper-persistent-data \\ lvm2 2、设置稳定的仓库: yum-config-manager –add-repo https://download.docker.com/linux/centos/docker-ce.repo 3、安装最新版的Docker引擎： yum install docker-ce docker-ce-cli containerd.io 4、启动Docker： systemctl start docker 5、在控制台上输入 docker -v 查看版本，有输出则成功了 2、 安装Docker-Compose安装好Docker，我们来安装它的一键管理化工具docker-compose1、获取Docker Compose的最新稳定版本： curl -L &quot;https://github.com/docker/compose/releases/download/1.24.1/docker-compose-$(uname -s)-$(uname -m)&quot; -o /usr/local/bin/docker-compose 2、对二进制文件授予可执行权限： chmod +x /usr/local/bin/docker-compose 3、创建Link ln -s /usr/local/bin/docker-compose /usr/bin/docker-compose 4、输入docker-compose -v 查看是否安装成功 3、Docker Compose搭建ELK在安装ELK前，必要的准备工作是不可以缺少的，因为难免会因为没有做好准备工作，而导致后续的错误。所以提前做好，就不会去犯那些错误。官方文档 https://www.elastic.co/guide/en/elasticsearch/reference/current/vm-max-map-count.htmlElasticsearch默认使用mmapfs目录来存储索引。操作系统默认的mmap计数太低可能导致内存不足，我们可以使用下面这条命令来增加内存： sysctl -w vm.max_map_count=262144 创建Elasticsearch数据挂载路径： mkdir -p /home/elasticsearch/data 对该路径授予777权限： chmod 777 /home/elasticsearch/data 创建Elasticsearch插件挂载路径： mkdir -p /home/elasticsearch/plugins 创建Logstash配置文件存储路径： mkdir -p /home/logstash 在该路径下创建logstash-febs.conf配置文件（没有安装vim的话可以使用yum install vim命令安装）： vim /home/logstash/logstash.conf 内容如下所示： input &#123; tcp &#123; mode =&gt; &quot;server&quot; host =&gt; &quot;0.0.0.0&quot; port =&gt; 4560 codec =&gt; json_lines &#125; &#125; output &#123; elasticsearch &#123; hosts =&gt; &quot;es:9200&quot; index =&gt; &quot;logstash-%&#123;+YYYY.MM.dd&#125;&quot; &#125; &#125; 创建ELK Docker Compose文件存储路径： mkdir -p /home/elk 在该目录下创建docker-compose.yml文件： vim /home/elk/docker-compose.yml 内容如下所示： version: &#39;3&#39; services: elasticsearch: image: elasticsearch:6.4.1 container_name: elasticsearch environment: - &quot;cluster.name=elasticsearch&quot; #集群名称为elasticsearch - &quot;discovery.type=single-node&quot; #单节点启动 - &quot;ES_JAVA_OPTS=-Xms512m -Xmx512m&quot; #jvm内存分配为512MB volumes: - /home/elasticsearch/plugins:/usr/share/elasticsearch/plugins - /home/elasticsearch/data:/usr/share/elasticsearch/data ports: - 9200:9200 kibana: image: kibana:6.4.1 container_name: kibana links: - elasticsearch:es #配置elasticsearch域名为es depends_on: - elasticsearch environment: - &quot;elasticsearch.hosts=http://es:9200&quot; #因为上面配置了域名，所以这里可以简写为http://es:9200 ports: - 5601:5601 logstash: image: logstash:6.4.1 container_name: logstash volumes: - /home/logstash/logstash.conf:/usr/share/logstash/pipeline/logstash.conf depends_on: - elasticsearch links: - elasticsearch:es ports: - 4560:4560 切换到/home/elk目录下，使用如下命令启动： docker-compose up -d 接下来就是漫长的下载过程（如果你够快，下面可以略过），假如你的速度因为镜像太慢的话，建议去换一个镜像，可以在阿里云上自己注册然后搜索docker镜像，按照上面的步骤就行如果你懒得注册我这里有一个方法修改该文件 /etc/docker/daemon.json将下面内容全部添加进去 &#123; &quot;registry-mirrors&quot;: [&quot;https://registry.docker-cn.com&quot;] &#125; 国内加速地址有： Docker中国区官方镜像 https://registry.docker-cn.com 网易 http://hub-mirror.c.163.com ustc https://docker.mirrors.ustc.edu.cn 中国科技大学 https://docker.mirrors.ustc.edu.cn 然后重启docker 服务 Systemctl restart docker（假如这里报错，八成是daemon.json的问题）去目录下/etc/docker/输入命令 mv daemon.json daemon.conf即可 这时候，大家都安装完了我们输入 docker ps 查看容器运行状态可以看到三个都在运行了 （错误情况：假如你ps没看到Elaticsearch没在运行，请记得按照上文配置对应内存，如果配置了，请去及时查看docker日志，或者查看elaticsearch日志，八成是因为root权限问题，有时候会遇到，修改权限启动即可。当然具体还是去看日志才会知道。小问题需要查看镜像日志可使用 docker logs xx命令， 如： docker logs -f -t --since=&quot;2019-08-09&quot; --tail=50 gitlab（容器名称，即NAMES） 自己输入对应时间都可以）在Logstash中安装json_lines插件使用如下命令进入到Logstash容器中： docker exec -it logstash /bin/bash 切换到/bin目录，输入 logstash-plugin install logstash-codec-json_lines安装json_lines插件，然后退出exit： 最后使用浏览器访问http://虚拟机IP地址:5601便可以看到Kibana管理界面：","categories":[],"tags":[],"author":"张存"},{"title":"mysql数据库压缩备份_Mysql备份压缩及恢复数据库方法总结","slug":"mysql数据库压缩备份-Mysql备份压缩及恢复数据库方法总结","date":"2022-04-25T05:24:06.000Z","updated":"2022-04-25T05:31:19.614Z","comments":true,"path":"2022/04/25/mysql-shu-ju-ku-ya-suo-bei-fen-mysql-bei-fen-ya-suo-ji-hui-fu-shu-ju-ku-fang-fa-zong-jie/","link":"","permalink":"https://blog.zhangcun.store/2022/04/25/mysql-shu-ju-ku-ya-suo-bei-fen-mysql-bei-fen-ya-suo-ji-hui-fu-shu-ju-ku-fang-fa-zong-jie/","excerpt":"","text":"一般情况我们通过mysqldump来备份MySQL数据库，并上传至其它备份机器。如果数据库比较大，在备份传输的时候可能会慢，所以我们尽量让备份的文件小一些。 在写自动备份脚本时，最好把备份结果直接压缩，恢复时也可以直接由压缩备份恢复。下面介绍如何使用bzip2和gzip进行压缩mysql备份文件。 备份并用bzip压缩： 代码如下 mysqldump | bzip2 &gt; outputfile.sql.bz2 从bzip2备份恢复: 代码如下 bunzip2 &lt; outputfile.sql.bz2 | mysql &lt; mysql options&gt; 备份并用gzip压缩： 代码如下 mysqldump | gzip &gt; outputfile.sql.gz 从gzip备份恢复： gunzip &lt; outputfile.sql.gz | mysql &lt; mysql options&gt; 补充本文章 备份指定数据库 代码如下 mysqldump -h hostname -u username -p databasename &gt; db.sql不明确指定路径的话被分到用户工作目录：C:Documents and SettingsAdministrator 可以明确指定备份目录： 代码如下 mysqldump -u root -p mydb -h 192.168.14.204 &gt; D:mydb.sql 说明： -p之后不用输入密码，点击回车键之后才需要输入密码。 直接将MySQL数据库压缩备份 代码如下 mysqldump -h hostname -u username -p databasename | gzip &gt; db.sql.gz 说明： gzip是linux下的压缩工具，所以在windows环境下无法使用。 备份MySQL数据库某个(些)表 代码如下 mysqldump -h hostname -u username -p databasename table1 table2 &gt; db.sql 同时备份多个MySQL数据库 代码如下 mysqldump -h hostname -u username -p –databases db1 db2 db3 &gt; dbs.sql 备份服务器上所有数据库 代码如下 mysqldump --all-databases &gt; allbackupfile.sql 测试： 代码如下 mysqldump --all-databases -u root -p &gt; allbackupfile.sql Enter password: ******windows下可以使用Mysql Query Browser的File–》Open Script来执行备份的脚本，同时也可以使用一下命令直接进行恢复： 代码如下 mysql -h hostname -u username -p databasename &lt; backupfile.sql","categories":[],"tags":[],"author":"张存"},{"title":"使用docker-compose 安装Redis最新版，并且设置密码","slug":"使用docker-compose-安装Redis最新版，并且设置密码","date":"2022-04-25T05:21:44.000Z","updated":"2022-04-25T05:21:50.345Z","comments":true,"path":"2022/04/25/shi-yong-docker-compose-an-zhuang-redis-zui-xin-ban-bing-qie-she-zhi-mi-ma/","link":"","permalink":"https://blog.zhangcun.store/2022/04/25/shi-yong-docker-compose-an-zhuang-redis-zui-xin-ban-bing-qie-she-zhi-mi-ma/","excerpt":"","text":"直接上docker-compose.yml。 version: &#39;2&#39; networks: app-tier: driver: bridge services: redis: container_name: &#39;redis&#39; image: &#39;redis&#39; restart: always networks: - app-tier ports: - 6999:6379 command: redis-server --port 6379 --requirepass password --appendonly yes","categories":[],"tags":[],"author":"张存"},{"title":"Python快速搭建HTTP服务","slug":"Python快速搭建HTTP服务","date":"2022-04-25T04:46:00.000Z","updated":"2022-04-25T04:50:30.025Z","comments":true,"path":"2022/04/25/python-kuai-su-da-jian-http-fu-wu/","link":"","permalink":"https://blog.zhangcun.store/2022/04/25/python-kuai-su-da-jian-http-fu-wu/","excerpt":"","text":"什么是HTTP服务? 通常是由HTTP客户端发起一个请求，建立一个到服务器指定端口（默认是80或其他端口）的TCP连接，用以为用户提供相应的服务。这里的客户端可以是浏览器，postman插件或是请求的命令（curl，wget等）等。 如何使用Python快速搭建HTTP服务？ 本文以SimpleHTTPServer为示例来讲解，使用Python可以完成一个简单的内建 HTTP 服务器。你可以把你的目录和文件都以HTTP的方式展示出来。你只需要干一件事情，那就是安装一个Python，此演示以Python3版本为标准进行展开。 构建步骤：1.检查本地是否安装Python，在cmd 里面输入命令：python 即可，返回如下提示表示安装正常 tips：不知道如何安装的可以看看青少年编辑专栏里面有详细的描述。 2.用cd 命令切换到你准备分享的目录下，如下我要分享的目录 wechat 3.执行命令python -m http.server 端口号，我这里演示指定端口号为：6789， 这个时候服务已经启动了。 4.在浏览器访问该主机的地址 http://IP:端口号/ 如果是本机的话就直接输入http://localhost:6789, 如果是内网其他用户需要访问就直接将localhost 修改为真实的ip 即可。 5.查看一下服务端的请求情况，有一个127.0.0.1的ip 发起了一个GET 请求（其实就是上一张截图发出来的请求），响应状态为200，如下图所示","categories":[],"tags":[],"author":"张存"},{"title":"show table status like 'table'\\G 详细信息介绍","slug":"show-table-status-like-table-G-详细信息介绍","date":"2022-04-24T12:44:34.000Z","updated":"2022-04-24T12:44:38.098Z","comments":true,"path":"2022/04/24/show-table-status-like-table-g-xiang-xi-xin-xi-jie-shao/","link":"","permalink":"https://blog.zhangcun.store/2022/04/24/show-table-status-like-table-g-xiang-xi-xin-xi-jie-shao/","excerpt":"","text":"mysql&gt; show table status like&#39;leyangjun&#39;\\G *************************** 1. row *************************** Name: leyangjun 表名字 Engine: MyISAM 表存储引擎 Version: 10 版本 Row_format: Dynamic 行格式 Rows: 3999999 表中的行数（对于非事物表是精确的） Avg_row_length: 31 平均每行包含的字节数 Data_length: 127995956 整个表的数据量（以字节进行计算） Max_data_length: 281474976710655 表最大的容纳量 Index_length: 41114624 索引数据占用磁盘空间的大小 Data_free: 0 对于myisam表，表示已分配，但未使用的空间 Auto_increment: 4000001 下一个Auto_increment值 Create_time: 2015-05-30 14:17:37 表最初创建的时间 Update_time: 2015-05-30 14:25:07 表数据最近被更新的时间 Check_time: NULL 使用check table命令或myisamchk工具检查时的最近检查时间 Collation: utf8_general_ci 表中默认的字符集和字符列排序规则 Checksum: NULL 如启用，则对整个表的内容计算实时的校验和checksum Create_options: 表创建时的其他所有选项 Comment: 本字段包含了其他额外的信息， 1 row in set (0.00 sec)","categories":[],"tags":[],"author":"张存"},{"title":"docker 删除_docker 批量删除镜像","slug":"docker-删除-docker-批量删除镜像","date":"2022-04-24T11:55:50.000Z","updated":"2022-04-24T12:02:07.090Z","comments":true,"path":"2022/04/24/docker-shan-chu-docker-pi-liang-shan-chu-jing-xiang/","link":"","permalink":"https://blog.zhangcun.store/2022/04/24/docker-shan-chu-docker-pi-liang-shan-chu-jing-xiang/","excerpt":"","text":"准备工作：查看运行中的容器 sudo docker container ls -a sudo docker container ls -a -q sudo docker container ls 准备工作：单独删除命令 docker container rm 容器id #删除容器 可简写： docker rm 容器id docker image rm 镜像ID #删除镜像 可简写： docker rmi 镜像ID 0、批量删除运行中的容器 在执行第1步前停掉所有的容器 docker container stop $(docker container ls -a -q) 1、批量删除容器 docker rm $(docker container ls -a -q) 2、批量删除镜像 docker rmi $(docker image ls -a -q)","categories":[],"tags":[],"author":"张存"},{"title":"制作一个pyhton2.7 ubuntu 镜像，书写Dockerfile运行一个web程序","slug":"制作一个pyhton2-7-ubuntu-镜像，书写Dockerfile运行一个web程序","date":"2022-04-24T11:45:56.000Z","updated":"2022-04-24T11:45:58.406Z","comments":true,"path":"2022/04/24/zhi-zuo-yi-ge-pyhton2-7-ubuntu-jing-xiang-shu-xie-dockerfile-yun-xing-yi-ge-web-cheng-xu/","link":"","permalink":"https://blog.zhangcun.store/2022/04/24/zhi-zuo-yi-ge-pyhton2-7-ubuntu-jing-xiang-shu-xie-dockerfile-yun-xing-yi-ge-web-cheng-xu/","excerpt":"","text":"运用ubuntu镜像运行一个容器 docker run -it -d --name=python3.6demo ubuntu 返回一个id 65a616b14344fe6691f5198a68c35899fca02761e554787d6014e022349e9c2e 进入docker终端 docker exec -it 65a bash 更新源 apt-get update 安装 python2.7 apt-get install python2.7 建立软连接 which python2.7 --查看python2.7位置 &gt; /usr/bin/python2.7 ln -s /usr/bin/python2.7 /usr/bin/python 提交新的镜像 docker commit -m=&quot;new python2.7 images&quot; -a=&quot;simayi&quot; 65a616b14344 simayi/python2.7:new 建立 Dockerfile,使用自定义的镜像运行 python 程序 创建一个目录和文件 mkdir ~/docker-demo cd ~/docker-demo touch Dockerfile &lt;注意: 此文件名必须为 Dockerfile&gt; touch requirements.txt touch app.py 编写 Dockerfile 和 Python 程序 vim app.py from flask import Flask from redis import Redis, RedisError import os import socket # Connect to Redis redis = Redis(host=&quot;redis&quot;, db=0, socket_connect_timeout=2, socket_timeout=2) app = Flask(__name__) @app.route(&quot;/&quot;) def hello(): try: visits = redis.incr(&quot;counter&quot;) except RedisError: visits = &quot;&lt;i&gt;cannot connect to Redis, counter disabled&lt;/i&gt;&quot; html = &quot;&lt;h3&gt;Hello &#123;name&#125;!&lt;/h3&gt;&quot; \\ &quot;&lt;b&gt;Hostname:&lt;/b&gt; &#123;hostname&#125;&lt;br/&gt;&quot; \\ &quot;&lt;b&gt;Visits:&lt;/b&gt; &#123;visits&#125;&quot; return html.format(name=os.getenv(&quot;NAME&quot;, &quot;world&quot;), hostname=socket.gethostname(), visits=visits) if __name__ == &quot;__main__&quot;: app.run(host=&#39;0.0.0.0&#39;, port=80) vim requirements.txt Flask Redis vim Dockerfile # 使用一个原始的镜像 FROM python:2.7-slim # 建立工作目录 /app WORKDIR /app # 将当前文件所在的目录下的所有文件 copy 到工作目录 COPY . /app # 运行命令安装 requirement.txt 依赖环境 RUN pip install --trusted-host pypi.python.org -r requirements.txt # docker 暴露80端口 EXPOSE 80 # 设置环境变脸 ENV NAME World # 运行命令, 启动 web 程序 CMD [&quot;python&quot;, &quot;app.py&quot;, &quot;runserver&quot;] 运行 docker 镜像命令 docker build -t friendlyhello . -t: 指定镜像的名称 运行应用 docker run -p 4000:80 friendlyhello 浏览器输入localhost:4000即可以看到输出","categories":[],"tags":[],"author":"张存"},{"title":"ubuntu ssh登入速度太慢的解决办法","slug":"ubuntu-ssh登入速度太慢的解决办法","date":"2022-04-24T11:42:07.000Z","updated":"2022-04-24T11:42:08.504Z","comments":true,"path":"2022/04/24/ubuntu-ssh-deng-ru-su-du-tai-man-de-jie-jue-ban-fa/","link":"","permalink":"https://blog.zhangcun.store/2022/04/24/ubuntu-ssh-deng-ru-su-du-tai-man-de-jie-jue-ban-fa/","excerpt":"","text":"打开/etc/ssh/sshd_config文件 sudo gedit /etc/ssh/sshd_config 将GSSAPIAuthentication 设置未no，同时添加UsePAM no 、UseDNS no这两项 # GSSAPI options GSSAPIAuthentication no UsePAM no UseDNS no 保存后重启ssh服务 sudo service ssh restart","categories":[],"tags":[],"author":"张存"},{"title":"docker安装-以及镜像源设置","slug":"docker安装-以及镜像源设置","date":"2022-04-24T11:32:47.000Z","updated":"2022-04-24T11:32:49.222Z","comments":true,"path":"2022/04/24/docker-an-zhuang-yi-ji-jing-xiang-yuan-she-zhi/","link":"","permalink":"https://blog.zhangcun.store/2022/04/24/docker-an-zhuang-yi-ji-jing-xiang-yuan-she-zhi/","excerpt":"","text":"首先至少要是centOS7的版本，这是要求 可以用官方给的命令行全自动安装，如下： curl -fsSL https://get.docker.com | bash -s docker --mirror Aliyun 这个唯一也是最大的缺陷就是外网太慢，基本上不具备使用功能，所以切换一下国内，改为： curl -sSL https://get.daocloud.io/docker | sh 但是，今天想要讲的是我们自己手动安装，这样也便于理解docker，当然也不难。 设置仓库 安装所需的软件包。yum-utils 提供了 yum-config-manager ，并且 device mapper 存储驱动程序需要 device-mapper-persistent-data 和 lvm2。 $ sudo yum install -y yum-utils \\ device-mapper-persistent-data \\ lvm2 然后选择yum国内源下载，这里我选择aliyun,命令行如下， $ sudo yum-config-manager \\ --add-repo \\ http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo 实际上它就是在/etc/yum.repo.d/下面，进入后就可以看到许多.repo文件，这些都是这些软件的下载源。 然后使用一个命令行就吧docker及其所需组件安装好啦 $ sudo yum install docker-ce docker-ce-cli containerd.io 这里最主要的实际上是docker-ce 启动 Docker。 $ sudo systemctl start docker 通过运行 hello-world 映像来验证是否正确安装了 Docker Engine-Community 。 $ sudo docker run hello-world 然后就可以去获取镜像，创建容器，使用docker了。 ** 这里又有一点需要讲一下：那就是镜像源的设置 创建或修改 /etc/docker/daemon.json 文件，修改为如下形式 $ vi /etc/docker/daemon.json &#123; &quot;registry-mirrors&quot;: [&quot;http://hub-mirror.c.63.com&quot;] &#125; 或者用阿里云的镜像源也行：https://fy9iz0e2.mirror.aliyuncs.com，多配置几个镜像源的方式如下 &#123;undefined “registry-mirrors”: [ “https://fy9iz0e2.mirror.aliyuncs.com”, “https://registry.docker-cn.com”, “http://hub-mirror.c.63.com”, “https://docker.mirrors.ustc.edu.cn” ] &#125; systemctl daemon-reload [root@master ~]# systemctl start docker Job for docker.service failed because the control process exited with error code. See “systemctl status docker.service” and “journalctl -xe” for details. 若重启出现上面的错误，则用另一种方式替换镜像源 vim /usr/lib/systemd/system/docker.service 替换 ExecStart=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock 为 ExecStart=/usr/bin/dockerd -H fd:// -H tcp://27.0.0.1:2376 --registry mirror=https://fy9iz0e2.mirror.aliyuncs.com","categories":[],"tags":[],"author":"张存"},{"title":"查看Linux系统内存、CPU、磁盘使用率和详细信息","slug":"查看Linux系统内存、CPU、磁盘使用率和详细信息","date":"2022-04-24T10:48:08.000Z","updated":"2022-04-24T10:48:21.071Z","comments":true,"path":"2022/04/24/cha-kan-linux-xi-tong-nei-cun-cpu-ci-pan-shi-yong-lu-he-xiang-xi-xin-xi/","link":"","permalink":"https://blog.zhangcun.store/2022/04/24/cha-kan-linux-xi-tong-nei-cun-cpu-ci-pan-shi-yong-lu-he-xiang-xi-xin-xi/","excerpt":"","text":"一、查看内存占用 1、free # free -m 以MB为单位显示内存使用情况 [root@localhost ~]# free -m total used free shared buff/cache available Mem: 11852 1250 8668 410 1934 9873 Swap: 6015 0 6015 # free -h 以GB为单位显示内存使用情况 [root@localhost ~]# free -h total used free shared buff/cache available Mem: 11G 1.2G 8.5G 410M 1.9G 9.6G Swap: 5.9G 0B 5.9G # free -t 以总和的形式查询内存的使用信息 [root@localhost ~]# free -t total used free shared buff/cache available Mem: 12137332 1285344 8870628 420268 1981360 10105740 Swap: 6160380 0 6160380 Total: 18297712 1285344 15031008 # free -s 5 周期性的查询内存使用信息 每5秒执行一次命令 [root@localhost ~]# free -s 5 total used free shared buff/cache available Mem: 12137332 1280796 8875008 420268 1981528 10110136 Swap: 6160380 0 6160380 解释： Mem：内存的使用情况总览表（物理内存） Swap：虚拟内存。即可以把数据存放在硬盘上的数据 shared：共享内存，即和普通用户共享的物理内存值 buffers：用于存放要输出到disk（块设备）的数据的 cached：存放从disk上读出的数据 total：机器总的物理内存 used：用掉的内存 free：空闲的物理内存 注：物理内存（total）=系统看到的用掉的内存（used）+系统看到空闲的内存（free） 2、查看某个pid的物理内存使用情况 # cat /proc/PID/status | grep VmRSS [root@localhost ~]# pidof nginx 27327 27326 [root@localhost ~]# [root@localhost ~]# cat /proc/27327/status | grep VmRSS VmRSS: 2652 kB [root@localhost ~]# [root@localhost ~]# cat /proc/27326/status | grep VmRSS VmRSS: 1264 kB [root@localhost ~]# [root@localhost ~]# pidof java 1973 [root@localhost ~]# cat /proc/1973/status | grep VmRSS VmRSS: 1166852 kB 由上面可知，nginx服务进程的两个pid所占物理内存为&quot;2652+1264=3916k&quot; 3、查看本机所有进程的内存占比之和 # cat mem_per.sh [root@localhost ~]# cat mem_per.sh #!/bin/bash ps auxw|awk &#39;&#123;if (NR&gt;1)&#123;print $4&#125;&#125;&#39; &gt; /opt/mem_list awk &#39;&#123;MEM_PER+=$1&#125;END&#123;print MEM_PER&#125;&#39; /opt/mem_list [root@localhost ~]# [root@localhost ~]# chmod 755 mem_per.sh [root@localhost ~]# [root@localhost ~]# sh mem_per.sh 64.4 [root@localhost ~]# 脚本配置解释： ps -auxw|awk &#39;&#123;print $3&#125;&#39; 表示列出本机所有进程的cpu利用率情况，结果中第一行带&quot;%CPU&quot;字符 ps -auxw|awk &#39;&#123;print $4&#125;&#39; 表示列出本机所有进程的内存利用率情况，结果中第一行带&quot;%MEM&quot;字符 ps auxw|awk &#39;&#123;if (NR&gt;1)&#123;print $4&#125;&#125; 表示将&quot;ps auxw&quot;结果中的第一行过滤(NR&gt;1)掉，然后打印第4行 二、查看CPU使用情况 1、top top后键入P看一下谁占用最大 # top -d 5 周期性的查询CPU使用信息 每5秒刷新一次 top - 02:37:55 up 4 min, 1 user, load average: 0.02, 0.10, 0.05 Tasks: 355 total, 1 running, 354 sleeping, 0 stopped, 0 zombie %Cpu(s): 3.0 us, 2.8 sy, 0.0 ni, 94.2 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st # us：表示用户空间程序的cpu使用率（没有通过nice调度） # sy：表示系统空间的cpu使用率，主要是内核程序。 # id：空闲cpu KiB Mem : 1868660 total, 1081340 free, 578388 used, 208932 buff/cache KiB Swap: 4194300 total, 4194300 free, 0 used. 1123992 avail Mem PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 2220 mysql 20 0 1307796 471172 7608 S 0.6 25.2 0:02.31 mysqld 349 root 20 0 0 0 0 S 0.4 0.0 0:01.14 kworker/0:3 644 root 20 0 0 0 0 S 0.4 0.0 0:00.17 xfsaild/dm-0 3489 root 20 0 146432 2268 1440 R 0.4 0.1 0:00.11 top 1 root 20 0 44500 7120 2596 S 0.2 0.4 0:01.69 systemd 283 root 39 19 0 0 0 S 0.2 0.0 0:00.18 khugepaged 2621 root 20 0 141264 5140 3896 S 0.2 0.3 0:00.18 sshd 2 root 20 0 0 0 0 S 0.0 0.0 0:00.01 kthreadd 3 root 20 0 0 0 0 S 0.0 0.0 0:00.01 ksoftirqd/0 4 root 20 0 0 0 0 S 0.0 0.0 0:00.00 kworker/0:0 5 root 0 -20 0 0 0 S 0.0 0.0 0:00.00 kworker/0:0H 6 root 20 0 0 0 0 S 0.0 0.0 0:00.02 kworker/u256:0 7 root rt 0 0 0 0 S 0.0 0.0 0:00.00 migration/0 8 root 20 0 0 0 0 S 0.0 0.0 0:00.00 rcu_bh 9 root 20 0 0 0 0 S 0.0 0.0 0:00.00 rcuob/0 10 root 20 0 0 0 0 S 0.0 0.0 0:00.00 rcuob/1 11 root 20 0 0 0 0 S 0.0 0.0 0:00.00 rcuob/2 2、ps auxw（查看本机的进程所占cpu和mem的百分比情况） 使用&quot;ps auxw&quot; 可以查看到本机的进程所占cpu和mem的百分比情况 # ps auxw | head -1 %CPU 进程的cpu占用率 %MEM 进程的内存占用率 [root@localhost ~]# ps auxw | head -1 USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND [root@localhost ~]# 查看java进程所占本机的cpu百分比， 如下为0.2% # ps auxw |grep -v grep|grep -w java|awk &#39;&#123;print $3&#125;&#39; [root@localhost ~]# ps auxw |grep -v grep|grep -w java|awk &#39;&#123;print $3&#125;&#39; 0.2 查看java进程所占本机的内存百分比， 如下为30.0% # ps auxw |grep -v grep|grep -w java|awk &#39;&#123;print $4&#125;&#39; [root@localhost ~]# ps auxw |grep -v grep|grep -w java|awk &#39;&#123;print $4&#125;&#39; 30.0 3、查看本机所有进程的CPU占比之和 # cat cpu_per.sh [root@localhost ~]# cat cpu_per.sh #!/bin/bash ps auxw|awk &#39;&#123;if (NR&gt;1)&#123;print $3&#125;&#125;&#39; &gt; /opt/cpu_list awk &#39;&#123;CPU_PER+=$1&#125;END&#123;print CPU_PER&#125;&#39; /opt/cpu_list [root@localhost ~]# [root@localhost ~]# chmod 755 cpu_per.sh [root@localhost ~]# [root@localhost ~]# sh cpu_per.sh 44.5 [root@localhost ~]# 三、查看cpu信息（信息记录在/proc/cpuinfo中） # 总核数 = 物理CPU个数 X 每颗物理CPU的核数 # 总逻辑CPU数 = 物理CPU个数 X 每颗物理CPU的核数 X 超线程数 1、查看虚拟机逻辑CPU的个数 # cat /proc/cpuinfo| grep &quot;processor&quot;| wc -l [root@localhost ~]# cat /proc/cpuinfo| grep &quot;processor&quot;| wc -l 6 2、查看物理CPU个数 # cat /proc/cpuinfo| grep &quot;physical id&quot;| sort| uniq| wc -l [root@localhost ~]# cat /proc/cpuinfo| grep &quot;physical id&quot;| sort| uniq| wc -l 1 3、列出CPU详细信息 # lscpu 服务器1： [root@localhost ~]# lscpu Architecture: x86_64 CPU op-mode(s): 32-bit, 64-bit Byte Order: Little Endian CPU(s): 6 On-line CPU(s) list: 0-5 Thread(s) per core: 1 Core(s) per socket: 6 座： 1 NUMA 节点： 1 厂商 ID： GenuineIntel CPU 系列： 6 型号： 15 型号名称： Intel(R) Core(TM)2 Duo CPU T7700 @ 2.40GHz 步进： 11 CPU MHz： 2194.916 BogoMIPS： 4389.83 超管理器厂商： KVM 虚拟化类型： 完全 L1d 缓存： 32K L1i 缓存： 32K L2 缓存： 4096K NUMA 节点0 CPU： 0-5 Flags: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx lm constant_tsc rep_good nopl eagerfpu pni ssse3 cx16 pcid sse4_2 x2apic hypervisor lahf_lm 服务器2： [root@bogon ~]# lscpu Architecture: x86_64 CPU op-mode(s): 32-bit, 64-bit Byte Order: Little Endian CPU(s): 8 On-line CPU(s) list: 0-7 Thread(s) per core: 1 Core(s) per socket: 8 Socket(s): 1 NUMA node(s): 1 Vendor ID: GenuineIntel CPU family: 6 Model: 79 Model name: Intel(R) Xeon(R) CPU E7-4830 v4 @ 2.00GHz Stepping: 1 CPU MHz: 1995.192 BogoMIPS: 3990.38 Hypervisor vendor: VMware Virtualization type: full L1d cache: 32K L1i cache: 32K L2 cache: 256K L3 cache: 35840K NUMA node0 CPU(s): 0-7 Flags: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts mmx fxsr sse sse2 ss ht syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts nopl xtopology tsc_reliable nonstop_tsc aperfmperf eagerfpu pni pclmulqdq ssse3 fma cx16 sse4_1 sse4_2 movbe popcnt aes xsave avx hypervisor lahf_lm 3dnowprefetch epb dtherm arat pln pts 4、查看每个物理CPU中core的个数(即核数) # cat /proc/cpuinfo| grep &quot;cpu cores&quot;| uniq [root@localhost ~]# cat /proc/cpuinfo| grep &quot;cpu cores&quot;| uniq cpu cores : 6 三、Linux下查看哪些进程占用的CPU和内存资源最多的方法 1、获取占用CPU资源最多的10个进程 # ps aux | head -1; ps aux | grep -v PID | sort -rn -k +3 | head -10 [root@localhost ~]# ps aux | head -1; ps aux | grep -v PID | sort -rn -k +3 | head -10 USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND root 9416 0.8 0.0 163544 6284 ? Ss 08:38 0:00 sshd: root@pts/0 root 3783 0.7 0.0 12072 2032 ? S May26 357:27 /bin/bash /usr/local/VMOptimizationTools/sangfor_guest_datareport root 9545 0.6 0.0 163224 5904 ? Ss 08:38 0:00 sshd: root@notty root 3966 0.3 0.0 12704 2676 ? S May26 183:12 /bin/bash /usr/local/VMOptimizationTools/sangfor_update_ipc_callback root 3784 0.3 0.0 12560 2552 ? S May26 182:42 /bin/bash /usr/local/VMOptimizationTools/sangfor_sfping 33 10431 0.3 0.1 409704 17832 ? S 08:38 0:00 /usr/sbin/apache2 -k start root 3986 0.2 0.0 12452 2280 ? S May26 122:23 /bin/bash /usr/local/VMOptimizationTools/sangfor_vm_proxyd_w root 3781 0.2 0.0 12740 2672 ? S May26 115:59 /bin/bash /usr/local/VMOptimizationTools/sangfor_vm_proxyd 500 23785 0.2 2.0 1790172 249528 ? Ss Jun25 11:30 oraclehelowin (LOCAL=NO) root 4053 0.1 0.0 12508 2520 ? S May26 75:16 /bin/bash /usr/local/VMOptimizationTools/sangfor_watchdog 2、获取占用内存资源最多的10个进程 # ps aux | head -1; ps aux | grep -v PID | sort -rn -k +4 | head -10 [root@localhost ~]# ps aux | head -1; ps aux | grep -v PID | sort -rn -k +4 | head -10 USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND 500 32304 0.0 5.7 1794892 700976 ? Ss May31 2:53 ora_dbw0_helowin 500 4785 0.0 4.5 1797912 550132 ? Ss May29 4:03 ora_dbw0_helowin 500 4796 0.0 3.5 1798308 426468 ? Ss May29 2:11 ora_smon_helowin 500 25850 0.0 2.5 1810144 307340 ? Ss Jun17 0:10 oraclehelowin (LOCAL=NO) 500 32471 0.0 2.4 1810184 299704 ? Ss Jun14 0:30 oraclehelowin (LOCAL=NO) 500 3927 0.0 2.3 1791308 283440 ? Ss Jun26 0:13 oraclehelowin (LOCAL=NO) 500 5432 0.0 2.1 1794272 261692 ? Ss May29 7:16 ora_cjq0_helowin 500 23785 0.2 2.0 1790172 249528 ? Ss Jun25 11:30 oraclehelowin (LOCAL=NO) 500 19092 0.0 2.0 1793248 253080 ? Ss Jun21 0:28 oraclehelowin (LOCAL=NO) 500 32310 0.0 1.8 1794224 229200 ? Ss May31 1:25 ora_smon_helowin 3、查看占用cpu最高的进程 # ps aux | head -1; ps aux | grep -v PID | sort -rn -k +3 | head -1 [root@localhost ~]# ps aux | head -1; ps aux | grep -v PID | sort -rn -k +3 | head -1 USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND root 3783 0.7 0.0 12072 2032 ? S May26 357:32 /bin/bash /usr/local/VMOptimizationTools/sangfor_guest_datareport 4、获取占用内存资源最高的进程 # ps aux | head -1; ps aux | grep -v PID | sort -rn -k +4 | head -1 [root@localhost ~]# ps aux | head -1; ps aux | grep -v PID | sort -rn -k +4 | head -1 USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND 500 32304 0.0 5.7 1794892 700976 ? Ss May31 2:53 ora_dbw0_helowin 四、Linux下查看某些进程的启动时间和运行时长 比如查看java进程的启动时间和运行时长 # ps -ef|grep -v grep|grep -w java|awk &#39;&#123;print $2&#125;&#39; # ps -eo pid,lstart,etime | grep 1973 其中： Mon Jun 24 09:25:41 2019 为java进程的启动时间 4-00:16:55 为java进程的运行时长，天-小时-分钟-秒 [root@localhost ~]# ps -ef|grep -v grep|grep -w java|awk &#39;&#123;print $2&#125;&#39; 1973 [root@localhost ~]# [root@localhost ~]# ps -eo pid,lstart,etime | grep 1973 1973 Mon Jun 24 09:25:41 2019 4-00:16:55 [root@localhost ~]# [root@localhost ~]# date Fri Jun 28 09:42:48 CST 2019 查看所有进程的启动事件、运行时长 # ps -eo user,pid,lstart,etime,cmd 查看nginx进程启动的精确时间和启动后运行的时长 # ps -eo pid,lstart,etime,cmd|grep nginx [root@nginx-proxy-client ~]# ps -eo pid,lstart,etime,cmd|grep nginx 1418 Mon Jun 24 13:38:18 2019 3-20:21:05 nginx: master process /usr/local/nginx/sbin/nginx 1419 Mon Jun 24 13:38:18 2019 3-20:21:05 nginx: worker process 5543 Fri Jun 28 09:59:23 2019 00:00 grep --color=auto nginx [root@nginx-proxy-client ~]# [root@nginx-proxy-client ~]# date 2019年 06月 28日 星期五 09:59:45 CST [root@nginx-proxy-client ~]# 五、查看网络情况 # ifconfig [root@localhost ~]# ifconfig eno16777736: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 inet 192.168.2.80 netmask 255.255.255.0 broadcast 192.168.2.255 inet6 fe80::20c:29ff:fe4c:ff47 prefixlen 64 scopeid 0x20&lt;link&gt; ether 00:0c:29:4c:ff:47 txqueuelen 1000 (Ethernet) RX packets 7866 bytes 632606 (617.7 KiB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 215 bytes 31932 (31.1 KiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 lo: flags=73&lt;UP,LOOPBACK,RUNNING&gt; mtu 65536 inet 127.0.0.1 netmask 255.0.0.0 inet6 ::1 prefixlen 128 scopeid 0x10&lt;host&gt; loop txqueuelen 0 (Local Loopback) RX packets 8 bytes 400 (400.0 B) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 8 bytes 400 (400.0 B) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 # ip a [root@localhost ~]# ip a 1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever 2: eno16777736: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP qlen 1000 link/ether 00:0c:29:4c:ff:47 brd ff:ff:ff:ff:ff:ff inet 192.168.2.80/24 brd 192.168.2.255 scope global eno16777736 valid_lft forever preferred_lft forever inet6 fe80::20c:29ff:fe4c:ff47/64 scope link valid_lft forever preferred_lft forever 四、查看磁盘以及分区情况 # df -Th 查看分区、挂载情况 [root@localhost ~]# df -Th Filesystem Type Size Used Avail Use% Mounted on /dev/mapper/centos-root xfs 15G 2.8G 13G 19% / devtmpfs devtmpfs 903M 0 903M 0% /dev tmpfs tmpfs 913M 0 913M 0% /dev/shm tmpfs tmpfs 913M 8.6M 904M 1% /run tmpfs tmpfs 913M 0 913M 0% /sys/fs/cgroup /dev/sda1 xfs 297M 115M 183M 39% /boot tmpfs tmpfs 183M 0 183M 0% /run/user/0 # lsblk 查看磁盘情况 [root@localhost ~]# lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sda 8:0 0 20G 0 disk ├─sda1 8:1 0 300M 0 part /boot └─sda2 8:2 0 19G 0 part ├─centos-root 253:0 0 15G 0 lvm / └─centos-swap 253:1 0 4G 0 lvm [SWAP] sr0 11:0 1 4G 0 rom # fdisk -l 查看详细的硬盘分区情况 [root@localhost ~]# fdisk -l Disk /dev/sda: 21.5 GB, 21474836480 bytes, 41943040 sectors Units = sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disk label type: dos Disk identifier: 0x0004a0a8 Device Boot Start End Blocks Id System /dev/sda1 * 2048 616447 307200 83 Linux /dev/sda2 616448 40478719 19931136 8e Linux LVM Disk /dev/mapper/centos-root: 16.1 GB, 16106127360 bytes, 31457280 sectors Units = sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disk /dev/mapper/centos-swap: 4294 MB, 4294967296 bytes, 8388608 sectors Units = sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes","categories":[],"tags":[],"author":"张存"},{"title":"MySQL max_allowed_packet设置及问题","slug":"MySQL-max-allowed-packet设置及问题","date":"2022-04-24T10:42:13.000Z","updated":"2022-04-24T10:42:15.415Z","comments":true,"path":"2022/04/24/mysql-max-allowed-packet-she-zhi-ji-wen-ti/","link":"","permalink":"https://blog.zhangcun.store/2022/04/24/mysql-max-allowed-packet-she-zhi-ji-wen-ti/","excerpt":"","text":"mysql根据配置文件会限制server接受的数据包大小。 有时候大的插入和更新会受max_allowed_packet 参数限制，导致写入或者更新失败。 查看目前配置 show VARIABLES like &#39;%max_allowed_packet%&#39;; 显示的结果为： +--------------------+---------+ | Variable_name | Value | +--------------------+---------+ | max_allowed_packet | 1048576 | +--------------------+---------+ 以上说明目前的配置是：1M 修改方法 1、修改配置文件 可以编辑my.cnf来修改（windows下my.ini）,在[mysqld]段或者mysql的server配置段进行修改。 max_allowed_packet = 20M 如果找不到my.cnf可以通过 mysql --help | grep my.cnf 去寻找my.cnf文件。 linux下该文件在/etc/下。 2、在mysql命令行中修改 在mysql 命令行中运行 set global max_allowed_packet = 2*1024*1024*10 然后退出命令行，重启mysql服务，再进入。 show VARIABLES like &#39;%max_allowed_packet%&#39;; 查看下max_allowed_packet是否编辑成功","categories":[],"tags":[],"author":"张存"},{"title":"解决SSH设置免密登录，却总是要求Enter passphrase for key ‘/root/.ssh/id_rsa‘:","slug":"解决SSH设置免密登录，却总是要求Enter-passphrase-for-key-‘-root-ssh-id-rsa‘","date":"2022-04-24T10:39:17.000Z","updated":"2022-04-24T10:39:23.656Z","comments":true,"path":"2022/04/24/jie-jue-ssh-she-zhi-mian-mi-deng-lu-que-zong-shi-yao-qiu-enter-passphrase-for-key-root-ssh-id-rsa/","link":"","permalink":"https://blog.zhangcun.store/2022/04/24/jie-jue-ssh-she-zhi-mian-mi-deng-lu-que-zong-shi-yao-qiu-enter-passphrase-for-key-root-ssh-id-rsa/","excerpt":"","text":"执行如下命令试试： ssh-add -K ~/.ssh/id_rsa （参数K也可能是小写k，根据系统不同）","categories":[],"tags":[],"author":"张存"},{"title":"备份某个mysql库","slug":"备份某个mysql库","date":"2022-04-24T10:38:09.000Z","updated":"2022-04-24T10:38:09.577Z","comments":true,"path":"2022/04/24/bei-fen-mou-ge-mysql-ku/","link":"","permalink":"https://blog.zhangcun.store/2022/04/24/bei-fen-mou-ge-mysql-ku/","excerpt":"","text":"mysqldump -uroot -p -h127.0.0.1 数据库名称 &gt; 路径.sql","categories":[],"tags":[],"author":"张存"},{"title":"Centos使用chrony做时间同步","slug":"Centos使用chrony做时间同步","date":"2022-04-24T10:30:23.000Z","updated":"2022-04-24T10:30:28.664Z","comments":true,"path":"2022/04/24/centos-shi-yong-chrony-zuo-shi-jian-tong-bu/","link":"","permalink":"https://blog.zhangcun.store/2022/04/24/centos-shi-yong-chrony-zuo-shi-jian-tong-bu/","excerpt":"","text":"Chrony是一个开源的自由软件，在RHEL 7操作系统，已经是默认服务，默认配置文件在 /etc/chrony.conf 它能保持系统时间与时间服务器（NTP）同步，让时间始终保持同步。相对NTP时间同步软件，速度更快、配置和依赖都更简单 Chrony有两个核心组件，分别是：chronyd：是守护进程，主要用于调整内核中运行的系统时间和时间服务器同步。它确定计算机增减时间的比率，并对此进行调整补偿。chronyc：提供一个用户界面，用于监控性能并进行多样化的配置。它可以在chronyd实例控制的计算机上工作，也可以在一台不同的远程计算机上工作。 配置的时候，需要首先配置chrony的服务器端，然后配置客户端与服务器端进行同步。如果基于外网的时钟服务器，那可以不用配置服务器器端 1、chrony工具安装 1、系统版本检查，使用cat /etc/system-release 2、使用rpm -qa |grep chrony查看系统是否已安装chrony，可看到默认已安装chrony的包。 3、如果没有安装环境可使用yum install chrony命令安装或者离线下载rpm包安装，下载地址：http://rpm.pbone.net/index.php3?stat=3&amp;limit=2&amp;srodzaj=3&amp;dl=40&amp;search=chrony，找到对应版本下载即可。 4、下载完后使用rpm -ivh chrony-2.1.1-4.el7.centos.x86_64.rpm安装即可 2、设置chrony的服务状态，并关闭防火墙 1、服务状态： 使用systemctl start chronyd.service 启动chrony服务 使用systemctl enable chronyd.service 设置开机同步时间 使用systemctl status chronyd.service 查看服务状态 2、直接关闭防火墙 systemctl stop firewalld.service #停止firewall systemctl disable firewalld.service #禁止firewall开机启动 2、或者不关闭防火墙、但允许NTP服务 firewall-cmd --add-service=ntp --permanent firewall-cmd --reload 因NTP使用123/UDP端口协议，所以允许NTP服务即可 3、服务端和客户端chrony配置 1、服务端配置 1）、配置文件修改 vi /etc/chrony.conf a、修改第22行，Allow NTP client access from local network，配置允许访问的客户端列表，支持CIDR，例如： allow 192.168/16 b、修改第29行设置同步，Serve time even if not synchronized to any NTP server.，打开注释即可，即： local stratum 10 2）、重启下服务端chrony服务，使用systemctl restart chronyd.service重启即可。 2、客户端配置 1）、配置文件修改 vim /etc/chrony.conf a、修改server即可，删掉其他的，添加要同步时间的源服务器ip，格式如下： server x.x.x.x iburst 2）、重启下客户端chrony服务，使用systemctl restart chronyd.service重启即可。 客户端使用chronyc sources -v命令完成同步即可 3）、查看同步状态 复制代码 [root@k8s-master tuned]# systemctl status chronyd -l ● chronyd.service - NTP client/server Loaded: loaded (/usr/lib/systemd/system/chronyd.service; enabled; vendor preset: enabled) Active: active (running) since Wed 2019-09-18 17:55:58 CST; 36s ago Docs: man:chronyd(8) man:chrony.conf(5) Process: 16160 ExecStartPost=/usr/libexec/chrony-helper update-daemon (code=exited, status=0/SUCCESS) Process: 16156 ExecStart=/usr/sbin/chronyd $OPTIONS (code=exited, status=0/SUCCESS) Main PID: 16158 (chronyd) Memory: 372.0K CGroup: /system.slice/chronyd.service └─16158 /usr/sbin/chronyd Sep 18 17:55:58 k8s-master systemd[1]: Starting NTP client/server... Sep 18 17:55:58 k8s-master chronyd[16158]: chronyd version 3.2 starting (+CMDMON +NTP +REFCLOCK +RTC +PRIVDROP +SCFILTER +SECHASH +SIGND +ASYNCDNS +IPV6 +DEBUG) Sep 18 17:55:58 k8s-master chronyd[16158]: Frequency -39.629 +/- 0.032 ppm read from /var/lib/chrony/drift Sep 18 17:55:58 k8s-master systemd[1]: Started NTP client/server. Sep 18 17:56:31 k8s-master chronyd[16158]: Selected source 78.46.102.180 复制代码 4、常用命令 查看时间同步源： $ chronyc sources -v 立即手工同步 $chronyc -a makestep 查看时间同步源状态： $ chronyc sourcestats -v 设置硬件时间 硬件时间默认为UTC： $ timedatectl set-local-rtc 1 启用NTP时间同步： $ timedatectl set-ntp yes 校准时间服务器： $ chronyc tracking 最后需要注意的是，配置完/etc/chrony.conf后，需重启chrony服务，否则可能会不生效。 5、各类参数说明 配置参数说明 参数 参数说明 server 该参数可以多次用于添加时钟服务器，必须以&quot;server &quot;格式使用。一般而言，你想添加多少服务器，就可以添加多少服务器 stratumweight stratumweight指令设置当chronyd从可用源中选择同步源时，每个层应该添加多少距离到同步距离。默认情况下，CentOS中设置为0，让chronyd在选择源时忽略源的层级 driftfile chronyd程序的主要行为之一，就是根据实际时间计算出计算机增减时间的比率，将它记录到一个文件中是最合理的，它会在重启后为系统时钟作出补偿，甚至可能的话，会从时钟服务器获得较好的估值 rtcsync rtcsync指令将启用一个内核模式，在该模式中，系统时间每11分钟会拷贝到实时时钟（RTC） allow/deny 这里你可以指定一台主机、子网，或者网络以允许或拒绝NTP连接到扮演时钟服务器的机器 cmdallow/cmddeny 跟上面相类似，只是你可以指定哪个IP地址或哪台主机可以通过chronyd使用控制命令 bindcmdaddress 该指令允许你限制chronyd监听哪个网络接口的命令包（由chronyc执行）。该指令通过cmddeny机制提供了一个除上述限制以外可用的额外的访问控制等级 makestep 通常，chronyd将根据需求通过减慢或加速时钟，使得系统逐步纠正所有时间偏差。在某些特定情况下，系统时钟可能会漂移过快，导致该调整过程消耗很长的时间来纠正系统时钟。该指令强制chronyd在调整期大于某个阀值时步进调整系统时钟，但只有在因为chronyd启动时间超过指定限制（可使用负值来禁用限制），没有更多时钟更新时才生效 chronyc命令参数说明： 参数 参数说明 accheck 检查NTP访问是否对特定主机可用 activity 该命令会显示有多少NTP源在线/离线 add server 手动添加一台新的NTP服务器。 clients 在客户端报告已访问到服务器 delete 手动移除NTP服务器或对等服务器 settime 手动设置守护进程时间 tracking 显示系统时间信息 6、设置时区（非必须） 查看当前系统时区： $ timedatectl Local time: Fri 2018-2-29 13:31:04 CST Universal time: Fri 2018-2-29 05:31:04 UTC RTC time: Fri 2018-2-29 08:17:20 Time zone: Asia/Shanghai (CST, +0800) NTP enabled: yes NTP synchronized: yes RTC in local TZ: no DST active: n/a 如果你当前的时区不正确，请按照以下操作设置。 查看所有可用的时区： $ timedatectl list-timezones 筛选式查看在亚洲S开的上海可用时区： $ timedatectl list-timezones | grep -E &quot;Asia/S.*&quot; Asia/Sakhalin Asia/Samarkand Asia/Seoul Asia/Shanghai Asia/Singapore Asia/Srednekolymsk 设置当前系统为Asia/Shanghai上海时区： $ timedatectl set-timezone Asia/Shanghai 设置完时区后，强制同步下系统时钟： $ chronyc -a makestep 200 OK 快速步骤 CentOS7.1采用chronyd进行时钟同步 systemctl status chronyd 查看时钟同步状态 chronyc -a makestep 手动同步时钟 配置时钟同步服务器 vim /etc/chrony.conf 里面会有类似 server 0.pool.ntp.org iburst server 1.pool.ntp.org iburst server 2.pool.ntp.org iburst server 3.pool.ntp.org iburst 把你的ntpd server放进去，然后执行 systemctl restart chronyd.service systemctl enable chronyd.service","categories":[],"tags":[],"author":"张存"},{"title":"Docker 删除所有无名称的镜像（悬空镜像）","slug":"Docker-删除所有无名称的镜像（悬空镜像）","date":"2022-04-24T10:28:50.000Z","updated":"2022-04-24T10:29:01.133Z","comments":true,"path":"2022/04/24/docker-shan-chu-suo-you-wu-ming-cheng-de-jing-xiang-xuan-kong-jing-xiang/","link":"","permalink":"https://blog.zhangcun.store/2022/04/24/docker-shan-chu-suo-you-wu-ming-cheng-de-jing-xiang-xuan-kong-jing-xiang/","excerpt":"","text":"我们在build镜像的过程中，可能会产生一些临时的不具有名称也没有作用的镜像他们的名称一般都是&lt;none&gt;,我们可以执行下面的命令将其清除掉： docker rmi $(docker images -f &quot;dangling=true&quot; -q)","categories":[],"tags":[],"author":"张存"},{"title":"docker image 转换 docker file","slug":"docker-image-转换-docker-file","date":"2022-04-24T03:37:58.000Z","updated":"2022-04-24T03:38:04.842Z","comments":true,"path":"2022/04/24/docker-image-zhuan-huan-docker-file/","link":"","permalink":"https://blog.zhangcun.store/2022/04/24/docker-image-zhuan-huan-docker-file/","excerpt":"","text":"code: https://github.com/sevck/WhaleTail 依赖，golang cd $GOPATH/src git clone https://github.com/P3GLEG/WhaleTail go build . help 复制代码 ./WhaleTail Usage of ./WhaleTail: -f string File containing images to analyze seperated by line -filter Filters filenames that create noise such as node_modules. Check ignore.go file for more details (default true) -v Print all details about the image -x Save layers to current directory","categories":[],"tags":[],"author":"张存"},{"title":"find xargs grep查找文件及文件内容","slug":"find-xargs-grep查找文件及文件内容","date":"2022-04-24T03:14:44.000Z","updated":"2022-04-24T03:14:48.240Z","comments":true,"path":"2022/04/24/find-xargs-grep-cha-zhao-wen-jian-ji-wen-jian-nei-rong/","link":"","permalink":"https://blog.zhangcun.store/2022/04/24/find-xargs-grep-cha-zhao-wen-jian-ji-wen-jian-nei-rong/","excerpt":"","text":"1，在某个路径下查文件。 在/etc下查找“*.log”的文件 find /etc -name “*.log” 2，扩展，列出某个路径下所有文件，包括子目录。 find /etc -name “*” 3，在某个路径下查找所有包含“hello abcserver”字符串的文件。 find /etc -name &quot;*&quot; | xargs grep &quot;hello abcserver&quot; 或者 find /etc -name “*” | xargs grep “hello abcserver” &gt; ./cqtest.txt","categories":[],"tags":[],"author":"张存"},{"title":"使用docker 安装maven私服 nexus","slug":"使用docker-安装maven私服-nexus","date":"2022-04-21T12:21:28.000Z","updated":"2022-04-21T12:22:58.051Z","comments":true,"path":"2022/04/21/shi-yong-docker-an-zhuang-maven-si-fu-nexus/","link":"","permalink":"https://blog.zhangcun.store/2022/04/21/shi-yong-docker-an-zhuang-maven-si-fu-nexus/","excerpt":"","text":"一、下载nexus3 镜像文件 docker pull sonatype/nexus3 二、指定虚拟机与容器共享文件夹 mkdir -p /usr/local/docker/nexus/nexus-data 三、给共享文件夹分配可读写权限 chmod 777 /usr/local/docker/nexus/nexus-data 四、启动容器 docker run -p 8081:8081 --name nexus -v /usr/local/docker/nexus/nexus-data:/nexus-data snoatype/nexus3 五、浏览器访问并查看admin登录密码 cat /usr/local/docker/nexus/nexus-data/password 六、配置本地maven setting.xml 文件mirror &lt;mirror&gt; &lt;id&gt;maven-releases&lt;/id&gt; &lt;mirrorOf&gt;*&lt;/mirrorOf&gt; &lt;name&gt;local&lt;/name&gt; &lt;url&gt;http://10.10.100.216:8081/repository/maven-public/&lt;/url&gt; &lt;/mirror&gt; 七、配置本地maven setting.xml 文件server &lt;server&gt; &lt;id&gt;maven-releases&lt;/id&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;admin&lt;/password&gt; &lt;/server&gt; &lt;server&gt; &lt;id&gt;maven-snapshots&lt;/id&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;admin&lt;/password&gt; &lt;/server&gt;","categories":[],"tags":[],"author":"张存"},{"title":"nginx 图片加载速度提升","slug":"nginx-图片加载速度提升","date":"2022-04-21T12:17:54.000Z","updated":"2022-04-21T12:17:55.751Z","comments":true,"path":"2022/04/21/nginx-tu-pian-jia-zai-su-du-ti-sheng/","link":"","permalink":"https://blog.zhangcun.store/2022/04/21/nginx-tu-pian-jia-zai-su-du-ti-sheng/","excerpt":"","text":"php 上传大文件失败的问题 https://www.cnblogs.com/cxx8181602/p/9282576.html 阿里云带宽速度的提升 1M nginx配置解决vue单页面打包文件大，首次加载慢的问题 https://www.cnblogs.com/goloving/p/9170269.html nginx 开启gzip压缩--字符串压缩比率很牛叉 https://www.cnblogs.com/qiangxia/p/5398692.html nginx 图片加载速度 https://www.cnblogs.com/jimisun/p/9467159.html gzip on; gzip_comp_level 5; gzip_min_length 1024; gzip_types text/plain application/x-javascript text/css application/xml text/javascript image/jpeg image/gif image/png; image.png 设置图片缓存等 proxy_connect_timeout 600; #nginx跟后端服务器连接超时时间(代理连接超时) proxy_read_timeout 600; #连接成功后，后端服务器响应时间(代理接收超时) proxy_send_timeout 600; #后端服务器数据回传时间(代理发送超时) proxy_buffer_size 32k; #设置代理服务器（nginx）保存用户头信息的缓冲区大小 proxy_buffers 4 32k; #proxy_buffers缓冲区，网页平均在32k以下的话，这样设置 proxy_busy_buffers_size 64k; #高负荷下缓冲大小（proxy_buffers*2） proxy_temp_file_write_size 16k; #设定缓存文件夹大小，大于这个值，将从upstream服务器传","categories":[],"tags":[],"author":"张存"},{"title":"shell脚本中按日期遍历文件","slug":"shell脚本中按日期遍历文件","date":"2022-04-21T12:13:15.000Z","updated":"2022-04-21T12:15:39.161Z","comments":true,"path":"2022/04/21/shell-jiao-ben-zhong-an-ri-qi-bian-li-wen-jian/","link":"","permalink":"https://blog.zhangcun.store/2022/04/21/shell-jiao-ben-zhong-an-ri-qi-bian-li-wen-jian/","excerpt":"","text":"#!/bin/sh datebeg=20120412 beg_s=`date -d &quot;$datebeg&quot; +%s` for ((DAY=0;DAY&lt;=31;DAY++)); do DAY1=`date -d @$beg_s +&quot;%Y-%m-%d&quot;` A1=`cat file.$&#123;DAY1&#125;.txt|cmd1|cmd2|blablabla...` B2=`cat file2.$&#123;DAY1&#125;.txt|cmd1|cmd2|blablabla...` echo &quot;$DAY1&quot; echo &quot;scale=2;$A1*100/$B2&quot; | bc beg_s=$((beg_s+86400)) done 备注：循环中通过BC命令对遍历的文件进行一些数值计算","categories":[],"tags":[],"author":"张存"},{"title":"linux 代理上网","slug":"linux-代理上网","date":"2022-04-21T12:07:40.000Z","updated":"2022-04-21T12:07:42.078Z","comments":true,"path":"2022/04/21/linux-dai-li-shang-wang/","link":"","permalink":"https://blog.zhangcun.store/2022/04/21/linux-dai-li-shang-wang/","excerpt":"","text":"vim /etc/profile export http_proxy=http://172.17.1.101:808 export https_proxy=http://172.17.1.101:808 source /etc/profile 验证 [root@fabric8 ~]# curl -I https://www.baidu.com HTTP/1.0 200 Connection established HTTP/1.1 200 OK Accept-Ranges: bytes Cache-Control: private, no-cache, no-store, proxy-revalidate, no-transform Connection: Keep-Alive Content-Length: 277 Content-Type: text/html Date: Tue, 04 Sep 2018 06:45:04 GMT Etag: &quot;575e1f5c-115&quot; Last-Modified: Mon, 13 Jun 2016 02:50:04 GMT Pragma: no-cache Server: bfe/1.0.8.18 不能ping （icmp协议）","categories":[],"tags":[],"author":"张存"},{"title":"ERROR: An HTTP request took too long to complete. Retry with --verbose to obtain debug information.","slug":"ERROR-An-HTTP-request-took-too-long-to-complete-Retry-with-verbose-to-obtain-debug-information","date":"2022-04-21T12:04:17.000Z","updated":"2022-04-21T12:04:41.306Z","comments":true,"path":"2022/04/21/error-an-http-request-took-too-long-to-complete-retry-with-verbose-to-obtain-debug-information/","link":"","permalink":"https://blog.zhangcun.store/2022/04/21/error-an-http-request-took-too-long-to-complete-retry-with-verbose-to-obtain-debug-information/","excerpt":"","text":"docker-compose 的问题 要改环境变量 xed ~/.profile export COMPOSE_HTTP_TIMEOUT=500 export DOCKER_CLIENT_TIMEOUT=500 source ~/.profile","categories":[],"tags":[],"author":"张存"},{"title":"如何在Ubuntu 20.04上安装Zabbix Agent？","slug":"如何在Ubuntu-20-04上安装Zabbix-Agent？","date":"2022-04-21T12:02:46.000Z","updated":"2022-04-21T12:02:48.041Z","comments":true,"path":"2022/04/21/ru-he-zai-ubuntu-20-04-shang-an-zhuang-zabbix-agent/","link":"","permalink":"https://blog.zhangcun.store/2022/04/21/ru-he-zai-ubuntu-20-04-shang-an-zhuang-zabbix-agent/","excerpt":"","text":"Zabbix是一款针对您的IT基础设施的监控解决方案。您可以监控网络中的大部分设备和服务器上的大部分服务。要监控应用程序，您必须在网络中安装一个Zabbix服务器。 需要在服务器安装Zabbixx Agent，您需要通过Zabbix服务器进行监控。本教程将帮助您在Ubuntu 20.04 LTS Linux系统上安装Zabbix Agent。 要求 您必须具有对您的Ubuntu 20.04 LTS系统的sudo特权帐户访问权限的shell访问权限。 1、配置Zabbix存储库 Zabbix团队为安装Zabbix软件包提供了合适的存储库。然后将存储库添加到系统中，这是Zabbix Agent程序必需的软件包。运行以下命令以启用Zabbix存储库。 wget https://repo.zabbix.com/zabbix/5.0/ubuntu/pool/main/z/zabbix-release/zabbix-release_5.0-1+focal_all.deb sudo dpkg -i zabbix-release_5.0-1+focal_all.deb 2、在Ubuntu上安装Zabbix Agent 在系统中成功添加Zabbix apt存储库后，让我们使用以下命令通过以下命令安装Zabbix Agent。 sudo apt update sudo apt install zabbix-agent Zabbix Agent已安装在您的系统上。 接下来，您需要配置Zabbix Agent以允许来自Zabbix服务器的连接。例如，您的Zabbix服务器使用192.168.10.254 IP地址运行。要对此进行更新，请编辑Zabbix Agent配置文件/etc/zabbix/zabbix_agentd.conf： sudo nano /etc/zabbix/zabbix_agentd.conf #Nano文本编辑器 并更新以下设置： Server=192.168.10.254 //Server=[zabbix server ip] Hostname=Server2 //Hostname=[Hostname of client system ] 1 2 保存文件并关闭它。 Ctrl + s 保存 Ctrl + x 退出 PS: Nano文本编辑器介绍参考：https://blog.csdn.net/weixin_43031092/article/details/107573185 3、管理Zabbix服务 现在，重新启动Zabbix服务以应用更改。同时启用服务以在系统启动时自动启动。运行以下命令以重新启动并启用Zabbix Agent服务。 sudo systemctl restart zabbix-agent sudo systemctl enable zabbix-agent 以下命令用于停止和状态Zabbix Agent服务： sudo systemctl stop zabbix-agent sudo systemctl status zabbix-agent","categories":[],"tags":[],"author":"张存"},{"title":"Docker 构建支持中文环境的Alpine及大小优化","slug":"Docker-构建支持中文环境的Alpine及大小优化","date":"2022-04-21T12:00:28.000Z","updated":"2022-04-21T12:00:30.934Z","comments":true,"path":"2022/04/21/docker-gou-jian-zhi-chi-zhong-wen-huan-jing-de-alpine-ji-da-xiao-you-hua/","link":"","permalink":"https://blog.zhangcun.store/2022/04/21/docker-gou-jian-zhi-chi-zhong-wen-huan-jing-de-alpine-ji-da-xiao-you-hua/","excerpt":"","text":"因SpringBoot日志出现乱码，研究原因后发现是从docker官方仓库pull的镜像不支持中文。 构建内容参考了：https://www.clxz.top/2019/05/09/160241/ 那就自己构建一个环境，本文只说构建Alpine及优化 1、Dockerfile如下： FROM alpine:3.12.0 # 清理临时文件要在 同一个RUN命令内进行， rm -rf .....，构建的时候每个RUN都会创建一个临时的容器，只有写在同一个RUN下才会在一个容器内执行 RUN apk --no-cache add ca-certificates wget &amp;&amp; \\ wget -q -O /etc/apk/keys/sgerrand.rsa.pub https://alpine-pkgs.sgerrand.com/sgerrand.rsa.pub &amp;&amp; \\ wget https://github.com/sgerrand/alpine-pkg-glibc/releases/download/2.25-r0/glibc-2.25-r0.apk &amp;&amp; \\ wget https://github.com/sgerrand/alpine-pkg-glibc/releases/download/2.25-r0/glibc-bin-2.25-r0.apk &amp;&amp; \\ wget https://github.com/sgerrand/alpine-pkg-glibc/releases/download/2.25-r0/glibc-i18n-2.25-r0.apk &amp;&amp; \\ apk add glibc-bin-2.25-r0.apk glibc-i18n-2.25-r0.apk glibc-2.25-r0.apk &amp;&amp; \\ rm -rfv glibc-bin-2.25-r0.apk glibc-i18n-2.25-r0.apk glibc-2.25-r0.apk # locale.md 见下面的内容 COPY ./locale.md /locale.md RUN cat locale.md | xargs -i /usr/glibc-compat/bin/localedef -i &#123;&#125; -f UTF-8 &#123;&#125;.UTF-8 &amp;&amp; \\ rm -rfv locale.md ENV LANG=en_US.UTF-8 \\ LANGUAGE=en_US.UTF-8 精简后的locale.md, 只保留了en 、zh开头的， 不然构建的镜像比较大，将近大了80Mb en_AG en_AU en_BW en_CA en_DK en_GB en_HK en_IE en_IN en_NG en_NZ en_PH en_SG en_US en_ZA en_ZM en_ZW zh_CN zh_HK zh_SG zh_TW zu_ZA 清理临时文件内容片段： RUN apk --no-cache add ca-certificate。。。 \\ 。。。。 rm -rfv glibc-bin-2.25-r0.apk glibc-i18n-2.25-r0.apk glibc-2.25-r0.apk RUN cat locale.md | xargs -i 。。。&amp;&amp; \\ rm -rfv locale.md 2、构建命令： docker build -t my-env/utf8-alpine:20.7.22.3 . 3、构建的过程： Sending build context to Docker daemon 124.9MB Step 1/5 : FROM alpine:3.12.0 ---&gt; a24bb4013296 Step 2/5 : RUN apk --no-cache add ca-certificates wget &amp;&amp; wget -q -O /etc/apk/keys/sgerrand.rsa.pub https://alpine-pkgs.sgerrand.com/sgerrand.rsa.pub &amp;&amp; wget https://github.com/sgerrand/alpine-pkg-glibc/releases/download/2.25-r0/glibc-2.25-r0.apk &amp;&amp; wget https://github.com/sgerrand/alpine-pkg-glibc/releases/download/2.25-r0/glibc-bin-2.25-r0.apk &amp;&amp; wget https://github.com/sgerrand/alpine-pkg-glibc/releases/download/2.25-r0/glibc-i18n-2.25-r0.apk &amp;&amp; apk add glibc-bin-2.25-r0.apk glibc-i18n-2.25-r0.apk glibc-2.25-r0.apk &amp;&amp; rm -rfv glibc-bin-2.25-r0.apk glibc-i18n-2.25-r0.apk glibc-2.25-r0.apk ---&gt; Running in 27530d5a8b80 fetch http://dl-cdn.alpinelinux.org/alpine/v3.12/main/x86_64/APKINDEX.tar.gz fetch http://dl-cdn.alpinelinux.org/alpine/v3.12/community/x86_64/APKINDEX.tar.gz (1/4) Installing ca-certificates (20191127-r4) (2/4) Installing libunistring (0.9.10-r0) (3/4) Installing libidn2 (2.3.0-r0) (4/4) Installing wget (1.20.3-r1) Executing busybox-1.31.1-r16.trigger Executing ca-certificates-20191127-r4.trigger OK: 8 MiB in 18 packages --2020-07-22 09:11:56-- htt 。。。。 。。。。。 下载文件 fetch http://dl-cdn.alpinelinux.org/alpine/v3.12/main/x86_64/APKINDEX.tar.gz fetch http://dl-cdn.alpinelinux.org/alpine/v3.12/community/x86_64/APKINDEX.tar.gz (1/4) Installing glibc (2.25-r0) (2/4) Installing libgcc (9.3.0-r2) (3/4) Installing glibc-bin (2.25-r0) (4/4) Installing glibc-i18n (2.25-r0) Executing glibc-bin-2.25-r0.trigger OK: 25 MiB in 22 packages removed &#39;glibc-bin-2.25-r0.apk&#39; removed &#39;glibc-i18n-2.25-r0.apk&#39; removed &#39;glibc-2.25-r0.apk&#39; Removing intermediate container 27530d5a8b80 ---&gt; 9927c6d3def0 Step 3/5 : COPY ./locale.md /locale.md ---&gt; 37cc6234b3ab Step 4/5 : RUN cat locale.md | xargs -i /usr/glibc-compat/bin/localedef -i &#123;&#125; -f UTF-8 &#123;&#125;.UTF-8 ---&gt; Running in 943755a1b6e2 Removing intermediate container 943755a1b6e2 ---&gt; c08ec601f5e2 Step 5/5 : ENV LANG=en_US.UTF-8 LANGUAGE=en_US.UTF-8 ---&gt; Running in 1983050bcf0a Removing intermediate container 1983050bcf0a ---&gt; 58488cb2f47b Successfully built 58488cb2f47b Successfully tagged my-env/utf8-alpine:20.7.22.2 4、查看构建后的文件结构 // 导出images docker save my-env/utf8-alpine:20.7.22.3 &gt; utf8-alpine_20.7.22.3.tar 解压后： - - manifest.json - repositories - 99562d84c6129cf4268373af341e110e8984e12626951c19515f956da947ccc6.json - e56500c70e5e3b9b23b2e31880fdcb10ec2eb8b262609f8f0463bfa61916fd01 // 这个是alpine:3.12.0 的layer - layer.tar - json - VERSION - c234ab8959edd9715318124ad66fe080ea55c2d95a77e98613e2e98411874d96 // 安装glibc-2.25xxx 的 layer - layer.tar - json - VERSION - f3f134a63b698e4faf269116d0c3f12c76b6bee939fea010eceacd4d5404a00f // locale.md 的layer - layer.tar - json - VERSION - 034a7ec19dfd3ab16e3f56e02bd4b9d816d390feee1da12194cacb1d546af577 // 根据local.md 生成的 locale 信息 - layer.tar - json - VERSION","categories":[],"tags":[],"author":"张存"},{"title":"nohup 定时日志分割（按日期和大小）","slug":"nohup-定时日志分割（按日期和大小）","date":"2022-04-21T11:56:13.000Z","updated":"2022-04-26T11:33:10.713Z","comments":true,"path":"2022/04/21/nohup-ding-shi-ri-zhi-fen-ge-an-ri-qi-he-da-xiao/","link":"","permalink":"https://blog.zhangcun.store/2022/04/21/nohup-ding-shi-ri-zhi-fen-ge-an-ri-qi-he-da-xiao/","excerpt":"","text":"很多时候，用nohup后台启动生成日志时，如果不进行分割，文件会越来越大，导致日志文件打开很慢，不方便问题的ji&#39;shi定位和解决。 此文记录实际开发过程中，按照日期分割日志的操作步骤 一、首先写一个可执行的shell脚本，本次较为简单，建立一个名为nohup_log.sh，内容如下: # !/bin/sh # 拷贝日志文件到 昨天的log中 cp /usr/local/release/nohup.out /usr/local/release/logfile_`date -d yesterday +%Y%m%d`.log # 清空nohup.out 日志 cat /dev/null &gt; /usr/local/release/nohup.out 按大小 # !/bin/sh # 拷贝日志文件到 昨天的log中 split -b 100m -d -a 4 /usr/local/release/nohup.out /usr/local/release/logfile_`date -d yesterday +%Y%m%d`.log # 清空nohup.out 日志 cat /dev/null &gt; /usr/local/release/nohup.out 二、先手动执行一下shell脚本 可能遇到的问题： 1、提示权限不够 解决办法：chmod 777 ./nohup_logfile.sh 2、提示“目标‘\\r’不是目录” 原因分析： 在linux终端下，输出\\r会什么都不显示，只是把光标移到行首 解决办法： 用vim打开sh脚本文件， 重新设置文件的格式 ：set ff 然后回车 再重新设置下文件格式： ：set ff=unix 然后保存退出 ：wq! 回车 三、加入定时任务 1、crontab -e 根据自己需要设置，定时执行的时间 #每5分钟执行一次 */5 * * * * /usr/local/release/nohup_logfile.sh #每天 0 0 * * * /usr/local/release/nohup_logfile.sh 保存并退出 2、使定时任务生效 service crond restart 3、查看是否生效 至此工作完成，日志生成量较大的，还需要根据大小进行分割的自行修改shell脚本后执行。 四、定期删除时间过久，释放空间的日志 需求：每天凌晨1点整执行一次脚本，删除Linux系统/root/logs/目录下且是30天前的.log日志文件。 实现： 0 1 * * * find /root/logs -mtime +30 -name &#39;*.log&#39; -exec rm -rf &#123;&#125; \\; 保存退出，使其生效","categories":[],"tags":[],"author":"张存"},{"title":"telnet批量测试端口脚本","slug":"telnet批量测试端口脚本","date":"2022-04-21T11:54:57.000Z","updated":"2022-04-21T11:54:59.481Z","comments":true,"path":"2022/04/21/telnet-pi-liang-ce-shi-duan-kou-jiao-ben/","link":"","permalink":"https://blog.zhangcun.store/2022/04/21/telnet-pi-liang-ce-shi-duan-kou-jiao-ben/","excerpt":"","text":"telnet.sh 复制代码 #!/bin/bash #功能，批量telnet端口，输入参数需要测试的IP:PORT列表文件：telnet_list.txt（文件名可以自定义，但是只能跟脚本放在同一目录） #使用方法： telnet.sh telnet_list.txt ;或者后台执行： sh telnet.sh telnet_list.txt &gt;tellog.log 2&gt;&amp;1 &amp; #输出2个文件到result目录中： telnet_alive.txt 为端口通的；telnet_die.txt为端口不通的情况。 #文件内容格式如下，文件中每一行第一个字符#开头的行为注释行，不进行处理： #127.0.0.1|631 #获取当前目录 BASEDIR=`dirname $0` BASEDIR=`cd $BASEDIR;pwd` #设置输出数据目录。 mkdir -p $BASEDIR/result result_dir=$BASEDIR/result #设置输入的IP和端口文件名 telnet_list=$1 #如果输入参数为空，默认list文件为当前目录下的telnet_list.txt if [[ -z $telnet_list ]]; then echo &quot;=&gt;list file name is default!&quot; telnet_list=telnet_list.txt fi echo &quot;telnet test file is : $telnet_list&quot; #重置上次执行的文件结果 mv $result_dir/telnet_alive.txt $result_dir/telnet_alive.txt.bak #进行telnet并输出到响应文件中 for line in `cat $BASEDIR/$telnet_list |grep -v ^# |grep -v ^$ ` do #获取测试IP ip=`echo $line | awk &#39;BEGIN&#123;FS=&quot;|&quot;&#125; &#123;print $1&#125;&#39;` #获取测试端口 port=`echo $line | awk &#39;BEGIN&#123;FS=&quot;|&quot;&#125; &#123;print $2&#125;&#39;` #telnent一次并暂停1秒输出到result/telnet_result.txt 文件中，文件数据每一次循环会重置。 echo &quot;(sleep 1;) | telnet $ip $port&quot; (sleep 1;) | telnet $ip $port &gt; $result_dir/telnet_result.txt #查找成功响应的数据并输出到到result/telnet_alive.txt 文件中。 successIp=`cat $result_dir/telnet_result.txt | grep -B 1 \\] | grep [0-9] | awk &#39;&#123;print $3&#125;&#39; | cut -d &#39;.&#39; -f 1,2,3,4` if [ -n &quot;$successIp&quot; ]; then echo &quot;$successIp|$port&quot; &gt;&gt; $result_dir/telnet_alive.txt fi done #查找失败数据并输出到result/telnet_die.txt文件内。 cat $BASEDIR/$telnet_list $result_dir/telnet_alive.txt | sort | uniq -u |grep -v ^# &gt; $result_dir/telnet_die.txt echo &quot;&gt;----------------------------------------------------------------------------------------------------&quot; echo &quot;telnet is run over !&quot; echo &quot;telnet ok file is : result/telnet_alive.txt &quot; echo &quot;telnet failes file is : result/telnet_die.txt &quot; echo &quot;&gt;----------------------------------------------------------------------------------------------------&quot; 复制代码 telnet_list.txt 复制代码 #hosts 10.186.118.24|7009 10.186.118.25|7009 10.186.118.26|7009 10.186.118.27|7009 10.186.118.28|7009 10.186.118.29|7009 10.186.118.30|7009 10.186.118.31|7009 10.186.118.32|7009 10.186.118.33|7009 10.186.118.34|7009 10.186.118.35|7009 10.186.118.36|7009 10.186.118.37|7009 10.186.118.38|7009 10.186.118.39|7009","categories":[],"tags":[],"author":"张存"},{"title":"elk-filebeat收集docker容器日志","slug":"elk-filebeat收集docker容器日志","date":"2022-04-21T11:40:05.000Z","updated":"2022-04-21T11:40:25.290Z","comments":true,"path":"2022/04/21/elk-filebeat-shou-ji-docker-rong-qi-ri-zhi/","link":"","permalink":"https://blog.zhangcun.store/2022/04/21/elk-filebeat-shou-ji-docker-rong-qi-ri-zhi/","excerpt":"","text":"1、使用docker-compose文件构建elk。文件如下： version: &#39;3&#39; services: elk: image: sebp/elk:640 ports: - &quot;5601:5601&quot; - &quot;9200:9200&quot; - &quot;5044:5044&quot; environment: - ES_JAVA_OPTS=-Xms512m -Xmx512m volumes: - ~dockerdata/elk:/var/lib/elasticsearch 2、执行docker-compose up -d 启动elk。可以使用docker logs 命令查看elk启动日志。启动成功后打开浏览器访问 http://127.0.0.1:5601 filebeat安装与配置 关于filebeat本文也不做过多介绍。只讲解安装与配置。 1、filebeat的docker-composep version: &#39;3&#39; services: filebeat: image: prima/filebeat:6 #restart: always volumes: - ./config/filebeat.yml:/filebeat.yml - ~/dockerdata/filebeat:/data - /var/lib/docker/containers:/var/lib/docker/containers 挂载说明 filebeat.yml配置需要在本地有对应文件，稍后会说到 filebeat抓取日志进度数据，挂载到本地，防止filebeat容器重启，所有日志重新抓取 因为要收集docker容器的日志，所以要挂在到docker日志存储目录，使它有读取权限 2、filebeat配置文件设置 在docker-compose.yml同级目录新建config文件夹 在config文件下新建filebeat.yml文件，文件内容如下： filebeat.prospectors: - type: log enabled: true paths: - /var/lib/docker/containers/*/*.log #需要读取日志的目录# json.keys_under_root: true # 因为docker使用的log driver是json-file，因此采集到的日志格式是json格式，设置为true之后，filebeat会将日志进行json_decode处理 json.add_error_key: true #如果启用此设置，则在出现JSON解组错误或配置中定义了message_key但无法使用的情况下，Filebeat将添加“error.message”和“error.type：json”键。 json.message_key: log #一个可选的配置设置，用于指定应用行筛选和多行设置的JSON密钥。 如果指定，键必须位于JSON对象的顶层，且与键关联的值必须是字符串，否则不会发生过滤或多行聚合。 tail_files: true # 将error日志合并到一行 multiline.pattern: &#39;^([0-9]&#123;4&#125;|[0-9]&#123;2&#125;)-[0-9]&#123;2&#125;&#39; multiline.negate: true multiline.match: after multiline.timeout: 10s # registry_file: /opt/filebeat/registry #-------------------------- Elasticsearch output ------------------------------ # 直接输出到elasticsearch,这里的hosts是elk地址，端口号是elasticsearch端口# output.elasticsearch: hosts: [&quot;10.9.70.62:9200&quot;] #==================== Elasticsearch template setting ========================== setup.template.name: &quot;filebeat.template.json&quot; setup.template.fields: &quot;filebeat.template.json&quot; setup.template.overwrite: true setup.template.enabled: false # 过滤掉一些不必要字段# processors: - drop_fields: fields: [&quot;input_type&quot;, &quot;offset&quot;, &quot;stream&quot;, &quot;beat&quot;] 在config文件下新建filebeat.template.json文件，文件内容如下： &#123; &quot;mappings&quot;: &#123; &quot;_default_&quot;: &#123; &quot;_all&quot;: &#123; &quot;norms&quot;: false &#125;, &quot;_meta&quot;: &#123; &quot;version&quot;: &quot;5.1.2&quot; &#125;, &quot;dynamic_templates&quot;: [ &#123; &quot;strings_as_keyword&quot;: &#123; &quot;mapping&quot;: &#123; &quot;ignore_above&quot;: 1024, &quot;type&quot;: &quot;keyword&quot; &#125;, &quot;match_mapping_type&quot;: &quot;string&quot; &#125; &#125; ], &quot;properties&quot;: &#123; &quot;@timestamp&quot;: &#123; &quot;type&quot;: &quot;date&quot; &#125;, &quot;beat&quot;: &#123; &quot;properties&quot;: &#123; &quot;hostname&quot;: &#123; &quot;ignore_above&quot;: 1024, &quot;type&quot;: &quot;keyword&quot; &#125;, &quot;name&quot;: &#123; &quot;ignore_above&quot;: 1024, &quot;type&quot;: &quot;keyword&quot; &#125;, &quot;version&quot;: &#123; &quot;ignore_above&quot;: 1024, &quot;type&quot;: &quot;keyword&quot; &#125; &#125; &#125;, &quot;input_type&quot;: &#123; &quot;ignore_above&quot;: 1024, &quot;type&quot;: &quot;keyword&quot; &#125;, &quot;message&quot;: &#123; &quot;norms&quot;: false, &quot;type&quot;: &quot;text&quot; &#125;, &quot;meta&quot;: &#123; &quot;properties&quot;: &#123; &quot;cloud&quot;: &#123; &quot;properties&quot;: &#123; &quot;availability_zone&quot;: &#123; &quot;ignore_above&quot;: 1024, &quot;type&quot;: &quot;keyword&quot; &#125;, &quot;instance_id&quot;: &#123; &quot;ignore_above&quot;: 1024, &quot;type&quot;: &quot;keyword&quot; &#125;, &quot;machine_type&quot;: &#123; &quot;ignore_above&quot;: 1024, &quot;type&quot;: &quot;keyword&quot; &#125;, &quot;project_id&quot;: &#123; &quot;ignore_above&quot;: 1024, &quot;type&quot;: &quot;keyword&quot; &#125;, &quot;provider&quot;: &#123; &quot;ignore_above&quot;: 1024, &quot;type&quot;: &quot;keyword&quot; &#125;, &quot;region&quot;: &#123; &quot;ignore_above&quot;: 1024, &quot;type&quot;: &quot;keyword&quot; &#125; &#125; &#125; &#125; &#125;, &quot;offset&quot;: &#123; &quot;type&quot;: &quot;long&quot; &#125;, &quot;source&quot;: &#123; &quot;ignore_above&quot;: 1024, &quot;type&quot;: &quot;keyword&quot; &#125;, &quot;tags&quot;: &#123; &quot;ignore_above&quot;: 1024, &quot;type&quot;: &quot;keyword&quot; &#125;, &quot;type&quot;: &#123; &quot;ignore_above&quot;: 1024, &quot;type&quot;: &quot;keyword&quot; &#125; &#125; &#125; &#125;, &quot;order&quot;: 0, &quot;settings&quot;: &#123; &quot;index.refresh_interval&quot;: &quot;5s&quot; &#125;, &quot;template&quot;: &quot;filebeat-*&quot; &#125; 执行docker-compose up -d 启动filebeat。 在需要抓取docker日志的所有主机上按照以上步骤安装运行filebeat即可。到这一步其实就已经可以在elk里面建立索引查抓取到的日志。但是如果docker容器很多的话，没有办法区分日志具体是来自哪个容器，所以为了能够在elk里区分日志来源，需要在具体的docker容器上做一些配置，接着看下面的内容 docker容器设置 可以给具体的docker容器增加labels，并且设置logging。参考以下docker-compose.yml version: &#39;3&#39; services: db: image: mysql:5.7 # 设置labels labels: service: db # logging设置增加labels.service logging: options: labels: &quot;service&quot; ports: - &quot;3306:3306&quot; 重新启动应用，然后访问http://127.0.0.1:5601 重新添加索引。查看日志，可以增加过滤条件 attrs.service:db,此时查看到的日志就全部来自db容器。","categories":[],"tags":[],"author":"张存"},{"title":"docker-compose使用方法","slug":"docker-compose使用方法","date":"2022-04-21T11:34:54.000Z","updated":"2022-04-21T11:35:00.940Z","comments":true,"path":"2022/04/21/docker-compose-shi-yong-fang-fa/","link":"","permalink":"https://blog.zhangcun.store/2022/04/21/docker-compose-shi-yong-fang-fa/","excerpt":"","text":"Docker-compose使用方法 一：简介 Dockerfile 可以让用户管理一个单独的应用容器；而 Compose 则允许用户在一个模板（YAML 格式）中定义一组相关联的应用容器（被称为一个 project，即项目），例如一个 Web 服务容器再加上后端的数据库服务容器等，就拿官网的 Python 例子来说，功能很简单，利用 redis 的 incr 的功能对页面的访问量进行统计。 二：全量全货环境介绍 常用命令 docker-compose: --help 查看帮助 up 前台启动 down 关闭所有 -f file 指定启动或关闭时的控制文件，如果不指定，默认为当前目录下docker-compose.yml up -d 后台启动 ps 查看容器状态 logs 查看日志 docker-compose.yml文件讲解 network_mode: host 对应了docker中的--network，默认使用bridge 服务 # 使用v2版本 version: &#39;2&#39; services: # 服务名 manageserver: # 使用的镜像 image: openjdk:7-jdk # 容器重启策略 no:默认策略，一直不重启 on-failure 失败才重启，on-failure:3 重启三次 always 一直重启 restart: always # 使用GPU version得指定&#39;2.3&#39;版本，需要安装nvidia-docker2 runtime: nvidia # 资源限制 ulimits: # 创建的进程限制（线程是轻量级的进程） nproc: 65535 # 打开文件数限制 nofile: soft: 20000 hard: 40000 # 内存限制 mem_limit: 512m # 端口映射 ports: - &quot;18001:18001&quot; - &quot;5009:5009&quot; # 保证几个server启动后，才启动 depends_on: - zoo1 - activemq - redis # 镜像变量 environment: - _JAVA_OPTIONS=-Duser.timezone=Asia/Shanghai - JAVA_OPTS=-agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=5009 - DB_URL=$&#123;DB_URL&#125; - DB_USER=$&#123;DB_USER&#125; - DB_PWD=$&#123;DB_PWD&#125; # 文件映射 volumes: - /srv/docker/app:/app # 指定接入点（镜像生成后，会执行的启动脚本） entrypoint: - /app/entrypoint.sh # 会覆盖dockerfile中 - manageserver # 往上面的脚本传参 Tomcat version: &#39;2&#39; services: rweb01: image: tomcat:7.0.75 # 保证后端服务先启动（但是无法保证后端服务无法完整启动） depends_on: - zoo1 - activemq - redis environment: - _JAVA_OPTIONS=-Duser.timezone=Asia/Shanghai volumes: - /srv/docker/tomcat/webapps/adminweb:/usr/local/tomcat/webapps/adminweb - /srv/docker/tomcat/webapps/accountweb:/usr/local/tomcat/webapps/accountweb ports: - &quot;7071:8080&quot; Oracle docker run --network=host -v /srv/docker/oracle/u01:/u01 -p 1521:1521 -p 1158:1158 --name oracle -d ufoscout/oracle-11g --network=host 网络模拟，和宿主机共用网卡（默认为bridge） --name 容器名 -d 后台启动 ufoscout/oracle-11g 镜像名 查看镜像启动 # docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 0b51c82037ac ufoscout/oracle-11g &quot;/bin/sh -c oracle.sh&quot; 6 months ago Up 4 months oracle &quot;/bin/sh -c oracle.sh&quot; 为接入文件，当容器启动后，会自动执行 三：日常维护使用命令 启动前置容器 # cd /root/docker &amp;&amp; docker-compose up -d 关闭前置容器 # cd /root/docker &amp;&amp; docker-compose down 查看容器运行日志 # cd /root/docker &amp;&amp; docker-compose logs 查看所有 # docker-compose logs redis 查看指定服务 查看服务运行状态 # docker-compose ps Name Command State Ports ------------------------------------------------------------------------------------ dockerfile_redis_1 docker-entrypoint.sh redis ... Up 6379/tcp dockerfile_web_1 /bin/sh -c python app.py Up 0.0.0.0:5000-&gt;5000/tcp # State up或exit ，当我们使用发现一个容器为exit状态，可以直接使用docker-compose up -d [server]启动 进入容器 docker exec -ti [id | name ] /bin/bash 数据库容器启动关闭 # docker start oracle 启动 # docker stop oracle 关闭","categories":[],"tags":[],"author":"张存"},{"title":"ubuntu如何降级到之前的版本","slug":"ubuntu如何降级到之前的版本","date":"2022-04-21T11:29:15.000Z","updated":"2022-04-21T11:29:26.388Z","comments":true,"path":"2022/04/21/ubuntu-ru-he-jiang-ji-dao-zhi-qian-de-ban-ben/","link":"","permalink":"https://blog.zhangcun.store/2022/04/21/ubuntu-ru-he-jiang-ji-dao-zhi-qian-de-ban-ben/","excerpt":"","text":"找出系统已经安装的内核版本，在终端里输入命令： dpkg --get-selections | grep linux-image 然后会显示系统中已安装的内核，例如： linux-image-3.0.0-32-generic instal linux-image-3.0.0-12-generic install linux-image-generic install 卸载新的内核版本，在终端里输入命令： sudo apt-get remove linux-image-3.0.0-32-generic 上面命令和含义是： dpkg --get-selections [&lt;表达式&gt; ...]把已选中的软件包列表打印到标准输出； grep linux-image 匹配查找； uname -a 查看已安装的linux内核版。 发现只有原先的内核版本了 最后update-grub一下，重启，就可以直接进入。","categories":[],"tags":[],"author":"张存"},{"title":"alpine镜像添加zh_CN.utf8","slug":"alpine镜像添加zh-CN-utf8","date":"2022-04-21T11:26:15.000Z","updated":"2022-04-21T11:26:19.355Z","comments":true,"path":"2022/04/21/alpine-jing-xiang-tian-jia-zh-cn-utf8/","link":"","permalink":"https://blog.zhangcun.store/2022/04/21/alpine-jing-xiang-tian-jia-zh-cn-utf8/","excerpt":"","text":"方法一：构建好的镜像 [root@node1 tmp]# docker image ls | grep jdk hlwojiv/alpine-jdk8 latest f726e71fd441 5 months ago 237MB [root@node1 tmp]# docker pull hlwojiv/alpine-jdk8 [root@node1 tmp]# docker run -it --rm hlwojiv/alpine-jdk8 /usr/glibc-compat/bin/locale -a | grep zh zh_CN.utf8 zh_HK.utf8 zh_SG.utf8 zh_TW.utf8 [root@node1 tmp]# docker run -it --rm hlwojiv/alpine-jdk8 env PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/java/jdk/bin HOSTNAME=ebb732aa197d TERM=xterm LANG=en_US.UTF-8 LANGUAGE=en_US.UTF-8 JAVA_HOME=/usr/java/jdk HOME=/root 方法二：使用dcokerfile构建 $ git clone https://github.com/hlwojiv/docker-alpine-jdk8.git $ cd docker-alpine-jdk8/ $ ls Dockerfile README.md jre8.tar.gz locale.md $ cat Dockerfile FROM docker.io/jeanblanchard/alpine-glibc MAINTAINER hlwojiv ADD jre8.tar.gz /usr/java/jdk/ RUN echo &#39;http://mirrors.ustc.edu.cn/alpine/v3.5/main&#39; &gt; /etc/apk/repositories \\ &amp;&amp; echo &#39;http://mirrors.ustc.edu.cn/alpine/v3.5/community&#39; &gt;&gt;/etc/apk/repositories \\ &amp;&amp; apk update &amp;&amp; apk add tzdata \\ &amp;&amp; ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime \\ &amp;&amp; echo &quot;Asia/Shanghai&quot; &gt; /etc/timezone RUN apk --no-cache add ca-certificates wget &amp;&amp; \\ wget -q -O /etc/apk/keys/sgerrand.rsa.pub https://alpine-pkgs.sgerrand.com/sgerrand.rsa.pub &amp;&amp; \\ wget https://github.com/sgerrand/alpine-pkg-glibc/releases/download/2.25-r0/glibc-2.25-r0.apk &amp;&amp; \\ wget https://github.com/sgerrand/alpine-pkg-glibc/releases/download/2.25-r0/glibc-bin-2.25-r0.apk &amp;&amp; \\ wget https://github.com/sgerrand/alpine-pkg-glibc/releases/download/2.25-r0/glibc-i18n-2.25-r0.apk &amp;&amp; \\ apk add glibc-bin-2.25-r0.apk glibc-i18n-2.25-r0.apk glibc-2.25-r0.apk # Iterate through all locale and install it # Note that locale -a is not available in alpine linux, use `/usr/glibc-compat/bin/locale -a` instead COPY ./locale.md /locale.md RUN cat locale.md | xargs -i /usr/glibc-compat/bin/localedef -i &#123;&#125; -f UTF-8 &#123;&#125;.UTF-8 # Set the lang, you can also specify it as as environment variable through docker-compose.yml ENV LANG=en_US.UTF-8 \\ LANGUAGE=en_US.UTF-8 ENV JAVA_HOME /usr/java/jdk ENV PATH $&#123;PATH&#125;:$&#123;JAVA_HOME&#125;/bin WORKDIR /opt $ cat locale.md en_US zh_CN $ docker build -t alpine-utf8-jdk . # 构建报错，locale.md某些语言报错 cannot open locale definition file `iw_IL&#39;: No such file or directory cannot open locale definition file `no_NO&#39;: No such file or directory cannot open locale definition file `pap_AN&#39;: No such file or directory 在dockerfile中修改语言环境 FROM alpine:3.6 # ---not shown here--- # Install language pack RUN apk --no-cache add ca-certificates wget &amp;&amp; \\ wget -q -O /etc/apk/keys/sgerrand.rsa.pub https://alpine-pkgs.sgerrand.com/sgerrand.rsa.pub &amp;&amp; \\ wget https://github.com/sgerrand/alpine-pkg-glibc/releases/download/2.25-r0/glibc-2.25-r0.apk &amp;&amp; \\ wget https://github.com/sgerrand/alpine-pkg-glibc/releases/download/2.25-r0/glibc-bin-2.25-r0.apk &amp;&amp; \\ wget https://github.com/sgerrand/alpine-pkg-glibc/releases/download/2.25-r0/glibc-i18n-2.25-r0.apk &amp;&amp; \\ apk add glibc-bin-2.25-r0.apk glibc-i18n-2.25-r0.apk glibc-2.25-r0.apk # Iterate through all locale and install it # Note that locale -a is not available in alpine linux, use `/usr/glibc-compat/bin/locale -a` instead COPY ./locale.md /locale.md RUN cat locale.md | xargs -i /usr/glibc-compat/bin/localedef -i &#123;&#125; -f UTF-8 &#123;&#125;.UTF-8 # Set the lang, you can also specify it as as environment variable through docker-compose.yml ENV LANG=en_US.UTF-8 \\ LANGUAGE=en_US.UTF-8 小结： 删了一些东西，重新构建 Dockerfile FROM docker.io/jeanblanchard/alpine-glibc COPY ./locale.md /locale.md # Install language pack #RUN echo &#39;http://mirrors.ustc.edu.cn/alpine/v3.5/main&#39; &gt; /etc/apk/repositories \\ # &amp;&amp; echo &#39;http://mirrors.ustc.edu.cn/alpine/v3.5/community&#39; &gt;&gt;/etc/apk/repositories \\ RUN apk update \\ &amp;&amp; apk add tzdata \\ &amp;&amp; cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime \\ &amp;&amp; apk del tzdata \\ &amp;&amp; apk --no-cache add ca-certificates wget \\ &amp;&amp; wget -q -O /etc/apk/keys/sgerrand.rsa.pub https://alpine-pkgs.sgerrand.com/sgerrand.rsa.pub \\ &amp;&amp; wget https://github.com/sgerrand/alpine-pkg-glibc/releases/download/2.25-r0/glibc-2.25-r0.apk \\ https://github.com/sgerrand/alpine-pkg-glibc/releases/download/2.25-r0/glibc-bin-2.25-r0.apk \\ https://github.com/sgerrand/alpine-pkg-glibc/releases/download/2.25-r0/glibc-i18n-2.25-r0.apk \\ &amp;&amp; apk add glibc-bin-2.25-r0.apk glibc-i18n-2.25-r0.apk glibc-2.25-r0.apk \\ &amp;&amp; sleep 3 \\ &amp;&amp; cat /locale.md | xargs -i /usr/glibc-compat/bin/localedef -i &#123;&#125; -f UTF-8 &#123;&#125;.UTF-8 \\ &amp;&amp; rm /etc/apk/keys/sgerrand.rsa.pub \\ &amp;&amp; rm /locale.md \\ glibc-2.25-r0.apk \\ glibc-bin-2.25-r0.apk \\ glibc-i18n-2.25-r0.apk \\ &amp;&amp; apk del wget ca-certificates\\ &amp;&amp; rm -rf /var/cache/apk/* \\ &amp;&amp; rm &quot;/root/.wget-hsts&quot; ENV LANG=en_US.UTF-8 \\ LANGUAGE=en_US.UTF-8 locale.md [root@glowing-bliss-1 tmp]# cat locale.md en_AG en_AU en_BW en_CA en_DK en_GB en_HK en_IE en_IN en_NG en_NZ en_PH en_SG en_US en_ZA en_ZM en_ZW zh_CN zh_HK zh_SG zh_TW zu_ZA [root@glowing-bliss-1 tmp]# docker build -t my:v0.6 . [root@glowing-bliss-1 tmp]# docker images | grep v0.6 my v0.6 29a1b86617b0 4 minutes ago 37.7MB [root@glowing-bliss-1 tmp]# docker run --rm -it my:v0.6 env PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin HOSTNAME=ca966becfb4c TERM=xterm GLIBC_VERSION=2.30-r0 LANG=en_US.UTF-8 LANGUAGE=en_US.UTF-8 HOME=/root failed to resize tty, using default size [root@glowing-bliss-1 tmp]# docker run --rm -it my:v0.6 /usr/glibc-compat/bin/locale -a | grep zh zh_CN.utf8 zh_HK.utf8 zh_SG.utf8 zh_TW.utf8","categories":[],"tags":[],"author":"张存"},{"title":"Linux(CentOS)配置Docker随宿主机自启，容器自启（ --restart=always）","slug":"Linux-CentOS-配置Docker随宿主机自启，容器自启（-restart-always）","date":"2022-04-21T11:19:39.000Z","updated":"2022-04-21T11:19:54.035Z","comments":true,"path":"2022/04/21/linux-centos-pei-zhi-docker-sui-su-zhu-ji-zi-qi-rong-qi-zi-qi-restart-always/","link":"","permalink":"https://blog.zhangcun.store/2022/04/21/linux-centos-pei-zhi-docker-sui-su-zhu-ji-zi-qi-rong-qi-zi-qi-restart-always/","excerpt":"","text":"1.配置docker自启 #把docker服务加入启动项，随系统启动 systemctl enable docker.service #查看是否成功 systemctl list-unit-files |grep docker 2.容器自启 复制代码 #docker run --restart always restart参数值说明如下： no - 容器不自动重启 on-failure - 容器退出状态不为0时自动重启 on-failure:[n] - 容器退出状态不为0时自动重启，最大尝试n次 always - 始终尝试自动重启 复制代码 有时候，我们创建容器时忘了添加参数 --restart=always ，当 Docker 重启时，容器未能自动启动。 此时可以修改 容器配置 docker container update --restart=always 容器名称或id 3.查看容器重启次数，和最后重启时间 #查看容器重启次数 docker inspect -f &quot;&#123;&#123; .RestartCount &#125;&#125;&quot; 容器名称或id #查看容器最后一次的启动时间 docker inspect -f &quot;&#123;&#123; .State.StartedAt &#125;&#125;&quot; 容器名称或id 无穷的伟大，也是从“0”开始的","categories":[],"tags":[],"author":"张存"},{"title":"cp 花括号备份{}","slug":"cp-花括号备份","date":"2022-04-20T11:31:37.000Z","updated":"2022-04-20T11:32:53.558Z","comments":true,"path":"2022/04/20/cp-hua-gua-hao-bei-fen/","link":"","permalink":"https://blog.zhangcun.store/2022/04/20/cp-hua-gua-hao-bei-fen/","excerpt":"","text":"这个命令个人觉得比较方便。记下来方便下次忘记时使用 [root@Client ~]# ls 43_12.txt anaconda-ks.cfg ce.sh [root@Client ~]# [root@Client ~]# cp ce.sh&#123;,.bak&#125; #备份成.bak模式 [root@Client ~]# ls 43_12.txt anaconda-ks.cfg ce.sh ce.sh.bak [root@Client ~]# [root@Client ~]# cp ce.sh&#123;,-beifen&#125; #备份成-bak模式 [root@Client ~]# ls 43_12.txt anaconda-ks.cfg ce.sh ce.sh.bak ce.sh-beifen [root@Client ~]# mv ce.sh&#123;,-bak&#125; #用来重命名 [root@Client ~]# ls 43_12.txt anaconda-ks.cfg ce.sh-bak","categories":[],"tags":[],"author":"张存"},{"title":"查看单个容器的日志路径","slug":"查看单个容器的日志路径","date":"2022-04-20T11:27:09.000Z","updated":"2022-04-20T11:27:43.731Z","comments":true,"path":"2022/04/20/cha-kan-dan-ge-rong-qi-de-ri-zhi-lu-jing/","link":"","permalink":"https://blog.zhangcun.store/2022/04/20/cha-kan-dan-ge-rong-qi-de-ri-zhi-lu-jing/","excerpt":"","text":"docker inspect --format=&#39;&#123;&#123;.LogPath&#125;&#125;&#39; product-center [root@c3-218 ~]# docker inspect --format=&#39;&#123;undefined&#123;.LogPath&#125;&#125;&#39; product-center /var/lib/docker/containers/9a4b077db746187037f570b0407aebee6f5e0e6860efd4ba36b984f31ef6414e/9a4b077db746187037f570b0407aebee6f5e0e6860efd4ba36b984f31ef6414e-json.log","categories":[],"tags":[],"author":"张存"},{"title":"使用 acme.sh 自动更新 ssl 证书","slug":"使用-acme-sh-自动更新-ssl-证书","date":"2022-04-20T11:20:31.000Z","updated":"2022-04-20T11:21:16.118Z","comments":true,"path":"2022/04/20/shi-yong-acme-sh-zi-dong-geng-xin-ssl-zheng-shu/","link":"","permalink":"https://blog.zhangcun.store/2022/04/20/shi-yong-acme-sh-zi-dong-geng-xin-ssl-zheng-shu/","excerpt":"","text":"今天发现 SSL 证书过期了，本来打算人工来 ZeroSSL 人工申请下更新下证书就算了，但是发现这次还是要验证 DNS，然后发现每次设置后使用 dnslookup 都可以看到效果了，点击 NEXT 还有会说不匹配，因为每次提交都要等好几分钟，几次不成我就不想再试了。打算再再次尝试下使用 Let’s Encrypt 的 SSL 自动更新的客户端（acme.sh），发现 在 shell 下 tab 键 都不会自动提示了，发现硬盘爆了，被 jenkins 的日志塞满了。记录下今天遇到几个问题的解决办法： 使用 du -h –max-depth=1 命令查看硬盘使用的情况，发现是日志文件 /var/log/jenkins/jenkins.log 文件达到了 10+g，删除后 使用 df -h 命令查看磁盘空间，发现并没有立即释放，然后又去 百度了 “linux删除文件后没有释放空间”，发现是 linux 默认进程运行的情况下，会标记使用到的文件，并不会立即的释放空间，使用 lsof |grep deleted 命令查看已经删除但是还没有释放的文件，找到进程 id， kill 掉 jenkins 进程后，再次查看磁盘大小，总算腾出来空间了。 然后开始整证书的问题，看了下 certbot 还是不支持 ubuntu 下面调用 acme v2 的接口，只支持在 docker 下面启动一个然后去申请，因为在 docker 下执行也比较麻烦，还得停掉 本机运行的 nginx 腾出80，443端口，太麻烦了，则选用 aceme.sh 这个文件，而且有比较完整中文的文档。可能是我今天运气不好，上次使用 dnspod 的 token 添加 TXT record 的时候已经添加了一个 token，这次 export DP_Id 和 DP_Key 之后发现还是不能添加成功，后来查了一下看了下别人执行的时候参数 debug 参数给了一个2，可以显示出接口返回的信息，返回的是dnspod的验证没有成功，我看了下请求的url 上的登录参数，发现使用的不是我刚 export 出来的，然后找了下，发现 acme.sh 同级目录下有一个 account.conf 的配置文件，打开后发现里面配置的 DP_Id 和 DP_Key 是上次的，修改为本次的后重新调用，MMP，这次直接 ACME 的调用次数限制把我挡住了，说我调用了太多次都失败了，看了ACME 接口限制每个域名一个周最多调用20次申请，所以最近只能等等了，等一个礼拜后重新执行 acme.sh –debug 2 –issue –dns dns_dp -d firegod.cn -d *.firegod.cn文章后面给了更简单的自动更新证书的方法，不需要再修改域名解析。 更新于2018年07月24日： 今天重新试了一下接口可以调用了，但是一直会说 域名的 TXT 记录没有生效，但是使用 nslookup 命令已经可以返回 TXT 记录了，百度了一下，网上说是如果有 CNAME 类型的解析，TXT 的就会失效，难道Let’s Encrypt验证的方式是通过浏览这个地址返回的内容来做验证的？暂停掉 CNAME 类型的泛域名的解析，过上几分钟等直接访问URL返回的是 TXT 记录的内容后再试试。 更新于2018年07月26日 去掉 CNAME 的泛域名解析后，执行上面命令的时候增加了 –dnssleep 700 的命令，强制让等到700秒后再去检查证书有效性，没注意看，时间到了后发现证书已经成功的申请到了保存在 .acme.sh目录下对应的域名目录下了 更新于2018年09月08日 今天更新证书，执行的命令是 acme.sh –debug 2 –issue –dnssleep 10 –dns dns_dp -d firegod.cn -d *.firegod.cn –force 更新于2018年12月23日申请到的证书中如果在火狐或者android手机浏览器中报告说是证书有问题，实际上可能是缺少中间证书信任链，可以参考我这篇文章解决： https 证书认证链缺失分析 更新于2019年02月25日今天发现证书又过期了，还是没有自动更新，而且我上面给的命令无法更新泛域名，于是经过我再次探索，发现可以直接使用 acme.sh –renew-all 来自动刷新所有的证书，此命令会智能的更新需要更新的证书，而不会更新最新才更新过的证书。例如下面这样的提示： 然后我使用下面的命令重新安装了cron任务，这下应该可以高枕无忧了。 yangyan@VM-202-6-ubuntu:~$ acme.sh –uninstall-cronjob [2019年 02月 25日 星期一 22:09:15 CST] Removing cron job yangyan@VM-202-6-ubuntu:~$ acme.sh –install-cronjob [2019年 02月 25日 星期一 22:09:20 CST] Installing cron job 更新于2019年03月03日 因为泛域名的证书，二级的泛域名只支持二级泛域名，如果是想要添加其他的域名，可以执行 : acme.sh –debug 2 –issue –dnssleep 10 –dns dns_dp -d a.b.c.firegod.cn后续再执行 –renew-all 命令的时候就会自动更新新增的域名了 更新于2020年04月22日： 今天发现 -renew-all 命令不能用了，最新的可以正常执行的命令是： acme.sh --cron 更新与2020年05月05日： 今天我换了一个服务器，nginx 的配置丢了，所以需要重新配置一下ssl，下面这个两个环境的值，可以登录DNSPOD申请API获取。如果是其他的域名解析服务商，可能也是类似的，看一下官方文档，估计变量名可能不同。 export DP_Id=”xxx”export DP_Key=”xxx”然后执行： ~/.acme.sh/acme.sh –issue -d firegod.cn -d *.firegod.cn –dns dns_dp今天发现一个命令可以自动的将acme.sh申请到的证书配置到nginx下面，虽然我的没有自动配置成功，但是却实现了复制证书到指定的地址，然后我人工配置了证书到nginx，下面的路径给的是需要将acme.sh申请到的证书复制到的路径，后面的那个reloadcmd参数是指，以后当证书更新后会自动执行的命令： ~/.acme.sh/acme.sh --install-cert -d firegod.cn \\ --key-file /opt/nginx/ssl/firegod.cn.key \\ --fullchain-file /opt/nginx/ssl/firegod.cn.crt \\ --reloadcmd &quot;service nginx force-reload&quot; 然后去nginx配置文件中添加： ssl_certificate /opt/nginx/ssl/firegod.cn.crt; ssl_certificate_key /opt/nginx/ssl/firegod.cn.key;","categories":[],"tags":[],"author":"张存"},{"title":"docker 删除不用的镜像","slug":"docker-删除不用的镜像","date":"2022-04-20T11:10:05.000Z","updated":"2022-04-20T11:10:09.408Z","comments":true,"path":"2022/04/20/docker-shan-chu-bu-yong-de-jing-xiang/","link":"","permalink":"https://blog.zhangcun.store/2022/04/20/docker-shan-chu-bu-yong-de-jing-xiang/","excerpt":"","text":"1.删除悬空的镜像 docker image prune -a -f 2.删除悬空的容器 docker container prune -f 3.定时清空镜像和脚本 [root@VM_0_42_centos opt]# cat clean.sh sh /opt/docker/lock.sh -t clean -a lock docker image prune -a -f docker container prune -f sh /opt/docker/lock.sh -t clean -a unlock dt=$(date) echo time is $dt","categories":[],"tags":[],"author":"张存"},{"title":"gitlab 备份&恢复","slug":"gitlab-备份-恢复","date":"2022-04-20T11:03:59.000Z","updated":"2022-04-20T11:06:36.280Z","comments":true,"path":"2022/04/20/gitlab-bei-fen-hui-fu/","link":"","permalink":"https://blog.zhangcun.store/2022/04/20/gitlab-bei-fen-hui-fu/","excerpt":"","text":"Gitlab 成功运行起来之后，最终的事情就是定期的备份，遇到问题后的还原。 备份配置 默认 Gitlab 的备份文件会创建在/var/opt/gitlab/backups文件夹中，格式为时间戳_日期_版本号_gitlab_backup.tar，例如：1515031353_2018_01_04_10.3.2_gitlab_backup.tar。 修改备份文件夹，需要修改配置文件/etc/gitlab/gitlab.rb中的： gitlab_rails[&#39;backup_path&#39;] = &#39;/your_wish/backups&#39; 然后gitlabctl-reconfigure生效。 手动备份 命令：gitlab-backup create For GitLab 12.1 and earlier, use gitlab-rake gitlab:backup:create 会在命令执行的时间点，在你配置的文件夹或者默认文件夹创建一个备份文件。 自动备份 0 2 * * * /opt/gitlab/bin/gitlab-backup create CRON=1 备份恢复 First make sure your backup tar file is in the backup directory described in the gitlab.rb configuration gitlab_rails[&#39;backup_path&#39;]. The default is /var/opt/gitlab/backups. It needs to be owned by the git user. cp 11493107454_2018_04_25_10.6.4-ce_gitlab_backup.tar /var/opt/gitlab/backups/ chown git.git /var/opt/gitlab/backups/11493107454_2018_04_25_10.6.4-ce_gitlab_backup.tar Stop the processes that are connected to the database. Leave the rest of GitLab running: gitlab-ctl stop unicorn gitlab-ctl stop sidekiq # Verify gitlab-ctl status Next, restore the backup, specifying the timestamp of the backup you wish to restore: # This command will overwrite the contents of your GitLab database! gitlab-backup restore BACKUP=1493107454_2018_04_25_10.6.4-ce For GitLab 12.1 and earlier, use gitlab-rake gitlab:backup:restore Next, restore /etc/gitlab/gitlab-secrets.json if necessary as mentioned above. Reconfigure, restart and check GitLab: gitlab-ctl reconfigure gitlab-ctl restart gitlab-rake gitlab:check SANITIZE=true If there is a GitLab version mismatch between your backup tar file and the installed version of GitLab, the restore command will abort with an error. Install the correct GitLab version and try again.","categories":[],"tags":[],"author":"张存"},{"title":"解决：Docker下运行Mysql出现：mbind: Operation not permitted","slug":"解决：Docker下运行Mysql出现：mbind-Operation-not-permitted","date":"2022-04-20T10:52:47.000Z","updated":"2022-04-20T10:59:22.715Z","comments":true,"path":"2022/04/20/jie-jue-docker-xia-yun-xing-mysql-chu-xian-mbind-operation-not-permitted/","link":"","permalink":"https://blog.zhangcun.store/2022/04/20/jie-jue-docker-xia-yun-xing-mysql-chu-xian-mbind-operation-not-permitted/","excerpt":"","text":"问题 mysql的错误 | 问题：操作不允许 mysql | mbind: Operation not permitted 1 2 原因 这是Docker的Seccomp安全限制问题 并且官方给出了指导和解释： DockerHup官方传送门 懒的抽筋的可以直接看解决办法 ↓ 解决方法： 在docker-compose.yml中忽略docker的安全验证，此时当容器就会带着这个参数启动(.yml已简化，看重点就行)* version: &#39;3.7&#39; services: mysql: image: mysql container_name: mysql #docker安全验证 security_opt: - seccomp:unconfined ports: - 3306:3306","categories":[],"tags":[],"author":"张存"},{"title":"DOCKER-COMPOSE创建mysql8","slug":"DOCKER-COMPOSE创建mysql8","date":"2022-04-20T10:37:51.000Z","updated":"2022-04-20T11:01:39.920Z","comments":true,"path":"2022/04/20/docker-compose-chuang-jian-mysql8/","link":"","permalink":"https://blog.zhangcun.store/2022/04/20/docker-compose-chuang-jian-mysql8/","excerpt":"","text":"废话不说，直接上yml version: &#39;3.1&#39; services: db: image: mysql container_name: mysql8 restart: always environment: MYSQL_ROOT_PASSWORD: #记得冒号与密码之间有个空格哈，这是yml的书写格式 command: --default-authentication-plugin=mysql_native_password --character-set-server=utf8mb4 --collation-server=utf8mb4_general_ci --explicit_defaults_for_timestamp=true --lower_case_table_names=1 --max_allowed_packet=128M; ports: - 3306:3306 volumes: - ./data:/var/lib/mysql docker方式： docker run --name mysq.db -p 3306:3306 -e MYSQL_ROOT_PASSWORD=123456 -d -v /home/mysql/:/var/lib/mysql mysql --lower_case_table_names=1 -e MYSQL_ROOT_PASSWORD :设置mysql密码 -v /home/mysql/:/var/lib/mysql:挂载磁盘实现数据持久化 --lower_case_table_names=1 :忽略大小写，docker mysql默认区分大小写的 注:参数顺序一定要对，–lower_case_table_names=1要加在镜像名后面，镜像名前面是参数，后面是mysql配置，不然会报错 lower_case_table_names=1 只能在初始化时配置，不然会报错 查看MySQL官方文档，有记录： lower_case_table_names can only be configured when initializing the server. Changing the lower_case_table_names setting after the server is initialized is prohibited. 只有在初始化的时候设置 lower_case_table_names=1 才有效 之前文章中记录了dockr安装mysql之后，发现该数据库对大小写敏感，然后各种百度修改配置、重启都不生效。 mysql表名是否区分大小写是通过lower_case_table_names参数来设置，登录mysql后可通过show Variables like ‘%table_names’ 来查看默认的值 不同系统，该参数的默认值是不同的。 参数值 参数说明 lower_case_table_names=1 表名存储在磁盘是小写的，但是比较的时候是不区分大小写 lower_case_table_names=0 表名存储为给定的大小和比较是区分大小写的 lower_case_table_names=2 表名存储为给定的大小写但是比较的时候是小写的 windows环境默认 1 ,linux环境默认0 ,macos环境默认2 docker exec -it mysql /bin/bash 这个时候已经是大小写不敏感了，可以进入mysql镜像中验证下 mysql -h localhost -u root -p Enter password: 直接回车 mysql&gt; show variables like &#39;%table_names&#39;; +------------------------+-------+ | Variable_name | Value | +------------------------+-------+ | lower_case_file_system | OFF | | lower_case_table_names | 1 | +------------------------+-------+ 2 rows in set (0.00 sec) 可以看到lower_case_table_names参数已经变为1 看下现在的密码的加密方式 select host,user,plugin,authentication_string from mysql.user; 新增用户和修改密码 mysql&gt; CREATE USER &#39;admin&#39;@&#39;%&#39; IDENTIFIED BY &#39;密码&#39;; mysql&gt; GRANT ALL ON *.* TO admin@&#39;%&#39; WITH GRANT OPTION; mysql&gt; FLUSH PRIVILEGES;","categories":[],"tags":[],"author":"张存"},{"title":"设置 SSH 通过密钥登录","slug":"设置-SSH-通过密钥登录","date":"2022-04-20T10:35:28.000Z","updated":"2022-04-20T10:35:32.322Z","comments":true,"path":"2022/04/20/she-zhi-ssh-tong-guo-mi-yao-deng-lu/","link":"","permalink":"https://blog.zhangcun.store/2022/04/20/she-zhi-ssh-tong-guo-mi-yao-deng-lu/","excerpt":"","text":"我们一般使用 PuTTY 等 SSH 客户端来远程管理 Linux 服务器。但是，一般的密码方式登录，容易有密码被暴力破解的问题。所以，一般我们会将 SSH 的端口设置为默认的 22 以外的端口，或者禁用 root 账户登录。其实，有一个更好的办法来保证安全，而且让你可以放心地用 root 账户从远程登录——那就是通过密钥方式登录。 密钥形式登录的原理是：利用密钥生成器制作一对密钥——一只公钥和一只私钥。将公钥添加到服务器的某个账户上，然后在客户端利用私钥即可完成认证并登录。这样一来，没有私钥，任何人都无法通过 SSH 暴力破解你的密码来远程登录到系统。此外，如果将公钥复制到其他账户甚至主机，利用私钥也可以登录。 下面来讲解如何在 Linux 服务器上制作密钥对，将公钥添加给账户，设置 SSH，最后通过客户端登录。 1. 制作密钥对 首先在服务器上制作密钥对。首先用密码登录到你打算使用密钥登录的账户，然后执行以下命令： [root@host ~]$ ssh-keygen &lt;== 建立密钥对 Generating public/private rsa key pair. Enter file in which to save the key (/root/.ssh/id_rsa): &lt;== 按 Enter Created directory &#39;/root/.ssh&#39;. Enter passphrase (empty for no passphrase): &lt;== 输入密钥锁码，或直接按 Enter 留空 Enter same passphrase again: &lt;== 再输入一遍密钥锁码 Your identification has been saved in /root/.ssh/id_rsa. &lt;== 私钥 Your public key has been saved in /root/.ssh/id_rsa.pub. &lt;== 公钥 The key fingerprint is: 0f:d3:e7:1a:1c:bd:5c:03:f1:19:f1:22:df:9b:cc:08 root@host 密钥锁码在使用私钥时必须输入，这样就可以保护私钥不被盗用。当然，也可以留空，实现无密码登录。 现在，在 root 用户的家目录中生成了一个 .ssh 的隐藏目录，内含两个密钥文件。id_rsa 为私钥，id_rsa.pub 为公钥。 2. 在服务器上安装公钥 键入以下命令，在服务器上安装公钥： [root@host ~]$ cd .ssh [root@host .ssh]$ cat id_rsa.pub &gt;&gt; authorized_keys 如此便完成了公钥的安装。为了确保连接成功，请保证以下文件权限正确： [root@host .ssh]$ chmod 600 authorized_keys [root@host .ssh]$ chmod 700 ~/.ssh 3. 设置 SSH，打开密钥登录功能 编辑 /etc/ssh/sshd_config 文件，进行如下设置： RSAAuthentication yes PubkeyAuthentication yes 另外，请留意 root 用户能否通过 SSH 登录： PermitRootLogin yes 当你完成全部设置，并以密钥方式登录成功后，再禁用密码登录： PasswordAuthentication no 最后，重启 SSH 服务： [root@host .ssh]$ service sshd restart 4. 将私钥下载到客户端，然后转换为 PuTTY 能使用的格式 使用 WinSCP、SFTP 等工具将私钥文件 id_rsa 下载到客户端机器上。然后打开 PuTTYGen，单击 Actions 中的 Load 按钮，载入你刚才下载到的私钥文件。如果你刚才设置了密钥锁码，这时则需要输入。 载入成功后，PuTTYGen 会显示密钥相关的信息。在 Key comment 中键入对密钥的说明信息，然后单击 Save private key 按钮即可将私钥文件存放为 PuTTY 能使用的格式。 今后，当你使用 PuTTY 登录时，可以在左侧的 Connection -&gt; SSH -&gt; Auth 中的 Private key file for authentication: 处选择你的私钥文件，然后即可登录了，过程中只需输入密钥锁码即可。","categories":[],"tags":[],"author":"张存"},{"title":"ubuntu 20.04 | 设置开机启动脚本","slug":"ubuntu-20-04-设置开机启动脚本","date":"2022-04-20T10:21:11.000Z","updated":"2022-04-20T10:21:13.021Z","comments":true,"path":"2022/04/20/ubuntu-20-04-she-zhi-kai-ji-qi-dong-jiao-ben/","link":"","permalink":"https://blog.zhangcun.store/2022/04/20/ubuntu-20-04-she-zhi-kai-ji-qi-dong-jiao-ben/","excerpt":"","text":"ubuntu 20.04 | 设置开机启动脚本 1. 编辑 rc-local.service 文件 2. 编辑 rc.local 文件 3. 创建软链接 1. 编辑 rc-local.service 文件 sudo chmod 777 /lib/systemd/system/rc-local.service sudo vim /lib/systemd/system/rc-local.service 在文件尾部添加以下内容： [Install] WantedBy=multi-user.target Alias=rc-local.service 2. 编辑 rc.local 文件 sudo vim /etc/rc.local 编辑 rc.local 文件并添加要开机执行的脚本，第一行#!/bin/sh，尾行exit 0。 （ubuntu18.04 版本之后默认没有 /etc/rc.local/etc/rc.local 文件，需要自己创建） #!/bin/sh echo &quot;看到这行字，说明添加自启动脚本成功。&quot; &gt; /usr/local/test.log # 中间这一段就是脚本的内容，例如：sudo ssr start exit 0 1 2 3 4 给lrc.local 文件加上权限。 sudo chmod +x /etc/rc.local 1 3. 创建软链接 # 创建方式：ln -s 原目录 映射目录 sudo ln -s /lib/systemd/system/rc-local.service /etc/systemd/system/","categories":[],"tags":[],"author":"张存"},{"title":"awk输出最后一列的命令","slug":"awk输出最后一列的命令","date":"2022-04-20T10:14:49.000Z","updated":"2022-04-20T10:16:21.848Z","comments":true,"path":"2022/04/20/awk-shu-chu-zui-hou-yi-lie-de-ming-ling/","link":"","permalink":"https://blog.zhangcun.store/2022/04/20/awk-shu-chu-zui-hou-yi-lie-de-ming-ling/","excerpt":"","text":"输出最后一列： awk -F’,’ ‘{print $NF}’ train_FraudRate.csv &gt; lastcolumn.txt","categories":[],"tags":[],"author":"张存"},{"title":"使用docker-compose快速搭建本地ElasticSearch7和Elastichd环境","slug":"使用docker-compose快速搭建本地ElasticSearch7和Elastichd环境","date":"2022-04-20T10:09:02.000Z","updated":"2022-04-20T10:12:25.762Z","comments":true,"path":"2022/04/20/shi-yong-docker-compose-kuai-su-da-jian-ben-di-elasticsearch7-he-elastichd-huan-jing/","link":"","permalink":"https://blog.zhangcun.store/2022/04/20/shi-yong-docker-compose-kuai-su-da-jian-ben-di-elasticsearch7-he-elastichd-huan-jing/","excerpt":"","text":"先编写docker-compose.es.yml version: &#39;3&#39; services: elasticsearch: image: elasticsearch:7.5.1 container_name: elasticsearch networks: - net-es volumes: - ../data/elasticsearch/data:/usr/share/elasticsearch/data #这里将elasticsearch的数据文件映射本地，以保证下次如果删除了容器还有数据 environment: - discovery.type=single-node ports: - &quot;9200:9200&quot; elastichd: image: containerize/elastichd:latest container_name: elasticsearch-hd networks: - net-es ports: - &quot;9800:9800&quot; depends_on: - &quot;elasticsearch&quot; links: - &quot;elasticsearch:demo&quot; #这里要注意，es和eshd要在相同网络才能被links networks: net-es: external: false 启动代码： docker-compose -f docker-compose.es.yml up 启动后访问http://localhost:9800打开elastichd 输入elasticsearch地址点connect即可","categories":[],"tags":[],"author":"张存"},{"title":"yum源安装docker","slug":"yum源安装docker","date":"2022-04-20T10:03:51.000Z","updated":"2022-04-20T10:03:52.990Z","comments":true,"path":"2022/04/20/yum-yuan-an-zhuang-docker/","link":"","permalink":"https://blog.zhangcun.store/2022/04/20/yum-yuan-an-zhuang-docker/","excerpt":"","text":"Centos7上安装docker Docker从1.13版本之后采用时间线的方式作为版本号，分为社区版CE和企业版EE。 社区版是免费提供给个人开发者和小型团体使用的，企业版会提供额外的收费服务，比如经过官方测试认证过的基础设施、容器、插件等。 社区版按照stable和edge两种方式发布，每个季度更新stable版本，如17.06，17.09；每个月份更新edge版本，如17.09，17.10。 一、安装docker 1、Docker 要求 CentOS 系统的内核版本高于 3.10 ，查看本页面的前提条件来验证你的CentOS 版本是否支持 Docker 。 通过 uname -r 命令查看你当前的内核版本 $ uname -r 2、使用 root 权限登录 Centos。确保 yum 包更新到最新。 $ sudo yum update 3、卸载旧版本(如果安装过旧版本的话) $ sudo yum remove docker docker-common docker-selinux docker-engine 4、安装需要的软件包， yum-util 提供yum-config-manager功能，另外两个是devicemapper驱动依赖的 $ sudo yum install -y yum-utils device-mapper-persistent-data lvm2 5、设置yum源 记得修改镜像源 国外镜像一般很难访问，建议配置阿里云镜像。yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo $ sudo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo 6、可以查看所有仓库中所有docker版本，并选择特定版本安装 $ yum list docker-ce --showduplicates | sort -r 7、安装docker $ sudo yum install docker-ce #由于repo中默认只开启stable仓库，故这里安装的是最新稳定版17.12.0 $ sudo yum install &lt;FQPN&gt; # 例如：sudo yum install docker-ce-17.12.0.ce 8、启动并加入开机启动 $ sudo systemctl start docker $ sudo systemctl enable docker 9、验证安装是否成功(有client和service两部分表示docker安装启动都成功了) $ docker version 二、问题 1、因为之前已经安装过旧版本的docker，在安装的时候报错如下： 复制代码 复制代码 Transaction check error: file /usr/bin/docker from install of docker-ce-17.12.0.ce-1.el7.centos.x86_64 conflicts with file from package docker-common-2:1.12.6-68.gitec8512b.el7.centos.x86_64 file /usr/bin/docker-containerd from install of docker-ce-17.12.0.ce-1.el7.centos.x86_64 conflicts with file from package docker-common-2:1.12.6-68.gitec8512b.el7.centos.x86_64 file /usr/bin/docker-containerd-shim from install of docker-ce-17.12.0.ce-1.el7.centos.x86_64 conflicts with file from package docker-common-2:1.12.6-68.gitec8512b.el7.centos.x86_64 file /usr/bin/dockerd from install of docker-ce-17.12.0.ce-1.el7.centos.x86_64 conflicts with file from package docker-common-2:1.12.6-68.gitec8512b.el7.centos.x86_64 复制代码 复制代码 2、卸载旧版本的包 $ sudo yum erase docker-common-2:1.12.6-68.gitec8512b.el7.centos.x86_64 3、再次安装docker 复制代码 $ sudo yum install docker-ce 安装完成后修改docker默认存储路径 4. 修改docker.service文件. vim /usr/lib/systemd/system/docker.service 5. 在里面的EXECStart的后面增加后如下: ExecStart=/usr/bin/dockerd --graph /home/docker","categories":[],"tags":[],"author":"张存"},{"title":"linux 下使用 rsync 进行文件 同步","slug":"linux-下使用-rsync-进行文件-同步-1","date":"2022-04-20T09:22:27.000Z","updated":"2022-04-20T09:22:49.153Z","comments":true,"path":"2022/04/20/linux-xia-shi-yong-rsync-jin-xing-wen-jian-tong-bu-1/","link":"","permalink":"https://blog.zhangcun.store/2022/04/20/linux-xia-shi-yong-rsync-jin-xing-wen-jian-tong-bu-1/","excerpt":"","text":"rsync 介绍 rsync是类unix系统下的数据镜像备份工具——remote sync。 rsync是一个功能非常强大的工具，其命令也有很多功能特色选项，我们下面就对它的选项一一进行分析说明。 它的特性如下： 可以镜像保存整个目录树和文件系统。 可以很容易做到保持原来文件的权限、时间、软硬链接等等。 无须特殊权限即可安装。 快速：第一次同步时 rsync 会复制全部内容，但在下一次只传输修改过的文件。rsync 在传输数据的过程中可以实行压缩及解压缩操作， 因此可以使用更少的带宽。 安全：可以使用scp、ssh等方式来传输文件，当然也可以通过直接的socket连接。 支持匿名传输，以方便进行网站镜像。 rysnc 的官方网站：http://rsync.samba.org/，可以从上面得到最新的版本。关于rsync算法的介绍点这里，还有陈皓blog. rsync的使用 Rsync的命令格式可以为以下六种： rsync [OPTION]... SRC DEST rsync [OPTION]... SRC [USER@]HOST:DEST rsync [OPTION]... [USER@]HOST:SRC DEST rsync [OPTION]... [USER@]HOST::SRC DEST rsync [OPTION]... SRC [USER@]HOST::DEST rsync [OPTION]... rsync://[USER@]HOST[:PORT]/SRC [DEST] rsync有六种不同的工作模式： 1. 拷贝本地文件；当SRC和DEST路径信息都不包含有单个冒号&quot;:&quot;分隔符时就启动这种工作模式。 2.使用一个远程shell程序（如rsh、ssh）来实现将本地机器的内容拷贝到远程机器。当DEST 路径地址包含单个冒号&quot;:&quot;分隔符时启动该模式。 3.使用一个远程shell程序（如rsh、ssh）来实现将远程机器的内容拷贝到本地机器。当SRC 地址路径包含单个冒号&quot;:&quot;分隔符时启动该模式。 4. 从远程rsync服务器中拷贝文件到本地机。当SRC路径信息包含&quot;::&quot;分隔符时启动该模式。 5. 从本地机器拷贝文件到远程rsync服务器中。当DEST路径信息包含&quot;::&quot;分隔符时启动该模式。 6. 列远程机的文件列表。这类似于rsync传输，不过只要在命令中省略掉本地机信息即可。 可以man rsync 参考 rsync 文档，了解详细的使用方法，下面解析一些参数的使用： rsync参数的具体解释如下： -v, --verbose 详细模式输出 -q, --quiet 精简输出模式 -c, --checksum 打开校验开关，强制对文件传输进行校验 -a, --archive 归档模式，表示以递归方式传输文件，并保持所有文件属性，等于-rlptgoD -r, --recursive 对子目录以递归模式处理 -R, --relative 使用相对路径信息 -b, --backup 创建备份，也就是对于目的已经存在有同样的文件名时，将老的文件重新命名为~filename。可以使用--suffix选项来指定不同的备份文件前缀。 --backup-dir 将备份文件(如~filename)存放在在目录下。 -suffix=SUFFIX 定义备份文件前缀 -u, --update 仅仅进行更新，也就是跳过所有已经存在于DST，并且文件时间晚于要备份的文件。(不覆盖更新的文件) -l, --links 保留软链结 -L, --copy-links 想对待常规文件一样处理软链结 --copy-unsafe-links 仅仅拷贝指向SRC路径目录树以外的链结 --safe-links 忽略指向SRC路径目录树以外的链结 -H, --hard-links 保留硬链结 -p, --perms 保持文件权限 -o, --owner 保持文件属主信息 -g, --group 保持文件属组信息 -D, --devices 保持设备文件信息 -t, --times 保持文件时间信息 -S, --sparse 对稀疏文件进行特殊处理以节省DST的空间 -n, --dry-run现实哪些文件将被传输 -W, --whole-file 拷贝文件，不进行增量检测 -x, --one-file-system 不要跨越文件系统边界 -B, --block-size=SIZE 检验算法使用的块尺寸，默认是700字节 -e, --rsh=COMMAND 指定使用rsh、ssh方式进行数据同步 --rsync-path=PATH 指定远程服务器上的rsync命令所在路径信息 -C, --cvs-exclude 使用和CVS一样的方法自动忽略文件，用来排除那些不希望传输的文件 --existing 仅仅更新那些已经存在于DST的文件，而不备份那些新创建的文件 --delete 删除那些DST中SRC没有的文件 --delete-excluded 同样删除接收端那些被该选项指定排除的文件 --delete-after 传输结束以后再删除 --ignore-errors 及时出现IO错误也进行删除 --max-delete=NUM 最多删除NUM个文件 --partial 保留那些因故没有完全传输的文件，以是加快随后的再次传输 --force 强制删除目录，即使不为空 --numeric-ids 不将数字的用户和组ID匹配为用户名和组名 --timeout=TIME IP超时时间，单位为秒 -I, --ignore-times 不跳过那些有同样的时间和长度的文件 --size-only 当决定是否要备份文件时，仅仅察看文件大小而不考虑文件时间 --modify-window=NUM 决定文件是否时间相同时使用的时间戳窗口，默认为0 -T --temp-dir=DIR 在DIR中创建临时文件 --compare-dest=DIR 同样比较DIR中的文件来决定是否需要备份 -P 等同于 --partial --progress 显示备份过程 -z, --compress 对备份的文件在传输时进行压缩处理 --exclude=PATTERN 指定排除不需要传输的文件模式 --include=PATTERN 指定不排除而需要传输的文件模式 --exclude-from=FILE 排除FILE中指定模式的文件 --include-from=FILE 不排除FILE指定模式匹配的文件 --version 打印版本信息 等等... 下面举例说明rsync的六种不同工作模式: 1)拷贝本地文件。当SRC和DES路径信息都不包含有单个冒号&quot;:&quot;分隔符时就启动这种工作模式。 如：rsync -a ./test.c /backup 2)使用一个远程shell程序(如rsh、ssh)来实现将本地机器的内容拷贝到远程机器。当DES路径地址包含单个冒号&quot;:&quot;分隔符时启动该模式。 如：rsync -avz test.c user@172.16.0.11:/home/user/src 3)使用一个远程shell程序(如rsh、ssh)来实现将远程机器的内容拷贝到本地机器。当SRC地址路径包含单个冒号&quot;:&quot;分隔符时启动该模式。 如：rsync -avz user@172.16.0.11:/home/user/src ./src 4)从远程rsync服务器中拷贝文件到本地机。当SRC路径信息包含&quot;::&quot;分隔符时启动该模式。 如：rsync -av user@172.16.0.11::www /databack 5)从本地机器拷贝文件到远程rsync服务器中。当DES路径信息包含&quot;::&quot;分隔符时启动该模式。 如：rsync -av /databack user@172.16.0.11::www 6)列远程机的文件列表。这类似于rsync传输，不过只要在命令中省略掉本地机信息即可。 如：rsync -v rsync://172.16.78.192 /www 常见问题举例: ssh端口更改后rsync的用法 rsync有两种常用的认证方式，一种为rsync-daemon方式，另外一种则是ssh。 ssh方式比较缺乏灵活性 一般为首选，但当远端服务器的ssh默认端口被修改后，rsync时找不到一个合适的方法来输入对方ssh服务端口号。 比如现在向机器 172.16.0.172 传送文件，但此时172.16.0.172的ssh端口已经不是 默认的22 端口。 键入命令 rsync test.c ustc@172.16.0.172:/home/ustc 出现如下的错误: 我们注意到rsync中的命令 参数 -e, --rsh=COMMAND 指定使用rsh、ssh方式进行数据同步。 参数的作用是可以使用户自由选择欲使用的shell程序来连接远端服务器，当然也可以设置成使用默认的ssh来连接，但是这样我们就可以加入ssh的参数了。 现在命令可以这样写了: rsync -e &#39;ssh -p 3333&#39; test.c ustc@172.16.0.172:/home/ustc 可见这是 文件传送修改ssh端口后的机器上成功,上面语句中使用了单引号，目的是为了使引号内的参数为引号内的命令所用。没有引号的话系统就会 识别-p是给rsync的一个参数了。","categories":[],"tags":[],"author":"张存"},{"title":"zabbix基于docker安装","slug":"zabbix基于docker安装","date":"2022-04-20T08:21:55.000Z","updated":"2022-04-20T09:23:11.190Z","comments":true,"path":"2022/04/20/zabbix-ji-yu-docker-an-zhuang/","link":"","permalink":"https://blog.zhangcun.store/2022/04/20/zabbix-ji-yu-docker-an-zhuang/","excerpt":"","text":"centos的版本 #cat /etc/redhat-release CentOS Linux release 7.5.1804 (Core) docker的安装 配置yum源 #vim /etc/yum.repos.d/docker-ce.repo [docker-ce-stable] name=Docker CE Stable - $basearch baseurl=https://mirrors.aliyun.com/docker-ce/linux/centos/7/$basearch/stable enabled=1 gpgcheck=1 gpgkey=https://mirrors.aliyun.com/docker-ce/linux/centos/gpg 安装docker-ce #wget https://mirrors.aliyun.com/centos-vault/7.3.1611/extras/x86_64/Packages/container-selinux-2.9-4.el7.noarch.rpm #yum localinstall container-selinux-2.9-4.el7.noarch.rpm -y #yum install docker-ce -y 启动docker #systemctl start docker 使用docker搭建zabbix 1 、先安装数据库mysql docker run --name zabbix-mysql-server --hostname zabbix-mysql-server \\ -e MYSQL_ROOT_PASSWORD=&quot;123456&quot; \\ -e MYSQL_USER=&quot;zabbix&quot; \\ -e MYSQL_PASSWORD=&quot;123456&quot; \\ -e MYSQL_DATABASE=&quot;zabbix&quot; \\ -p 33061:3306 \\ -d mysql:5.7 \\ --character-set-server=utf8 --collation-server=utf8_bin 2 、创建zabbix-server docker run --name zabbix-server-mysql --hostname zabbix-server-mysql \\ --link zabbix-mysql-server:mysql \\ -e DB_SERVER_HOST=&quot;mysql&quot; \\ -e MYSQL_USER=&quot;zabbix&quot; \\ -e MYSQL_DATABASE=&quot;zabbix&quot; \\ -e MYSQL_PASSWORD=&quot;123456&quot; \\ -v /etc/localtime:/etc/localtime:ro \\ -v /data/docker/zabbix/alertscripts:/usr/lib/zabbix/alertscripts \\ -v /data/docker/zabbix/externalscripts:/usr/lib/zabbix/externalscripts \\ -p 10051:10051 \\ -d \\ zabbix/zabbix-server-mysql 3 、安装web-nginx 安装zabbix-web-nginx docker run --name zabbix-web-nginx-mysql --hostname zabbix-web-nginx-mysql \\ --link zabbix-mysql-server:mysql \\ --link zabbix-server-mysql:zabbix-server \\ -e DB_SERVER_HOST=&quot;mysql&quot; \\ -e MYSQL_USER=&quot;zabbix&quot; \\ -e MYSQL_PASSWORD=&quot;123456&quot; \\ -e MYSQL_DATABASE=&quot;zabbix&quot; \\ -e ZBX_SERVER_HOST=&quot;zabbix-server&quot; \\ -e PHP_TZ=&quot;Asia/Shanghai&quot; \\ -p 7000:80 \\ -p 8443:443 \\ -d \\ zabbix/zabbix-web-nginx-mysql 查看docker镜像 # docker ps -s CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES SIZE d96b4abdd502 zabbix/zabbix-web-nginx-mysql &quot;docker-entrypoint.sh&quot; 3 days ago Up 12 hours 0.0.0.0:7000-&gt;80/tcp, 0.0.0.0:8443-&gt;443/tcp zabbix-web-nginx-mysql 2.06kB (virtual 163MB) 23cb7c5842d0 zabbix/zabbix-server-mysql &quot;docker-entrypoint.sh&quot; 3 days ago Up 12 hours 0.0.0.0:10051-&gt;10051/tcp zabbix-server-mysql 25MB (virtual 87.7MB) b1bea58475f1 mysql:5.7 &quot;docker-entrypoint.s…&quot; 3 days ago Up 12 hours 0.0.0.0:33061-&gt;3306/tcp, 33060/tcp zabbix-mysql-server 28B (virtual 372MB) zabbix-server基于docker安装完毕！ 关闭防火墙和selinux 访问：http://宿主机IP：7000 默认用户名：Admin 默认登陆ming echo 1 &gt; /proc/sys/net/ipv4/ip_forward #容器内网络与外网通，在宿主机上要开启网络转换 ps：开启网络转换容器只能ping通宿主机，不能通外网，重启docker就OK 进入zabbix-server容器 # docker exec -it zabbix-server-mysql /bin/bash bash-4.3# ping 1.1.1.1 PING 1.1.1.1 (1.1.1.1) 56(84) bytes of data. 64 bytes from 1.1.1.1: icmp_seq=1 ttl=127 time=197 ms 64 bytes from 1.1.1.1: icmp_seq=2 ttl=127 time=196 ms ps:网络通外网 查看ipbash-4.3# ip -4 a 1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN qlen 1000 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever 278: eth0@if279: &lt;BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN&gt; mtu 1500 qdisc noqueue state UP inet 172.17.0.15/16 scope global eth0 valid_lft forever preferred_lft forever 替换容器中的安装源 1、备份配置文件： cp -a /etc/apk/repositories /etc/apk/repositories.bak 2、修改repositories文件，将http://dl-cdn.alpinelinux.org/替换成https://mirrors.huaweicloud.com/，可以参考如下命令：sed -i s@http://dl-cdn.alpinelinux.org/@https://mirrors.huaweicloud.com/@g /etc/apk/repositories 3、执行apk update更新索引，执行apk search xxx查询软件包，执行apk add xxx安装软件包 安装zabbix-agent 并配置 #rpm -ivh https://repo.zabbix.com/zabbix/4.0/rhel/7/x86_64/zabbix-release-4.0-1.el7.noarch.rpm #yum -y install zabbix-agent-4.0.1 docker exec -it zabbix-server-mysql ip addr 1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever 278: eth0@if279: &lt;BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN&gt; mtu 1500 qdisc noqueue state UP link/ether 02:42:ac:11:00:0f brd ff:ff:ff:ff:ff:ff inet 172.17.0.15/16 scope global eth0 valid_lft forever preferred_lft forever inet6 fe80::42:acff:fe11:f/64 scope link valid_lft forever preferred_lft forever # vim /etc/zabbix/zabbix_agentd.conf Server=172.17.0.15 UnsafeUserParameters=1 Include=/etc/zabbix/zabbix_agentd.d/*.conf # systemctl start zabbix-agent.service 注意：如果要对宿主机进行监控，请编辑宿主机的zabbix_agentd.conf，将Server地址，默认127.0.0.1，修改为docker-server容器地址，否则不通；如果是对其他主机的监控则使用docker-zabbix-server宿主机的IP。","categories":[],"tags":[],"author":"张存"},{"title":"date显示年月日时分秒","slug":"date显示年月日时分秒","date":"2022-04-12T09:50:56.000Z","updated":"2022-04-12T09:51:01.977Z","comments":true,"path":"2022/04/12/date-xian-shi-nian-yue-ri-shi-fen-miao/","link":"","permalink":"https://blog.zhangcun.store/2022/04/12/date-xian-shi-nian-yue-ri-shi-fen-miao/","excerpt":"","text":"echo &quot;`date +&quot;%F %T&quot;`&quot;","categories":[],"tags":[],"author":"张存"},{"title":"ubuntu server 系统语言显示英文","slug":"ubuntu-server-系统语言显示英文","date":"2022-04-12T06:42:02.000Z","updated":"2022-04-12T06:42:25.325Z","comments":true,"path":"2022/04/12/ubuntu-server-xi-tong-yu-yan-xian-shi-ying-wen/","link":"","permalink":"https://blog.zhangcun.store/2022/04/12/ubuntu-server-xi-tong-yu-yan-xian-shi-ying-wen/","excerpt":"","text":"安装完毕后在本地命令行窗口或者通过SSH远程登录管理，运行一些命令发现中文都是一些乱码，这是推荐安装Ubuntu server 服务器版本时选择语言为English的原因。如果设置了中文，可以通过下面的方法修改系统语言为英文： sudo nano /var/lib/locales/supported.d/local 改成 en_US.UTF-8 UTF-8 sudo vim /etc/default/locale 将 LANG=”zh_CN.UTF-8″ LANGUAGE=”zh_CN:zh” 修改为：LANG=”en_US.UTF-8″ LANGUAGE=”en_US:en” sudo locale-gen reboot 重启系统之后，ubuntu server 系统语言显示英文，也就不再出现乱码中文了。 如果出现warning: setlocale: LC_CTYPE: cannot change locale (en_US) 執行下列指令:sudo locale-gen en_US.UTF-8 sudo update-locale LANG=en_US.UTF-8","categories":[],"tags":[],"author":"张存"},{"title":"每天定时日志切割脚本","slug":"每天定时日志切割脚本","date":"2022-04-12T06:40:17.000Z","updated":"2022-04-12T06:40:20.777Z","comments":true,"path":"2022/04/12/mei-tian-ding-shi-ri-zhi-qie-ge-jiao-ben/","link":"","permalink":"https://blog.zhangcun.store/2022/04/12/mei-tian-ding-shi-ri-zhi-qie-ge-jiao-ben/","excerpt":"","text":"#/bin/sh curdate=`date -d -1day +%Y%m%d` #时间 source=/data/apps/route/nohup.out #路径 target=/data/apps/route/log/nohup&quot;$curdate&quot;_ #切割完的路径 fileSize=`ls -l $source |awk &#39;&#123;print $5&#125;&#39;` #10m #计算方式 1M=1024*1024 # nohup.log 超过10m 日志切割 threshSize=10485760 if [ &quot;$fileSize&quot; -gt &quot;$threshSize&quot; ];then echo &quot;lograte cut log...&quot; split -C 10m -d -a 5 $source $target cat /dev/null &gt; $source #清理30天前nohup 文件 #find /data/apps/route/log/ -type f -mtime +30 -name /home/fdm/log/tmp/nohup* -exec rm -f &#123;&#125; \\; #rm -f /home/eno/log/tmp/nohup* fi 配置定时任务 0 0 * * * /bin/sh /data/apps/route/lograte.sh","categories":[],"tags":[],"author":"张存"},{"title":"简单使用普通用户启动tomcat","slug":"简单使用普通用户启动tomcat","date":"2022-04-12T06:36:50.000Z","updated":"2022-04-12T06:37:21.409Z","comments":true,"path":"2022/04/12/jian-dan-shi-yong-pu-tong-yong-hu-qi-dong-tomcat/","link":"","permalink":"https://blog.zhangcun.store/2022/04/12/jian-dan-shi-yong-pu-tong-yong-hu-qi-dong-tomcat/","excerpt":"","text":"新建用户tomcat，该用户不能登录 useradd tomcat -s &#39;/sbin/nologin&#39; 将/usr/local/tomcat/bin/startup.sh更名 mv /usr/local/tomcat/bin/startup.sh /usr/local/tomcat/bin/startup_.sh 将/usr/local/tomcat/bin/shutdown.sh更名 mv /usr/local/tomcat/bin/shutdown.sh /usr/local/tomcat/bin/shutdown_.sh 新建启动脚本startup.sh touch /usr/local/tomcat/bin/startup.sh 其内容如下： 复制代码 #!/bin/bash ## set user tomcat to /bin/bash to start server usermod -s /bin/bash tomcat ## use tomcat user to start server su - tomcat -c /usr/local/tomcat_web/bin/startup_.sh ## set user tomcat to /sbin/nologin usermod -s /sbin/nologin tomcat 复制代码 新建关闭脚本shutdown.sh touch /usr/local/tomcat/bin/shutdown.sh 内容如下： 复制代码 #!/bin/bash ## set user tomcat to /bin/bash to shutdown server usermod -s /bin/bash tomcat ## use tomcat user to shudown server su - tomcat -c /usr/local/tomcat_web/bin/shuwdown_.sh ## set user tomcat to /sbin/nologin usermod -s /sbin/nologin tomcat 复制代码 设置tomcat用户权限 chown -R tomcat:tomcat /usr/local/tomcat/ chmod -R 744 /usr/local/tomcat 判断tomcat用户是否存在 ret=`id -u tomcat &gt;&amp; /dev/null` if [ $? -ne 0 ];then echo &quot;not exist&quot; fi 也可以普通用户使用开机启动服务启动tomcat /usr/lib/systemd/system/下新建文件tomcat.service,将下面内容拷贝其中 复制代码 [Unit] Description=Tomcat #After=syslog.target network.target remote-fs.target nss-lookup.target After=syslog.target network.target remote-fs.target nss-lookup.target redis.service mysql.service Requires=mysql.service redis.service [Service] Type=forking PIDFile=/usr/local/tomcat/tomcat.pid ExecStart=/usr/local/tomcat/bin/startup.sh ExecReload=/bin/kill -s HUP $MAINPID ExecStop=/usr/local/tomcat/bin/shutdown.sh PrivateTmp=true User=tomcat [Install] WantedBy=multi-user.target 复制代码 注册到系统服务 systemctl enable tomcat.service 使新注册服务生效 systemctl daemon-reload","categories":[],"tags":[],"author":"张存"},{"title":"查看 docker 容器使用的资源","slug":"查看-docker-容器使用的资源","date":"2022-04-12T06:18:33.000Z","updated":"2022-04-12T06:24:05.710Z","comments":true,"path":"2022/04/12/cha-kan-docker-rong-qi-shi-yong-de-zi-yuan/","link":"","permalink":"https://blog.zhangcun.store/2022/04/12/cha-kan-docker-rong-qi-shi-yong-de-zi-yuan/","excerpt":"","text":"在容器的使用过程中，如果能及时的掌握容器使用的系统资源，无论对开发还是运维工作都是非常有益的。 幸运的是 docker 自己就提供了这样的命令：docker stats。 默认输出 docker stats 命令用来显示容器使用的系统资源。不带任何选项执行 docker stats 命令： $ docker stats 默认情况下，stats 命令会每隔 1 秒钟刷新一次输出的内容直到你按下 ctrl + c。下面是输出的主要内容： [CONTAINER]：以短格式显示容器的 ID。 [CPU %]：CPU 的使用情况。 [MEM USAGE / LIMIT]：当前使用的内存和最大可以使用的内存。 [MEM %]：以百分比的形式显示内存使用情况。 [NET I/O]：网络 I/O 数据。 [BLOCK I/O]：磁盘 I/O 数据。 [PIDS]：PID 号。 只返回当前的状态 如果不想持续的监控容器使用资源的情况，可以通过 --no-stream 选项只输出当前的状态： $ docker stats --no-stream 这样输出的结果就不会变化了，看起来省劲不少。 只输出指定的容器 如果我们只想查看个别容器的资源使用情况，可以为 docker stats 命令显式的指定目标容器的名称或者是 ID： $ docker stats --no-stream registry 1493 当有很多的容器在运行时，这样的结果看起来会清爽一些。这里的 registry 和 1493 分别是容器的名称和容器的 ID。注意，多个容器的名称或者是 ID 之间需要用空格进行分割。 细心的同学可能已经发现了，第一列不再显示默认的容器 ID，而是显示了我们传入的容器名称和 ID。基于此，我们可以通过简单的方式使用容器的名称替代默认输出中的容器 ID： $ docker stats $(docker ps --format=&#123;&#123;.Names&#125;&#125;) 用容器的名称替代 ID 后输出的结果是不是友好一些？ 格式化输出的结果 我们在前面搞了点小手段把输出中的容器 ID 替换成了名称。其实 docker stats 命令支持我们通过 --format 选项自定义输出的内容和格式： $ docker stats --format &quot;table &#123;&#123;.Name&#125;&#125;\\t&#123;&#123;.CPUPerc&#125;&#125;\\t&#123;&#123;.MemUsage&#125;&#125;&quot; 上面的命令中我们只输出了 Name, CPUPerc 和 Memusage 三列。下面是自定义的格式中可以使用的所有占位符： .Container 根据用户指定的名称显示容器的名称或 ID。 .Name 容器名称。 .ID 容器 ID。 .CPUPerc CPU 使用率。 .MemUsage 内存使用量。 .NetIO 网络 I/O。 .BlockIO 磁盘 I/O。 .MemPerc 内存使用率。 .PIDs PID 号。 有了这些信息我们就可以完全按照自己的需求或者是偏好来控制 docker stats 命令输出的内容了。 除了以 table 格式输出结果，还可以通过 format 选项输出 json 格式的结果： $ docker stats --no-stream --format \\ &quot;&#123;\\&quot;container\\&quot;:\\&quot;&#123;&#123; .Container &#125;&#125;\\&quot;,\\&quot;memory\\&quot;:&#123;\\&quot;raw\\&quot;:\\&quot;&#123;&#123; .MemUsage &#125;&#125;\\&quot;, \\&quot;percent\\&quot;:\\&quot;&#123;&#123; .MemPerc &#125;&#125;\\&quot;&#125;,\\&quot;cpu\\&quot;:\\&quot;&#123;&#123; .CPUPerc &#125;&#125;\\&quot;&#125;&quot; 总结 通过 docker stats 命令我们可以看到容器使用系统资源的情况。这为我们进一步的约束容器可用资源或者是调查与资源相关的问题提供了依据。除了 docker 自带的命令，像 glances 等工具也已经支持查看容器使用的资源情况了，有兴趣的朋友可以去了解一下。","categories":[],"tags":[],"author":"张存"},{"title":"Ubuntu 20.04 在启动界面无限期等待：“a start job is running for hold until boot process finishes”","slug":"Ubuntu-20-04-在启动界面无限期等待：“a-start-job-is-running-for-hold-until-boot-process-finishes”","date":"2022-04-12T06:14:56.000Z","updated":"2022-04-12T06:14:58.574Z","comments":true,"path":"2022/04/12/ubuntu-20-04-zai-qi-dong-jie-mian-wu-xian-qi-deng-dai-a-start-job-is-running-for-hold-until-boot-process-finishes/","link":"","permalink":"https://blog.zhangcun.store/2022/04/12/ubuntu-20-04-zai-qi-dong-jie-mian-wu-xian-qi-deng-dai-a-start-job-is-running-for-hold-until-boot-process-finishes/","excerpt":"","text":"在一次更新操作后，进入系统，一直卡在启动动画界面，显式“正在检查磁盘文件系统”。 按方向键（左），进入TTY模式，显示无限期等待。 a start job is running for hold until boot process finishes ... 此时，出现了两个情况：1、按住CTRL + ALT + F3进入TTY3，然后再按住CTRL + ALT + F1切换图像登录界面，系统正常进入GDM登录界面。2、上述操作后，依旧无法正常进入GDM登录界面。强制关闭系统（此时ALT + PRINT + REISUB大法也无法正常重启），通过恢复模式进入Ubuntu系统。猜测可能是系统更新后，GDM配置错误。 打开命令行，键入dpkg-reconfigure gdm3，重新配置GDM。重启系统，正常进入登录界面。","categories":[],"tags":[],"author":"张存"},{"title":"配置Samba支持用户Web直接修改自己的登录密码","slug":"配置Samba支持用户Web直接修改自己的登录密码","date":"2022-04-12T06:12:01.000Z","updated":"2022-04-12T06:12:04.924Z","comments":true,"path":"2022/04/12/pei-zhi-samba-zhi-chi-yong-hu-web-zhi-jie-xiu-gai-zi-ji-de-deng-lu-mi-ma/","link":"","permalink":"https://blog.zhangcun.store/2022/04/12/pei-zhi-samba-zhi-chi-yong-hu-web-zhi-jie-xiu-gai-zi-ji-de-deng-lu-mi-ma/","excerpt":"","text":"前言：公司新进了一批存储，于是一台新的R710服务器被用于这个存储的载体，而这次因为这个存储大家都抢着用，于是，Samba的需求也就应声而出，实际上按照网上铺天盖地的文档，配置个samba非常简单，即便是多部门多人使用，也仅仅只是多做一些设置。但是，为了方便大家，我们遇到了一个新的需求： 让用户自己修改自己Samba账号的密码 目标： 配置Samba，让用户能够修改自己的密码 分析： 因为之前没有配置过这样的内容，所以先google一下，于是网上的众多网友给出了4种解决办法： 方法一： 给予使用者 telnet/ssh 登入的权限，登陆到服务器运行smbpasswd进行修改密码。 评论：很多其他部门的同事作为Windows终端的用户根本没听说过Linux，更别说使用了，即便是简单的修改密码，况且linux上给他们设置的账号都是nologin，所以这种方式十分不科学。 方法二： 把samba建成pdc， windows加入域中， samba用户通过windows登陆域， samba用户在windows上按“ctrl+alt+del”修改密码 评论：我们的网络受其他分公司共同控制，而且这台Linux不打算加域。 方法三： 采用LDAP来做。 评论：我们的LDAP离我们还略微遥远……而这台机器作为我们的私有，不打算让其他更多分公司的人所使用。 方法四： 或者是changepassword来通过web改密码。 评论：在自己写hosts的情况下，这种看似是比较简单且人性化的了。 方案： 使用changepassword这个软件达到“让用户自己修改Samba的密码”的功效。 实际上，在深入的研究了网上所谓的使用changpassword方案让用户修改密码之后，发现实际上原理是这样的： 1.changepassword这个软件是能让用户从web界面修改系统密码的一款软件，它并没有让你获得修改samba密码的功能！ 2.而如何实现修改samba密码的功能呢，就要用到pam_smbpass.so这个模块，它才是真正能让samba密码和系统密码同步的利器！ 于是，实际上的原理其实是，用户通过Web页面使用changepassword来修改系统的密码，然后由pam_smbpass.so模块自动将系统密码同步给了samba，以达到用户修改samba密码的目的。 实现： 1.我的系统环境如下： 操作系统：CentOS 5.8 已装服务：Samba，且启动正常 2.安装changerpassword，实现Web界面修改系统密码 changerpassword的官网： http://changepassword.sourceforge.net/ wget http://sourceforge.net/projects/changepassword/files/changepassword/0.9/changepassword-0.9.tar.gz tar zxvf changepassword-0.9.tar.gz cd changepassword-0.9 修改conf.h头文件，设置软件修改密码使用的临时目录（本来为/tmp，但是实际上是不能用的，要新建一个权限为777的目录） vim conf.h 将前三行的定义修改为自己创建的目录（这里我修改到了/var/smbchangepwd目录下）： // temporary directory and files to use char TMPFILE[]=&quot;/var/smbchangepwd/changepassword-shadow-XXXXXX&quot;; char TMPSMBFILE[]=&quot;/var/smbchangepwd/changepassword-smb-XXXXXX&quot;; char TMPSQUIDFILE[]=&quot;/var/smbchangepwd/changepassword-squid-XXXXXX&quot;; 创建需要用到的目录（第二个为编译configure时候用到的cgidir） mkdir –pv /var/smbchangepwd mkdir –pv /home/webuser/www/samba-change-passwd 编译安装 ./configure --enable-cgidir=/home/webuser/www/samba-change-passwd --enable-language=English --enable-smbpasswd=/etc/samba/smbpasswd --disable-squidpasswd --enable-logo=opentech.jpg 这里解释一下: --enable-cgidir : 这个目录是Web页面要读取的目录，一般可以设置为网站的根目录，或者网站根目录下的某个目录，比如/var/www/smb/，程序会将最后的web访问页放在这个目录中。 --enable-language: 设置程序的显示语言，里面支持Chinese --enable-smbpasswd: smb的密码文件存放位置 --disable-squidpasswd: 禁用squid同步密码 --enable-logo:这是装饰Web页面中的标题的图片，可以随便指定，只要是http支持的图片格式都可以，需要我们手动放一个图片在cgidir中。 按照官方的来的话这里只要直接make，完后make install 即可，但是，从我自己安装的经验来看，这里一定会报错的，报错如下： DSMBPASSWD=\\&quot;/etc/samba/smbpasswd\\&quot; -DSQUIDPASSWD=\\&quot;no\\&quot; -DLOGO=\\&quot;none\\&quot; -L./smbencrypt –ldes /usr/bin/ld: skipping incompatible ./smbencrypt/libdes.a when searching for –ldes /usr/bin/ld: cannot find –ldes collect2: ld returned 1 exit status make: *** [changepassword.cgi] Error 1 从报错可以看到/usr/bin/ld: cannot find –ldes ，网上有不少解决办法，实际上那都无法解决根本问题，而官方实际上也知道会遇到这个问题，于是我们只需重新编译加载libdes即可： cd smbencrypt/ tar -xzvf libdes-4.04b.tar.gz cd des/ make cp libdes.a ../ cd ../.. 这时从新make,make install即可完成安装： make make install 安装程序会拷贝一个叫changepassword.cgi的文件到我们指定的--cgidir目录，这时，只要我们配置好http,确保能从web直接访问到这个文件即可。当然，别忘了拷贝一个你喜欢的图片到--cgidir所指定的那个目录,名字当然就用那个--logo的名字~ 这里我的环境由于用的是lighttpd做的web，所以我在lighttpd上加入这样的支持（这个根据自己Web配置不同自己添加Apache默认实际上不用配置的）： vim /etc/lighttpd/applications.conf else $HTTP[&quot;host&quot;] =~ &quot;^samba&quot; &#123; server.document-root = &quot;/home/webuser/www/samba-change-passwd&quot; cgi.assign = ( &quot;.cgi&quot; =&gt; &quot;&quot; ) &#125; OK,一切就绪后，我们打开Web，在浏览器中输入： http://你的ip/如果你还有目录/changepassword.cgi 我这里是： 3.实现samba与系统密码同步 实际上配置samba与系统密码同步的原理十分简单，我们都知道密码都是由Pam进行管理的，理论上，当我们使用命令来修改系统密码的时候是调用了pam的密码管理机制，才修改成功的，那么我们其实只要在Pam里加上当修改系统密码的时候也一起让pam把samba的密码给修改掉，我们就赢了~~ 于是带着这样的想法，我们找到了一个模块，samba官方提供的专门用于使用pam来管理密码的模块：pam_smbpass.so 它的位置位于： x86 : /lib/security/pam_smbpass.so x64 : /lib64/security/pam_smbpass.so 然后我们只需要将这个模块加入到密码验证的机制里即可： vim /etc/pam.d/system-auth 编辑system-auth这个pam文件 修改里面的password段插入一行新的password行（这里我的system-auth的配置，注意我加了一行关于pam_smbpass.so的内容）： auth required pam_env.so auth sufficient pam_unix.so nullok try_first_pass auth requisite pam_succeed_if.so uid &gt;= 500 quiet auth required pam_deny.so account required pam_unix.so account sufficient pam_succeed_if.so uid &lt; 500 quiet account required pam_permit.so password requisite pam_cracklib.so try_first_pass retry=3 password required /lib64/security/pam_smbpass.so nullok use_authtok try_first_pass password sufficient pam_unix.so md5 shadow nullok try_first_pass use_authtok password required pam_deny.so session optional pam_keyinit.so revoke session required pam_limits.so session [success=1 default=ignore] pam_succeed_if.so service in crond quiet use_uid session required pam_unix.so 然后保存，这时理论上，当你修改系统密码的时候，关联的这个模块也会修改samba的密码。 但是这还不够，我们还要对samba进行一些设置： vim /etc/samba/smb.conf 在[global]段设置samba的加密方式为： security = user # passdb backend = tdbsam encrypt passwords = yes smb passwd file = /etc/samba/smbpasswd pam password change = yes 注意，请务必注释掉默认的passdb backend = tdbsam项 然后重启samba: /etc/init.d/smb restart 如果一切正确的话，在/etc/samba下应该已经有一个 smbpasswd这个文件了。这个文件里记录的就是所有可以登陆samba的用户以及密码，初始情况下应该是空才对。 接下来就需要我们手动使用smbpasswd –a 往里添加用户了。 注意：只有在smbpasswd中已经存在的系统用户，当你修改该系统用户的密码的时候，才会一同修改smbpasswd中的用户。 这样，我们就达成了让用户从Web修改自己用户系统密码，然后同步到smb的任务。 后记： 在刚开始打算查找如何完成这个samba配置的时候，从网上获取了无数的内容，但是，发现网友全都是摘抄，根本没有自己去验证过配置的正确性，也根本没有人能解释为什么这样配置。包括使用什么： # passwd chat = **NEW*NUIX*password* %n\\n *Retype*new*UNIX*password* %n\\n *successfully* # passwd program = /usr/bin/passwd %u # unix password sync = yes 这样的配置我也试了，的确smb的密码文件能刷新，但是实际上却无法进行同步。 而smb官方给的文档排版和分类也非常差，实在是不能忍。","categories":[],"tags":[],"author":"张存"},{"title":"Mysql 查看连接数,状态 最大并发数","slug":"Mysql-查看连接数-状态-最大并发数","date":"2022-04-12T05:53:04.000Z","updated":"2022-04-12T05:53:14.188Z","comments":true,"path":"2022/04/12/mysql-cha-kan-lian-jie-shu-zhuang-tai-zui-da-bing-fa-shu/","link":"","permalink":"https://blog.zhangcun.store/2022/04/12/mysql-cha-kan-lian-jie-shu-zhuang-tai-zui-da-bing-fa-shu/","excerpt":"","text":"show variables like &#39;%max_connections%&#39;; 查看最大连接数 set global max_connections=1000 重新设置 复制代码 mysql&gt; show status like &#39;Threads%&#39;; +-------------------+-------+ | Variable_name | Value | +-------------------+-------+ | Threads_cached | 58 | | Threads_connected | 57 | ###这个数值指的是打开的连接数 | Threads_created | 3676 | | Threads_running | 4 | ###这个数值指的是激活的连接数，这个数值一般远低于connected数值 +-------------------+-------+ 复制代码 Threads_connected 跟show processlist结果相同，表示当前连接数。准确的来说，Threads_running是代表当前并发数 复制代码 这是是查询数据库当前设置的最大连接数 mysql&gt; show variables like &#39;%max_connections%&#39;; +-----------------+-------+ | Variable_name | Value | +-----------------+-------+ | max_connections | 1000 | +-----------------+-------+ 可以在/etc/my.cnf里面设置数据库的最大连接数 [mysqld] max_connections = 1000 复制代码 MySQL服务器的线程数需要在一个合理的范围之内，这样才能保证MySQL服务器健康平稳地运行。Threads_created表示创建过的线程数，通过查看Threads_created就可以查看MySQL服务器的进程状态。 复制代码 mysql&gt; show global status like &#39;Thread%&#39;; +-------------------+-------+ | Variable_name | Value | +-------------------+-------+ | Threads_cached | 46 | | Threads_connected | 2 | | Threads_created | 570 | | Threads_running | 1 | +-------------------+-------+ 复制代码 如果我们在MySQL服务器配置文件中设置了thread_cache_size，当客户端断开之后，服务器处理此客户的线程将会缓存起来以响应下一个客户而不是销毁(前提是缓存数未达上限)。 Threads_created表示创建过的线程数，如果发现Threads_created值过大的话，表明MySQL服务器一直在创建线程，这也是比较耗资源，可以适当增加配置文件中thread_cache_size值，查询服务器 thread_cache_size配置： 复制代码 mysql&gt; show variables like &#39;thread_cache_size&#39;; +-------------------+-------+ | Variable_name | Value | +-------------------+-------+ | thread_cache_size | 64 | +-------------------+-------+ 示例中的服务器还是挺健康的 复制代码 1.show status Threads_connected 当前的连接数 Connections 试图连接到(不管是否成功)MySQL服务器的连接数。 Max_used_connections 服务器启动后已经同时使用的连接的最大数量。 2.set GLOBAL max_connections=连接数; flush privileges 3.修改/etc/my.cnf中的max_connections 4.show processlist 显示当前正在执行的MySQL连接 5.mysqladmin -u&lt;user&gt; -p&lt;pwd&gt; -h&lt;host&gt; status 显示当前mysql状态 Uptime: 13131 Threads: 1 Questions: 22 Slow queries: 0 Opens: 16 Flush tables: 1 Open tables: 1 Queries per second avg: 0.1 mysqladmin -u&lt;user&gt; -p&lt;pwd&gt; -h&lt;host&gt; extended-status 显示mysql的其他状态 +-----------------------------------+----------+ | Variable_name | Value | +-----------------------------------+----------+ | Aborted_clients | 0 | | Aborted_connects | 1 | | Binlog_cache_disk_use | 0 | | Binlog_cache_use | 0 | | Bytes_received | 1152 | | Bytes_sent | 10400 | | Com_admin_commands | 0 | | Com_assign_to_keycache | 0 | ............................................................. | Threads_cached | 2 | | Threads_connected | 1 | | Threads_created | 3 | | Threads_running | 1 | | Uptime | 13509 | | Uptime_since_flush_status | 13509 | +-----------------------------------+----------+ 命令： show processlist; 如果是root帐号，你能看到所有用户的当前连接。如果是其它普通帐号，只能看到自己占用的连接。 show processlist;只列出前100条，如果想全列出请使用show full processlist; MySQL&gt; show processlist; 命令： show status; 命令：show status like &#39;%下面变量%&#39;; Aborted_clients 由于客户没有正确关闭连接已经死掉，已经放弃的连接数量。 Aborted_connects 尝试已经失败的MySQL服务器的连接的次数。 Connections 试图连接MySQL服务器的次数。 Created_tmp_tables 当执行语句时，已经被创造了的隐含临时表的数量。 Delayed_insert_threads 正在使用的延迟插入处理器线程的数量。 Delayed_writes 用INSERT DELAYED写入的行数。 Delayed_errors 用INSERT DELAYED写入的发生某些错误(可能重复键值)的行数。 Flush_commands 执行FLUSH命令的次数。 Handler_delete 请求从一张表中删除行的次数。 Handler_read_first 请求读入表中第一行的次数。 Handler_read_key 请求数字基于键读行。 Handler_read_next 请求读入基于一个键的一行的次数。 Handler_read_rnd 请求读入基于一个固定位置的一行的次数。 Handler_update 请求更新表中一行的次数。 Handler_write 请求向表中插入一行的次数。 Key_blocks_used 用于关键字缓存的块的数量。 Key_read_requests 请求从缓存读入一个键值的次数。 Key_reads 从磁盘物理读入一个键值的次数。 Key_write_requests 请求将一个关键字块写入缓存次数。 Key_writes 将一个键值块物理写入磁盘的次数。 Max_used_connections 同时使用的连接的最大数目。 Not_flushed_key_blocks 在键缓存中已经改变但是还没被清空到磁盘上的键块。 Not_flushed_delayed_rows 在INSERT DELAY队列中等待写入的行的数量。 Open_tables 打开表的数量。 Open_files 打开文件的数量。 Open_streams 打开流的数量(主要用于日志记载） Opened_tables 已经打开的表的数量。 Questions 发往服务器的查询的数量。 Slow_queries 要花超过long_query_time时间的查询数量。 Threads_connected 当前打开的连接的数量。 Threads_running 不在睡眠的线程数量。 Uptime 服务器工作了多少秒。 My.ini配置 虚拟内存 innodb_buffer_pool_size=576M -&gt;128M InnoDB引擎缓冲区 query_cache_size=100M -&gt;32 查询缓存 tmp_table_size=102M -&gt;32M 临时表大小 key_buffer_size=16m -&gt;8M 设置max_connections 命令：show variables like &#39;%max_connections%&#39; （这个办法在debian＋mysql Ver 12.22 Distrib 4.0.22, for pc-Linux (i386) 里实验了） 设置办法是在my.cnf文件中，添加下面的最后红色的一行： -------------------------------------------------------------------------------- [mysqld] port=3306 #socket=MySQL skip-locking set-variable = key_buffer=16K set-variable = max_allowed_packet=1M set-variable = thread_stack=64K set-variable = table_cache=4 set-variable = sort_buffer=64K set-variable = net_buffer_length=2K set-variable = max_connections=32000 （在院里的DELL机器mysql4.0里的语法不同 max_connecionts=2000 直接这么写就好了 ） -------------------------------------------------------------------------------- 修改完毕后，重启MySQL即可。当然，为了确保设置正确，应该查看一下max_connections。 注意： 1、虽然这里写的32000。但实际MySQL服务器允许的最大连接数16384； 2、除max_connections外，上述其他配置应该根据你们系统自身需要进行配置，不必拘泥； 3、添加了最大允许连接数，对系统消耗增加不大。 4、如果你的mysql用的是my.ini作配置文件，设置类似，但设置的格式要稍作变通。 用mysqld --help 可以查看到max_connections 变量。 或者 mysql -uuser -p 后mysql&gt;show variables; 也会看到max_connections 。 下面是修改张老师 的redhat9的方法： 先是mysql -uw01f -p mysql&gt;show variables; 看到max_connections 为100 mysql&gt;exit; vi /etc/my.cnf [mysqld] set-variable=max_connections=250 #加入这些内容 :wq /etc/init.d/mysqld restart 好了，行了。","categories":[],"tags":[],"author":"张存"},{"title":"nginx通过upstream实现负载均衡","slug":"nginx通过upstream实现负载均衡","date":"2022-04-12T05:32:53.000Z","updated":"2022-04-12T05:36:32.724Z","comments":true,"path":"2022/04/12/nginx-tong-guo-upstream-shi-xian-fu-zai-jun-heng/","link":"","permalink":"https://blog.zhangcun.store/2022/04/12/nginx-tong-guo-upstream-shi-xian-fu-zai-jun-heng/","excerpt":"","text":"随着业务和用户不断增加，单台服务器无法满足业务需求，产生服务器集群的场景。为了能充分利用服务器集群，最理想的方式就是整个集群的利用率都很平均且稳定在理想值范围内。 负载均衡（Load Balance）就是为了满足能够均衡的利用整个服务器集群从而产生的一种算法 ，常见的实现策略有：随机、轮询、哈希、一致性哈希和加权。 nginx目前比较常用的模块有： 1. 轮询 定义：依次把客户端请求分配到不同的服务器中 配置示例： 复制代码 upstream zhangQ &#123; server ip1:port1; server ip2:port2; &#125; server &#123; listen 80; server_name localhost; #charset koi8-r; #access_log /var/log/nginx/host.access.log main; location / &#123; proxy_pass http://zhangQ; &#125; &#125; 复制代码 2. 最少连接 定义：把客户端请求分配到连接数最少的服务器中 如果每台服务器处理业务的时间都一样，那么此策略与轮询差不多。 如果每台服务器处理业务的时间不一样，那么采用轮询算法会导致业务逻辑处理较慢的服务器压力越来越大负载较高，这样的业务场景，把客户端请求分配到连接数较少的服务器能达到更好的负载效果。 配置示例： 复制代码 upstream zhangQ &#123; least_conn; #实际就是比轮询多这一行 server ip1:port1; server ip2:port2; &#125; server &#123; listen 80; server_name localhost; #charset koi8-r; #access_log /var/log/nginx/host.access.log main; location / &#123; proxy_pass http://zhangQ; &#125; &#125; 复制代码 3. ip_hash 定义：把访问的客户端的ip利用hash算法计算为一个数值，同一个数值会落到相同的服务器。 涉及到负载均衡基本上都会设计到session的保持，但使用ip_hash就不需要关注这个问题。 配置示例： 复制代码 upstream zhangQ &#123; ip_hash; #实际就是比轮询多这一行 server ip1:port1; server ip2:port2; &#125; server &#123; listen 80; server_name localhost; #charset koi8-r; #access_log /var/log/nginx/host.access.log main; location / &#123; proxy_pass http://zhangQ; &#125; &#125; 复制代码 4. weight 定义：权重实际就是加权轮询，根据加权值会优先分配到权重高的服务器 服务器基本都是配置不一，高配置服务器通常都会比低配置服务器赋予较高的权重值。 配置示例： 复制代码 upstream zhangQ &#123; server ip1:port1 weight=3; #加上weight server ip2:port2 weight=1; &#125; server &#123; listen 80; server_name localhost; #charset koi8-r; #access_log /var/log/nginx/host.access.log main; location / &#123; proxy_pass http://zhangQ; &#125; &#125; 复制代码 如果按照如上配置，就是每4次客户端请求，会有3次落在ip1上，1次落在ip2上。 附上upstream中常用的几个属性配置： 名称 定义 示例 fail_timeout 可以理解为熔断时间，经过这个配置的时间如果服务器没响应则失败 fail_timeout=2s max_fails 最大失败数，默认值是1，当超过最大次数时，返回proxy_next_upstream模块定义的错误. max_fails=2 down 有此标记的服务器不参与负载 backup 当所有非backup服务器忙或者down的时候会请求这台服务器","categories":[],"tags":[],"author":"张存"},{"title":"centOS7中安装redis5.0.4","slug":"centOS7中安装redis5-0-4","date":"2022-04-12T05:25:28.000Z","updated":"2022-04-12T05:26:20.372Z","comments":true,"path":"2022/04/12/centos7-zhong-an-zhuang-redis5-0-4/","link":"","permalink":"https://blog.zhangcun.store/2022/04/12/centos7-zhong-an-zhuang-redis5-0-4/","excerpt":"","text":"一：简介是完全开源免费的，用C语言编写的，遵守BSD协议，是一个高性能的(key/value)分布式内存数据库，基于内存运行并支持持久化的NoSQL数据库，是当前最热门的NoSql数据库之一，也被人们称为数据结构服务器。 二：安装Redis5.0.4下载 #切换目录(所有第三方软件都放在opt)cd opt#下载wget http://download.redis.io/releases/redis-5.0.4.tar.gz#如果过 wget 命令出错，执行：yum -y install wget#再次下载wget http://download.redis.io/releases/redis-5.0.4.tar.gz解压 tar -xzvf redis-5.0.4.tar.gzcd redis-5.0.4安装gcc编译工具 #查看gcc目前版本gcc -v#如果gcc -v找不到任何东西则安装gcc，如果有则跳过此步骤直接进行第4步yum -y install gcc编译源码 #编译make#make完成后继续执行make install配置后台运行 如果想后台启动。需要修改redis.conf文件 #备份配置文件 redis.confmkdir -p /myrediscp redis.conf /myredis/#编辑vim /myredis/redis.conf#daemonize no 改为 daemonize yes#protected-mode yes 改为 protected-mode no#注释 bind 启动 #启动服务端src/redis-server /myredis/redis.conf#启动客户端src/redis-cli -p 6379#关闭 redis 服务shutdownexit","categories":[],"tags":[],"author":"张存"},{"title":"ElasticSearch 429 Too Many Requests circuit_breaking_exception","slug":"ElasticSearch-429-Too-Many-Requests-circuit-breaking-exception","date":"2022-04-12T05:20:04.000Z","updated":"2022-04-12T05:20:11.291Z","comments":true,"path":"2022/04/12/elasticsearch-429-too-many-requests-circuit-breaking-exception/","link":"","permalink":"https://blog.zhangcun.store/2022/04/12/elasticsearch-429-too-many-requests-circuit-breaking-exception/","excerpt":"","text":"错误提示 &#123; &quot;statusCode&quot;: 429, &quot;error&quot;: &quot;Too Many Requests&quot;, &quot;message&quot;: &quot;[circuit_breaking_exception] [parent] Data too large, data for [&lt;http_request&gt;] would be [2087772160/1.9gb], which is larger than the limit of [1503238553/1.3gb], real usage: [2087772160/1.9gb], new bytes reserved: [0/0b], usages [request=0/0b, fielddata=1219/1.1kb, in_flight_requests=0/0b, accounting=605971/591.7kb], with &#123; bytes_wanted=2087772160 &amp; bytes_limit=1503238553 &amp; durability=\\&quot;PERMANENT\\&quot; &#125;&quot; &#125; 重要解决办法 关闭circuit检查： indices.breaker.type: none 集群config/jvm.options设置如下 -Xms2g -Xmx2g #-XX:+UseConcMarkSweepGC -XX:+UseG1GC -XX:CMSInitiatingOccupancyFraction=75 -XX:+UseCMSInitiatingOccupancyOnly 以下这些都不用看了 再尝试其他查询也是如此。经排查，原来是ES默认的缓存设置让缓存区只进不出引起的，具体分析一下。 ES缓存区概述 ES在查询时，会将索引数据缓存在内存（JVM）中： 上图是ES的JVM Heap中的状况，可以看到有两条界限：驱逐线 和 断路器。当缓存数据到达驱逐线时，会自动驱逐掉部分数据，把缓存保持在安全的范围内。 当用户准备执行某个查询操作时，断路器就起作用了，缓存数据+当前查询需要缓存的数据量到达断路器限制时，会返回Data too large错误，阻止用户进行这个查询操作。 ES把缓存数据分成两类，FieldData和其他数据，我们接下来详细看FieldData，它是造成我们这次异常的“元凶”。 FieldData ES配置中提到的FieldData指的是字段数据。当排序（sort），统计（aggs）时，ES把涉及到的字段数据全部读取到内存（JVM Heap）中进行操作。相当于进行了数据缓存，提升查询效率。 监控FieldData 仔细监控fielddata使用了多少内存以及是否有数据被驱逐是非常重要的。 ielddata缓存使用可以通过下面的方式来监控 # 对于单个索引使用 &#123;ref&#125;indices-stats.html[indices-stats API] GET /_stats/fielddata?fields=* # 对于单个节点使用 &#123;ref&#125;cluster-nodes-stats.html[nodes-stats API] GET /_nodes/stats/indices/fielddata?fields=* #或者甚至单个节点单个索引 GET /_nodes/stats/indices/fielddata?level=indices&amp;fields=* # 通过设置 ?fields=* 内存使用按照每个字段分解了 fielddata中的memory_size_in_bytes表示已使用的内存总数，而evictions（驱逐）为0。且经过一段时间观察，字段所占内存大小都没有变化。由此推断，当下的缓存处于无法有效驱逐的状态。 Cache配置 indices.fielddata.cache.size 配置fieldData的Cache大小，可以配百分比也可以配一个准确的数值。cache到达约定的内存大小时会自动清理，驱逐一部分FieldData数据以便容纳新数据。默认值为unbounded无限。 indices.fielddata.cache.expire用于约定多久没有访问到的数据会被驱逐，默认值为-1，即无限。expire配置不推荐使用，按时间驱逐数据会大量消耗性能。而且这个设置在不久之后的版本中将会废弃。 看来，Data too large异常就是由于fielddata.cache的默认值为unbounded导致的了。 FieldData格式 除了缓存取大小之外，我们还可以控制字段数据缓存到内存中的格式。 在mapping中，我们可以这样设置： &#123; &quot;tag&quot;: &#123; &quot;type&quot;: &quot;string&quot;, &quot;fielddata&quot;: &#123; &quot;format&quot;: &quot;fst&quot; &#125; &#125; &#125; 对于String类型，format有以下几种： paged_bytes (默认)：使用大量的内存来存储这个字段的terms和索引。 fst：用FST的形式来存储terms。这在terms有较多共同前缀的情况下可以节约使用的内存，但访问速度上比paged_bytes 要慢。 doc_values：fieldData始终存放在disk中，不加载进内存。访问速度最慢且只有在index:no/not_analyzed的情况适用。 对于数字和地理数据也有可选的format，但相对String更为简单，具体可在api中查看。 从上面我们可以得知一个信息：我们除了配置缓存区大小以外，还可以对不是特别重要却量很大的String类型字段选择使用fst缓存类型来压缩大小。 断路器 fieldData的缓存配置中，有一个点会引起我们的疑问：fielddata的大小是在数据被加载之后才校验的。假如下一个查询准备加载进来的fieldData让缓存区超过可用堆大小会发生什么？很遗憾的是，它将产生一个OOM异常。 断路器就是用来控制cache加载的，它预估当前查询申请使用内存的量，并加以限制。断路器的配置如下： indices.breaker.fielddata.limit：这个 fielddata 断路器限制fielddata的大小，默认情况下为堆大小的60%。 indices.breaker.request.limit：这个 request 断路器估算完成查询的其他部分要求的结构的大小， 默认情况下限制它们到堆大小的40%。 indices.breaker.total.limit：这个 total 断路器封装了 request 和 fielddata 断路器去确保默认情况下这2个部分使用的总内存不超过堆大小的70%。 查询 /_cluster/settings 设置 PUT /_cluster/settings &#123; &quot;persistent&quot;: &#123; &quot;indices.breaker.fielddata.limit&quot;: &quot;60%&quot; &#125; &#125; PUT /_cluster/settings &#123; &quot;persistent&quot;: &#123; &quot;indices.breaker.request.limit&quot;: &quot;40%&quot; &#125; &#125; PUT /_cluster/settings &#123; &quot;persistent&quot;: &#123; &quot;indices.breaker.total.limit&quot;: &quot;70%&quot; &#125; &#125; 断路器限制可以通过文件 config/elasticsearch.yml 指定，也可以在集群上动态更新： PUT /_cluster/settings &#123; &quot;persistent&quot; : &#123; &quot;indices.breaker.fielddata.limit&quot; : 40% &#125; &#125; 当缓存区大小到达断路器所配置的大小时会发生什么事呢？答案是：会返回开头我们说的Data too large异常。这个设定是希望引起用户对ES服务的反思，我们的配置有问题吗？是不是查询语句的形式不对，一条查询语句需要使用这么多缓存吗？ 在文件 config/elasticsearch.yml 文件中设置缓存使用回收 indices.fielddata.cache.size: 40% 总结 1.这次Data too large异常是ES默认配置的一个坑，我们没有配置indices.fielddata.cache.size，它就不回收缓存了。缓存到达限制大小，无法往里插入数据。个人感觉这个默认配置不友好，不知ES是否在未来版本有所改进。 2. 当前fieldData缓存区大小 &lt; indices.fielddata.cache.size 当前fieldData缓存区大小+下一个查询加载进来的fieldData &lt; indices.breaker.fielddata.limit fielddata.limit的配置需要比fielddata.cache.size稍大。而fieldData缓存到达fielddata.cache.size的时候就会启动自动清理机制。expire配置不建议使用。 3.indices.breaker.request.limit限制查询的其他部分需要用的内存大小。indices.breaker.total.limit限制总（fieldData+其他部分）大小。 4.创建mapping时，可以设置fieldData format控制缓存数据格式","categories":[],"tags":[],"author":"张存"},{"title":"docker-compose安装mongodb","slug":"docker-compose安装mongodb","date":"2022-04-08T05:41:00.000Z","updated":"2022-04-08T05:42:04.427Z","comments":true,"path":"2022/04/08/docker-compose-an-zhuang-mongodb/","link":"","permalink":"https://blog.zhangcun.store/2022/04/08/docker-compose-an-zhuang-mongodb/","excerpt":"","text":"1. 配置docker-compose.yml #该Yaml文件改编自DockerHub中的配置文件 version: &#39;3.8&#39; services: mongo: image: mongo:4.4.0 #根据需要选择自己的镜像 restart: always ports: - 27017:27017 #对外暴露停供服务的端口，正式生产的时候理论不用暴露。 volumes: - /docker/mongodb/data/db:/data/db # 挂载数据目录 - /docker/mongodb/data/log:/var/log/mongodb # 挂载日志目录 - /docker/mongodb/data/config:/etc/mongo # 挂载配置目录 # command: --config /docker/mongodb/mongod.conf # 配置文件 2. 创建配置文件 # mongod.conf # for documentation of all options, see: # http://docs.mongodb.org/manual/reference/configuration-options/ # Where and how to store data. storage: dbPath: /data/db journal: enabled: true directoryPerDB: true engine: wiredTiger wiredTiger: engineConfig: cacheSizeGB: 8 directoryForIndexes: true # where to write logging data. systemLog: destination: file logAppend: true path: /var/log/mongodb/mongod.log # network interfaces net: port: 27017 bindIp: 0.0.0.0 # how the process runs processManagement: timeZoneInfo: /usr/share/zoneinfo #replication: replication: oplogSizeMB: 51200 replSetName: rs0 3. 运行mongodb docker-compose -f docker-compose.yml up -d 4. 进入mongodb docker exec -it mongo /bin/bash 5. 添加用户 mongo use admin db.createUser(&#123;user:&quot;root&quot;,pwd:&quot;root&quot;,roles:[&#123;role:&#39;root&#39;,db:&#39;admin&#39;&#125;]&#125;) exit","categories":[],"tags":[],"author":"张存"},{"title":"给Linux的history日志 添加时间戳和用户名","slug":"给Linux的history日志-添加时间戳和用户名","date":"2022-04-07T07:11:29.000Z","updated":"2022-04-08T04:15:56.978Z","comments":true,"path":"2022/04/07/gei-linux-de-history-ri-zhi-tian-jia-shi-jian-chuo-he-yong-hu-ming/","link":"","permalink":"https://blog.zhangcun.store/2022/04/07/gei-linux-de-history-ri-zhi-tian-jia-shi-jian-chuo-he-yong-hu-ming/","excerpt":"","text":"在linux日常使用中，可以方便查看history中的哪个用户什么时间发的什么命令。 在 /etc/profile 中 添加 export HISTTIMEFORMAT=”%F %T whoami “效果： 1086 2017-07-24 18:51:23 root history 1087 2017-07-24 18:51:59 root vim /etc/profile 1088 2017-07-24 18:52:28 root source /etc/profile 1089 2017-07-24 18:52:31 root history 1090 2017-07-24 18:52:42 root vim /etc/profile 1091 2017-07-24 18:52:55 root source /etc/profile 1092 2017-07-24 18:52:58 root history","categories":[],"tags":[],"author":"张存"},{"title":"shell脚本判断端口是否打开","slug":"shell脚本判断端口是否打开","date":"2022-04-07T03:47:31.000Z","updated":"2022-04-07T03:47:32.276Z","comments":true,"path":"2022/04/07/shell-jiao-ben-pan-duan-duan-kou-shi-fou-da-kai/","link":"","permalink":"https://blog.zhangcun.store/2022/04/07/shell-jiao-ben-pan-duan-duan-kou-shi-fou-da-kai/","excerpt":"","text":"[root@www zabbix_scripts]# cat check_httpd.sh #!/bin/bash a=`lsof -i:80 | wc -l` if [ &quot;$a&quot; -gt &quot;0&quot; ];then echo &quot;0&quot; else echo &quot;1&quot; fi","categories":[],"tags":[],"author":"张存"},{"title":"git如何设置使用代理","slug":"git如何设置使用代理","date":"2022-04-07T03:44:43.000Z","updated":"2022-04-07T03:44:53.157Z","comments":true,"path":"2022/04/07/git-ru-he-she-zhi-shi-yong-dai-li/","link":"","permalink":"https://blog.zhangcun.store/2022/04/07/git-ru-he-she-zhi-shi-yong-dai-li/","excerpt":"","text":"使用命令直接设定socks或者http代理即可。 socks代理： git config –global http.proxy ‘socks5://127.0.0.1:1080’ git config –global https.proxy ‘socks5://127.0.0.1:1080’ 如果有问题，可以把单引号去掉试一下，并且将http和https代理都设置上试一下 也可以直接修改~/.gitconfig文件。 vi ~/.gitconfig 新建或修改这两项配置 [http] proxy = socks5://127.0.0.1:1080 [https] proxy = socks5://127.0.0.1:1080 http/https代理 git config –global http.proxy http://127.0.0.1:8080 git config –global https.proxy https://127.0.0.1:8080 然后再git clone等命令就会自动走代理了。 如果要取消代理： git config –global –unset http.proxy git config –global –unset https.proxy 这里要说明一下，带参数是临时的，修改配置文件是永久变更，修改后最好重启所有 git bash 保证设置生效。 查看配置信息： git config -l –global","categories":[],"tags":[],"author":"张存"},{"title":"使用nginx反向代理jenkins","slug":"使用nginx反向代理jenkins","date":"2022-04-07T03:20:48.000Z","updated":"2022-04-07T03:24:16.913Z","comments":true,"path":"2022/04/07/shi-yong-nginx-fan-xiang-dai-li-jenkins/","link":"","permalink":"https://blog.zhangcun.store/2022/04/07/shi-yong-nginx-fan-xiang-dai-li-jenkins/","excerpt":"","text":"在Jenkins 官方网站（http://jenkins-ci.org/）下载最新版本war包。拷贝到 $TOMCAT_HOME/webapps 下（不用解压）。启动tomcat服务。 找到nginx的配置文件，如nginx默认配置文件路径在/usr/local/nginx/conf/nginx.conf。 打开nginx.conf配置文件：sudo vim /usr/local/nginx/conf/nginx.conf 修改配置文件 #user nobody; worker_processes 1; #error_log logs/error.log; #error_log logs/error.log notice; #error_log logs/error.log info; #pid logs/nginx.pid; events { worker_connections 1024; } http { include mime.types; default_type application/octet-stream; sendfile on; #keepalive_timeout 0; keepalive_timeout 65; server &#123; listen 80; server_name localhost; #access_log /var/log/jenkins_access_log main; #error_log /var/log/jenkins_error_log debug_http; client_max_body_size 60M; client_body_buffer_size 512k; location / &#123; proxy_pass http://localhost:8080/; proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; &#125; &#125; } 将上述部分加入到配置文件中。 5.重启nginx服务 service nginx start 6.访问jenkins页面 http://locallhost/jenkins 这样就可以访问到jenkins了，当然我们现在和直接访问jenkins（http://localhost:8080/jenkins） 的区别是少了端口号，这是因为我们在同一台机器上，无法直接体现出jenkins的反向代理功能。","categories":[],"tags":[],"author":"张存"},{"title":"shell 批量检测多台服务器的某个端口","slug":"shell-批量检测多台服务器的某个端口","date":"2022-04-02T05:39:59.000Z","updated":"2022-04-02T05:42:16.844Z","comments":true,"path":"2022/04/02/shell-pi-liang-jian-ce-duo-tai-fu-wu-qi-de-mou-ge-duan-kou/","link":"","permalink":"https://blog.zhangcun.store/2022/04/02/shell-pi-liang-jian-ce-duo-tai-fu-wu-qi-de-mou-ge-duan-kou/","excerpt":"","text":"echo 192.168.1.&#123;1..255&#125; &gt; ip2.txt #!/bin/bash for i in `cat ip2.txt` do #ping $i -c 1 -w 1 |head -n 2 |grep &quot;=&quot; nc -v -w 1 $i 22 if [ $? -eq 0 ] then echo &quot;$i not do ipsec !&quot; &gt;&gt; ./result.txt else echo &quot;$i finish ipsec !&quot; &gt;&gt;./resultdown.txt fi done exit 0","categories":[],"tags":[],"author":"张存"},{"title":"微信网页版地址","slug":"微信网页版地址-1","date":"2022-04-02T05:38:36.000Z","updated":"2022-04-02T09:57:03.018Z","comments":true,"path":"2022/04/02/wei-xin-wang-ye-ban-di-zhi-1/","link":"","permalink":"https://blog.zhangcun.store/2022/04/02/wei-xin-wang-ye-ban-di-zhi-1/","excerpt":"","text":"微信网页版地址 https://wx.qq.com/","categories":[],"tags":[],"author":"张存"},{"title":"docker参数--restart=always的作用","slug":"docker参数-restart-always的作用","date":"2022-03-10T08:12:22.000Z","updated":"2022-03-10T08:12:39.473Z","comments":true,"path":"2022/03/10/docker-can-shu-restart-always-de-zuo-yong/","link":"","permalink":"https://blog.zhangcun.store/2022/03/10/docker-can-shu-restart-always-de-zuo-yong/","excerpt":"","text":"创建容器时没有添加参数 --restart=always ，导致的后果是：当 Docker 重启时，容器未能自动启动。 现在要添加该参数怎么办呢，方法有二： 1、Docker 命令修改 docker container update --restart=always 容器名字 复制代码 操作实例如下： [root@localhost mnt]# docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 46cdfc60b7a6 nginx &quot;nginx -g &#39;daemon ...&quot; About a minute ago Up 42 seconds 80/tcp n3 79d55a734c26 nginx &quot;nginx -g &#39;daemon ...&quot; About a minute ago Up 42 seconds 80/tcp n2 f7b2206c019d nginx &quot;nginx -g &#39;daemon ...&quot; About a minute ago Up 46 seconds 80/tcp n1 [root@localhost mnt]# docker container update --restart=always n1 n1 [root@localhost mnt]# systemctl restart docker [root@localhost mnt]# docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 46cdfc60b7a6 nginx &quot;nginx -g &#39;daemon ...&quot; 2 minutes ago Exited (0) 5 seconds ago n3 79d55a734c26 nginx &quot;nginx -g &#39;daemon ...&quot; 2 minutes ago Exited (0) 5 seconds ago n2 f7b2206c019d nginx &quot;nginx -g &#39;daemon ...&quot; 2 minutes ago Up 2 seconds 80/tcp n1 复制代码 2、直接改配置文件（经测试后无效，修改配置文件后，启动容器后，该参数有自动变成了no，修改不生效） 复制代码 首先停止容器，不然无法修改配置文件 配置文件路径为：/var/lib/docker/containers/容器ID 在该目录下找到一个文件 hostconfig.json ，找到该文件中关键字 RestartPolicy 修改前配置：&quot;RestartPolicy&quot;:&#123;&quot;Name&quot;:&quot;no&quot;,&quot;MaximumRetryCount&quot;:0&#125; 修改后配置：&quot;RestartPolicy&quot;:&#123;&quot;Name&quot;:&quot;always&quot;,&quot;MaximumRetryCount&quot;:0&#125; 最后启动容器。 复制代码 修改docker容器的挂载路径 停止所有docker容器 sudo docker stop $(docker ps -a | awk &#39;&#123; print $1&#125;&#39; | tail -n +2) 停止docker服务 sudo service docker stop 修改mysql路径 cd ~ sudo cp -r mysql/ /home/server/ 备份容器配置文件 cd /var/lib/docker/containers/de9c6501cdd3 cp hostconfig.json hostconfig.json.bak cp config.v2.json config.v2.json.bak 修改hostconfig的冒号前的配置路径 vi hostconfig.json &quot;Binds&quot;: [&quot;/home/server/mysql/conf/my.cnf:/etc/mysql/my.cnf&quot;, &quot;/home/server/mysql/logs:/logs&quot;, &quot;/home/server/mysql/data:/mysql_data&quot;], 修改config的Source的配置路径 复制代码 复制代码 vi config.v2.json &quot;MountPoints&quot;: &#123; &quot;/etc/mysql/my.cnf&quot;: &#123; &quot;Source&quot;: &quot;/home/server/mysql/conf/my.cnf&quot;, &quot;Destination&quot;: &quot;/etc/mysql/my.cnf&quot;, &quot;RW&quot;: true, &quot;Name&quot;: &quot;&quot;, &quot;Driver&quot;: &quot;&quot;, &quot;Relabel&quot;: &quot;&quot;, &quot;Propagation&quot;: &quot;rprivate&quot;, &quot;Named&quot;: false, &quot;ID&quot;: &quot;&quot; &#125;, &quot;/logs&quot;: &#123; &quot;Source&quot;: &quot;/home/server/mysql/logs&quot;, &quot;Destination&quot;: &quot;/logs&quot;, &quot;RW&quot;: true, &quot;Name&quot;: &quot;&quot;, &quot;Driver&quot;: &quot;&quot;, &quot;Relabel&quot;: &quot;&quot;, &quot;Propagation&quot;: &quot;rprivate&quot;, &quot;Named&quot;: false, &quot;ID&quot;: &quot;&quot; &#125;, &quot;/mysql_data&quot;: &#123; &quot;Source&quot;: &quot;/home/server/mysql/data&quot;, &quot;Destination&quot;: &quot;/mysql_data&quot;, &quot;RW&quot;: true, &quot;Name&quot;: &quot;&quot;, &quot;Driver&quot;: &quot;&quot;, &quot;Relabel&quot;: &quot;&quot;, &quot;Propagation&quot;: &quot;rprivate&quot;, &quot;Named&quot;: false, &quot;ID&quot;: &quot;&quot; &#125;, &quot;/var/lib/mysql&quot;: &#123; &quot;Source&quot;: &quot;&quot;, &quot;Destination&quot;: &quot;/var/lib/mysql&quot;, &quot;RW&quot;: true, &quot;Name&quot;: &quot;85d91bff7012b57606af819480ce267449084e81ab386737c80ace9fe75f6621&quot;, &quot;Driver&quot;: &quot;local&quot;, &quot;Relabel&quot;: &quot;&quot;, &quot;Propagation&quot;: &quot;&quot;, &quot;Named&quot;: false, &quot;ID&quot;: &quot;897cd0152dd152166cb2715044ca4a3915a1b66280e0eb096eb74c2d737d7f77&quot; &#125; &#125;, 复制代码 复制代码 启动docker服务 sudo service docker start 启动所有docker容器 sudo docker start $(docker ps -a | awk &#39;&#123; print $1&#125;&#39; | tail -n +2) 修改docker默认的存储位置 docker 的所有images及相关信息存储位置为：/var/lib/docker 查看默认的docker存储路径 docker info |grep &#39;Docker Root Dir&#39; WARNING: No swap limit support Docker Root Dir: /var/lib/docker 停止所有docker容器 sudo docker stop $(docker ps -a | awk &#39;&#123; print $1&#125;&#39; | tail -n +2) 停止docker服务 sudo service docker stop cd /var/lib 打包docker目录 sudo tar -czvf /usr/docker.tar.gz docker/ cd /usr/ sudo tar -xzvf docker.tar.gz 修改docker默认的存储位置 sudo vim /etc/docker/daemon.json &#123; &quot;graph&quot;: &quot;/home/server/docker&quot; &#125; 启动docker服务 sudo service docker start 启动所有docker容器 sudo docker start $(docker ps -a | awk &#39;&#123; print $1&#125;&#39; | tail -n +2) 查看修改后docker存储路径 复制代码 docker info |grep &#39;Docker Root Dir&#39; WARNING: No swap limit support Docker Root Dir: /usr/docker","categories":[],"tags":[],"author":"张存"},{"title":"佛祖保佑，永不宕机/永无bug","slug":"佛祖保佑，永不宕机-永无bug","date":"2022-03-07T07:08:19.000Z","updated":"2022-03-07T07:09:05.454Z","comments":true,"path":"2022/03/07/fo-zu-bao-you-yong-bu-dang-ji-yong-wu-bug/","link":"","permalink":"https://blog.zhangcun.store/2022/03/07/fo-zu-bao-you-yong-bu-dang-ji-yong-wu-bug/","excerpt":"","text":"没钱请大师/神父给服务器开光？ 没关系，自己 DIY 啊。启动服务器后，先把佛祖加载。 如果是程序员，那就把佛祖写带在源码最前面。 _oo8oo_ o8888888o 88&quot; . &quot;88 (| -_- |) 0\\ = /0 ___/&#39;===&#39;\\___ .&#39; \\\\| |// &#39;. / \\\\||| : |||// \\ / _||||| -:- |||||_ \\ | | \\\\\\ - /// | | | \\_| &#39;&#39;\\---/&#39;&#39; |_/ | \\ .-\\__ &#39;-&#39; __/-. / ___&#39;. .&#39; /--.--\\ &#39;. .&#39;___ .&quot;&quot; &#39;&lt; &#39;.___\\_&lt;|&gt;_/___.&#39; &gt;&#39; &quot;&quot;. | | : `- \\`.:`\\ _ /`:.`/ -` : | | \\ \\ `-. \\_ __\\ /__ _/ .-` / / =====`-.____`.___ \\_____/ ___.`____.-`===== `=---=` ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 佛祖保佑 永不宕机/永无bug","categories":[],"tags":[],"author":"张存"},{"title":"十二星座啪啪啪排行，哪个星座最爱啪啪啪？","slug":"十二星座啪啪啪排行，哪个星座最爱啪啪啪？","date":"2022-03-07T06:55:09.000Z","updated":"2022-03-07T06:55:24.747Z","comments":true,"path":"2022/03/07/shi-er-xing-zuo-pa-pa-pa-pai-xing-na-ge-xing-zuo-zui-ai-pa-pa-pa/","link":"","permalink":"https://blog.zhangcun.store/2022/03/07/shi-er-xing-zuo-pa-pa-pa-pai-xing-na-ge-xing-zuo-zui-ai-pa-pa-pa/","excerpt":"","text":"12星座当中，最爱啪啪的星座排行，实在害羞就躲在被窝里偷偷看吧，一起来看看你的男神排在第几? 第12名：天秤座偶尔尽情澎湃 天秤座的人，是风象星座。可能在所有的星座里面，天秤座的性欲在占在底部了，他们其实内心里面总有有一竿子秤砣在主导着自己，觉得很多事情还不是时候去做，所以有的时候性欲上来了，还是会被自己无情的压制下去，这样的感觉真的非常的不好，我也不知道天秤座的人，狮子是怎么能够忍受得了的啊？他们总是会想着一些性欲之外的东西，譬如每天可能想着做很多事情，忙里忙外个不停，回来的时候就像是个死猪似得，倒头就睡，身边的对象一定会特别的讨厌他们这样的状态吧，也许你们真的应该为了自己的爱人，做个正常的人。 第11名：金牛座受到约束 金牛座的人，是土象星座。在所有的星座中，他们的性欲是最不强的，也许在金牛的而心里，有更多的事情值得自己去做吧，不会每天想着不切实际的啪啪啪，他们的眼里，只有钱，他们也一度的认为，只要有了钱，想要多少的啪啪啪都可以，怕的就是自己没有能力给足对方想要的生活，所以一直以来都不敢释放自己的性欲，金牛座的人，有时候思想还真的是很古板啊，受不了啦，赶快做个正常点的人成不？ 第10名：射手座性欲一般 射手座的人，是火象星座。在所有人的眼里，射手才是这个世界上最淡定的人呢，不管什么时候，他们都能够从容的对待啪啪啪这样的事情，他们觉得有时候这只是彼此之间的需求罢了，没有必要总是挂在嘴边上，多么的有失大体啊，所以在排行中，射手座的性欲并不是太靠前，如果你是射手座的男女朋友，你自身性欲很强的话，找射手可能会降低你的性欲度吧！ 第9名：巨蟹座把持不住 巨蟹座的人，是水象星座。在所有的星座当中，巨蟹座的人，是最懂得尊重被人的星座，肃然他们也很想啪啪啪，但是不知道怎么回事，总会有一种思想在困惑着自己，觉得不应该这样做，久而久之，巨蟹座的性欲也会受到约束，不能够完全的放开自己，所以在所有的星座之中，巨蟹座的性欲相对来说还行吧，也不是那种特备想要啪啪啪的人，但是不得不啪啪啪的时候，他们也会表现得很主动。 第8名：双鱼座在乎感觉 双鱼座的人，是水象星座。在很多人的眼里，觉得双鱼座的人很性感，嗲嗲的声音让人觉得很销魂，很多人都会对他们很感兴趣，但是其实他们自身的性欲并不是很强的那种，可能会需要你的知道，才能够将自己带上性欲的轨道，也不知道是因为他们自身接触的事物的缘故还是什么，总是觉得性欲这些事情自己不是很感兴趣，但是如果自己的对象提出来的话，也不会去拒绝，在所有的星座里面，我想只有双鱼座的人，在面对啪啪啪的时候，会如此的淡定，可能正在和爱人啪啪啪的时候，还会想着什么电视没有看，边做边和爱人说等下要去看什么好看的节目，真的是醉了！ 第7名：摩羯座爱好啪啪啪 摩羯座的人，是土象星座。在星座的排行榜里面，摩羯是最喜欢啪啪啪的，所以不管在繁忙的工作之余还是下班之后，都会要求和自己喜欢的来一次，可能到达的次数算下来每天都会有至少一次，真的是醉醉的了，真的真好！ 第6名：狮子座热情似火 狮子座的人，是火象星座。他们是所有的星座中最能够体验到热情的星座，因为也许他们不会很主动的去要求啪啪啪，但是与他们相处过程中，他们所散发出来的妖媚和热情，真的会让人把持不住的哦，总是会把人家勾搭得神魂颠倒，自己再迅速的离开，这样的人最有心机了，所有总有很多的人想要和狮子座的人啪啪啪，因为他们真的很诱惑，真的让人觉得很把持不住，特性感，他们自己的性格也很强。 第5名：双子座喜欢体验激情 双子座的人，是风象星座。在所有的星座之中，我想双子应该是最直接的人，他们性格本来就不会受任何的约束，所以就算是啪啪啪，他们也不会特别的在意，觉得这是每个人都会经历的事情，只不过真的是早晚的问题罢了，他们很会享受啪啪啪的过程，因为在双子认为，这是一种精神上的刺激，每个人都会有自己的自己的性欲，但是看要能够维持多久，双子一般会持续很长的时间，真的让人刮目相看啊！ 第4名：处女座得不到的在骚动 处女座的人，是土象星座。在所有的星座中，处女是很懂事的星座，但是就算是再懂事的星座，也会有性欲啊，他们在所有的排行里卖弄占第四位，其实处女也有一些小闷骚，在和自己的男女朋友聊天的话，也会时不时的和对方说想要那个，直到把对方的性欲勾起为止，也许是因为性格的原因，处女也会赢得很多人的喜欢，一点都不会在乎有没有人爱自己，有没有人和自己啪啪啪，因为他们真的从来没有缺少过。 第3名：白羊座为爱疯狂 白羊座的人，是火象星座。在白羊的心里，其实很喜欢啪啪啪的感觉，以为内他们觉得人在啪啪啪的时候，就会什么烦恼都没有了，长时间这样下面，就会离不开这样的感觉，也就形成了我们所说的性欲，其实他们的骨子里面还是蛮闷骚的，对于自己想要做的事情，不会很轻易的说出来，单丝会通过很多种渠道，去勾起对方的性欲，让自己理所当然的吃别人的豆腐，所以总是会坏坏的白羊，他们从来不会缺少爱，在和爱人啪啪啪的时候，脑子里唯一浮现的词可能就是爽了，真的觉得他们应该主动一点，总不能想着让别人来勾引自己吧！ 第2名：水瓶座喜欢刺激 水瓶座的人，是风象星座。在所有的星座当中，水瓶座的人也是数一数二的性欲强者，对于他们来说，啪啪啪是这个世界上最美好的东西，自己不管在多大的年龄层都不会去拒绝的，所以他们的体力和思想都很开放，在水瓶座的身上，很容易发生一夜情，因为可能自己很花心，没有很固定的对象，所以总是会去一些不正当的场合，有的时候性欲来了，也是没有办法的，他如果真的有对象的话，一定会快活死的，总是会要求自己的对象和自己啪啪啪，也不知道他们每天是吃了什么，总是精力旺盛，所以水瓶座在性欲排行上面，也非常的耀眼，真希望他们会始终如一的对一个人产生兴趣，不要那么花心。 第1名：天蝎座爱啪啪啪 天蝎座的人，是水象星座。大家万万没有想到吧，在所有的星座当中，咱们的天蝎座是性欲最强的星座呢，其实这也是可以理解的，天蝎座的人很有颜值，以至于他们的身上总是存在着很强的自信，他们从来不会缺少追求者，所以也就成就了他们对于自己很强的存在感，他们性欲真的不是一般的强，和自己的爱人在一起的话，他们总是会说这样的话题，可能开始对方没有想到这个话题，他们也会硬是把对方的话题迁到这里，说着说着可能自己就要行动了，而小编不得不说的是，不管天蝎座的人是男生还是女生，精力都特别的旺盛，一般人还真的没有他们的体力，作为天蝎宝宝的爱人，真的是幸福死啦！","categories":[],"tags":[],"author":"张存"},{"title":"Linux中的文件和目录结构详解","slug":"Linux中的文件和目录结构详解-2","date":"2022-03-07T05:50:40.000Z","updated":"2022-03-07T06:56:40.471Z","comments":true,"path":"2022/03/07/linux-zhong-de-wen-jian-he-mu-lu-jie-gou-xiang-jie-2/","link":"","permalink":"https://blog.zhangcun.store/2022/03/07/linux-zhong-de-wen-jian-he-mu-lu-jie-gou-xiang-jie-2/","excerpt":"","text":"对于每一个Linux学习者来说，了解Linux文件系统的目录结构，是学好Linux的至关重要的一步.，深入了解linux文件目录结构的标准和每个目录的详细功能，对于我们用好linux系统只管重要，下面我们就开始了解一下linux目录结构的相关知识。 当在使用Linux的时候，如果您通过ls –l / 就会发现，在/下包涵很多的目录，比如etc、usr、var、bin … … 等目录，而在这些目录中，我们进去看看，发现也有很多的目录或文件。文件系统在Linux下看上去就象树形结构，所以我们可以把文件系统的结构形象的称为 树形结构。 文件系统的是用来组织和排列文件存取的，所以它是可见的，在Linux中，我们可以通过ls等工具来查看其结构，在Linux系统中，我们见到的都是树形结构；比如操作系统安装在一个文件系统中，它表现为由/ 起始的树形结构。linux文件系统的最顶端是/，我们称/为Linux的root，也就是 Linux操作系统的文件系统。Linux的文件系统的入口就是/，所有的目录、文件、设备都在/之下，/就是Linux文件系统的组织者，也是最上级的领导者。 由于linux是开放源代码，各大公司和团体根据linux的核心代码做各自的操作，编程。这样就造成在根下的目录的不同。这样就造成个人不能使用他人的linux系统的PC。因为你根本不知道一些基本的配置，文件在哪里。。。这就造成了混乱。这就是FHS（Filesystem Hierarchy Standard ）机构诞生的原因。该机构是linux爱好者自发的组成的一个团体，主要是是对linux做一些基本的要求，不至于是操作者换一台主机就成了linux的‘文盲’。 根据FHS(http://www.pathname.com/fhs/)的官方文件指出， 他们的主要目的是希望让使用者可以了解到已安装软件通常放置于那个目录下， 所以他们希望独立的软件开发商、操作系统制作者、以及想要维护系统的用户，都能够遵循FHS的标准。 也就是说，FHS的重点在于规范每个特定的目录下应该要放置什么样子的数据而已。 这样做好处非常多，因为Linux操作系统就能够在既有的面貌下(目录架构不变)发展出开发者想要的独特风格。 事实上，FHS是根据过去的经验一直再持续的改版的，FHS依据文件系统使用的频繁与否与是否允许使用者随意更动， 而将目录定义成为四种交互作用的形态，用表格来说有点像底下这样： 可分享的(shareable) 不可分享的(unshareable) 不变的(static) /usr (软件放置处) /etc (配置文件) /opt (第三方协力软件) /boot (开机与核心档) 可变动的(variable) /var/mail (使用者邮件信箱) /var/run (程序相关) /var/spool/news (新闻组) /var/lock (程序相关) 四中类型: 1.可分享的： 可以分享给其他系统挂载使用的目录，所以包括执行文件与用户的邮件等数据， 是能够分享给网络上其他主机挂载用的目录； 2.不可分享的： 自己机器上面运作的装置文件或者是与程序有关的socket文件等， 由于仅与自身机器有关，所以当然就不适合分享给其他主机了。 3.不变的： 有些数据是不会经常变动的，跟随着distribution而不变动。 例如函式库、文件说明文件、系统管理员所管理的主机服务配置文件等等； 4.可变动的： 经常改变的数据，例如登录文件、一般用户可自行收受的新闻组等。 事实上，FHS针对目录树架构仅定义出三层目录底下应该放置什么数据而已，分别是底下这三个目录的定义： / (root, 根目录)：与开机系统有关； /usr (unix software resource)：与软件安装/执行有关； /var (variable)：与系统运作过程有关。 一. 根目录 (/) 的意义与内容： 根目录是整个系统最重要的一个目录，因为不但所有的目录都是由根目录衍生出来的， 同时根目录也与开机/还原/系统修复等动作有关。 由于系统开机时需要特定的开机软件、核心文件、开机所需程序、 函式库等等文件数据，若系统出现错误时，根目录也必须要包含有能够修复文件系统的程序才行。 因为根目录是这么的重要，所以在FHS的要求方面，他希望根目录不要放在非常大的分区， 因为越大的分区内你会放入越多的数据，如此一来根目录所在分区就可能会有较多发生错误的机会。 因此FHS标准建议：根目录(/)所在分区应该越小越好， 且应用程序所安装的软件最好不要与根目录放在同一个分区内，保持根目录越小越好。 如此不但效能较佳，根目录所在的文件系统也较不容易发生问题。说白了，就是根目录和Windows的C盘一个样。 根据以上原因，FHS认为根目录(/)下应该包含如下子目录： 目录 应放置档案内容 /bin 系统有很多放置执行档的目录，但/bin比较特殊。因为/bin放置的是在单人维护模式下还能够被操作的指令。在/bin底下的指令可以被root与一般帐号所使用，主要有：cat,chmod(修改权限), chown, date, mv, mkdir, cp, bash等等常用的指令。 /boot 主要放置开机会使用到的档案，包括Linux核心档案以及开机选单与开机所需设定档等等。Linux kernel常用的档名为：vmlinuz ，如果使用的是grub这个开机管理程式，则还会存在/boot/grub/这个目录。 /dev 在Linux系统上，任何装置与周边设备都是以档案的型态存在于这个目录当中。 只要通过存取这个目录下的某个档案，就等于存取某个装置。比要重要的档案有/dev/null, /dev/zero, /dev/tty , /dev/lp*, / dev/hd*, /dev/sd*等等 /etc 系统主要的设定档几乎都放置在这个目录内，例如人员的帐号密码档、各种服务的启始档等等。 一般来说，这个目录下的各档案属性是可以让一般使用者查阅的，但是只有root有权力修改。 FHS建议不要放置可执行档(binary)在这个目录中。 比较重要的档案有：/etc/inittab, /etc/init.d/, /etc/modprobe.conf, /etc/X11/, /etc/fstab, /etc/sysconfig/等等。 另外，其下重要的目录有：/etc/init.d/ ：所有服务的预设启动script都是放在这里的，例如要启动或者关闭iptables的话： /etc/init.d/iptables start、/etc/init.d/ iptables stop /etc/xinetd.d/ ：这就是所谓的super daemon管理的各项服务的设定档目录。 /etc/X11/ ：与X Window有关的各种设定档都在这里，尤其是xorg.conf或XF86Config这两个X Server的设定档。 /home 这是系统预设的使用者家目录(home directory)。 在你新增一个一般使用者帐号时，预设的使用者家目录都会规范到这里来。比较重要的是，家目录有两种代号： ~ ：代表当前使用者的家目录，而 ~guest：则代表用户名为guest的家目录。 /lib 系统的函式库非常的多，而/lib放置的则是在开机时会用到的函式库，以及在/bin或/sbin底下的指令会呼叫的函式库而已 。 什么是函式库呢？妳可以将他想成是外挂，某些指令必须要有这些外挂才能够顺利完成程式的执行之意。 尤其重要的是/lib/modules/这个目录，因为该目录会放置核心相关的模组(驱动程式)。 /media media是媒体的英文，顾名思义，这个/media底下放置的就是可移除的装置。 包括软碟、光碟、DVD等等装置都暂时挂载于此。 常见的档名有：/media/floppy, /media/cdrom等等。 /mnt 如果妳想要暂时挂载某些额外的装置，一般建议妳可以放置到这个目录中。在古早时候，这个目录的用途与/media相同啦。 只是有了/media之后，这个目录就用来暂时挂载用了。 /opt 这个是给第三方协力软体放置的目录 。 什么是第三方协力软体啊？举例来说，KDE这个桌面管理系统是一个独立的计画，不过他可以安装到Linux系统中，因此KDE的软体就建议放置到此目录下了。 另外，如果妳想要自行安装额外的软体(非原本的distribution提供的)，那么也能够将你的软体安装到这里来。 不过，以前的Linux系统中，我们还是习惯放置在/usr/local目录下。 /root 系统管理员(root)的家目录。 之所以放在这里，是因为如果进入单人维护模式而仅挂载根目录时，该目录就能够拥有root的家目录，所以我们会希望root的家目录与根目录放置在同一个分区中。 /sbin Linux有非常多指令是用来设定系统环境的，这些指令只有root才能够利用来设定系统，其他使用者最多只能用来查询而已。放在/sbin底下的为开机过程中所需要的，里面包括了开机、修复、还原系统所需要的指令。至于某些伺服器软体程式，一般则放置到/usr/sbin/当中。至于本机自行安装的软体所产生的系统执行档(system binary)，则放置到/usr/local/sbin/当中了。常见的指令包括：fdisk, fsck, ifconfig, init, mkfs等等。 /srv srv可以视为service的缩写，是一些网路服务启动之后，这些服务所需要取用的资料目录。 常见的服务例如WWW, FTP等等。 举例来说，WWW伺服器需要的网页资料就可以放置在/srv/www/里面。呵呵，看来平时我们编写的代码应该放到这里了。 /tmp 这是让一般使用者或者是正在执行的程序暂时放置档案的地方。这个目录是任何人都能够存取的，所以你需要定期的清理一下。当然，重要资料不可放置在此目录啊。 因为FHS甚至建议在开机时，应该要将/tmp下的资料都删除。 事实上FHS针对根目录所定义的标准就仅限于上表，不过仍旧有些目录也需要我们了解一下，具体如下： 目录 应放置文件内容 /lost+found 这个目录是使用标准的ext2/ext3档案系统格式才会产生的一个目录，目的在于当档案系统发生错误时，将一些遗失的片段放置到这个目录下。 这个目录通常会在分割槽的最顶层存在，例如你加装一个硬盘于/disk中，那在这个系统下就会自动产生一个这样的目录/disk/lost+found /proc 这个目录本身是一个虚拟文件系统(virtual filesystem)喔。 他放置的资料都是在内存当中，例如系统核心、行程资讯(process)（是进程吗?）、周边装置的状态及网络状态等等。因为这个目录下的资料都是在记忆体（内存）当中，所以本身不占任何硬盘空间。比较重要的档案（目录）例如： /proc/cpuinfo, /proc/dma, /proc/interrupts, /proc/ioports, /proc/net/*等等。呵呵，是虚拟内存吗[guest]？ /sys 这个目录其实跟/proc非常类似，也是一个虚拟的档案系统，主要也是记录与核心相关的资讯。 包括目前已载入的核心模组与核心侦测到的硬体装置资讯等等。 这个目录同样不占硬盘容量。 除了这些目录的内容之外，另外要注意的是，因为根目录与开机有关，开机过程中仅有根目录会被挂载， 其他分区则是在开机完成之后才会持续的进行挂载的行为。就是因为如此，因此根目录下与开机过程有关的目录， 就不能够与根目录放到不同的分区去。 那哪些目录不可与根目录分开呢？有底下这些： /etc：配置文件 /bin：重要执行档 /dev：所需要的设备文件 /lib：执行档所需的函式库与核心所需的模块 /sbin：重要的系统执行文件 这五个目录不可与根目录分开在不同的分区。 二. /usr 的意义与内容： 依据FHS的基本定义，/usr里面放置的数据属于可分享的与不可变动的(shareable, static)， 如果你知道如何透过网络进行分区的挂载(例如在服务器篇会谈到的NFS服务器)，那么/usr确实可以分享给局域网络内的其他主机来使用喔。 /usr不是user的缩写，其实usr是Unix Software Resource的缩写， 也就是Unix操作系统软件资源所放置的目录，而不是用户的数据啦。这点要注意。 FHS建议所有软件开发者，应该将他们的数据合理的分别放置到这个目录下的次目录，而不要自行建立该软件自己独立的目录。 因为是所有系统默认的软件(distribution发布者提供的软件)都会放置到/usr底下，因此这个目录有点类似Windows 系统的C:\\Windows\\ + C:\\Program files\\这两个目录的综合体，系统刚安装完毕时，这个目录会占用最多的硬盘容量。 一般来说，/usr的次目录建议有底下这些： 目录 应放置文件内容 /usr/X11R6/ 为X Window System重要数据所放置的目录，之所以取名为X11R6是因为最后的X版本为第11版，且该版的第6次释出之意。 /usr/bin/ 绝大部分的用户可使用指令都放在这里。请注意到他与/bin的不同之处。(是否与开机过程有关) /usr/include/ c/c++等程序语言的档头(header)与包含档(include)放置处，当我们以tarball方式 (*.tar.gz 的方式安装软件)安装某些数据时，会使用到里头的许多包含档。 /usr/lib/ 包含各应用软件的函式库、目标文件(object file)，以及不被一般使用者惯用的执行档或脚本(script)。 某些软件会提供一些特殊的指令来进行服务器的设定，这些指令也不会经常被系统管理员操作， 那就会被摆放到这个目录下啦。要注意的是，如果你使用的是X86_64的Linux系统， 那可能会有/usr/lib64/目录产生 /usr/local/ 统管理员在本机自行安装自己下载的软件(非distribution默认提供者)，建议安装到此目录， 这样会比较便于管理。举例来说，你的distribution提供的软件较旧，你想安装较新的软件但又不想移除旧版， 此时你可以将新版软件安装于/usr/local/目录下，可与原先的旧版软件有分别啦。 你可以自行到/usr/local去看看，该目录下也是具有bin, etc, include, lib...的次目录 /usr/sbin/ 非系统正常运作所需要的系统指令。最常见的就是某些网络服务器软件的服务指令(daemon) /usr/share/ 放置共享文件的地方，在这个目录下放置的数据几乎是不分硬件架构均可读取的数据， 因为几乎都是文本文件嘛。在此目录下常见的还有这些次目录：/usr/share/man：联机帮助文件 /usr/share/doc：软件杂项的文件说明 /usr/share/zoneinfo：与时区有关的时区文件 /usr/src/ 一般原始码建议放置到这里，src有source的意思。至于核心原始码则建议放置到/usr/src/linux/目录下。 三. /var 的意义与内容： 如果/usr是安装时会占用较大硬盘容量的目录，那么/var就是在系统运作后才会渐渐占用硬盘容量的目录。 因为/var目录主要针对常态性变动的文件，包括缓存(cache)、登录档(log file)以及某些软件运作所产生的文件， 包括程序文件(lock file, run file)，或者例如MySQL数据库的文件等等。常见的次目录有： 目录 应放置文件内容 /var/cache/ 应用程序本身运作过程中会产生的一些暂存档 /var/lib/ 程序本身执行的过程中，需要使用到的数据文件放置的目录。在此目录下各自的软件应该要有各自的目录。 举例来说，MySQL的数据库放置到/var/lib/mysql/而rpm的数据库则放到/var/lib/rpm去 /var/lock/ 某些装置或者是文件资源一次只能被一个应用程序所使用，如果同时有两个程序使用该装置时， 就可能产生一些错误的状况，因此就得要将该装置上锁(lock)，以确保该装置只会给单一软件所使用。 举例来说，刻录机正在刻录一块光盘，你想一下，会不会有两个人同时在使用一个刻录机烧片？ 如果两个人同时刻录，那片子写入的是谁的数据？所以当第一个人在刻录时该刻录机就会被上锁， 第二个人就得要该装置被解除锁定(就是前一个人用完了)才能够继续使用 /var/log/ 非常重要。这是登录文件放置的目录。里面比较重要的文件如/var/log/messages, /var/log/wtmp(记录登入者的信息)等。 /var/mail/ 放置个人电子邮件信箱的目录，不过这个目录也被放置到/var/spool/mail/目录中，通常这两个目录是互为链接文件。 /var/run/ 某些程序或者是服务启动后，会将他们的PID放置在这个目录下 /var/spool/ 这个目录通常放置一些队列数据，所谓的“队列”就是排队等待其他程序使用的数据。 这些数据被使用后通常都会被删除。举例来说，系统收到新信会放置到/var/spool/mail/中， 但使用者收下该信件后该封信原则上就会被删除。信件如果暂时寄不出去会被放到/var/spool/mqueue/中， 等到被送出后就被删除。如果是工作排程数据(crontab)，就会被放置到/var/spool/cron/目录中。 由于FHS仅是定义出最上层(/)及次层(/usr, /var)的目录内容应该要放置的文件或目录数据， 因此，在其他次目录层级内，就可以随开发者自行来配置了。 四. 目录树(directory tree) : 在Linux底下，所有的文件与目录都是由根目录开始的。那是所有目录与文件的源头, 然后再一个一个的分支下来，因此，我们也称这种目录配置方式为：目录树(directory tree), 这个目录树的主要特性有： 目录树的启始点为根目录 (/, root)； 每一个目录不止能使用本地端的 partition 的文件系统，也可以使用网络上的 filesystem 。举例来说， 可以利用 Network File System (NFS) 服务器挂载某特定目录等。 每一个文件在此目录树中的文件名(包含完整路径)都是独一无二的。 如果我们将整个目录树以图的方法来显示，并且将较为重要的文件数据列出来的话，那么目录树架构就如下图所示： 五. 绝对路径与相对路径 除了需要特别注意的FHS目录配置外，在文件名部分我们也要特别注意。因为根据档名写法的不同，也可将所谓的路径(path)定义为绝对路径(absolute)与相对路径(relative)。 这两种文件名/路径的写法依据是这样的： 绝对路径： 由根目录(/)开始写起的文件名或目录名称， 例如 /home/dmtsai/.bashrc； 相对路径： 相对于目前路径的文件名写法。 例如 ./home/dmtsai 或 http://www.cnblogs.com/home/dmtsai/ 等等。反正开头不是 / 就属于相对路径的写法 而你必须要了解，相对路径是以你当前所在路径的相对位置来表示的。举例来说，你目前在 /home 这个目录下， 如果想要进入 /var/log 这个目录时，可以怎么写呢？ cd /var/log (absolute) cd ../var/log (relative) 因为你在 /home 底下，所以要回到上一层 (../) 之后，才能继续往 /var 来移动的，特别注意这两个特殊的目录： . ：代表当前的目录，也可以使用 ./ 来表示； .. ：代表上一层目录，也可以 ../ 来代表。 这个 . 与 .. 目录概念是很重要的，你常常会看到 cd .. 或 ./command 之类的指令下达方式， 就是代表上一层与目前所在目录的工作状态。 实例1：如何先进入/var/spool/mail/目录，再进入到/var/spool/cron/目录内？ 命令： cd /var/spool/mail cd ../cron 说明： 由于/var/spool/mail与/var/spool/cron是同样在/var/spool/目录中。如此就不需要在由根目录开始写起了。这个相对路径是非常有帮助的，尤其对于某些软件开发商来说。 一般来说，软件开发商会将数据放置到/usr/local/里面的各相对目录。 但如果用户想要安装到不同目录呢？就得要使用相对路径。 实例2：网络文件常常提到类似./run.sh之类的数据，这个指令的意义为何？ 说明： 由于指令的执行需要变量的支持，若你的执行文件放置在本目录，并且本目录并非正规的执行文件目录(/bin, /usr/bin等为正规)，此时要执行指令就得要严格指定该执行档。./代表本目录的意思，所以./run.sh代表执行本目录下， 名为run.sh的文件","categories":[],"tags":[],"author":"张存"},{"title":"docker 安装es7与es-head","slug":"docker-安装es7与es-head","date":"2022-03-04T07:02:52.000Z","updated":"2022-03-04T07:04:40.944Z","comments":true,"path":"2022/03/04/docker-an-zhuang-es7-yu-es-head/","link":"","permalink":"https://blog.zhangcun.store/2022/03/04/docker-an-zhuang-es7-yu-es-head/","excerpt":"","text":"1、docker run -d –name elasticsearch -p 12000:9200 -p 13000:9300 -e “discovery.type=single-node” elasticsearch:7.3.0 2、docker run -d --name elasticsearch-head -p 10100:9100 mobz/elasticsearch-head:5 3、在浏览器打开：127.0.0.1:9100，连接不上，然后 修改es.yml文件 增加 # head插件设置 http.cors.enabled: true http.cors.allow-origin: &quot;*&quot; #设置可以访问的ip 这里全部设置通过 4、查询可能不成功，查询时报错&#123;&quot;error&quot;:&quot;Content-Type header [application/x-www-form-urlencoded] is not supported&quot;,&quot;status&quot;:406&#125; 5、安装vim: 备份source.list文件 mv /etc/apt/sources.list /etc/apt/sources.list.bak 替换为阿里云国内镜像 echo &quot;deb http://mirrors.aliyun.com/debian/ stretch main non-free contrib&quot; &gt;&gt; /etc/apt/sources.listecho &quot;deb-src http://mirrors.aliyun.com/debian/ stretch main non-free contrib&quot; &gt;&gt; /etc/apt/sources.listecho &quot;deb http://mirrors.aliyun.com/debian-security stretch/updates main&quot; &gt;&gt; /etc/apt/sources.listecho &quot;deb-src http://mirrors.aliyun.com/debian-security stretch/updates main&quot; &gt;&gt; /etc/apt/sources.listecho &quot;deb http://mirrors.aliyun.com/debian/ stretch-updates main non-free contrib&quot; &gt;&gt; /etc/apt/sources.listecho &quot;deb-src http://mirrors.aliyun.com/debian/ stretch-updates main non-free contrib&quot; &gt;&gt; /etc/apt/sources.listecho &quot;deb http://mirrors.aliyun.com/debian/ stretch-backports main non-free contrib&quot; &gt;&gt; /etc/apt/sources.listecho &quot;deb-src http://mirrors.aliyun.com/debian/ stretch-backports main non-free contrib&quot; &gt;&gt; /etc/apt/sources.list 更新安装源 apt-get update 安装 Vim apt-get install vim 6、解决方法: 1、进入head安装目录；docker exec -it 名称 bash 2、打开文件夹_site，cd _site/ 3、编辑vendor.js 共有两处 ①. 6886行 contentType: &quot;application/x-www-form-urlencoded 改成 contentType: &quot;application/json;charset=UTF-8&quot; ②. 7574行 var inspectData = s.contentType === &quot;application/x-www-form-urlencoded&quot; &amp;&amp; 改成 var inspectData = s.contentType === &quot;application/json;charset=UTF-8&quot; &amp;&amp; 4、退出容器exit 然后重启 5、重新查询，可以查出数据","categories":[],"tags":[],"author":"张存"},{"title":"ES中安装拼音分词器","slug":"ES中安装拼音分词器","date":"2022-03-04T05:40:32.000Z","updated":"2022-03-04T07:14:59.758Z","comments":true,"path":"2022/03/04/es-zhong-an-zhuang-pin-yin-fen-ci-qi/","link":"","permalink":"https://blog.zhangcun.store/2022/03/04/es-zhong-an-zhuang-pin-yin-fen-ci-qi/","excerpt":"","text":"ES作为最强大的全文检索工具（没有之一），中英文分词几乎是必备功能，下面简单说明下分词器安装步骤（详细步骤网上很多，本文只提供整体思路和步骤）： 下载拼音分词器 拼音分词器：https://github.com/medcl/elasticsearch-analysis-pinyin 安装wget https://github.com/medcl/elasticsearch-analysis-pinyin/releases/download/v7.13.1/elasticsearch-analysis-pinyin-7.13.1.zip (下载对应版本)。 docker cp elasticsearch-analysis-pinyin-7.13.1.zip elasticsearch:/usr/share/elasticsearch/plugins 进入elasticsearch安装目录/plugins；mkdir pinyin；cd pinyin； docker exec -it elasticsearch bash cd /usr/share/elasticsearch/plugins unzip elasticsearch-analysis-pinyin-7.13.1.zip -d pinyinrm elasticsearch-analysis-pinyin-7.13.1.zip 部署后，记得重启es节点3. 验证POST _analyze { “analyzer”: “pinyin”, “text”: “美国人”} 测试通过_analyze测试下分词器是否能正常运行： GET my_index/_analyze{ “text”:[“刘德华”], “analyzer”:”pinyin”}向index中put中文数据： POST my_index/index_type -d’{“name”:”刘德华”}‘中文分词测试（通过查询字符串）curl http://localhost:9200/my_index/index_type/_search?q=name:刘curl http://localhost:9200/my_index/index_type/_search?q=name:刘德 拼音测试 （通过查询字符串）curl http://localhost:9200/my_index/index_type/_search?q=name.pinyin:liucurl http://localhost:9200/my_index/index_type/_search?q=name.pinyin:ldhcurl http://localhost:9200/my_index/index_type/_search?q=name.pinyin:de+hua","categories":[],"tags":[],"author":"张存"},{"title":"ubuntu apt curl wget 代理设置","slug":"ubuntu-apt-curl-wget-代理设置","date":"2022-03-04T05:06:03.000Z","updated":"2022-03-04T05:24:07.858Z","comments":true,"path":"2022/03/04/ubuntu-apt-curl-wget-dai-li-she-zhi/","link":"","permalink":"https://blog.zhangcun.store/2022/03/04/ubuntu-apt-curl-wget-dai-li-she-zhi/","excerpt":"","text":"由于公司内网问题，经常涉及到需要设置网络代理的问题。总结如下： 考虑到经常需要更换密码，一般使用临时代理 =================================== apt代理设置 $ apt -o Acquire::http::proxy=&quot;http://username:password@ip:port/&quot; install XXX ================================== curl 代理设置 使用命令： $ curl -x http://username:password@ip:port/ URL =================================== wget代理设置 wget -e &quot;http://username:password@ip:port/&quot; URL ==================================== 持久化以上代理 如果需要apt、wget、curl 一直使用代理，可以直接编辑~/.bashrc文件。 $ vim ~/.bashrc 文末添加两行： http_proxy=http://username:password@ip:port/ export http_proxy","categories":[],"tags":[],"author":"张存"},{"title":"写字楼里写字间","slug":"写字楼里写字间","date":"2022-03-04T02:27:15.000Z","updated":"2022-03-04T02:29:40.447Z","comments":true,"path":"2022/03/04/xie-zi-lou-li-xie-zi-jian/","link":"","permalink":"https://blog.zhangcun.store/2022/03/04/xie-zi-lou-li-xie-zi-jian/","excerpt":"","text":"写字楼里写字间，写字间中程序员； 程序人员写程序，又将程序换酒钱； 酒醒只在屏前坐，酒醉还来屏下眠； 酒醉酒醒日复日，屏前屏下年复年； 但愿老死电脑间，不愿鞠躬老板前； 奔驰宝马贵者趣，公交自行程序员； 别人笑我太疯癫，我笑自己命太贱； 但见满街漂亮妹，哪个归得程序员；","categories":[],"tags":[],"author":"张存"},{"title":"docker部署elasticsearch容器安装ik分词器","slug":"docker部署elasticsearch容器安装ik分词器","date":"2022-03-03T06:21:51.000Z","updated":"2022-03-10T09:57:31.620Z","comments":true,"path":"2022/03/03/docker-bu-shu-elasticsearch-rong-qi-an-zhuang-ik-fen-ci-qi/","link":"","permalink":"https://blog.zhangcun.store/2022/03/03/docker-bu-shu-elasticsearch-rong-qi-an-zhuang-ik-fen-ci-qi/","excerpt":"","text":"首先，我的系统为win10系统，在这里需要告知一下，使用docker部署完elasticsearch(后续简称为es)和kibana后（可参考使用docker部署elasticsearch 和kibana），我们需要在elasticsearch容器中添加ik分词器插件，操作如下： 我们首先需要在我们的主机下载ik分词器的压缩包，地址为：https://github.com/medcl/elasticsearch-analysis-ik/releases，因为我采用的es和kibana的版本是6.7.2的版本，因此我下载的ik分词器的版本为6.7.2的版本，尽量保持tag标签的统一性，防止出现不兼容的情况，下载完成后，保存在指定的目录中： 我存放的目录为：C:\\Users\\Administrator\\Desktop 然后我们使用docker的cp命令来将主机的文件拷贝到容器的指定目录中 es中有一个plugins目录，我们需要将分词器文件保存在此目录中，如何查看容器的此目录在哪，可执行一下步骤进行查看： 1. 进入es的终端 docker exec -it elasticsearch /bin/bash 2. 获取到plugins目录： 因此es的plugins目录在： /usr/share/elasticsearch/plugins 3. 使用exit命令退出es终端，使用docker copy [主机目录] [容器名称:容器地址] 将分词器拷贝到容器的指定目录中，命令如下： docker cp C:\\\\Users\\\\Administrator\\\\Desktop\\\\elasticsearch-analysis-ik-6.7.2.zip elasticsearch:/usr/share/elasticsearch/plugins 4. 再次进入es容器终端，进入plugins目录，我们发现ik分词器已经拷贝到此目录中： 5. 解压zip压缩包，命令为：unzip elasticsearch-analysis-ik-6.7.2.zip -d ik-analyzer 6. 退出es终端, 使用docker restart elasticsearch 命令重启es; 7. 使用kibana查看分词器是否生效： 8.查看elasticsearch安装了哪些分词器 curl http://192.168.x.x:9200/_cat/plugins 到此，就完成了使用docker来完成对es添加ik分词器插件的内容。 docker network connect 网络名 容器名 （打通网络）","categories":[],"tags":[],"author":"张存"},{"title":"Ubuntu16.04安装Slurm","slug":"Ubuntu16-04安装Slurm","date":"2022-03-03T02:49:42.000Z","updated":"2022-03-03T02:49:46.661Z","comments":true,"path":"2022/03/03/ubuntu16-04-an-zhuang-slurm/","link":"","permalink":"https://blog.zhangcun.store/2022/03/03/ubuntu16-04-an-zhuang-slurm/","excerpt":"","text":"1. 安装MUNGE 安装MUNGE进行身份验证。确保集群中的所有节点具有相同的munge.key。确保Munge的守护程序munged在Slurm的守护进程之前启动。(由于我是在本地测试的，就没有设置多个节点，需要同步的可通过scp同步) sudo apt-get install munge # 安装munge sudo /usr/sbin/create-munge-key # 生成munge密钥 2. 安装SLURM sudo apt-get install slurm-llnl 3. 配置SLURM 进入etc/slurm-llnl/下，创建slurm.conf，可自定义配置 ControlMachine=localhost SlurmctldPort=6817 SlurmdPort=6818 AuthType=auth/munge StateSaveLocation=/tmp SlurmdSpoolDir=/tmp/slurmd SwitchType=switch/none MpiDefault=none SlurmctldPidFile=/var/run/slurm-llnl/slurmctld.pid SlurmdPidFile=/var/run/slurm-llnl/slurmd.pid ProctrackType=proctrack/pgid CacheGroups=0 ReturnToService=2 TaskPlugin=task/affinity # make the default memory per core DefMemPerNode=1024 MaxJobCount=20 MinJobAge=180 # TIMERS SlurmctldTimeout=120 SlurmdTimeout=120 InactiveLimit=0 KillWait=30 Waittime=0 # SCHEDULING SchedulerType=sched/backfill #SchedulerPort=7321 SelectType=select/cons_res SelectTypeParameters=CR_CPU_Memory FastSchedule=0 # LOGGING SlurmctldDebug=3 #SlurmctldLogFile=/var/log/slurmctld.log SlurmdDebug=3 #SlurmdLogFile=/var/log/slurmd.log JobCompType=jobcomp/none #JobCompLoc= JobAcctGatherType=jobacct_gather/none # COMPUTE NODES NodeName=DEFAULT PartitionName=DEFAULT MaxTime=INFINITE State=UP # NODES NodeName=localhost CPUs=1 RealMemory=1024 PartitionName=compute Nodes=ALL Default=YES Shared=YES 4. 启动MUNGE systemctl start munge systemctl status munge systemctl enable munge 5. 测试slurmd配置 slurmd -C 6. 开启slurmctld服务 systemctl start slurmctld systemctl status slurmctld systemctl enable slurmctld 7.测试命令 scontrol show nodes sinfo 以上！","categories":[],"tags":[],"author":"张存"},{"title":"Docker 环境下搭建nexus私服","slug":"Docker-环境下搭建nexus私服","date":"2022-03-01T10:05:39.000Z","updated":"2022-03-01T10:05:46.950Z","comments":true,"path":"2022/03/01/docker-huan-jing-xia-da-jian-nexus-si-fu/","link":"","permalink":"https://blog.zhangcun.store/2022/03/01/docker-huan-jing-xia-da-jian-nexus-si-fu/","excerpt":"","text":"1、安装docker 一、脚本安装 本机环境CentOS7，用户为roothtml 下载脚本到工做目录 curl -fsSL https://get.docker.com -o get-docker.sh 执行脚本 sudo sh get-docker.sh 执行完会自动退出shell，须要从新登陆。git 2、安装docker-compose(可选) 一、脚本安装 安装docker-compose的可执行命令到/usr/local/bin sudo curl -L &quot;https://github.com/docker/compose/releases/download/1.24.1/docker-compose-$(uname -s)-$(uname -m)&quot; -o /usr/local/bin/docker-compose 增长可执行权限 sudo chmod +x /usr/local/bin/docker-compose 不出意外，本地网络是下载不动的...github 能够尝试 Github手动下载，或者开加速器。下载完成后copy到/usr/local/bin,而后增长可执行权限docker 3、启动docker service docker start 或 systemctl start docker 4、拉取镜像 一、查找镜像 docker search nexus 通常安装star数最多的版本，目前最新是sonatype/nexus3shell 二、拉取镜像 docker pull sonatype/nexus3 5、利用docker启动容器(五或六任选其一) 一、最简单的方式： docker run -p 8081:8081 --name nexus sonatype/nexus3 二、指定数据卷，防止每次启动容器，容器里的数据丢失，实现容器和虚拟机数据共享。 若是有容器和下面要建立的容器同名的话，先删除 docker rm &lt;container_name&gt; 指定虚拟机与容器共享的文件夹 mkdir /usr/local/docker/nexus/nexus-data 启动容器 docker run -p 8081:8081 --name nexus -v /usr/local/docker/nexus/nexus-data:/nexus-data snoatype/nexus3 指定数据卷后启动，可能会报一些权限错误，致使启动不起来。可能会须要修改文件夹权限 chmod 777 /usr/local/docker/nexus/nexus-data 6、利用docker-compose启动nexus容器（五或六任选其一） 一、建立docker-compose.yml mkdir /usr/local/docker cd /usr/local/docker vi docker-compose.yml docker-compose.yml内容以下： version: &quot;3.7&quot; services: nexus: restart: &quot;no&quot; image: sonatype/nexus3 container_name: nexus ports: - 8081:8081 volumes: - /usr/local/docker/nexus/nexus-data:/nexus-data version : 指定docker-compose语法版本，版本不一样，支持的docker也不一样浏览器 restart网络 services : 多种服务的根节点less nexus : 服务名随意起，表明要建立的服务curl restart : 容器的重启策略，有no、always、on-failure、 unless-stopped四种可选值。maven image : 容器依据的镜像 container_name : 容器名 ports : 端口 volumes : 数据卷 注意：yml文件缩进必须用空格 7、访问nexus 一、打开浏览器，访问 http://&lt;host address&gt;:8081/ 二、管理员登陆密码在 /usr/local/docker/nexus/nexus-data 中admin开头的文件中，将其拷贝输入便可。 三、登陆以后会要求修改密码，按要求修改便可。 8、项目发布到nexus的仓库 一、首先修改maven的setting.xml文件，添加用户信息，以便jar包上传私服时进行身份认证,修改内容以下： &lt;servers&gt; &lt;server&gt; &lt;id&gt;maven-releases&lt;/id&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;112233&lt;/password&gt; &lt;/server&gt; &lt;server&gt; &lt;id&gt;maven-snapshots&lt;/id&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;112233&lt;/password&gt; &lt;/server&gt; &lt;/servers&gt; id : 为nexus的仓库名称， username : nexus用户名 password : nexus密码 二、建立maven项目，修改pom.xml 增长发布管理节点 &lt;distributionManagement&gt; &lt;snapshotRepository&gt; &lt;id&gt;maven-snapshots&lt;/id&gt; &lt;name&gt;maven-snapshots-repository&lt;/name&gt; &lt;url&gt;http://192.168.172.141:8081/repository/maven-snapshots/&lt;/url&gt; &lt;/snapshotRepository&gt; &lt;repository&gt; &lt;id&gt;maven-releases&lt;/id&gt; &lt;name&gt;maven-releases-repository&lt;/name&gt; &lt;url&gt;http://192.168.172.141:8081/repository/maven-releases/&lt;/url&gt; &lt;/repository&gt; &lt;/distributionManagement&gt; snapshotRepository : 快照仓库 repository : 发行仓库 id : 与上面的server的id一致 name : 随便 url : 仓库地址，从nexus中能够找到 三、项目打包发布 maven会根据&lt;version/&gt;中是否含有SANPSHOT来选择是发布到快照仓库，仍是发行版仓库 项目打包 mvn clean package -Dmaven.test.skip=true 项目发布 mvn deploy 运行完即可在nexus中看到本身的项目了。 9、jar包安装到nexus私服 有时项目开发时，一些maven依赖下载不下来，一直报错。这时，能够手动下载jar包，将其安装到nexus私服，再从nexus解决依赖问题。下面以安装kaptcha为例： mvn deploy:deploy-file -DgroupId=com.google.code.kaptcha -DartifactId=kaptcha -Dversion=2.3 -Dpackaging=jar -Dfile=D:\\kaptcha-2.3.2.jar -Durl=http://192.168.172.141:8081/repository/third/ -DrepositoryId=third DgroupId : jar包的groupId Dversion : jar包的版本 Dfile : jar包所在位置 Durl : 仓库地址 DrepositoryId : 仓库名 这里新建了名为third的第三方仓库，注意要在setting.xml增长一个server节点，配置用户名和密码。同时要将third仓库加到maven-public组中，由于第十步要依赖的是maven-public组。将 third加入maven-pulic组后，只要依赖maven-public，即可取到third中的jar包。 10、从nexus下载依赖 在pom.xml中增长以下仓库配置： &lt;repositories&gt; &lt;repository&gt; &lt;id&gt;nexus&lt;/id&gt; &lt;name&gt;Nexus Repository&lt;/name&gt; &lt;url&gt;http://192.168.172.141:8081/repository/maven-public/&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/snapshots&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/releases&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;pluginRepositories&gt; &lt;pluginRepository&gt; &lt;id&gt;nexus&lt;/id&gt; &lt;name&gt;Nexus Plugin Repository&lt;/name&gt; &lt;url&gt;http://192.168.172.141:8081/repository/maven-public/&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/snapshots&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/releases&gt; &lt;/pluginRepository&gt; &lt;/pluginRepositories&gt; 能够看到 上面的url节点填写的都是maven-public组的url，而maven-releases,maven-snapshots,third都包含在maven-public中，因此能取到三个仓库的内容。","categories":[],"tags":[],"author":"张存"},{"title":"Nginx Log日志统计分析常用命令","slug":"Nginx-Log日志统计分析常用命令","date":"2022-03-01T09:39:15.000Z","updated":"2022-03-01T09:42:53.430Z","comments":true,"path":"2022/03/01/nginx-log-ri-zhi-tong-ji-fen-xi-chang-yong-ming-ling/","link":"","permalink":"https://blog.zhangcun.store/2022/03/01/nginx-log-ri-zhi-tong-ji-fen-xi-chang-yong-ming-ling/","excerpt":"","text":"1.IP相关统计 1.1 统计IP访问量（独立ip访问数量） awk &#39;&#123;print $1&#125;&#39; access.log | sort -n | uniq | wc -l 1.2 查看某一时间段的IP访问量(4-5点) grep &quot;07/Apr/2017:0[4-5]&quot; access.log | awk &#39;&#123;print $1&#125;&#39; | sort | uniq -c| sort -nr | wc -l 1.3 查看访问最频繁的前100个IP awk &#39;&#123;print $1&#125;&#39; access.log | sort -n |uniq -c | sort -rn | head -n 100 1.4 查看访问100次以上的IP awk &#39;&#123;print $1&#125;&#39; access.log | sort -n |uniq -c |awk &#39;&#123;if($1 &gt;100) print $0&#125;&#39;|sort -rn 1.5 查询某个IP的详细访问情况,按访问频率排序 grep &#39;127.0.01&#39; access.log |awk &#39;&#123;print $7&#125;&#39;|sort |uniq -c |sort -rn |head -n 100 2.页面访问统计 2.1 查看访问最频的页面(TOP100) awk &#39;&#123;print $7&#125;&#39; access.log | sort |uniq -c | sort -rn | head -n 100 2.2 查看访问最频的页面([排除php页面】(TOP100) grep -v &quot;.php&quot; access.log | awk &#39;&#123;print $7&#125;&#39; | sort |uniq -c | sort -rn | head -n 100 2.3 查看页面访问次数超过100次的页面 cat access.log | cut -d &#39; &#39; -f 7 | sort |uniq -c | awk &#39;&#123;if ($1 &gt; 100) print $0&#125;&#39; | less 2.4 查看最近1000条记录，访问量最高的页面 tail -1000 access.log |awk &#39;&#123;print $7&#125;&#39;|sort|uniq -c|sort -nr|less 3.每秒每分钟每小时请求量统计 3.1 统计每秒的请求数,top100的时间点(精确到秒) awk &#39;&#123;print $4&#125;&#39; access.log |cut -c 14-21|sort|uniq -c|sort -nr|head -n 100 3.2 统计每分钟的请求数,top100的时间点(精确到分钟) awk &#39;&#123;print $4&#125;&#39; access.log |cut -c 14-18|sort|uniq -c|sort -nr|head -n 100 3.3 每小时的请求数,top100的时间点(精确到小时) awk &#39;&#123;print $4&#125;&#39; access.log |cut -c 14-15|sort|uniq -c|sort -nr|head -n 100 4.性能分析 *在nginx log中最后一个字段加入$request_time 4.1 列出传输时间超过 3 秒的页面，显示前20条 cat access.log|awk &#39;($NF &gt; 3)&#123;print $7&#125;&#39;|sort -n|uniq -c|sort -nr|head -20 4.2 列出php页面请求时间超过3秒的页面，并统计其出现的次数，显示前100条 cat access.log|awk &#39;($NF &gt; 1 &amp;&amp; $7~/\\.php/)&#123;print $7&#125;&#39;|sort -n|uniq -c|sort -nr|head -100 5.蜘蛛抓取统计 5.1 统计蜘蛛抓取次数 grep &#39;Baiduspider&#39; access.log |wc -l 5.2 统计蜘蛛抓取404的次数 grep &#39;Baiduspider&#39; access.log |grep &#39;404&#39; | wc -l 6.TCP连接统计 6.1 查看当前TCP连接数 netstat -tan | grep &quot;ESTABLISHED&quot; | grep &quot;:80&quot; | wc -l 6.2 用tcpdump嗅探80端口的访问看看谁最高 tcpdump -i eth0 -tnn dst port 80 -c 1000 | awk -F&quot;.&quot; &#39;&#123;print $1&quot;.&quot;$2&quot;.&quot;$3&quot;.&quot;$4&#125;&#39; | sort | uniq -c | sort -nr","categories":[],"tags":[],"author":"张存"},{"title":"在nginx中设置jenkins的反向代理","slug":"在nginx中设置jenkins的反向代理","date":"2022-03-01T03:49:29.000Z","updated":"2022-03-01T03:49:32.964Z","comments":true,"path":"2022/03/01/zai-nginx-zhong-she-zhi-jenkins-de-fan-xiang-dai-li/","link":"","permalink":"https://blog.zhangcun.store/2022/03/01/zai-nginx-zhong-she-zhi-jenkins-de-fan-xiang-dai-li/","excerpt":"","text":"1.修改nginx 的config文件，一般在/etc/nginx/nginx.conf,在server 中添加location块 ··· location /jenkins&#123; proxy_pass http://jenkins_ip:jenkins_port; proxy_redirect http:// https://; sendfile off; proxy_set_header Host $host:$server_port; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_max_temp_file_size 0; #this is the maximum upload size client_max_body_size 10m; client_body_buffer_size 128k; proxy_connect_timeout 90; proxy_send_timeout 90; proxy_read_timeout 90; proxy_temp_file_write_size 64k; # Required for new HTTP-based CLI proxy_http_version 1.1; proxy_request_buffering off; proxy_buffering off; # Required for HTTP-based CLI to work over SSL &#125; ···","categories":[],"tags":[],"author":"张存"},{"title":"使用DockerCompose搭建Redis集群","slug":"使用DockerCompose搭建Redis集群","date":"2022-03-01T03:37:11.000Z","updated":"2022-03-01T03:37:21.186Z","comments":true,"path":"2022/03/01/shi-yong-dockercompose-da-jian-redis-ji-qun/","link":"","permalink":"https://blog.zhangcun.store/2022/03/01/shi-yong-dockercompose-da-jian-redis-ji-qun/","excerpt":"","text":"一、安装Docker Compose 1.下载docker-compose，我这里选择1.25.5这个版本 sudo curl -L &quot;https://github.com/docker/compose/releases/download/1.25.5/docker-compose-$(uname -s)-$(uname -m)&quot; -o /usr/local/bin/docker-compose 2.下载好之后，设置权限 sudo chmod +x /usr/local/bin/docker-compose 3.检测是否安装成功 docker-compose --version 出现下图则表示安装成功 二、Redis镜像 1.下载redis镜像，我这里选择5.0.3 docker pull redis:5.0.3 2.查看镜像 docker image ls -a 三、准备容器挂载的目录 1.创建根目录 mkdir /docker/redis 2.创建容器目录，我这里采用3主1从的方式。端口分别为7001-7006。然后创建给每个节点创建对应的目录和配置文件 mkdir 700&#123;1..6&#125; mkdir 700&#123;1..6&#125;/data mkdir 700&#123;1..6&#125;/config touch 700&#123;1..6&#125;/config/redis.config 四、准备配置文件 1.将redis.config解压后，复制到各个节点的config下 五、准备docker-compose.yml vi docker-compose.yml 然后按键盘i，进入输入模式 复制以下内容： version: &#39;3&#39; services: redis1: image: redis:5.0.3 restart: always volumes: - /docker/redis/7001/config/redis.conf:/etc/redis/redis.conf - /docker/redis/7001/data:/data environment: - TZ=Asia/Shanghai - LANG=en_US.UTF-8 ports: - &#39;7001:6379&#39; #服务端口 - &#39;17001:16379&#39; #集群端口 command: [&quot;redis-server&quot;, &quot;/etc/redis/redis.conf&quot;] privileged: true #环境变量 redis2: image: redis:5.0.3 #network_mode: host restart: always volumes: - /docker/redis/7002/config/redis.conf:/etc/redis/redis.conf - /docker/redis/7002/data:/data environment: - TZ=Asia/Shanghai - LANG=en_US.UTF-8 ports: - &#39;7002:6379&#39; #服务端口 - &#39;17002:16379&#39; #集群端口 command: [&quot;redis-server&quot;, &quot;/etc/redis/redis.conf&quot;] privileged: true #环境变量 redis3: image: redis:5.0.3 #network_mode: host restart: always volumes: - /docker/redis/7003/config/redis.conf:/etc/redis/redis.conf - /docker/redis/7003/data:/data environment: - TZ=Asia/Shanghai - LANG=en_US.UTF-8 ports: - &#39;7003:6379&#39; #服务端口 - &#39;17003:16379&#39; #集群端口 command: [&quot;redis-server&quot;, &quot;/etc/redis/redis.conf&quot;] privileged: true #环境变量 redis4: image: redis:5.0.3 #network_mode: host restart: always volumes: - /docker/redis/7004/config/redis.conf:/etc/redis/redis.conf - /docker/redis/7004/data:/data environment: - TZ=Asia/Shanghai - LANG=en_US.UTF-8 ports: - &#39;7004:6379&#39; #服务端口 - &#39;17004:16379&#39; #集群端口 command: [&quot;redis-server&quot;, &quot;/etc/redis/redis.conf&quot;] privileged: true #环境变量 redis5: image: redis:5.0.3 #network_mode: host restart: always volumes: - /docker/redis/7005/config/redis.conf:/etc/redis/redis.conf - /docker/redis/7005/data:/data environment: - TZ=Asia/Shanghai - LANG=en_US.UTF-8 ports: - &#39;7005:6379&#39; #服务端口 - &#39;17005:16379&#39; #集群端口 command: [&quot;redis-server&quot;, &quot;/etc/redis/redis.conf&quot;] privileged: true #环境变量 redis6: image: redis:5.0.3 #network_mode: host restart: always volumes: - /docker/redis/7006/config/redis.conf:/etc/redis/redis.conf - /docker/redis/7006/data:/data environment: - TZ=Asia/Shanghai - LANG=en_US.UTF-8 ports: - &#39;7006:6379&#39; #服务端口 - &#39;17006:16379&#39; #集群端口 command: [&quot;redis-server&quot;, &quot;/etc/redis/redis.conf&quot;] privileged: true #环境变量 按键盘esc，输入:wq，保存文件 六、启动容器 以后台启动 docker-compose up -d 使用docker-compose ps查看容器列表，发现已经全部启动 再使用docker container ls比较看下 七、组建集群 redis-cli -h 192.168.200.135 -p 7001 --cluster create 192.168.200.135:7001 192.168.200.135:7002 192.168.200.135:7003 192.168.200.135:7004 192.168.200.135:7005 192.168.200.135:7006 --cluster-replicas 1 八、查看集群信息 可以看到主从关系 注意 1.使用docker-compose的方式，如果未指定网络，会以文件夹 + _default的规则自动创建一个名为redis_default的网络（文件夹名为redis），该次创建的所有容器都会加入该网络，其中的容器可以相互访问。 常见问题 1.搭建集群的时候，一直是Waiting for the cluster to join..... 我最初的想法是docker是相互隔离的，所以每个node中的端口都可以使用默认的6379。最开始配置为： ports: - &#39;7001:6379&#39; #服务端口 - &#39;17001:16379&#39; #集群端口 ... ports: - &#39;7006:6379&#39; #服务端口 - &#39;17006:16379&#39; #集群端口 其实这种配置有问题的。在启动容器的时候虽然正常，但是集群的节点间是无法通信的。因为redis集群间的通信端口是10000+当前节点port，在组建集群时，每个容器中的node，端口都是6379，会通过16379访问其他node，而容器映射的端口是17001不是16379，所以才会一直waiting。 2.Node 192.168.200.135:7002 is not empty. Either the node already knows other nodes (check with CLUSTER NODES) or contains some key in database 0 删除对应node中data下的内容即可，我这里是测试环境为了方便，删除所有node下data的内，命令如下： 先停止容器，docker-compose down ，然后删除所有节点data下的内rm -f /docker/redis/700&#123;1..6&#125;/data/*","categories":[],"tags":[],"author":"张存"},{"title":"mysql 压缩备份 压缩还原 命令","slug":"mysql-压缩备份-压缩还原-命令","date":"2022-02-28T11:54:01.000Z","updated":"2022-02-28T11:54:04.737Z","comments":true,"path":"2022/02/28/mysql-ya-suo-bei-fen-ya-suo-huan-yuan-ming-ling/","link":"","permalink":"https://blog.zhangcun.store/2022/02/28/mysql-ya-suo-bei-fen-ya-suo-huan-yuan-ming-ling/","excerpt":"","text":"1、mysqldump 备份并压缩sql文件mysql&gt;mysqldump -h主机ip -u用户名 -p密码（也可不输入） 数据库名 | gzip &gt; 压缩后文件位置 2、mysql直接用压缩文件恢复 mysql&gt;gunzip &lt; backupfile.sql.gz | mysql -u用户名 -p密码（也可不输入） 数据库名","categories":[],"tags":[],"author":"张存"},{"title":"Docker容器日志查看与清理","slug":"Docker容器日志查看与清理","date":"2022-02-28T11:39:39.000Z","updated":"2022-02-28T11:39:41.137Z","comments":true,"path":"2022/02/28/docker-rong-qi-ri-zhi-cha-kan-yu-qing-li/","link":"","permalink":"https://blog.zhangcun.store/2022/02/28/docker-rong-qi-ri-zhi-cha-kan-yu-qing-li/","excerpt":"","text":"使用场景 docker 容器日志导致主机磁盘空间满了。docker logs -f container_name 噼里啪啦一大堆，很占用空间，不用的日志可以清理掉了。 清理 Docker 容器日志 #!/bin/sh echo &quot;======== start clean docker containers logs ========&quot; logs=$(find /var/lib/docker/containers/ -name *-json.log) for log in $logs do echo &quot;clean logs : $log&quot; cat /dev/null &gt; $log done echo &quot;======== end clean docker containers logs ========&quot; # 脚本赋权 chmod +x clean_docker_log.sh # 执行脚本 ./clean_docker_log.sh 设置 Docker 容器日志大小 设置一个容器服务的日志大小上限。 上述方法，日志文件迟早又会涨回来。要从根本上解决问题，需要限制容器服务的日志大小上限。这个通过配置容器 docker-compose 的 max-size 选项来实现 nginx: image: nginx:1.12.1 restart: always logging: driver: “json-file” options: max-size: “5g” 重启 nginx 容器之后，其日志文件的大小就被限制在 5GB，再也不用担心了。 全局设置日志大小 vim /etc/docker/daemon.json 新建/etc/docker/daemon.json，若有就不用新建了。添加 log-dirver 和 log-opts 参数，样例如下： registry-mirrors 是容器镜像地址，你可以用阿里云的（免费的） &#123; &quot;registry-mirrors&quot;: [&quot;http://f613ce8f.m.daocloud.io&quot;], &quot;log-driver&quot;:&quot;json-file&quot;, &quot;log-opts&quot;: &#123;&quot;max-size&quot;:&quot;500m&quot;, &quot;max-file&quot;:&quot;3&quot;&#125; &#125; max-size=500m，意味着一个容器日志大小上限是 500M， max-file=3，意味着一个容器有三个日志，分别是 id+.json、id+1.json、id+2.json。 # 重启docker守护进程 systemctl daemon-reload systemctl restart docker PS: 我个人的感觉就是，如果不收集日志，我建议定时执行日志清理就可以了。像我之前遇到的情况就是，服务崩了，一直在刷错误日志，这个时候就需要清理掉。","categories":[],"tags":[],"author":"张存"},{"title":"jenkins jobs空间清理 modules过大。","slug":"jenkins-jobs空间清理-modules过大。","date":"2022-02-28T11:24:08.000Z","updated":"2022-02-28T11:35:47.276Z","comments":true,"path":"2022/02/28/jenkins-jobs-kong-jian-qing-li-modules-guo-da/","link":"","permalink":"https://blog.zhangcun.store/2022/02/28/jenkins-jobs-kong-jian-qing-li-modules-guo-da/","excerpt":"","text":"查看modules大小 du -h –max-depth=1 /opt/jenkins/data/jobs/*/modules/ 直接上脚本 #!/bin/bash echo &#39;+————————–开始删除1天前的modules&#39; files=`find /opt/jenkins/data/jobs/*/modules/* -mtime +1 -type d` deletelog=`find /opt/jenkins/data/jobs/*/modules/* -mtime +1 -type d | xargs ls -dlh|sort|xargs|sed &quot;s/drwxr/\\n\\rdrwxr/g&quot;` filelog=`find /opt/jenkins/data/jobs/*/modules/* -mtime +1 -type d | xargs du -h --max-depth=1` if [ ! &quot;$files&quot; = &quot;&quot; ] then echo &#39;+————————–即将删除的文件：&#39; echo $&#123;deletelog&#125; echo -e &quot;$&#123;filelog&#125; \\n&quot; rm -rf $&#123;files&#125; else echo &#39;+————————–没有文件要删除&#39; fi echo &#39;+————————–删除文件执行结束&#39; echo &quot;#—————本脚本执行结束`date &quot;+%Y-%m-%d-%H:%M:%S&quot;`&quot; echo &quot;#—————V2.0 by jeff AZURE&quot; echo &quot;#—————本次版本号V$&#123;BUILD&#125;&quot; echo &quot;#—————本次执行在$(hostname)&quot;","categories":[],"tags":[],"author":"张存"},{"title":"jenkins配置邮件通知","slug":"jenkins配置邮件通知","date":"2022-02-28T10:46:44.000Z","updated":"2022-05-06T09:50:34.694Z","comments":true,"path":"2022/02/28/jenkins-pei-zhi-you-jian-tong-zhi/","link":"","permalink":"https://blog.zhangcun.store/2022/02/28/jenkins-pei-zhi-you-jian-tong-zhi/","excerpt":"","text":"完成基于jenkins的持续集成部署后，任务构建执行完成，测试结果需要通知到相关人员。这篇博客，介绍如何在jenkins中配置邮件通知的方法。。。 一、安装邮件插件 由于Jenkins自带的邮件功能比较鸡肋，因此这里推荐安装专门的邮件插件，不过下面也会顺带介绍如何配置Jenkins自带的邮件功能作用。 可以通过系统管理→管理插件→可选插件，选择Email Extension Plugin插件进行安装： 由于我已经安装了该插件，因此这里显示在已安装目录下,还未安装的童鞋可以通过右上角的搜索框搜索改插件，然后在线安装，安装好之后重启Jenkins。 二、系统设置 通过系统管理→系统设置，进行邮件配置： 1、设置jenkins地址和管理员邮箱地址 2、设置发件人等信息 PS：这里的发件人邮箱地址切记要和系统管理员邮件地址保持一致（当然，也可以设置专门的发件人邮箱，不过不影响使用，根据具体情况设置即可） 上图的默认收件人邮箱可以添加多人，中间用英文半角逗号隔开即可。 3、配置邮件内容模版 附：邮箱内容模版（Default Content）： &lt;!DOCTYPE html&gt; &lt;html&gt; &lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;$&#123;ENV, var=&quot;JOB_NAME&quot;&#125;-第$&#123;BUILD_NUMBER&#125;次构建日志&lt;/title&gt; &lt;/head&gt; &lt;body leftmargin=&quot;8&quot; marginwidth=&quot;0&quot; topmargin=&quot;8&quot; marginheight=&quot;4&quot; offset=&quot;0&quot;&gt; &lt;table width=&quot;95%&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; style=&quot;font-size: 11pt; font-family: Tahoma, Arial, Helvetica, sans-serif&quot;&gt; &lt;tr&gt; 本邮件由系统自动发出，无需回复！&lt;br/&gt; 各位同事，大家好，以下为$&#123;PROJECT_NAME &#125;项目构建信息&lt;/br&gt; &lt;td&gt;&lt;font color=&quot;#CC0000&quot;&gt;构建结果 - $&#123;BUILD_STATUS&#125;&lt;/font&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;br /&gt; &lt;b&gt;&lt;font color=&quot;#0B610B&quot;&gt;构建信息&lt;/font&gt;&lt;/b&gt; &lt;hr size=&quot;2&quot; width=&quot;100%&quot; align=&quot;center&quot; /&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt; &lt;ul&gt; &lt;li&gt;项目名称 ： $&#123;PROJECT_NAME&#125;&lt;/li&gt; &lt;li&gt;构建编号 ： 第$&#123;BUILD_NUMBER&#125;次构建&lt;/li&gt; &lt;li&gt;触发原因： $&#123;CAUSE&#125;&lt;/li&gt; &lt;li&gt;构建状态： $&#123;BUILD_STATUS&#125;&lt;/li&gt; &lt;li&gt;构建日志： &lt;a href=&quot;$&#123;BUILD_URL&#125;console&quot;&gt;$&#123;BUILD_URL&#125;console&lt;/a&gt;&lt;/li&gt; &lt;li&gt;构建 Url ： &lt;a href=&quot;$&#123;BUILD_URL&#125;&quot;&gt;$&#123;BUILD_URL&#125;&lt;/a&gt;&lt;/li&gt; &lt;li&gt;工作目录 ： &lt;a href=&quot;$&#123;PROJECT_URL&#125;ws&quot;&gt;$&#123;PROJECT_URL&#125;ws&lt;/a&gt;&lt;/li&gt; &lt;li&gt;项目 Url ： &lt;a href=&quot;$&#123;PROJECT_URL&#125;&quot;&gt;$&#123;PROJECT_URL&#125;&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;h4&gt;&lt;font color=&quot;#0B610B&quot;&gt;失败用例&lt;/font&gt;&lt;/h4&gt; &lt;hr size=&quot;2&quot; width=&quot;100%&quot; /&gt; $FAILED_TESTS&lt;br/&gt; &lt;h4&gt;&lt;font color=&quot;#0B610B&quot;&gt;最近提交(#$SVN_REVISION)&lt;/font&gt;&lt;/h4&gt; &lt;hr size=&quot;2&quot; width=&quot;100%&quot; /&gt; &lt;ul&gt; $&#123;CHANGES_SINCE_LAST_SUCCESS, reverse=true, format=&quot;%c&quot;, changesFormat=&quot;&lt;li&gt;%d [%a] %m&lt;/li&gt;&quot;&#125; &lt;/ul&gt; 详细提交: &lt;a href=&quot;$&#123;PROJECT_URL&#125;changes&quot;&gt;$&#123;PROJECT_URL&#125;changes&lt;/a&gt;&lt;br/&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/body&gt; &lt;/html&gt; 4、设置邮件触发机制 上面的几步完成后，点击应用，保存即可。 5、配置Jenkins自带的邮件功能 配置内容如下，和Email Extension Plugin插件同样的配置，可以通过勾选通过发送测试邮件测试配置按钮来测试配置是否成功发送邮件，如下图： 完成上面的系统设置后，点击保存即可。 三、项目配置 在完成系统设置后，还需要给需要构建的项目进行邮件配置。 1、进入项目配置界面 进入新建的项目界面，点击配置按钮，进入系统配置页面： 2、配置构建后操作模块 进入系统配置页面后，点击上方的构建后操作选项，配置内容如下： 进入构建后操作的模块，然后会看到下面的内容，具体的配置信息如图中标注： 接上图： 配置内容默认即可，邮件内容类型可以根据自己的配置选择，收件人列表可以从前面的系统设置中默认收件人选项配置。 四、构建触发邮件测试 如下图，为我收到的测试邮件，邮件内容可以通过系统设置里面进行个性化的配置，可参考我上面的模板，或者自定义即可。","categories":[],"tags":[],"author":"张存"},{"title":"Shell学习笔记之在linux定时任务crontab中使用nohup不输出到nohup文件","slug":"Shell学习笔记之在linux定时任务crontab中使用nohup不输出到nohup文件","date":"2022-02-28T10:44:04.000Z","updated":"2022-02-28T10:44:07.203Z","comments":true,"path":"2022/02/28/shell-xue-xi-bi-ji-zhi-zai-linux-ding-shi-ren-wu-crontab-zhong-shi-yong-nohup-bu-shu-chu-dao-nohup-wen-jian/","link":"","permalink":"https://blog.zhangcun.store/2022/02/28/shell-xue-xi-bi-ji-zhi-zai-linux-ding-shi-ren-wu-crontab-zhong-shi-yong-nohup-bu-shu-chu-dao-nohup-wen-jian/","excerpt":"","text":"0x00 概述 在linux定时任务crontab中使用nohup不输出到nohup文件,这时候需要做个重定向,将输出结果重定向到nohup文件即可. 0x02 增加重定向 最初的shell脚本,注意该脚本在命令行正常运行是可以把输出自动只想nohup.out文件的 #!/bin/bash ps -ef|grep test.py |grep -v &quot;grep&quot; # 判断脚本是否启动 if [ $? -ne 0 ] #如果没有 then echo &quot;start process.....&quot; nohup python /home/hlz/Desktop/test.py &amp; # 执行启动脚本命令,nohup输出是追加到日志文件,这样不会覆盖掉之前的日志文件 else echo &quot;runing.....&quot; fi 在命令行直接sh这个脚本文件, 脚本的输出会自动定向到脚本同级目录的nohup.out文件内; 但是当把这个脚本挂载到定时任务crontab内, 脚本的输出则不会定向到脚本同级目录的nohup.out文件内; 这时候需要做个重定向,注意两个脚本的区别: #!/bin/bash ps -ef|grep test.py |grep -v &quot;grep&quot; # 判断脚本是否启动 if [ $? -ne 0 ] #如果没有 then echo &quot;start process.....&quot; nohup python /home/hlz/Desktop/test.py &gt;&gt; /home/hlz/Desktop/test.log 2&gt;&amp;1 &amp; # 执行启动脚本命令,nohup输出是追加到日志文件,这样不会覆盖掉之前的日志文件 else echo &quot;runing.....&quot; fi 需要加入指定重定向的文件绝对路径,后续该脚本定时启动的时候无论重启多少次,脚本的输出都会重定向到这个文件内","categories":[],"tags":[],"author":"张存"},{"title":"在线websocket测试-online tool-postjson","slug":"在线websocket测试-online-tool-postjson","date":"2022-02-28T10:42:07.000Z","updated":"2022-04-20T11:33:54.445Z","comments":true,"path":"2022/02/28/zai-xian-websocket-ce-shi-online-tool-postjson/","link":"","permalink":"https://blog.zhangcun.store/2022/02/28/zai-xian-websocket-ce-shi-online-tool-postjson/","excerpt":"","text":"http://coolaf.com/tool/chattest","categories":[],"tags":[],"author":"张存"},{"title":"禁止ubuntu 20.04自动休眠","slug":"禁止ubuntu-20-04自动休眠","date":"2022-02-28T10:39:36.000Z","updated":"2022-02-28T10:40:45.274Z","comments":true,"path":"2022/02/28/jin-zhi-ubuntu-20-04-zi-dong-xiu-mian/","link":"","permalink":"https://blog.zhangcun.store/2022/02/28/jin-zhi-ubuntu-20-04-zi-dong-xiu-mian/","excerpt":"","text":"ubuntu 20.04登陆之后，如果系统较长时间不操作，系统就自动休眠了。 如果重启之后，从来都没有登陆，就不会出现系统自动休眠的情况。 观察系统日志，发现类似如下的内容： Feb 25 22:15:38 server NetworkManager[737]: &lt;info&gt; [1582668938.0193] manager: sleep: sleep requested (sleeping: no enabled: yes) Feb 25 22:15:38 server NetworkManager[737]: &lt;info&gt; [1582668938.0239] manager: NetworkManager state is now ASLEEP Feb 25 22:15:38 server whoopsie[1025]: [22:15:38] offline Feb 25 22:15:38 server gnome-shell[956]: Screen lock is locked down, not locking Feb 25 22:15:38 server systemd[1]: Reached target Sleep. Feb 25 22:15:38 server systemd[1]: Starting Suspend... Feb 25 22:15:38 server kernel: [ 1235.212537] PM: suspend entry (s2idle) Feb 25 22:15:38 server systemd-sleep[1705]: Suspending system... 发现是触发了systemd的自动休眠功能，检查休眠功能的状态以及历史记录，如下： $ systemctl status sleep.target ● sleep.target - Sleep Loaded: loaded (/lib/systemd/system/sleep.target; static; vendor preset: enabled) Active: inactive (dead) Docs: man:systemd.special(7) Feb 24 13:18:08 xps systemd[1]: Reached target Sleep. Feb 26 13:29:31 xps systemd[1]: Stopped target Sleep. Feb 26 13:29:57 xps systemd[1]: Reached target Sleep. Feb 26 13:30:19 xps systemd[1]: Stopped target Sleep. 普通桌面应用这个情况问题不大，但是如果是作为服务器使用的时候，我们一般远程访问系统，这个功能就会导致我们无法远程控制服务器，因此我们需要关闭这个功能。 执行关闭休眠功能的命令，如下： sudo systemctl mask sleep.target suspend.target hibernate.target hybrid-sleep.target Created symlink /etc/systemd/system/sleep.target → /dev/null. Created symlink /etc/systemd/system/suspend.target → /dev/null. Created symlink /etc/systemd/system/hibernate.target → /dev/null. Created symlink /etc/systemd/system/hybrid-sleep.target → /dev/null. 再次观察系统休眠状态，如下： $ systemctl status sleep.target ● sleep.target Loaded: masked (Reason: Unit sleep.target is masked.) Active: inactive (dead) 发现自动休眠功能已经被关闭，不会出现自动休眠导致远程控制无法访问的情况了。","categories":[],"tags":[],"author":"张存"},{"title":"iptables 做本地转发","slug":"iptables-做本地转发","date":"2022-02-28T10:36:00.000Z","updated":"2022-02-28T10:36:52.006Z","comments":true,"path":"2022/02/28/iptables-zuo-ben-di-zhuan-fa/","link":"","permalink":"https://blog.zhangcun.store/2022/02/28/iptables-zuo-ben-di-zhuan-fa/","excerpt":"","text":"需求： 服务器192.168.1.209 上 某个web程序监听到了127.0.0.1 的8000 端口上。 要通过访问192.168.1.209的80端口来访问127.0.0.1的8000端口： 做法：iptables -t nat -I PREROUTING -p tcp –dport 8080 -j DNAT –to 127.0.0.1:8000 开启本地路由转发！！！ sysctl -w net.ipv4.conf.eno16780032.route_localnet=1 #eno16780032 的名字为 流量进入的网卡的名字 也可以把所有的网卡的本地路由打开 sudo iptables-save","categories":[],"tags":[],"author":"张存"},{"title":"Ubuntu环境下的iptables的端口转发配置实例","slug":"Ubuntu环境下的iptables的端口转发配置实例","date":"2022-02-28T10:29:09.000Z","updated":"2022-02-28T10:30:05.380Z","comments":true,"path":"2022/02/28/ubuntu-huan-jing-xia-de-iptables-de-duan-kou-zhuan-fa-pei-zhi-shi-li/","link":"","permalink":"https://blog.zhangcun.store/2022/02/28/ubuntu-huan-jing-xia-de-iptables-de-duan-kou-zhuan-fa-pei-zhi-shi-li/","excerpt":"","text":"打开转发开关 要让iptables的端口转发生效，首先需要打开转发开关 方法一：临时打开，重启后失效 $sudo su #echo 1 &gt;/proc/sys/net/ipv4/ip_forward 方法二：永久打开，重启依然有效 编辑/etc/sysctl.conf文件，将net.ipv4.ip_forward=1前面的#注释去掉，保存文件，然后执行sudo sysctl -p使其生效 典型使用场景举例 场景一：目标机的22端口外网没有打开，通过本地端口转发实现通过其他端口访问ssh的22端口 案例：125.69.67.213机器的22端口未对外开放，但开放了3000~4000之间的端口，因此通过3000端口转发到22实现ssh登录 sudo iptables -t nat -A PREROUTING -p tcp -i eth0 -d 125.69.67.213 --dport 3000 -j DNAT --to 125.69.67.213:22 这个属于本机端A端口转发到本机的B端口 场景二：将内网的22端口映射到外网的一个端口，实现SSH直接登录，不用跳转 案例：192.168.2.61为外网机，192.168.2.70为内网机，如果不做映射，需要先登录到61，再登录到70.做如下映射之后，可直接通过外网机的3003登录到内网机 sudo iptables -t nat -A PREROUTING -d 192.168.2.61 -p tcp --dport 3003 -j DNAT --to-destination 192.168.2.70:22 sudo iptables -t nat -A POSTROUTING -d 192.168.2.70 -p tcp --dport 22 -j SNAT --to 192.168.2.61 注：(1) 本例中也可以通过SecureCRT的自动登录实现。 场景三：在外网直接访问内网的MySQL数据库 案例：很多时候数据库在内网机，外网不能直接访问，但做运维的时候可能需要通过图形界面工具直接连上去。做端口映射就可以解决这个问题。例如：将外网机192.168.2.61的3001端口转发到内网机192.168.2.70的MySQL的3306端口 sudo iptables -t nat -A PREROUTING -d 192.168.2.61 -p tcp --dport 3001 -j DNAT --to-destination 192.168.2.70:3306 sudo iptables -t nat -A POSTROUTING -d 192.168.2.70 -p tcp --dport 3306 -j SNAT --to 192.168.2.61 iptables其他常见操作 查看当前iptables的所有规则 sudo iptables -L 或者 sudo iptables-save iptables规则保存到文件 sudo sh -c &quot;iptables-save &gt; /etc/iptables.rules&quot; 从文件恢复iptables的规则 sudo iptables-restore /etc/iptables.rules 开机启动加载iptables规则 注：配置的规则系统默认重启后就失效，因此做开机启动时加载iptables的配置也有必要。 在/etc/network/interfaces的末尾添加如下一行： pre-up iptables-restore &lt; /etc/iptables.rules 如果想在关机的时候自动保存修改过的iptables规则，可添加如下行 post-down iptables-save &gt; /etc/iptables.up.rules","categories":[],"tags":[],"author":"张存"},{"title":"nginx 域名重定向跳转至另一个域名","slug":"nginx-域名重定向跳转至另一个域名","date":"2022-02-24T05:37:13.000Z","updated":"2022-02-24T05:37:41.010Z","comments":true,"path":"2022/02/24/nginx-yu-ming-chong-ding-xiang-tiao-zhuan-zhi-ling-yi-ge-yu-ming/","link":"","permalink":"https://blog.zhangcun.store/2022/02/24/nginx-yu-ming-chong-ding-xiang-tiao-zhuan-zhi-ling-yi-ge-yu-ming/","excerpt":"","text":"域名 www.test123.com 跳转到www.test456.com server &#123; listen 80; server_name www.test123.com; rewrite ^/(.*) http://www.test456.com/$1 permanent; &#125;","categories":[],"tags":[],"author":"张存"},{"title":"Nginx 出现504 Gateway Time-out的解决方法","slug":"Nginx-出现504-Gateway-Time-out的解决方法","date":"2022-02-24T02:27:31.000Z","updated":"2022-02-24T02:27:38.692Z","comments":true,"path":"2022/02/24/nginx-chu-xian-504-gateway-time-out-de-jie-jue-fang-fa/","link":"","permalink":"https://blog.zhangcun.store/2022/02/24/nginx-chu-xian-504-gateway-time-out-de-jie-jue-fang-fa/","excerpt":"","text":"nginx+tomcat 后端为tomcat，nginx代理报504超时错误。 问题处理： 1、修改/etc/nginx/nginx.conf，添加如下信息： 复制代码 http &#123; include /etc/nginx/mime.types; default_type application/octet-stream; log_format main &#39;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#39; &#39;$status $body_bytes_sent &quot;$http_referer&quot; &#39; &#39;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&#39;; access_log /var/log/nginx/access.log main; sendfile on; #tcp_nopush on; keepalive_timeout 65; #gzip on; include /etc/nginx/conf.d/*.conf; #用于tomcat反向代理,解决nginx 504错误 proxy_connect_timeout 300; #单位秒 proxy_send_timeout 300; #单位秒 proxy_read_timeout 300; #单位秒 proxy_buffer_size 16k; proxy_buffers 4 64k; proxy_busy_buffers_size 128k; proxy_temp_file_write_size 128k; # ps:以timeout结尾配置项时间要配置大点 &#125; 复制代码 2、修改server&#123;&#125;，添加如下信息： 复制代码 location / &#123; proxy_pass http://182.61.131.62:33060/; proxy_redirect off; proxy_send_timeout 300; proxy_read_timeout 300; proxy_connect_timeout 300; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; &#125;","categories":[],"tags":[],"author":"张存"},{"title":"禅道admin忘记密码","slug":"禅道admin忘记密码","date":"2022-02-23T13:08:38.000Z","updated":"2022-02-23T13:10:22.145Z","comments":true,"path":"2022/02/23/shan-dao-admin-wang-ji-mi-ma/","link":"","permalink":"https://blog.zhangcun.store/2022/02/23/shan-dao-admin-wang-ji-mi-ma/","excerpt":"","text":"/opt/zbox/run/mysql/mysql -uroot -p 禅道数据库root默认密码123456 MariaDB [(none)]&gt; show databases; +--------------------+ | Database | +--------------------+ | information_schema | | mysql | | performance_schema | | zentao | | zentaobiz | | zentaopro | +--------------------+ 6 rows in set (0.00 sec) MariaDB [(none)]&gt; use zentao; Reading table information for completion of table and column names You can turn off this feature to get a quicker startup with -A 忘记admin密码后，修改zt_user表 MariaDB [zentao]&gt; select id,account,password from zt_user; +----+---------+----------------------------------+ | id | account | password | +----+---------+----------------------------------+ | 1 | admin | 070b17106ddfd497e1018e6a9990fb5f | +----+---------+----------------------------------+ 1 row in set (0.00 sec) MariaDB [zentao]&gt; update zt_user set password=&#39;e10adc3949ba59abbe56e057f20f883e&#39; where id=1; Query OK, 1 row affected (0.00 sec) Rows matched: 1 Changed: 1 Warnings: 0 MariaDB [zentao]&gt; e10adc3949ba59abbe56e057f20f883e即：123456","categories":[],"tags":[],"author":"张存"},{"title":"Elasticsearch built-in security features are not enabled去除","slug":"Elasticsearch-built-in-security-features-are-not-enabled去除","date":"2022-02-23T13:03:18.000Z","updated":"2022-02-23T13:03:39.037Z","comments":true,"path":"2022/02/23/elasticsearch-built-in-security-features-are-not-enabled-qu-chu/","link":"","permalink":"https://blog.zhangcun.store/2022/02/23/elasticsearch-built-in-security-features-are-not-enabled-qu-chu/","excerpt":"","text":"在个人学习或者内网开放ES+VPN连接的情况下我们完全不需要开启安全功能，其他情况在生产集群中还是建议开启安全选项的。因此，这里将他关闭先 在elasticsearch.yml 配置禁用安全选项xpack.security.enabled，之后重启ElasticSearch即可： xpack.security.enabled: false 重启即可","categories":[],"tags":[],"author":"张存"},{"title":"记录 Ubuntu18.04 中文乱码，解决方法","slug":"记录-Ubuntu18-04-中文乱码，解决方法","date":"2022-02-23T13:01:30.000Z","updated":"2022-02-23T13:01:55.603Z","comments":true,"path":"2022/02/23/ji-lu-ubuntu18-04-zhong-wen-luan-ma-jie-jue-fang-fa/","link":"","permalink":"https://blog.zhangcun.store/2022/02/23/ji-lu-ubuntu18-04-zhong-wen-luan-ma-jie-jue-fang-fa/","excerpt":"","text":"1.查看现有语言环境 locale 2.如果没有 en_US.UTF-8 则安装 locale-gen en_US.UTF-8 3.可用语言环境 locale -a 4.永久更改编码，运行以下命令。 注意 如果是 docker 容器，重启会无效 echo “export LC_ALL=en_US.UTF-8” &gt;&gt; /etc/profiledocker 镜像 运行以下代码 echo “export LC_ALL=en_US.UTF-8” &gt;&gt; /root/.bashrc 5.要让刚才的修改马上生效，需要执行以下命令 完成 source /etc/profile","categories":[],"tags":[],"author":"张存"},{"title":"mysql查看编码格式以及修改编码格式","slug":"mysql查看编码格式以及修改编码格式","date":"2022-02-23T10:13:59.000Z","updated":"2022-02-23T10:18:14.923Z","comments":true,"path":"2022/02/23/mysql-cha-kan-bian-ma-ge-shi-yi-ji-xiu-gai-bian-ma-ge-shi/","link":"","permalink":"https://blog.zhangcun.store/2022/02/23/mysql-cha-kan-bian-ma-ge-shi-yi-ji-xiu-gai-bian-ma-ge-shi/","excerpt":"","text":"进入mysql，输入show variables like ‘character%’;查看当前字符集编码情况其中，character_set_client为客户端编码方式； character_set_connection为建立连接使用的编码； character_set_database数据库的编码； character_set_results结果集的编码； character_set_server数据库服务器的编码； 只要保证以上四个采用的编码方式一样，就不会出现乱码问题。 修改数据库的编码格式 方法一：命令为：set character% = utf8； 例如：set character_set_client =utf8; 但是这个修改只是暂时的，限于当前会话，一旦数据库退出，就会失效 方法二：修改my.cnf文件 命令：vi /etc/my.cnf（提示：my.cnf文件的具体位置因安装版本或系统而异） 找到[client] 添加： character-set-server=utf8 找到[mysqld] 添加： character-set-server=utf8 然后重启mysql服务。","categories":[],"tags":[],"author":"张存"},{"title":"Nginx 502 Bad Gateway 原因与解决方法","slug":"Nginx-502-Bad-Gateway-原因与解决方法","date":"2022-02-23T10:11:01.000Z","updated":"2022-02-23T10:12:09.703Z","comments":true,"path":"2022/02/23/nginx-502-bad-gateway-yuan-yin-yu-jie-jue-fang-fa/","link":"","permalink":"https://blog.zhangcun.store/2022/02/23/nginx-502-bad-gateway-yuan-yin-yu-jie-jue-fang-fa/","excerpt":"","text":"FastCGI执行时间过长 根据实际情况调高以下参数值 fastcgi_connect_timeout 300; fastcgi_send_timeout 300; fastcgi_read_timeout 300; FastCGI Buffer不够 nginx和apache一样，有前端缓冲限制，可以调整缓冲参数 fastcgi_buffer_size 32k; fastcgi_buffers 8 32k;","categories":[],"tags":[],"author":"张存"},{"title":"sql.gz数据备份与恢复","slug":"sql-gz数据备份与恢复-1","date":"2022-02-23T09:58:40.000Z","updated":"2022-02-23T09:58:42.725Z","comments":true,"path":"2022/02/23/sql-gz-shu-ju-bei-fen-yu-hui-fu-1/","link":"","permalink":"https://blog.zhangcun.store/2022/02/23/sql-gz-shu-ju-bei-fen-yu-hui-fu-1/","excerpt":"","text":"数据全备 mysqldump –skip-opt -h hostname -u username -ppassword databasename | gzip &gt; sqlback.sql.gz 数据恢复 gunzip &lt; sqlback.sql.gz | mysql -uusername -ppassword databasename","categories":[],"tags":[],"author":"张存"},{"title":"Redis Cluster日常操作命令梳理","slug":"Redis-Cluster日常操作命令梳理","date":"2022-02-18T10:18:57.000Z","updated":"2022-02-18T10:19:14.986Z","comments":true,"path":"2022/02/18/redis-cluster-ri-chang-cao-zuo-ming-ling-shu-li/","link":"","permalink":"https://blog.zhangcun.store/2022/02/18/redis-cluster-ri-chang-cao-zuo-ming-ling-shu-li/","excerpt":"","text":"在之前的一篇文章已经介绍了Redis Cluster及其部署，下面说下Redis Cluster日常操作命令： 一、以下命令是Redis Cluster集群所独有的，执行下面命令需要先登录redis： [root@manage redis]# redis-cli -c -p 6382 -h 192.168.10.12 （客户端命令：redis-cli -c -p port -h ip） 192.168.10.12:6382&gt; 登录redis后，在里面可以进行下面命令操作 集群 cluster info ：打印集群的信息 cluster nodes ：列出集群当前已知的所有节点（ node），以及这些节点的相关信息。 节点 cluster meet &lt;ip&gt; &lt;port&gt; ：将 ip 和 port 所指定的节点添加到集群当中，让它成为集群的一份子。 cluster forget &lt;node_id&gt; ：从集群中移除 node_id 指定的节点。 cluster replicate &lt;master_node_id&gt; ：将当前从节点设置为 node_id 指定的master节点的slave节点。只能针对slave节点操作。 cluster saveconfig ：将节点的配置文件保存到硬盘里面。 槽(slot) cluster addslots &lt;slot&gt; [slot ...] ：将一个或多个槽（ slot）指派（ assign）给当前节点。 cluster delslots &lt;slot&gt; [slot ...] ：移除一个或多个槽对当前节点的指派。 cluster flushslots ：移除指派给当前节点的所有槽，让当前节点变成一个没有指派任何槽的节点。 cluster setslot &lt;slot&gt; node &lt;node_id&gt; ：将槽 slot 指派给 node_id 指定的节点，如果槽已经指派给 另一个节点，那么先让另一个节点删除该槽&gt;，然后再进行指派。 cluster setslot &lt;slot&gt; migrating &lt;node_id&gt; ：将本节点的槽 slot 迁移到 node_id 指定的节点中。 cluster setslot &lt;slot&gt; importing &lt;node_id&gt; ：从 node_id 指定的节点中导入槽 slot 到本节点。 cluster setslot &lt;slot&gt; stable ：取消对槽 slot 的导入（ import）或者迁移（ migrate）。 键 cluster keyslot &lt;key&gt; ：计算键 key 应该被放置在哪个槽上。 cluster countkeysinslot &lt;slot&gt; ：返回槽 slot 目前包含的键值对数量。 cluster getkeysinslot &lt;slot&gt; &lt;count&gt; ：返回 count 个 slot 槽中的键 。 二、集群中Master的下线及恢复 1）Master下线后，其对应的Slaver节点会自动变为Master节点，如下截图： 2）原来的Master重启后变成Slaver节点，并是原来Master节点的Slaver节点 三，添加节点 1）新配置二个测试节点 # cd /etc/redis //新增配置 # cp redis-6379.conf redis-6378.conf &amp;&amp; sed -i &quot;s/6379/6378/g&quot; redis-6378.conf # cp redis-6382.conf redis-6385.conf &amp;&amp; sed -i &quot;s/6382/6385/g&quot; redis-6385.conf //启动 # redis-server /etc/redis/redis-6385.conf &gt; /var/log/redis/redis-6385.log 2&gt;&amp;1 &amp; # redis-server /etc/redis/redis-6378.conf &gt; /var/log/redis/redis-6378.log 2&gt;&amp;1 &amp; 2）添加主节点 # redis-trib.rb add-node 192.168.10.219:6378 192.168.10.219:6379 注释： 192.168.10.219:6378是新增的节点 192.168.10.219:6379集群任一个旧节点 3）添加从节点 # redis-trib.rb add-node --slave --master-id 03ccad2ba5dd1e062464bc7590400441fafb63f2 192.168.10.220:6385 192.168.10.219:6379 注释： --slave，表示添加的是从节点 --master-id 03ccad2ba5dd1e062464bc7590400441fafb63f2,主节点的node id，在这里是前面新添加的6378的node id 192.168.10.220:6385,新节点 192.168.10.219:6379集群任一个旧节点 4）重新分配slot # redis-trib.rb reshard 192.168.10.219:6378 //下面是主要过程 How many slots do you want to move (from 1 to 16384)? 1000 //设置slot数1000 What is the receiving node ID? 03ccad2ba5dd1e062464bc7590400441fafb63f2 //新节点node id Please enter all the source node IDs. Type &#39;all&#39; to use all the nodes as source nodes for the hash slots. Type &#39;done&#39; once you entered all the source nodes IDs. Source node #1:all //表示全部节点重新洗牌 Do you want to proceed with the proposed reshard plan (yes/no)? yes //确认重新分 新增加的主节点，是没有slots的， M: 03ccad2ba5dd1e062464bc7590400441fafb63f2 192.168.10.219:6378 slots:0-332,5461-5794,10923-11255 (0 slots) master 主节点如果没有slots的话，存取数据就都不会被选中。 可以把分配的过程理解成打扑克牌，all表示大家重新洗牌；输入某个主节点的node id，然后在输入done的话，就好比从某个节点，抽牌。 5）查看一下，集群情况 [root@slave2 redis]# redis-trib.rb check 192.168.10.219:6379 Connecting to node 192.168.10.219:6379: OK Connecting to node 192.168.10.220:6385: OK Connecting to node 192.168.10.219:6378: OK Connecting to node 192.168.10.220:6382: OK Connecting to node 192.168.10.220:6383: OK Connecting to node 192.168.10.219:6380: OK Connecting to node 192.168.10.219:6381: OK Connecting to node 192.168.10.220:6384: OK &gt;&gt;&gt; Performing Cluster Check (using node 192.168.10.219:6379) M: 5d8ef5a7fbd72ac586bef04fa6de8a88c0671052 192.168.10.219:6379 slots:5795-10922 (5128 slots) master 1 additional replica(s) S: 9c240333476469e8e2c8e80b089c48f389827265 192.168.10.220:6385 slots: (0 slots) slave replicates 03ccad2ba5dd1e062464bc7590400441fafb63f2 M: 03ccad2ba5dd1e062464bc7590400441fafb63f2 192.168.10.219:6378 slots:0-332,5461-5794,10923-11255 (1000 slots) master 1 additional replica(s) M: 19b042c17d2918fade18a4ad2efc75aa81fd2422 192.168.10.220:6382 slots:333-5460 (5128 slots) master 1 additional replica(s) M: b2c50113db7bd685e316a16b423c9b8abc3ba0b7 192.168.10.220:6383 slots:11256-16383 (5128 slots) master 1 additional replica(s) S: 6475e4c8b5e0c0ea27547ff7695d05e9af0c5ccb 192.168.10.219:6380 slots: (0 slots) slave replicates 19b042c17d2918fade18a4ad2efc75aa81fd2422 S: 1ee01fe95bcfb688a50825d54248eea1e6133cdc 192.168.10.219:6381 slots: (0 slots) slave replicates b2c50113db7bd685e316a16b423c9b8abc3ba0b7 S: 9a2a1d75b8eb47e05eee1198f81a9edd88db5aa1 192.168.10.220:6384 slots: (0 slots) slave replicates 5d8ef5a7fbd72ac586bef04fa6de8a88c0671052 [OK] All nodes agree about slots configuration. &gt;&gt;&gt; Check for open slots... &gt;&gt;&gt; Check slots coverage... [OK] All 16384 slots covered. 三、手动改变slave从节点所属的master主节点（一个slave只能属于一个master，而一个master可以有多个slave） //查看一下6378的从节点 # redis-cli -p 6378 cluster nodes | grep slave | grep 03ccad2ba5dd1e062464bc7590400441fafb63f2 //将6385加入到新的master # redis-cli -c -p 6385 -h 192.168.10.220 192.168.10.220:6385&gt; cluster replicate 5d8ef5a7fbd72ac586bef04fa6de8a88c0671052 //新master的node id OK 192.168.10.220:6385&gt; quit //查看新master的slave # redis-cli -p 6379 cluster nodes | grep slave | grep 5d8ef5a7fbd72ac586bef04fa6de8a88c0671052 四、删除节点 1）删除从节点 # redis-trib.rb del-node 192.168.10.220:6385 &#39;9c240333476469e8e2c8e80b089c48f389827265&#39; 2）删除主节点 如果主节点有从节点，将从节点转移到其他主节点 如果主节点有slot，去掉分配的slot，然后在删除主节点 # redis-trib.rb reshard 192.168.10.219:6378 //取消分配的slot,下面是主要过程 How many slots do you want to move (from 1 to 16384)? 1000 //被删除master的所有slot数量 What is the receiving node ID? 5d8ef5a7fbd72ac586bef04fa6de8a88c0671052 //接收6378节点slot的master Please enter all the source node IDs. Type &#39;all&#39; to use all the nodes as source nodes for the hash slots. Type &#39;done&#39; once you entered all the source nodes IDs. Source node #1:03ccad2ba5dd1e062464bc7590400441fafb63f2 //被删除master的node-id Source node #2:done Do you want to proceed with the proposed reshard plan (yes/no)? yes //取消slot后，reshard 新增master节点后，也进行了这一步操作，当时是分配，现在去掉。反着的。 # redis-trib.rb del-node 192.168.10.219:6378 &#39;03ccad2ba5dd1e062464bc7590400441fafb63f2&#39; 新的master节点被删除了，这样就回到了，就是这篇文章开头，还没有添加节点的状态 五、复制迁移 在redis集群中通过&quot;cluster replicate &lt;master_node_id&gt; &quot;命令可以将一个slave节点重新配置为另外一个master的slave。 注意：这个只是针对slave节点，即登录到slave节点的reids中，执行这个命令。 比如172.16.60.204:7003是172.16.60.202:7000主节点的slave节点，也可以把他设置成172.16.60.205:7004主节点的slave节点。 172.16.60.205:7004主节点的ID是48cbab906141dd26241ccdbc38bee406586a8d03 则操作为 [root@redis-new01 ~]# /data/redis-4.0.6/src/redis-cli -h 172.16.60.204 -c -p 7003 172.16.60.204:7003&gt; cluster replicate 48cbab906141dd26241ccdbc38bee406586a8d03 OK 172.16.60.204:7003&gt; 这样172.16.60.204:7003节点就变成了172.16.60.205:7004主节点的slave节点，而不再是172.16.60.202:7000主节点的slave节点！ 这样可以自动的将一个复制节点从一个master下移动到另外一个master下。 这种情况下的复制节点的自动重配置被称为复制迁移。 复制迁移可以提升系统的可靠性和抗灾性。 在某种情况下，你想让集群的复制节点从一个master迁移到另一个master的原因可能是： 集群的抗崩溃能力总是跟集群中master 拥有的平均slave数量成正比。 比如，如果一个集群中每个master只有一个slave，当master和slave都挂掉的时候这个集群就崩溃了。因为此时有一些哈希槽无法找到了。 虽然网络分裂会把一堆节点从集群中孤立出来（这样你一下就会知道集群出问题了），但是其他的更常见的硬件或者软件的问题并不会在多台机器上同时发生， 所以很 可能在你的这个集群（平均每个master只有一个slave）有一个slave在早上4点挂掉，然后他的master在随后的早上6点挂掉。这样依然会 导致集群崩溃。 可以通过给每个master都再多加一个slave节点来改进系统的可靠性，但是这样很昂贵。复制迁移允许只给某些master增加slave。比方说你的集群有20个节点， 10个master，每个master都有1个slave。然后你增加3个 slave到集群中并把他们分配给某几个master节点，这样某些master就会拥有多于1个slave。 当某个 master失去了slave的时候，复制迁移可以将slave节点从拥有富余slave的master旗下迁移给没有slave的master。所以当 你的slave在早上4点挂掉的时候， 另一个slave会被迁移过来取代它的位置，这样当master节点在早上5点挂掉的时候，依然有一个slave可 以被选举为master，集群依然可以正常运行。 所以简而言之，关于复制迁移应该注意下面几个方面： - 集群在迁移的时候会尝试去迁移拥有最多slave数量的master旗下的slave。 - 想利用复制迁移特性来增加系统的可用性，你只需要增加一些slave节点给单个master（哪个master节点并不重要）。 - 复制迁移是由配置项cluster-migration-barrier控制的 六、升级节点 升级从服务器节点很简单，因为你只需要停止节点然后用已更新的Redis版本重启。如果有客户端使用从服务器节点分离读请求，它们应该能够在某个节点 不可用时重新连接另一个从服务器。 升级主服务器要稍微复杂一些，建议的步骤是： 1）使用cluster failover来触发一次手工故障转移主服务器(请看本文档的手工故障转移小节)。 2）等待主服务器变为从服务器。 3）像升级从服务器那样升级这个节点。 4）如果你想让你刚刚升级的节点成为主服务器，触发一次新的手工故障转移，让升级的节点重新变回主服务器。 可以按照这些步骤来一个节点一个节点的升级，直到全部节点升级完毕。 目前redis cluster集群的启动只能空节点启动，当节点有数据时会有err警告，但是只要进行fix就好了 redis-trib.rb fix 用这个命令修复下就OK了。 七、Redis缓存清理 1）登陆redis # src/redis-cli -c -h 192.168.1.100 -p 6379 2）执行： 192.168.1.100:6379&gt; dbsize 3） 192.168.1.100:6379&gt; flushall ================================================================ redis集群指定key值得缓存清理： 1)登录至指定端口的redis服务器 # src/redis-cli -c -h 192.168.1.100 -p 6379 2）查看所有key值 （或者使用info命令也能查看出来） keys * 3）删除指定索引的值 del key *************** 当你发现自己的才华撑不起野心时，就请安静下来学习吧！***************","categories":[],"tags":[],"author":"张存"},{"title":"Linux下的nexus数据迁移","slug":"Linux下的nexus数据迁移","date":"2022-02-18T10:04:55.000Z","updated":"2022-02-18T10:05:05.341Z","comments":true,"path":"2022/02/18/linux-xia-de-nexus-shu-ju-qian-yi/","link":"","permalink":"https://blog.zhangcun.store/2022/02/18/linux-xia-de-nexus-shu-ju-qian-yi/","excerpt":"","text":"https://www.cnblogs.com/guarderming/p/10901440.html 我在原私服的nexus服务器中， 1、备份原nexus使用命令 tar zcvf nexus-20220218.tar.gz ./nexus/ 完成tar包的压缩 打包完毕后，会生成一个nexus-2018-0801.tar.gz 的文件，文件越多，越大，压缩就越慢。 2、将已经完成tar包，拷贝到新的服务器地址： 登录新服务器，进入想要迁移的目录，注意tar的大小和硬盘的大小 使用命令scp拷贝： 3、在新服务器中解压tar包，如下 解压完成后。确认目录下的配置文件 是否已经保存为对应的nexus解压目录。 4、这个时候启动nexus会报这个错误： 如何解决呢： 我们需要运行 这个命令，单次解决root不运营start命令的问题，然后在执行./nexus start，此时，系统会提示nexus已经成功启动： 目前，比较卡顿的步骤就是最后一个问题。","categories":[],"tags":[],"author":"张存"},{"title":"ETCD的安装","slug":"ETCD的安装","date":"2022-02-18T09:27:09.000Z","updated":"2022-02-18T09:27:18.741Z","comments":true,"path":"2022/02/18/etcd-de-an-zhuang/","link":"","permalink":"https://blog.zhangcun.store/2022/02/18/etcd-de-an-zhuang/","excerpt":"","text":"0,操作用户与环境 # whoami root # uname -a Linux VM_0_2_centos 3.10.0-693.el7.x86_64 #1 SMP Tue Aug 22 21:09:27 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux 1,添加etcd用户及用户组 groupadd etcd &amp;&amp; useradd -c &quot;Etcd user&quot; -g etcd -s /sbin/nologin -r etcd etcd用户 tail /etc/passwd etcd:x:995:1001:Etcd user:/home/etcd:/sbin/nologin 2,下载二进制文件 DOWNLOAD_URL=https://storage.googleapis.com/etcd #etcd存储地址 ETCD_VER=v3.1.5 #设置etcd版本号 wget $&#123;DOWNLOAD_URL&#125;/$&#123;ETCD_VER&#125;/etcd-$&#123;ETCD_VER&#125;-linux-amd64.tar.gz tar xvf etcd-$&#123;ETCD_VER&#125;-linux-amd64.tar.gz 3,部署文件 将如下内容写入文件 /etc/etcd/etcd.conf 中： # [member] ETCD_NAME=default ETCD_DATA_DIR=&quot;/var/lib/etcd/default.etcd&quot; # ETCD_WAL_DIR=&quot;&quot; # ETCD_SNAPSHOT_COUNT=&quot;10000&quot; # ETCD_HEARTBEAT_INTERVAL=&quot;100&quot; # ETCD_ELECTION_TIMEOUT=&quot;1000&quot; # ETCD_LISTEN_PEER_URLS=&quot;http://localhost:2380&quot; ETCD_LISTEN_CLIENT_URLS=&quot;http://0.0.0.0:2379&quot; # ETCD_MAX_SNAPSHOTS=&quot;5&quot; # ETCD_MAX_WALS=&quot;5&quot; # ETCD_CORS=&quot;&quot; # # [cluster] # ETCD_INITIAL_ADVERTISE_PEER_URLS=&quot;http://localhost:2380&quot; # if you use different ETCD_NAME (e.g. test), set ETCD_INITIAL_CLUSTER value for this name, i.e. &quot;test=http://...&quot; # ETCD_INITIAL_CLUSTER=&quot;default=http://localhost:2380&quot; # ETCD_INITIAL_CLUSTER_STATE=&quot;new&quot; # ETCD_INITIAL_CLUSTER_TOKEN=&quot;etcd-cluster&quot; ETCD_ADVERTISE_CLIENT_URLS=&quot;http://0.0.0.0:2379&quot; # ETCD_DISCOVERY=&quot;&quot; # ETCD_DISCOVERY_SRV=&quot;&quot; # ETCD_DISCOVERY_FALLBACK=&quot;proxy&quot; # ETCD_DISCOVERY_PROXY=&quot;&quot; # # [proxy] # ETCD_PROXY=&quot;off&quot; # ETCD_PROXY_FAILURE_WAIT=&quot;5000&quot; # ETCD_PROXY_REFRESH_INTERVAL=&quot;30000&quot; # ETCD_PROXY_DIAL_TIMEOUT=&quot;1000&quot; # ETCD_PROXY_WRITE_TIMEOUT=&quot;5000&quot; # ETCD_PROXY_READ_TIMEOUT=&quot;0&quot; # # [security] # ETCD_CERT_FILE=&quot;&quot; # ETCD_KEY_FILE=&quot;&quot; # ETCD_CLIENT_CERT_AUTH=&quot;false&quot; # ETCD_TRUSTED_CA_FILE=&quot;&quot; # ETCD_PEER_CERT_FILE=&quot;&quot; # ETCD_PEER_KEY_FILE=&quot;&quot; # ETCD_PEER_CLIENT_CERT_AUTH=&quot;false&quot; # ETCD_PEER_TRUSTED_CA_FILE=&quot;&quot; # [logging] # ETCD_DEBUG=&quot;false&quot; # examples for -log-package-levels etcdserver=WARNING,security=DEBUG # ETCD_LOG_PACKAGE_LEVELS=&quot;&quot; 记得创建 目录 #mkdir -p /var/lib/etcd/default.etcd 并修改权限 #chown -R etcd:etcd /var/lib/etcd/ 4,将 etcd, etcdctl放入 /usr/bin/下，并将如下内容写进/usr/lib/systemd/system/etcd.service文件 #cd etcd-$&#123;ETCD_VER&#125;-linux-amd64 #cp etcd /usr/bin/ #cp etcdctl /usr/bin/ [Unit] Description=Etcd Server After=network.target After=network-online.target Wants=network-online.target [Service] Type=notify WorkingDirectory=/var/lib/etcd/ EnvironmentFile=-/etc/etcd/etcd.conf User=etcd # set GOMAXPROCS to number of processors ExecStart=/bin/bash -c &quot;GOMAXPROCS=$(nproc) /usr/bin/etcd --name=\\&quot;$&#123;ETCD_NAME&#125;\\&quot; --data-dir=\\&quot;$&#123;ETCD_DATA_DIR&#125;\\&quot; --listen-client-urls=\\&quot;$&#123;ETCD_LISTEN_CLIENT_URLS&#125;\\&quot;&quot; Restart=on-failure LimitNOFILE=65536 [Install] WantedBy=multi-user.target 5,运行 #systemctl start etcd.service &amp;&amp; systemctl enable etcd #systemctl status etcd ● etcd.service - Etcd Server Loaded: loaded (/usr/lib/systemd/system/etcd.service; enabled; vendor preset: disabled) Active: active (running) since Fri 2018-06-22 14:04:50 CST; 13min ago Main PID: 4818 (etcd) CGroup: /system.slice/etcd.service └─4818 /usr/bin/etcd --name=default --data-dir=/var/lib/etcd/default.etcd --listen-client-urls=http://0.0.0.0:2379 Jun 22 14:04:50 VM_0_2_centos etcd[4818]: 8e9e05c52164694d received MsgVoteResp from 8e9e05c52164694d at term 2 Jun 22 14:04:50 VM_0_2_centos etcd[4818]: 8e9e05c52164694d became leader at term 2 Jun 22 14:04:50 VM_0_2_centos etcd[4818]: raft.node: 8e9e05c52164694d elected leader 8e9e05c52164694d at term 2 Jun 22 14:04:50 VM_0_2_centos etcd[4818]: setting up the initial cluster version to 3.1 Jun 22 14:04:50 VM_0_2_centos etcd[4818]: published &#123;Name:default ClientURLs:[http://0.0.0.0:2379]&#125; to cluster cdf818194e3a8c32 Jun 22 14:04:50 VM_0_2_centos etcd[4818]: ready to serve client requests Jun 22 14:04:50 VM_0_2_centos etcd[4818]: serving insecure client requests on [::]:2379, this is strongly discouraged! Jun 22 14:04:50 VM_0_2_centos systemd[1]: Started Etcd Server. Jun 22 14:04:50 VM_0_2_centos etcd[4818]: set the initial cluster version to 3.1 Jun 22 14:04:50 VM_0_2_centos etcd[4818]: enabled capabilities for version 3.1 #netstat -anp|grep 2379 tcp6 0 0 :::2379 :::* LISTEN 4818/etcd","categories":[],"tags":[],"author":"张存"},{"title":"Linux 系统cpu利用率计算（shell版）","slug":"Linux-系统cpu利用率计算（shell版）","date":"2022-02-16T11:37:07.000Z","updated":"2022-02-16T11:37:09.874Z","comments":true,"path":"2022/02/16/linux-xi-tong-cpu-li-yong-lu-ji-suan-shell-ban/","link":"","permalink":"https://blog.zhangcun.store/2022/02/16/linux-xi-tong-cpu-li-yong-lu-ji-suan-shell-ban/","excerpt":"","text":"Linux系统的cpu利用率不像windows的任务管理器这么直观能看到。top和vmstat是一个看到cpu利用率的方式。 下面是我自己计算cpu使用率的方法，以备自己做监控视图用。 [root@Centos5 admin]# more /proc/stat cpu 494881706 19 67370877 876689477 17202366 200116 0 cpu0 96177278 1 13815598 71114795 780840 160297 0 cpu1 55637645 2 7822250 116484226 2099600 5076 0 cpu2 55163466 2 7460892 116965069 2441533 6266 0 cpu3 59323490 2 7755772 112506339 2445624 6001 0 cpu4 57541559 2 7651880 114524670 2321514 5737 0 cpu5 56891878 3 7629496 115132164 2386230 5592 0 cpu6 56887733 3 7617390 115174187 2355772 5791 0 cpu7 57258654 1 7617597 114788022 2371250 5351 0 这个是官方对cpu对第一行数据的解释： The number of jiffies (1/100ths of a second) that the system spent in user mode, user mode with low priority (nice), system mode, and the idle task, respectively. The last value should be 100 times the second entry in the uptime pseudo-file. 各个参数的具体解释： 第一排是cpu总计，下面是2个4核cpu的参数，故有8行数据。 user (494881706) 从系统启动开始累计到当前时刻，用户态的CPU时间（单位：jiffies） ，不包含 nice值为负进程。1jiffies=0.01秒 nice (19) 从系统启动开始累计到当前时刻，nice值为负的进程所占用的CPU时间（单位：jiffies） system (67370877) 从系统启动开始累计到当前时刻，核心时间（单位：jiffies） idle (876689477) 从系统启动开始累计到当前时刻，除硬盘IO等待时间以外其它等待时间（单位：jiffies） iowait (17202366) 从系统启动开始累计到当前时刻，硬盘IO等待时间（单位：jiffies） ， irq (200116) 从系统启动开始累计到当前时刻，硬中断时间（单位：jiffies） softirq (0) 从系统启动开始累计到当前时刻，软中断时间（单位：jiffies） CPU利用率技术脚本： 本脚本持续显示cpu的利用率。 #!/bin/bash while(true) do CPU_1=$(cat /proc/stat | grep &#39;cpu &#39; | awk &#39;&#123;print $2&quot; &quot;$3&quot; &quot;$4&quot; &quot;$5&quot; &quot;$6&quot; &quot;$7&quot; &quot;$8&#125;&#39;) SYS_IDLE_1=$(echo $CPU_1 | awk &#39;&#123;print $4&#125;&#39;) Total01=$(echo $CPU_1 | awk &#39;&#123;printf &quot;%.f&quot;,$1+$2+$3+$4+$5+$6+$7&#125;&#39;) sleep 2 CPU_2=$(cat /proc/stat | grep &#39;cpu &#39; | awk &#39;&#123;print $2&quot; &quot;$3&quot; &quot;$4&quot; &quot;$5&quot; &quot;$6&quot; &quot;$7&quot; &quot;$8&#125;&#39;) SYS_IDLE_2=$(echo $CPU_2 | awk &#39;&#123;print $4&#125;&#39;) Total_2=$(echo $CPU_2 | awk &#39;&#123;printf &quot;%.f&quot;,$1+$2+$3+$4+$5+$6+$7&#125;&#39;) SYS_IDLE=`expr $SYS_IDLE_2 - $SYS_IDLE_1` Total=`expr $Total_2 - $Total01` TT=`expr $SYS_IDLE \\* 100` SYS_USAGE=`expr $TT / $Total` SYS_Rate=`expr 100 - $SYS_USAGE` echo &quot;The CPU Rate : $SYS_Rate%&quot; echo &quot;------------------&quot; done","categories":[],"tags":[],"author":"张存"},{"title":"find、xargs、grep","slug":"find、xargs、grep","date":"2022-02-16T10:30:55.000Z","updated":"2022-02-16T10:31:01.174Z","comments":true,"path":"2022/02/16/find-xargs-grep/","link":"","permalink":"https://blog.zhangcun.store/2022/02/16/find-xargs-grep/","excerpt":"","text":"find find命令用于：在一个目录（及子目录）中搜索文件，你可以指定一些匹配条件，如按文件名、文件类型、用户甚至是时间戳查找文件。 find命令一般简化形式（还可以更复杂，更多操作） find [path...] [expression] path：find命令所查找的目录路径。例如用.来表示当前目录，用/来表示系统根目录 touch一些测试文件 $ ls hello.cpp kg.lua kobebryant Kobe.lua 参考：http://tiger-hu.iteye.com/blog/1927754 按名字查找 -name 和 -iname的区别在于前者对大小写敏感，后者不敏感 $ find . -name &quot;k*&quot; ./kobebryant ./kg.lua $ find . -iname &quot;k*&quot; ./kobebryant ./Kobe.lua ./kg.lua 按时间查找 -atime -n[+n]: 找出文件访问时间在n日之内[之外]的文件。 -ctime -n[+n]: 找出文件更改时间在n日之内[之外]的文件。 -mtime -n[+n]: 找出修改数据时间在n日之内[之外]的文件。 -amin -n[+n]: 找出文件访问时间在n分钟之内[之外]的文件。 -cmin -n[+n]: 找出文件更改时间在n分钟之内[之外]的文件。 -mmin -n[+n]: 找出修改数据时间在n分钟之内[之外]的文件。 比如：找出一天内修改文件 $ find -ctime -1 . ./hello.cpp ./kobebryant ./Kobe.lua ./kg.lua 基于找到的文件执行操作 -exec: 对匹配的文件执行该参数所给出的shell命令。相应命令的形式为&#39;command&#39; &#123;&#125; \\;，注意&#123;&#125;和\\；之间的空格，同时两个&#123;&#125;之间没有空格。特别注意：分号是必须打，作为-exec的结束符 -ok: 其主要功能和语法格式与-exec完全相同，唯一的差别是在于该选项更加安全，因为它会在每次执行shell命令之前均予以提示，只有在回答为y的时候， 其后的shell命令才会被继续执行。需要说明的是，该选项不适用于自动化脚本，因为该提供可能会挂起整个自动化流程。 比如：找出60分钟内修改的文件，并执行ls -l ，也就是显示出详情 $ find . -cmin -60 -exec ls -l &#123;&#125; \\; 总用量 0 -rw-rw-r-- 1 philosophie philosophie 0 8月 5 22:29 hello.cpp -rw-rw-r-- 1 philosophie philosophie 0 8月 5 22:27 kg.lua -rw-rw-r-- 1 philosophie philosophie 0 8月 5 22:27 kobebryant -rw-rw-r-- 1 philosophie philosophie 0 8月 5 22:27 Kobe.lua -rw-rw-r-- 1 philosophie philosophie 0 8月 5 22:29 ./hello.cpp -rw-rw-r-- 1 philosophie philosophie 0 8月 5 22:27 ./kobebryant -rw-rw-r-- 1 philosophie philosophie 0 8月 5 22:27 ./Kobe.lua -rw-rw-r-- 1 philosophie philosophie 0 8月 5 22:27 ./kg.lua 比如：找出kg为首的文件，提示删除 $ find . -name &quot;kg*&quot; -ok rm &#123;&#125; \\; &lt; rm ... ./kg.lua &gt; ? y $ ls hello.cpp kobebryant Kobe.lua 按文件所属的owner和group查找： -user: 查找owner属于-user选项后面指定用户的文件。 ! -user: 查找owner不属于-user选项后面指定用户的文件。 -group: 查找group属于-group选项后面指定组的文件。 ! -group: 查找group不属于-group选项后面指定组的文件。 比如 $ find . -user philosophie . ./hello.cpp ./kobebryant ./Kobe.lua 按指定目录深度查找 -maxdepth: 后面的参数表示距当前目录指定的深度，其中1表示当前目录，2表示一级子目录，以此类推。在指定该选项后，find只是在找到指定深度后就不在递归其子目录了。下例中的深度为1，表示只是在当前子目录中搜索。如果没有设置该选项，find将递归当前目录下的所有子目录。 $ mkdir hhh $ cd hhh/ $ touch h.c $ find . -maxdepth 1 -name &quot;*&quot; # 当前目录找不到 h.c . ./hello.cpp ./kobebryant ./hhh ./Kobe.lua $ find . -maxdepth 2 -name &quot;*&quot; # 1级子目录找到了h.c . ./hello.cpp ./kobebryant ./hhh ./hhh/h.c ./Kobe.lua 按文件权限属性查找 补充：文件权限，分别为 所有者、所在组、其他组，八进制数字 $ ll 总用量 12 drwxrwxr-x 3 philosophie philosophie 4096 8月 5 23:56 ./ drwxrwxr-x 3 philosophie philosophie 4096 8月 5 22:26 ../ -rw-rw-r-- 1 philosophie philosophie 0 8月 5 22:29 hello.cpp drwxrwxr-x 2 philosophie philosophie 4096 8月 5 23:57 hhh/ -rw-rw-r-- 1 philosophie philosophie 0 8月 5 22:27 kobebryant -rw-rw-r-- 1 philosophie philosophie 0 8月 5 22:27 Kobe.lua $ find . -perm 664 ./hello.cpp ./kobebryant ./hhh/h.c ./Kobe.lua $ find . -perm 775 . ./hhh 按文件类型查找 -type：后面指定文件的类型。 b - 块设备文件。 d - 目录。 c - 字符设备文件。 p - 管道文件。 l - 符号链接文件。 f - 普通文件。 $ mkdir kkk $ find . -type d . ./kkk ./hhh $ find . -type d -name &quot;h*&quot; ./hhh 按文件大小查找 -size [+/-]100[c/k/M/G]: 表示文件的长度为等于[大于/小于]100块[字节/k/M/G]的文件。 -empty: 查找空文件。 比如，查找文件大小为0的文件可以这样写 -size [+/-]100[c/k/M/G]: 表示文件的长度为等于[大于/小于]100块[字节/k/M/G]的文件。 -empty: 查找空文件。 比如 $ find . -size 0 -exec ls -l &#123;&#125; \\; -rw-rw-r-- 1 philosophie philosophie 0 8月 6 10:30 ./b -rw-rw-r-- 1 philosophie philosophie 0 8月 6 10:30 ./a 也可以 $ find . -empty -exec ls -l &#123;&#125; \\; -rw-rw-r-- 1 philosophie philosophie 0 8月 6 10:30 ./b -rw-rw-r-- 1 philosophie philosophie 0 8月 6 10:30 ./a 按更改时间比指定文件新或比文件旧的方式查找 -newer file 比如，查找比b更新的文件，也就是更晚创建的文件 $ find . -newer b 查找不比b更新的文件，输出会包括文件b $ find . ! -newer b xargs 背景：在使用find命令的-exec选项处理匹配到的文件时， find命令将所有匹配到的文件一起传递给exec执行。但有些系统对能够传递给exec的命令长度有限制，这样在find命令运行几分钟之后，就会出现溢出错误。 find命令把匹配到的文件传递给xargs命令，而xargs命令每次只获取一部分文件而不是全部，不像-exec选项那样。这样它可以先处理最先获取的一部分文件，然后是下一批，并如此继续下去。 在有些系统中，使用-exec选项会为处理每一个匹配到的文件而发起一个相应的进程，并非将匹配到的文件全部作为参数一次执行；这样在有些情况下就会出现进程过多，系统性能下降的问题，因而效率不高； 而使用xargs命令则只有一个进程。 比如：找到所有普通文件，并测试每个文件是什么类型的 $ find . -type f -print|xargs file ./b: empty ./c: empty ./a: empty ./t.sh: a /bin/bsah script, ASCII text executable ./hello.lua: ASCII text grep 参考：http://blog.csdn.net/zhushuai1221/article/details/53097008 grep (global search regular expression(RE) and print out the line 全局搜索正则表达式并把行打印出来。 作用：它能使用正则表达式搜索文本，并把匹配的行打印出来。 Unix的grep家族包括grep、egrep和fgrep。egrep和fgrep的命令只跟grep有很小不同。egrep是grep的扩展，支持更多的re元字符， fgrep就是fixed grep或fast grep，它们把所有的字母都看作单词。 Linux使用GNU版本的grep。它功能更强，可以通过-G、-E、-F命令行选项来使用egrep和fgrep的功能。 常用的grep选项有： -c 只输出匹配行的计数。 -i 不区分大小写。 -h 查询多文件时不显示文件名。 -l 查询多文件时只输出包含匹配字符的文件名。 -n 显示匹配行及行号。 -s 不显示不存在或无匹配文本的错误信息。 -v 显示不包含匹配文本的所有行。 比如： 将utils.lua出现local的行取出来 $ grep local utils.lua local TableDB = require(&#39;.TableDB&#39;) local M = &#123;&#125; 显示出来的同时显示行号 $ grep -n local utils.lua 2:local TableDB = require(&#39;.TableDB&#39;) 3:local M = &#123;&#125; 我这里显示出的local是标记了红色的，原本应该不是默认这样的，要使得查找的关键字的显示颜色应该要这样写 grep -n --color=auto &#39;local&#39; 但是之所以默认这样是因为~/.bashrc这个文件配置过了，如下 将匹配的行的前2行后3行也打印出来，就拿bashrc这个文件为例，找出配置了grep的地方。（后面的grep不用引号也是可以的） $ cat ~/.bashrc | grep -n -A3 -B2 &#39;grep&#39; 80- #alias vdir=&#39;vdir --color=auto&#39; 81- 82: alias grep=&#39;grep --color=auto&#39; 83: alias fgrep=&#39;fgrep --color=auto&#39; 84: alias egrep=&#39;egrep --color=auto&#39; 85-fi 86- 87-# colored GCC warnings and errors 按文件的内容查找文件 # grep ‘energywise’ * #在当前目录搜索带&#39;energywise&#39;行的文件 # grep -r ‘energywise’ * #在当前目录及其子目录下搜索&#39;energywise&#39;行的文件 # grep -l -r ‘energywise’ * #在当前目录及其子目录下搜索&#39;energywise&#39;行的文件","categories":[],"tags":[],"author":"张存"},{"title":"Shell for 循环嵌套的写法","slug":"Shell-for-循环嵌套的写法","date":"2022-02-16T06:12:11.000Z","updated":"2022-02-16T06:12:40.603Z","comments":true,"path":"2022/02/16/shell-for-xun-huan-qian-tao-de-xie-fa/","link":"","permalink":"https://blog.zhangcun.store/2022/02/16/shell-for-xun-huan-qian-tao-de-xie-fa/","excerpt":"","text":"#!/bin/bash for num in 1 2 3 4 5 do for char in &quot;a b c d e&quot; do echo $num $char done done","categories":[],"tags":[],"author":"张存"},{"title":"docker-compose 手工指定容器IP","slug":"docker-compose-手工指定容器IP","date":"2022-02-16T06:08:12.000Z","updated":"2022-02-16T06:10:21.911Z","comments":true,"path":"2022/02/16/docker-compose-shou-gong-zhi-ding-rong-qi-ip/","link":"","permalink":"https://blog.zhangcun.store/2022/02/16/docker-compose-shou-gong-zhi-ding-rong-qi-ip/","excerpt":"","text":"docker-compose 手工指定容器IP 首先明确两点： 1只有自定义网络，才能手工指定每个容器的ip。默认的bridge是不行的！ 2 手工设定了网段比如172.19.0.0 不影响docker在host装的网卡docker0 的172.17.0.1 容器内的172.19.0.XX 还是可以通过172.17.0.1访问到主机。 docker-compose.yml 参考官网 https://docs.docker.com/compose/compose-file/#network-configuration-reference 复制代码 version: &#39;3.7&#39; services: x1: image: XXX restart: always tty: true networks: mynet1: ipv4_address: 172.19.0.2 networks: mynet1: ipam: config: - subnet: 172.19.0.0/16 复制代码 几点说明： 1 2以前，可以在ipam里指定gateway 3以后不许了； 2 静态指定ip，则每个容器都要静态指定，添加networks 部分 3 运行docker-compose up 首先会创建network 注意之前如果已经运行过多个不同工程的docker-compose 可能已经自动创建了很多network 这样如果IP网段已经分配过了，就会失败: ERROR: Pool overlaps with other one on this address space 类似地，此外如果已经创建了network mynet1的网段 为 172.28.0.0，但是想改成172.19.0.1，也会说失败 这样都需要清理一下无效的network 清除各种不用的docker相关东西 参考 https://blog.csdn.net/wennuanddianbo/article/details/78453325 docker network prune 4 3以后无法指定IP地址类型。只能是ipV6，在node里 const requestIp = require(&#39;request-ip&#39;); ... app.use(requestIp.mw()) ... req.clientIp 得到的都是ipv6地址，都在ipv4地址前都补上了::fff: 形如 ::ffff:172.19.0.10 —————————————","categories":[],"tags":[],"author":"张存"},{"title":"Linux截取文件指定行数之间的内容","slug":"Linux截取文件指定行数之间的内容","date":"2022-02-11T13:32:21.000Z","updated":"2022-02-11T13:33:11.011Z","comments":true,"path":"2022/02/11/linux-jie-qu-wen-jian-zhi-ding-xing-shu-zhi-jian-de-nei-rong/","link":"","permalink":"https://blog.zhangcun.store/2022/02/11/linux-jie-qu-wen-jian-zhi-ding-xing-shu-zhi-jian-de-nei-rong/","excerpt":"","text":"如果你只想看文件的前100行，可以使用head命令，如head -100 filename 如果你想查看文件的后100行，可以使用tail命令，如：tail -100 filename 或 tail -n 100 filename 查看文件中间一段，你可以使用sed命令，如：sed -n ‘100,200p’ filename 这样你就可以只查看文件的第100行到第200行。 截取的文件可以用重定向输入到新的文件中：head -100 filename &gt;a.txt","categories":[],"tags":[],"author":"张存"},{"title":"linux的一个find命令配合rm删除某天前的文件","slug":"linux的一个find命令配合rm删除某天前的文件","date":"2022-02-11T12:08:03.000Z","updated":"2022-02-11T12:08:50.240Z","comments":true,"path":"2022/02/11/linux-de-yi-ge-find-ming-ling-pei-he-rm-shan-chu-mou-tian-qian-de-wen-jian/","link":"","permalink":"https://blog.zhangcun.store/2022/02/11/linux-de-yi-ge-find-ming-ling-pei-he-rm-shan-chu-mou-tian-qian-de-wen-jian/","excerpt":"","text":"语句写法：find 对应目录 -mtime +天数 -name “文件名” -exec rm -rf {} ; 例1： 将/usr/local/backups目录下所有10天前带”.”的文件删除 find /usr/local/backups -mtime +10 -name “.“ -exec rm -rf {} ; find：linux的查找命令，用户查找指定条件的文件 /usr/local/backups：想要进行清理的任意目录 -mtime：标准语句写法 ＋10：查找10天前的文件，这里用数字代表天数，＋30表示查找30天前的文件 “.“：希望查找的数据类型，”.jpg”表示查找扩展名为jpg的所有文件，”“表示查找所有文件，这个可以灵活运用，举一反三 -exec：固定写法 rm -rf：强制删除文件，包括目录 {} ; ：固定写法，一对大括号+空格+\\ find $1 -name “*.html” -mtime +1 -print0 |xargs -0 rm -v","categories":[],"tags":[],"author":"张存"},{"title":"linux中find查找指定时间段的文件并grep查找内容","slug":"linux中find查找指定时间段的文件并grep查找内容","date":"2022-02-11T09:20:28.000Z","updated":"2022-02-11T09:23:40.541Z","comments":true,"path":"2022/02/11/linux-zhong-find-cha-zhao-zhi-ding-shi-jian-duan-de-wen-jian-bing-grep-cha-zhao-nei-rong/","link":"","permalink":"https://blog.zhangcun.store/2022/02/11/linux-zhong-find-cha-zhao-zhi-ding-shi-jian-duan-de-wen-jian-bing-grep-cha-zhao-nei-rong/","excerpt":"","text":"find . -type f -newermt &#39;2016-01-01 00:00:00&#39; ! -newermt &#39;2016-02-01 12:00:00&#39; -exec grep aaaa &#123;&#125; \\; &gt; tmp.txt find -newerXY file/time：XY为占位符，a、B、m、c、t分别代表上次访问时间、创建时间、上次modify时间、上次索引节点改变时间和绝对时间；find根据Y的值来计算file的某个时间戳，然后根据X的值来做匹配。t不能做X。","categories":[],"tags":[],"author":"张存"},{"title":"Mysql 一次性备份导出所有数据库","slug":"Mysql-一次性备份导出-导入恢复所有数据库","date":"2022-01-24T11:18:33.000Z","updated":"2022-01-24T11:27:22.995Z","comments":true,"path":"2022/01/24/mysql-yi-ci-xing-bei-fen-dao-chu-dao-ru-hui-fu-suo-you-shu-ju-ku/","link":"","permalink":"https://blog.zhangcun.store/2022/01/24/mysql-yi-ci-xing-bei-fen-dao-chu-dao-ru-hui-fu-suo-you-shu-ju-ku/","excerpt":"","text":"导出全部数据库mysqldump -uroot -p –all-databases &gt; sqlfile.sql","categories":[],"tags":[],"author":"张存"},{"title":"docker-compose启动容器后执行脚本或命令不退出 | 运行内部程序","slug":"docker-compose启动容器后执行脚本或命令不退出-运行内部程序","date":"2022-01-24T05:27:40.000Z","updated":"2022-01-24T09:57:00.630Z","comments":true,"path":"2022/01/24/docker-compose-qi-dong-rong-qi-hou-zhi-xing-jiao-ben-huo-ming-ling-bu-tui-chu-yun-xing-nei-bu-cheng-xu/","link":"","permalink":"https://blog.zhangcun.store/2022/01/24/docker-compose-qi-dong-rong-qi-hou-zhi-xing-jiao-ben-huo-ming-ling-bu-tui-chu-yun-xing-nei-bu-cheng-xu/","excerpt":"","text":"说下我的需求，就是在使用 docker-compose 启动server容器后，执行命令或者执行脚本运行容器内部的进程。 容器是个基于django框架的web server，通过uwsgi启动，我是这样操作的： 1.在docker-compose.yaml文件中，在容器设置部分加入entrypoint: /root/path/xxx.sh，另外也编辑command: bash， 2.启动服务，docker-compose up -d，后台进程启动服务， 3.查看服务，docker-compose ps，发现容器处于Restarting，换句话说，容器启动有问题， 4.先停止服务，docker-compose stop 于是，我注释掉docker-compose的entrypoint部分，然后docker-compose up -d，查看服务docker-compose ps，容器处于up状态，于是我通过exec命令在容器中执行相关命令，如下图： 可以看到uwsgi进程是起来了，本地测试web server的接口, 显然，这与我们的初衷不符，在 docker-compose 的时候，通常希望通过docker-compose up -d起来容器后，容器内部的应用程序就起来了，如果我们还需要通过exec，这种操作未免多余。 好在，docker还有个特别之处，我们可以通过 docker build 读取到 Dockerfile中的指令后，在构建新镜像再起容器的时候，可以直接执行脚本文件运行容器内部应用程序，同时不退出容器。 Dockerfile的设置： #dockerfile to build image for docker-composeFROM xxxxx/xxxserver-ubuntu16.04:1.0 MAINTAINER &#x78;&#120;&#120;&#x40;&#103;&#111;&#x6f;&#x67;&#x6c;&#x65;&#46;&#x63;&#111;&#109;&#46;&#x63;&#x6e; ENV PYTHON 2.7 ENV DJANGO 1.11.5 LABEL version=1.1 WORKDIR /opt/big_factory/xxxserver EXPOSE 9443 #此处设置ENTRYPOINT，在创建容器的时候会运行此命令，执行脚本，起应用服务ENTRYPOINT [“sh”,”/root/xxxserver/uwsgi_run.sh”]在对应的脚本文件中，这样设置： #!/bin/bash #run itpserver with uwsgi/usr/local/bin/uwsgi -d –ini /opt/big_factory/xxxserver/xxxapi_uwsgi.ini #never exit，此处是为了运行完上条应用服务后，有对应的前台进程tail -f /dev/null本文中的脚本文件用的是 tail 命令，当然也可以用其他的命令，如ping, top, sleep等，只不过tail相对系统开销小，而且/dev/null是个黑洞，啥都可以往里扔，也不显示。 接下来看看效果怎样。 在docker build新镜像后，同样docker-compose up -d启动容器服务，查看容器状态docker-compose ps，进入容器并查看进程: 事实证明，确实有效。 上述操作，解决了 docker-compose 启动容器时，运行脚本文件来起容器内部的应用程序，且容器正常运行up的需求。 总结如果我们通过 docker-compose 运行容器，并运行内部应用服务的话，可以按照以下设置进行操作： 编写Dockerfile，在文件中设置ENTRYPOINT指令，一般可以执行启动应用的脚本文件，脚本文件最后应该有不退出的命令，如tail/top/ping等，然后通过docker build -t name:tag .创建新的镜像 编写docker-compose.yml/yaml文件，内部指定基于Dockerfile创建的镜像 通过 docker-compose up -d启动容器","categories":[],"tags":[],"author":"张存"},{"title":"Ubuntu 永久修改 ulimit -n","slug":"Ubuntu-永久修改-ulimit-n","date":"2022-01-18T05:00:51.000Z","updated":"2022-01-18T05:16:43.306Z","comments":true,"path":"2022/01/18/ubuntu-yong-jiu-xiu-gai-ulimit-n/","link":"","permalink":"https://blog.zhangcun.store/2022/01/18/ubuntu-yong-jiu-xiu-gai-ulimit-n/","excerpt":"","text":"设置文件最大打开数 #系统 vim /etc/sysctl.conf #添加 fs.file-max = 65535 sysctl -p #用户 vim /etc/security/limits.conf #添加 * hard nofile 65535 * soft nofile 65535 root soft nproc 65535 root hard nproc 65535 root soft nofile 65535 root hard nofile 65535 注意L这个每个用户都要配置，有些说只有root用户才需要写出来，但是有时候测试的时候发现普通用户没有写在这没有生效 test soft nproc 65535 test hard nproc 65535 test soft nofile 65535 test hard nofile 65535 #Systemd sed -i &#39;/DefaultLimitNOFILE/c DefaultLimitNOFILE=65535&#39; /etc/systemd/*.conf systemctl daemon-reexec 搞定，重启即可。。。重启后可以查看ulimit -n是否显示为65535 验证 #打开新的终端 #ssh remote_user@host #查看系统限制 cat /proc/sys/fs/file-max #查看用户硬限制 ulimit -Hn #查看用户软限制 ulmit -Sn #查看某进程的限制 cat /proc/PID/limits # 将 PID 替换为具体的进程 ID #查看其他用户限制 su - www -c &#39;ulimit -aHS&#39; -s &#39;/bin/bash&#39;","categories":[],"tags":[],"author":"张存"},{"title":"以指定用户启动和进入docker容器","slug":"以指定用户启动和进入docker容器","date":"2022-01-17T13:44:15.000Z","updated":"2022-01-17T13:44:18.703Z","comments":true,"path":"2022/01/17/yi-zhi-ding-yong-hu-qi-dong-he-jin-ru-docker-rong-qi/","link":"","permalink":"https://blog.zhangcun.store/2022/01/17/yi-zhi-ding-yong-hu-qi-dong-he-jin-ru-docker-rong-qi/","excerpt":"","text":"第一次用run创建并启动容器，运行命令 docker run -it -u user_name –name container_name -d image_name /bin/bash 之后可以用exec进入容器，运行命令 docker exec -it -u user_name container_name /bin/bash 还可以指定主机名 –hostname user_hostname 指定网络 –network=user_network 指定ip –ip 172.18.0.3","categories":[],"tags":[],"author":"张存"},{"title":"alpine用户创建和管理","slug":"alpine用户创建和管理","date":"2022-01-17T13:39:49.000Z","updated":"2022-01-17T13:42:32.981Z","comments":true,"path":"2022/01/17/alpine-yong-hu-chuang-jian-he-guan-li/","link":"","permalink":"https://blog.zhangcun.store/2022/01/17/alpine-yong-hu-chuang-jian-he-guan-li/","excerpt":"","text":"Alpine Linux是一个社区开发的面向安全应用的轻量级Linux发行版,基于 uClibc 和 Busybox的操作系统，非常适合用来做docker镜像，基于Alpine Linux的最小Docker镜像，具有完整的包索引，大小仅为5 MB！ alpine和一般的Linux命令有些不一样，创建用户组用addgroupaddgroup -g 1000 -S redis 创建用户用adduseradduser redis -D -G redis -u 1000 -s /bin/sh 修改用户密码echo -e “rootpwd\\nrootpwd” | passwd root 默认情况下，普通用户执行su会报错，要执行chmod 4755 /bin/busybox后才行。 dockerfile里，可以同时改变用户同时COPY文件到镜像里。（为什么一定要同时作？？如果不同时作，docker的layer增加一层，改权限和属主，镜像大小会翻倍。）COPY –chown=redis:redis redis.conf /data/redis.conf","categories":[],"tags":[],"author":"张存"},{"title":"“ -bash：sudo：未找到命令”对于Linux，Debian，CentOS的错误和解决方案","slug":"“-bash：sudo：未找到命令”对于Linux，Debian，CentOS的错误和解决方案","date":"2022-01-17T13:37:59.000Z","updated":"2022-01-17T13:38:15.277Z","comments":true,"path":"2022/01/17/bash-sudo-wei-zhao-dao-ming-ling-dui-yu-linux-debian-centos-de-cuo-wu-he-jie-jue-fang-an/","link":"","permalink":"https://blog.zhangcun.store/2022/01/17/bash-sudo-wei-zhao-dao-ming-ling-dui-yu-linux-debian-centos-de-cuo-wu-he-jie-jue-fang-an/","excerpt":"","text":"sudo command is used to execute command as another user. This is generally used to run command as root. In some cases we can get an error like -bash:sudo:command not found which means sudo is not installed. In this tutorial we will look different ways and distributions to solve this problem. sudo命令用于以另一个用户身份执行命令。 通常用于以root身份运行命令。 在某些情况下，我们会收到-bash:sudo:command not found类的错误，这意味着未安装sudo 。 在本教程中，我们将探讨解决此问题的不同方式和分布。 为Debian，Ubuntu，Mint，Kali安装Sudo (Install Sudo For Debian, Ubuntu, Mint, Kali)We can install sudo for Debian, Ubuntu, Mint and Kali related distributions for deb or apt with the following command. But before we should be root user because package installation requires root privileges. 我们可以安装sudo适用于Debian，Ubuntu的，薄荷和卡利相关发行deb或apt使用下面的命令。 但是在我们应该是root用户之前，因为软件包安装需要root特权。 $ su$ apt install sudo","categories":[],"tags":[],"author":"张存"},{"title":"Ubuntu18.04更换国内源","slug":"Ubuntu18-04更换国内源","date":"2022-01-17T13:35:48.000Z","updated":"2022-01-17T13:36:30.015Z","comments":true,"path":"2022/01/17/ubuntu18-04-geng-huan-guo-nei-yuan/","link":"","permalink":"https://blog.zhangcun.store/2022/01/17/ubuntu18-04-geng-huan-guo-nei-yuan/","excerpt":"","text":"打开/etc/apt/sources.list vi /etc/apt/sources.list 将原有的数据注释掉，换上国内镜像 阿里云源 deb http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiverse 清华源 deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-updates main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-backports main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-security main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-proposed main restricted universe multiverse deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic main restricted universe multiverse deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-updates main restricted universe multiverse deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-backports main restricted universe multiverse deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-security main restricted universe multiverse deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-proposed main restricted universe multiverse 中科大源 deb https://mirrors.ustc.edu.cn/ubuntu/ bionic main restricted universe multiverse deb https://mirrors.ustc.edu.cn/ubuntu/ bionic-updates main restricted universe multiverse deb https://mirrors.ustc.edu.cn/ubuntu/ bionic-backports main restricted universe multiverse deb https://mirrors.ustc.edu.cn/ubuntu/ bionic-security main restricted universe multiverse deb https://mirrors.ustc.edu.cn/ubuntu/ bionic-proposed main restricted universe multiverse deb-src https://mirrors.ustc.edu.cn/ubuntu/ bionic main restricted universe multiverse deb-src https://mirrors.ustc.edu.cn/ubuntu/ bionic-updates main restricted universe multiverse deb-src https://mirrors.ustc.edu.cn/ubuntu/ bionic-backports main restricted universe multiverse deb-src https://mirrors.ustc.edu.cn/ubuntu/ bionic-security main restricted universe multiverse deb-src https://mirrors.ustc.edu.cn/ubuntu/ bionic-proposed main restricted universe multiverse 更改完成之后执行以下命令 apt update apt upgrade","categories":[],"tags":[],"author":"张存"},{"title":"To run a command as administrator (user \"root\"), use \"sudo <command>\". See \"man sudo_root\" for detai","slug":"To-run-a-command-as-administrator-user-root-use-sudo-command-See-man-sudo-root-for-detai","date":"2022-01-17T13:31:42.000Z","updated":"2022-01-17T13:31:44.000Z","comments":true,"path":"2022/01/17/to-run-a-command-as-administrator-user-root-use-sudo-command-see-man-sudo-root-for-detai/","link":"","permalink":"https://blog.zhangcun.store/2022/01/17/to-run-a-command-as-administrator-user-root-use-sudo-command-see-man-sudo-root-for-detai/","excerpt":"","text":"touch ~/.sudo_as_admin_successful","categories":[],"tags":[],"author":"张存"},{"title":"alpine-linux安装sudo的正确姿势","slug":"alpine-linux安装sudo的正确姿势","date":"2022-01-17T13:28:22.000Z","updated":"2022-01-17T13:29:22.688Z","comments":true,"path":"2022/01/17/alpine-linux-an-zhuang-sudo-de-zheng-que-zi-shi/","link":"","permalink":"https://blog.zhangcun.store/2022/01/17/alpine-linux-an-zhuang-sudo-de-zheng-que-zi-shi/","excerpt":"","text":"问题在alpine-linux 3.11.6下su进入root用户直接apk add sudo后，在普通用户下运行sudo xxx输入3次密码后报错：[username] is not in the sudoers file. This incident will be reported. 正确姿势安装sudo$ apk add sudo把指定的用户添加到wheel组，只有在wheel组的用户才有权限访问sudo命令$ addgroup [username] wheel去掉执行sudo命令时每次输入烦人的密码$ visudo找到行”# %wheel ALL=(ALL) NOPASSWD: ALL”去掉’#’号取消注释，:wq保存。 退出root，退出登录的用户，登录被添加到wheel组的用户，执行$ sudo -v 没有提示则成功。","categories":[],"tags":[],"author":"张存"},{"title":"Nginx配置禁止IP访问","slug":"Nginx配置禁止IP访问","date":"2022-01-17T02:21:17.000Z","updated":"2022-01-17T02:24:46.800Z","comments":true,"path":"2022/01/17/nginx-pei-zhi-jin-zhi-ip-fang-wen/","link":"","permalink":"https://blog.zhangcun.store/2022/01/17/nginx-pei-zhi-jin-zhi-ip-fang-wen/","excerpt":"","text":"时间背景使用Nginx代理服务，请求先到前端的代理服务器，然后由代理服务器的nginx转发请求到后端的服务器。开始默认没有对IP访问做限制，现在要求禁止IP访问， 大概是一个这样的架构： 想要禁止IP访问，那么就直接修改后端的web服务器的配置，然后修改配置如下： # nginx.conf文件 server &#123; listen 80 default_server; server_name _; return 200 &quot;ip cannot access&quot;; &#125; 123456然后重启Nginx服务，测试发现使用IP和域名都无法访问了，有点儿慌。 最后发现问题是proxy_pass的配置有问题，具体配置如下： #代理服务器配置upstream backend{ server 192.168.189.31:80;}server { listen 80; server_name www.kaige.com; location / &#123; proxy_pass http://backend; proxy_buffer_size 128k; proxy_buffers 100 128k; proxy_busy_buffers_size 256k; proxy_connect_timeout 600s; proxy_send_timeout 1200; proxy_read_timeout 1200; proxy_http_version 1.1; proxy_set_header Connection &quot;&quot;; &#125; &#125; 上面的配置中，发现请求到后端服务器时并不是通过域名去访问的，也就是代理到后端服务器是没有携带域名，所以后端服务器并不知道域名，通过IP来处理请求。 修改后的配置： upstream backend{ server 192.168.189.31:80;}server { listen 80; server_name www.kaige.com; location / &#123; proxy_pass http://backend; proxy_set_header Host $host; # 携带host请求到后端 proxy_set_header X-Forwarded-For $remote_addr; # 远端IP proxy_buffer_size 128k; proxy_buffers 100 128k; proxy_busy_buffers_size 256k; proxy_connect_timeout 600s; proxy_send_timeout 1200; proxy_read_timeout 1200; proxy_http_version 1.1; proxy_set_header Connection &quot;&quot;; &#125; &#125;","categories":[],"tags":[],"author":"张存"},{"title":"Docker：清理Docker占用的磁盘空间","slug":"docker清理","date":"2022-01-14T07:05:48.000Z","updated":"2022-01-14T07:07:42.749Z","comments":true,"path":"2022/01/14/docker-qing-li/","link":"","permalink":"https://blog.zhangcun.store/2022/01/14/docker-qing-li/","excerpt":"","text":"Docker：清理Docker占用的磁盘空间 容器清理 docker container prune : 仅删除停止运行的容器。 docker rm -f $(docker ps -aq) : 删除所有容器（包括停止的、正在运行的）。 docker container rm -f $(docker container ls -aq) : 同上。 镜像清理 docker rmi &lt;image id&gt; ：通过镜像的id来删除指定镜像。 有一些镜像是隐形的： 子镜像，就是被其他镜像引用的中间镜像，不能被删除。 悬挂状态的镜像，就是不会再被使用的镜像，可以被删除。 其他命令： docker image ls -f dangling=true : 可以列出所有悬挂状态的镜像 并使用命令 docker image rm $(docker image ls -f dangling=true -q) 或 docker image prune进行删除。 docker image rm $(docker image ls -q) ：删除所有镜像。但正在被容器使用的镜像无法删除。 数据卷清理 docker volume rm $(docker volume ls -q) ：删除不再使用的数据卷。 docker volume prune ：同上。 缓存清理 Docker 18.09 引入了 BuildKit ，提升了构建过程的性能、安全、存储管理等能力。 docker builder prune ：删除 build cache。 一键清理 docker system df 命令，类似于 Linux上的 df 命令，用于查看 Docker 的磁盘使用情况： TYPE列出了 Docker 使用磁盘的 4 种类型： Images ：所有镜像占用的空间，包括拉取下来的镜像，和本地构建的。 Containers ：运行的容器占用的空间，表示每个容器的读写层的空间。 Local Volumes ：容器挂载本地数据卷的空间。 Build Cache ：镜像构建过程中产生的缓存空间（只有在使用 BuildKit 时才有，Docker 18.09 以后可用）。 最后的 RECLAIMABLE 是可回收大小。 docker system prune : 可以用于清理磁盘，删除关闭的容器、无用的数据卷和网络，以及 dangling 镜像（即无 tag 的镜像）。 docker system prune -a : 清理得更加彻底，可以将没有容器使用 Docker镜像都删掉。 注意，这两个命令会把你暂时关闭的容器，以及暂时没有用到的 Docker 镜像都删掉了。","categories":[],"tags":[],"author":"张存"},{"title":"MySQL查看库大小、表大小、索引大小","slug":"MySQL查看库大小、表大小、索引大小","date":"2022-01-14T06:52:58.000Z","updated":"2022-01-14T06:55:00.842Z","comments":true,"path":"2022/01/14/mysql-cha-kan-ku-da-xiao-biao-da-xiao-suo-yin-da-xiao/","link":"","permalink":"https://blog.zhangcun.store/2022/01/14/mysql-cha-kan-ku-da-xiao-biao-da-xiao-suo-yin-da-xiao/","excerpt":"","text":"在实际生产过程中，数据库可能会堆积一些无用的数据，通过查询占用空间大小，可以在一定程度上帮助我们分析问题。 information_schema说明 通过MySQL的 information_schema 数据库，可查询数据库中每个表占用的空间、表记录的行数；该库中有一个 TABLES 表，这个表主要字段分别是： 字段名 值 TABLE_SCHEMA 数据库名 TABLE_NAME 表名 ENGINE 所使用的存储引擎 TABLES_ROWS 记录数 DATA_LENGTH 数据大小 INDEX_LENGTH 索引大小 查看所有库的大小 SELECT TABLE_SCHEMA AS &#39;Database Name&#39;, CONCAT(ROUND(SUM(data_length/(1024*1024)),2),&#39; M&#39;) AS &#39;Data Size&#39;, CONCAT(ROUND(SUM(index_length/(1024*1024)),2),&#39; M&#39;) AS &#39;Index Size&#39;, CONCAT(ROUND(SUM((data_length+index_length)/(1024*1024)),2),&#39; M&#39;) AS&#39;Total&#39; FROM information_schema.TABLES GROUP BY TABLE_SCHEMA ORDER BY SUM(data_length+index_length) DESC; 查询结果示例如下: +--------------------+-----------+------------+----------+ | Database Name | Data Size | Index Size | Total | +--------------------+-----------+------------+----------+ | test | 308.88 M | 14.31 M | 323.20 M | | mysql | 2.20 M | 0.18 M | 2.39 M | | information_schema | 0.16 M | 0.00 M | 0.16 M | | sys | 0.02 M | 0.00 M | 0.02 M | | performance_schema | 0.00 M | 0.00 M | 0.00 M | +--------------------+-----------+------------+----------+ 查看指定库的大小 在查看所有库大小的基础上添加WHERE条件: SELECT TABLE_SCHEMA AS &#39;Database Name&#39;, CONCAT(ROUND(SUM(data_length/(1024*1024)),2),&#39; M&#39;) AS &#39;Data Size&#39;, CONCAT(ROUND(SUM(index_length/(1024*1024)),2),&#39; M&#39;) AS &#39;Index Size&#39;, CONCAT(ROUND(SUM((data_length+index_length)/(1024*1024)),2),&#39; M&#39;) AS&#39;Total&#39; FROM information_schema.TABLES WHERE table_schema=&#39;test&#39; GROUP BY TABLE_SCHEMA; 查询结果示例如下: +--------------------+-----------+------------+----------+ | Database Name | Data Size | Index Size | Total | +--------------------+-----------+------------+----------+ | test | 308.88 M | 14.31 M | 323.20 M | +--------------------+-----------+------------+----------+ 查看指定库的所有表的大小 SELECT CONCAT(table_schema,&#39;.&#39;,table_name) AS &#39;Table Name&#39;, table_rows AS &#39;Number of Rows&#39;, CONCAT(ROUND(data_length/(1024*1024),2),&#39; M&#39;) AS &#39;Data Size&#39;, CONCAT(ROUND(index_length/(1024*1024),2),&#39; M&#39;) AS &#39;Index Size&#39;, CONCAT(ROUND((data_length+index_length)/(1024*1024),2),&#39; M&#39;) AS&#39;Total&#39; FROM information_schema.TABLES WHERE table_schema=&#39;test&#39; ORDER BY (data_length+index_length) DESC; 查询结果示例如下: +-------------------+----------------+-----------+------------+----------+ | Table Name | Number of Rows | Data Size | Index Size | Total | +-------------------+----------------+-----------+------------+----------+ | test.Message | 268683 | 33.58 M | 14.03 M | 47.61 M | | test.Notification | 35381 | 24.55 M | 0.00 M | 24.55 M | | test.Order | 3546 | 5.52 M | 0.17 M | 5.69 M | | test.AccessToken | 41850 | 4.55 M | 0.00 M | 4.55 M | | test.user | 365 | 0.13 M | 0.00 M | 0.13 M | +-------------------+----------------+-----------+------------+----------+ 查看指定库的指定表的大小 在查看所有表大小的基础上添加and table_name=条件: SELECT CONCAT(table_schema,&#39;.&#39;,table_name) AS &#39;Table Name&#39;, table_rows AS &#39;Number of Rows&#39;, CONCAT(ROUND(data_length/(1024*1024),2),&#39; M&#39;) AS &#39;Data Size&#39;, CONCAT(ROUND(index_length/(1024*1024),2),&#39; M&#39;) AS &#39;Index Size&#39;, CONCAT(ROUND((data_length+index_length)/(1024*1024),2),&#39; M&#39;) AS&#39;Total&#39; FROM information_schema.TABLES WHERE table_schema=&#39;test&#39; and table_name=&#39;Message&#39; ORDER BY (data_length+index_length) DESC; 查询结果示例如下: +-------------------+----------------+-----------+------------+----------+ | Table Name | Number of Rows | Data Size | Index Size | Total | +-------------------+----------------+-----------+------------+----------+ | test.Message | 268683 | 33.58 M | 14.03 M | 47.61 M | +-------------------+----------------+-----------+------------+----------+","categories":[],"tags":[],"author":"张存"},{"title":"Xshell批量导入IP地址","slug":"Xshell批量导入IP地址","date":"2022-01-14T06:19:05.000Z","updated":"2022-01-14T06:32:03.355Z","comments":true,"path":"2022/01/14/xshell-pi-liang-dao-ru-ip-di-zhi/","link":"","permalink":"https://blog.zhangcun.store/2022/01/14/xshell-pi-liang-dao-ru-ip-di-zhi/","excerpt":"","text":"我的xshell被覆盖了~~~结果原来的host没了，很郁闷要一个一个添加，网上找了很长时间在Xshell中批量添加IP的文章，结果都不行。 从CSV文件导入多个会话这是Xshell最要求的功能之一。我们的一些系统管理员用户提到，他们必须与服务器更改IP和主机名动辄工作。所以我们创造了我们的进口刀具的特征来帮助他们进口数百次使用CSV文件。本指南将告诉你如何一步一步你可以使用CSV文件导入会话。 P修复一个CSV文件目前Xshell支持逗号或制表符分隔的数据： 会话名称主机协议端口用户名称密码使用记事本（或者你可以使用Excel或谷歌电子表格），输入主机的数据像下面的例子： 你可以在CSV文件中有更多的信息。这些列不支持Xshell，你可以简单地选择“not-use当导入文件从Xshell这些领域将无法导入。 进口环节使用Xshell CSV文件从Xshell导入CSV文件，按照下面的步骤： Open Xshell and select File &gt; Import 源的位置，选择在上一步中创建的CSV文件。如果会话存在部分选择在覆盖行动。Overwrite：如果相同的会话名称已经存在覆盖会话。忽略：进口工具如果相同的会话名称已经存在跳过会议。重命名: Import tool will rename the session being imported and add number at the end of the session name.点击下一步继续。定义每列代表： 笔记：你可以选择以下6个选项：会议名称、主机、协议、端口、用户名、密码，not-use单击“下一步”。在这一步中，你可以审查会议，将进口 单击下一步开始进口 审查的结果，单击“完成”按钮，关闭导入对话框。批量添加完成后，在C:\\Users\\MT\\Documents\\NetSarang\\Xshell\\Sessions\\（我的是在这个目录哈~）中新建文件夹，把该归类的归类。然后再打开xshell，搞定！bingo!","categories":[],"tags":[],"author":"张存"},{"title":"Shell脚本监控Linux系统CPU使用率","slug":"Shell脚本监控Linux系统CPU使用率","date":"2022-01-14T05:58:37.000Z","updated":"2022-01-14T05:59:33.523Z","comments":true,"path":"2022/01/14/shell-jiao-ben-jian-kong-linux-xi-tong-cpu-shi-yong-lu/","link":"","permalink":"https://blog.zhangcun.store/2022/01/14/shell-jiao-ben-jian-kong-linux-xi-tong-cpu-shi-yong-lu/","excerpt":"","text":"一、概述通过top或者htop命令。可以看到每一个cpu核心的使用情况，但是服务器的整体cpu使用情况，就无法直观的看到。 需要通过shell脚本才能实现。 二、Shell脚本cpu_ck.sh #/bin/bash #environment variable source /etc/profile #cpu cpu_us=`vmstat | awk &#39;&#123;print $13&#125;&#39; | sed -n &#39;$p&#39;` cpu_sy=`vmstat | awk &#39;&#123;print $14&#125;&#39; | sed -n &#39;$p&#39;` cpu_id=`vmstat | awk &#39;&#123;print $15&#125;&#39; | sed -n &#39;$p&#39;` cpu_sum=$(($cpu_us+$cpu_sy)) echo $cpu_sum","categories":[],"tags":[],"author":"张存"},{"title":"阿里企业邮箱管理员账号更改密码方法","slug":"阿里云企业企业邮箱管理员账号更改密码方法","date":"2022-01-14T05:56:16.000Z","updated":"2022-01-14T05:56:52.992Z","comments":true,"path":"2022/01/14/a-li-yun-qi-ye-qi-ye-you-xiang-guan-li-yuan-zhang-hao-geng-gai-mi-ma-fang-fa/","link":"","permalink":"https://blog.zhangcun.store/2022/01/14/a-li-yun-qi-ye-qi-ye-you-xiang-guan-li-yuan-zhang-hao-geng-gai-mi-ma-fang-fa/","excerpt":"","text":"https://www.ali-exmail.cn/ask/220.html","categories":[],"tags":[],"author":"张存"},{"title":"VMWare占用443端口，导致httpd服务器无法正常启动","slug":"VMWare占用443端口，导致httpd服务器无法正常启动","date":"2022-01-14T05:53:44.000Z","updated":"2022-01-14T05:55:01.558Z","comments":true,"path":"2022/01/14/vmware-zhan-yong-443-duan-kou-dao-zhi-httpd-fu-wu-qi-wu-fa-zheng-chang-qi-dong/","link":"","permalink":"https://blog.zhangcun.store/2022/01/14/vmware-zhan-yong-443-duan-kou-dao-zhi-httpd-fu-wu-qi-wu-fa-zheng-chang-qi-dong/","excerpt":"","text":"“/etc/httpd/conf/httpd.conf” 1010L, 34442C written[root@kfdev www]# lscgi-bin error html icons manual usage[root@kfdev www]# /usr/sbin/apachectl start(98)Address already in use: make_sock: could not bind to address [::]:443(98)Address already in use: make_sock: could not bind to address 0.0.0.0:443no listening sockets available, shutting downUnable to open logs[root@kfdev www]# vi /etc/httpd/conf/httpd.conf 由于443端口被占用，导致的httpd服务器无法正常启动。 我们在终端输入：#service httpd restart显示错误：停止 httpd： [失败]正在启动 httpd：(98)Address already in use: make_sock: could not bind to address [::]:443(98)Address already in use: make_sock: could not bind to address 0.0.0.0:443no listening sockets available, shutting downUnable to open logs [失败] 1.我们终端输入命令显示443端口被被那个程序占用#netstat -lnp|grep 443 tcp 0 0 0.0.0.0:443 0.0.0.0:* LISTEN 2573/vmware-hostdtcp 0 0 :::443 :::* LISTEN 2573/vmware-hostd2.#kill 2573 //杀死2573号进程 3.#service httpd restart //重启服务器显示成功，问题暂时解决 停止 httpd： [确定]正在启动 httpd： [确定] ***************上面的命令只能暂时起作用，我们需要为vmware指定端口才能永远解决问题 2.我们终端输入命令#grep 443 /etc/vmware //匹配443端口所在文件 2.然后我们修改配置文件端口号#gedit /etc/vmware/hostd/proxy.xml &amp; -1 880 //将次选项端口号改成880保存退出，问题解决 #history | grep gedit //用来在历史输入命令中查找用过的gedit命令","categories":[],"tags":[],"author":"张存"},{"title":"解决ssh过一会就卡住断开问题","slug":"解决ssh过一会就卡住断开问题","date":"2022-01-14T05:45:46.000Z","updated":"2022-01-14T05:46:00.588Z","comments":true,"path":"2022/01/14/jie-jue-ssh-guo-yi-hui-jiu-qia-zhu-duan-kai-wen-ti/","link":"","permalink":"https://blog.zhangcun.store/2022/01/14/jie-jue-ssh-guo-yi-hui-jiu-qia-zhu-duan-kai-wen-ti/","excerpt":"","text":"#vi /etc/ssh/ssh_configServerAliveInterval 60ServerAliveCountMax 3 #vi /etc/ssh/sshd_config #找到以下两行#ClientAliveInterval 0#ClientAliveCountMax 3#修改为ClientAliveInterval 60ClientAliveCountMax 3#然后保存，重启 sshd服务systemctl restart sshd","categories":[],"tags":[],"author":"张存"},{"title":"Jenkins中文设置","slug":"Jenkins中文设置","date":"2022-01-14T05:44:43.000Z","updated":"2022-01-14T05:44:43.936Z","comments":true,"path":"2022/01/14/jenkins-zhong-wen-she-zhi/","link":"","permalink":"https://blog.zhangcun.store/2022/01/14/jenkins-zhong-wen-she-zhi/","excerpt":"","text":"https://blog.csdn.net/zh__quan/article/details/106230100","categories":[],"tags":[],"author":"张存"},{"title":"关于Office弹窗+横幅提示“你的许可证不是正版，并且你可能是盗版软件的受害者...”的解决方案——以Office2019为例","slug":"关于Office弹窗-横幅提示“你的许可证不是正版，并且你可能是盗版软件的受害者-”的解决方案——以Office2019为例","date":"2022-01-14T05:42:27.000Z","updated":"2022-01-14T05:42:58.706Z","comments":true,"path":"2022/01/14/guan-yu-office-dan-chuang-heng-fu-ti-shi-ni-de-xu-ke-zheng-bu-shi-zheng-ban-bing-qie-ni-ke-neng-shi-dao-ban-ruan-jian-de-shou-hai-zhe-de-jie-jue-fang-an-yi-office2019-wei-li/","link":"","permalink":"https://blog.zhangcun.store/2022/01/14/guan-yu-office-dan-chuang-heng-fu-ti-shi-ni-de-xu-ke-zheng-bu-shi-zheng-ban-bing-qie-ni-ke-neng-shi-dao-ban-ruan-jian-de-shou-hai-zhe-de-jie-jue-fang-an-yi-office2019-wei-li/","excerpt":"","text":"遭遇问题 前一段时间，博主电脑的Office2019软件忽然开始在每次打开时弹出“你的许可证不是正版，并且你可能是盗版软件的受害者。使用正版Office，避免干扰并保护你的文件安全。”的弹窗+横幅提示，因为博主要准备答辩暂且搁置了这个问题。直到今天撰写材料再次遭遇了这个碍眼的玩意儿，于是干脆一不做二不休把它给解决掉。 之所以博主要写这么一篇博客进行记录，是因为网上千篇一律的错误方法盛行，且并未解决博主需求。因此，接下来将会以博主电脑上的Office2019为例进行记录。 未成功解决的错误方法 网上千篇一律的错误方法（可能仅适用于2501版本之前的版本）主要按以下步骤完成：文件&gt;&gt;账号&gt;&gt;管理设置&gt;&gt;开启可选的连接体验（把勾选给去掉）&gt;&gt;重启office 然而，经过博主的测试，这种方法根本行不通！！！ 解决方案 最终，博主在账户中更改了密钥，也并未有其他设置，便成功解决了这个问题。 附录 - 各个版本Office对应更换密钥Office2019版本GRBR4-J4N3M-KTX9C-JM4PJ-J8HPT Office2016版本XQNVK-8JYDB-WJ9W3-YJ8YR-WFG99 Office2013版本GQVNC-24YPY-KHJB4-CQRT3-GF2DH","categories":[],"tags":[],"author":"张存"},{"title":"【Jenkins】插件更改国内源","slug":"【Jenkins】插件更改国内源","date":"2022-01-10T11:25:23.000Z","updated":"2022-01-10T11:26:28.263Z","comments":true,"path":"2022/01/10/jenkins-cha-jian-geng-gai-guo-nei-yuan/","link":"","permalink":"https://blog.zhangcun.store/2022/01/10/jenkins-cha-jian-geng-gai-guo-nei-yuan/","excerpt":"","text":"最近调试脚本，本机安装了Jenkins，但是安装插件时一直失败。更改升级站点也不生效，究其原因是因为default.json中插件下载地址还是https://updates.jenkins.io， 升级站点设置未生效。 需要操作两个步骤 进入 Manage Jenkins -》 Manage Plugin -&gt; Advanced 最下面有 Update Site 设置为：https://mirrors.tuna.tsinghua.edu.cn/jenkins/updates/update-center.json 修改服务器配置，进入 jenkins安装目录 ， /updates/default.json ，将其中的 updates.jenkins-ci.org/download 替换为 mirrors.tuna.tsinghua.edu.cn/jenkins ，然后把www.google.com 修改为 www.baidu.com 重启Jenkins服务 再次下载插件就可以了","categories":[],"tags":[],"author":"张存"},{"title":"mysql连接数设置操作方法(Too many connections)","slug":"mysql连接数设置操作方法-Too-many-connections","date":"2022-01-10T11:20:06.000Z","updated":"2022-01-10T11:21:36.496Z","comments":true,"path":"2022/01/10/mysql-lian-jie-shu-she-zhi-cao-zuo-fang-fa-too-many-connections/","link":"","permalink":"https://blog.zhangcun.store/2022/01/10/mysql-lian-jie-shu-she-zhi-cao-zuo-fang-fa-too-many-connections/","excerpt":"","text":"mysql在使用过程中，发现连接数超了~~~~ [root@linux-node1 ~]# mysql -u glance -h 192.168.1.17 -pEnter password: ERROR 1040 (08004): Too many connections 解决办法，这也是centos7下修改mysql连接数的做法：1）临时修改MariaDB [(none)]&gt; show variables like “max_connections”;+—————–+——-+| Variable_name | Value |+—————–+——-+| max_connections | 214 |+—————–+——-+1 row in set (0.00 sec)MariaDB [(none)]&gt; set GLOBAL max_connections=1000;Query OK, 0 rows affected (0.00 sec)MariaDB [(none)]&gt; show variables like “max_connections”;+—————–+——-+| Variable_name | Value |+—————–+——-+| max_connections | 1000 |+—————–+——-+1 row in set (0.00 sec) 2）永久修改：配置/etc/my.cnf[mysqld]新添加一行如下参数：max_connections=1000重启mariadb服务，再次查看mariadb数据库最大连接数，可以看到最大连接数是214，并非我们设置的1000。MariaDB [(none)]&gt; show variables like ‘max_connections’;+—————–+——-+| Variable_name | Value |+—————–+——-+| max_connections | 214 |+—————–+——-+这是由于mariadb有默认打开文件数限制。可以通过配置/usr/lib/systemd/system/mariadb.service来调大打开文件数目。 配置/usr/lib/systemd/system/mariadb.service[Service]新添加两行如下参数：LimitNOFILE=10000LimitNPROC=10000 重新加载系统服务，并重启mariadb服务systemctl –system daemon-reloadsystemctl restart mariadb.service 再次查看mariadb数据库最大连接数，可以看到最大连接数已经是1000MariaDB [(none)]&gt; show variables like ‘max_connections’;+—————–+——-+| Variable_name | Value |+—————–+——-+| max_connections | 1000 |+—————–+——-+ 以上这篇mysql连接数设置操作方法(Too many connections)就是小编分享给大家的全部内容了","categories":[],"tags":[],"author":"张存"},{"title":"jitsi搭建","slug":"jitsi搭建","date":"2022-01-10T10:03:02.000Z","updated":"2022-01-10T10:03:03.904Z","comments":true,"path":"2022/01/10/jitsi-da-jian/","link":"","permalink":"https://blog.zhangcun.store/2022/01/10/jitsi-da-jian/","excerpt":"","text":"https://jitsi.github.io/handbook/docs/devops-guide/devops-guide-quickstart","categories":[],"tags":[],"author":"张存"},{"title":"使用Windows远程桌面连接Ubuntu 20.04","slug":"使用Windows远程桌面连接Ubuntu-20-04","date":"2021-12-30T08:23:41.000Z","updated":"2021-12-30T08:26:22.737Z","comments":true,"path":"2021/12/30/shi-yong-windows-yuan-cheng-zhuo-mian-lian-jie-ubuntu-20-04/","link":"","permalink":"https://blog.zhangcun.store/2021/12/30/shi-yong-windows-yuan-cheng-zhuo-mian-lian-jie-ubuntu-20-04/","excerpt":"","text":"安装xrdp，在terminal中输入：sudo apt install xrdp然后在terminal中输入：sudo vim /etc/xrdp/startwm.sh,并将最后两行test和exec用#注释掉，在最后一行添加gnome-session。","categories":[],"tags":[],"author":"张存"},{"title":"docker内运行的grafana重置登录密码","slug":"docker内运行的grafana重置登录密码","date":"2021-12-30T05:32:30.000Z","updated":"2021-12-30T05:33:07.066Z","comments":true,"path":"2021/12/30/docker-nei-yun-xing-de-grafana-chong-zhi-deng-lu-mi-ma/","link":"","permalink":"https://blog.zhangcun.store/2021/12/30/docker-nei-yun-xing-de-grafana-chong-zhi-deng-lu-mi-ma/","excerpt":"","text":"以grafana 5.4.2为例，docker可以直接从docker hub下载： $ docker pull grafana/grafana:5.4.2docker运行方法可以参考grafana的官方文档， $ docker run -d -p 3000:3000 –name grafana grafana/grafana:5.4.2如果忘记登录密码怎么办？网上搜索出的方法大多是通过修改数据库记录的方式，其实grafana有更简单的方法重置密码，方法如下： $ docker exec –user 472 -it grafana /bin/bash grafana@xxxxxxxxxxxx:/usr/share/grafana$ cd /usr/share/grafana/bingrafana@xxxxxxxxxxxx:/usr/share/grafana/bin$ ./grafana-cli admin reset-admin-password admin以用户ID 472进入docker，通过grafana-cli的reset-admin-password命令重新设置admin用户的密码为默认的admin。","categories":[],"tags":[],"author":"张存"},{"title":"Linux删除指定时间的文件（比如几分钟前(后)，几天前(后)）","slug":"Linux删除指定时间的文件（比如几分钟前-后-，几天前-后-）","date":"2021-12-30T03:23:40.000Z","updated":"2021-12-30T03:24:25.499Z","comments":true,"path":"2021/12/30/linux-shan-chu-zhi-ding-shi-jian-de-wen-jian-bi-ru-ji-fen-zhong-qian-hou-ji-tian-qian-hou/","link":"","permalink":"https://blog.zhangcun.store/2021/12/30/linux-shan-chu-zhi-ding-shi-jian-de-wen-jian-bi-ru-ji-fen-zhong-qian-hou-ji-tian-qian-hou/","excerpt":"","text":"要执行这个命令分三步：1、先找出该目录下名字符合的文件；2、过滤出指定时间内的文件；3、执行删除命令。 1 找出指定条件的文件 - find 命令比如找出当前目录下的所有txt文件 find ./ -name ‘*.txt’ 2 找出指定时间的文件找出最后20分钟内访问的文件 find ./ -name ‘*.txt’ -amin -20 -ls 找出最后1天内访问的文件 find ./ -name ‘*.txt’ -atime -1 -ls 找出最后20分钟内内修改过的文件 find ./ -name ‘*.txt’ -mmin -20 -ls 找出最后1天内修改过的文件 find ./ -name ‘*.txt’ -mtime -1 -ls 找出最后20分钟内状态改变的文件 find ./ -name ‘*.txt’ -cmin -20 -ls 找出最后2天内状态改变的文件 find ./ -name ‘*.txt’ -ctime -2 -ls 以上是某时间之内的文件，那么某时间之前的呢？ 找出20分钟之前访问的文件 find ./ -name ‘*.txt’ -amin +20 -ls 找出最后1天前访问的文件 find ./ -name ‘*.txt’ -atime +1 -ls 其他的就不一一列举了，大家只要知道 +n 表示n之前时间，,-n 表示 n之后时间, n 表示 n 时间 3 执行删除命令 -exec rm {} ; 那么，组合之后就是： find ./ -name ‘*.txt’ -amin -20 -ls -exec rm {} ; 表示删除20分钟之内访问过的文件。","categories":[],"tags":[],"author":"张存"},{"title":"shell-删除指定时间前的文件","slug":"shell-删除指定时间前的文件","date":"2021-12-30T03:18:17.000Z","updated":"2021-12-30T03:18:42.779Z","comments":true,"path":"2021/12/30/shell-shan-chu-zhi-ding-shi-jian-qian-de-wen-jian/","link":"","permalink":"https://blog.zhangcun.store/2021/12/30/shell-shan-chu-zhi-ding-shi-jian-qian-de-wen-jian/","excerpt":"","text":"*需要配合find和rm两个命令完成 显示20分钟前的文件： find /home/prestat/bills/test -type f -mmin +20 -exec ls -l {} ; 删除20分钟前的文件： find /home/prestat/bills/test -type f -mmin +20 -exec rm {} ; 具体操作需要掌握find命令的各种参数 https://www.cnblogs.com/wanqieddy/archive/2011/06/09/2076785.html","categories":[],"tags":[],"author":"张存"},{"title":"ubuntu下防火墙端口号的设置","slug":"ubuntu下防火墙端口号的设置","date":"2021-12-30T03:14:10.000Z","updated":"2021-12-30T03:14:41.090Z","comments":true,"path":"2021/12/30/ubuntu-xia-fang-huo-qiang-duan-kou-hao-de-she-zhi/","link":"","permalink":"https://blog.zhangcun.store/2021/12/30/ubuntu-xia-fang-huo-qiang-duan-kou-hao-de-she-zhi/","excerpt":"","text":"1.打开某个特定的端口号 iptables -A INPUT -p tcp –dport 22 -j ACCEPTiptables -A OUTPUT -p tcp –sport 22 -j ACCEPT再使用 iptables -L -n ,查看是否添加上去 2.禁用某个IP访问 iptables -A INPUT -p tcp -s 192.168.1.2 -j DROP iptables：unrecognized service 解决方法 在ubuntu中由于不存在 /etc/init.d/iptales文件，所以无法使用service等命令来启动iptables，需要用modprobe命令。 启动iptables modprobe ip_tables 关闭iptables（关闭命令要比启动复杂） iptables -F iptables -X iptables -Z iptables -P INPUT ACCEPT iptables -P OUTPUT ACCEPT iptables -P FORWARD ACCEPT modprobe -r ip_tables 依次执行以上命令即可关闭iptables，否则在执行modproble -r ip_tables时将会提示","categories":[],"tags":[],"author":"张存"},{"title":"解决tail命令提示“tail: inotify 资源耗尽，无法使用 inotify 机制，回归为 polling 机制”","slug":"解决tail命令提示“tail-inotify-资源耗尽，无法使用-inotify-机制，回归为-polling-机制”","date":"2021-12-27T02:29:19.000Z","updated":"2021-12-27T02:30:31.272Z","comments":true,"path":"2021/12/27/jie-jue-tail-ming-ling-ti-shi-tail-inotify-zi-yuan-hao-jin-wu-fa-shi-yong-inotify-ji-zhi-hui-gui-wei-polling-ji-zhi/","link":"","permalink":"https://blog.zhangcun.store/2021/12/27/jie-jue-tail-ming-ling-ti-shi-tail-inotify-zi-yuan-hao-jin-wu-fa-shi-yong-inotify-ji-zhi-hui-gui-wei-polling-ji-zhi/","excerpt":"","text":"解决tail命令提示“tail: inotify 资源耗尽，无法使用 inotify 机制，回归为 polling 机制” 临时解决方法： #查看 inotify 的相关配置$ sysctl fs.inotifyfs.inotify.max_queued_events = 16384fs.inotify.max_user_instances = 128fs.inotify.max_user_watches = 8192#临时修改配置（重启后会恢复）$ sudo sysctl -w fs.inotify.max_user_watches=100000 永久解决方法： $ sudo echo fs.inotify.max_user_watches=100000 | sudo tee -a /etc/sysctl.conf#重载配置文件，使之马上生效$ sudo sysctl -p","categories":[],"tags":[],"author":"张存"},{"title":"nohup 同时实现记录日志和屏幕输出","slug":"nohup-同时实现记录日志和屏幕输出","date":"2021-12-27T02:23:38.000Z","updated":"2021-12-27T02:24:42.791Z","comments":true,"path":"2021/12/27/nohup-tong-shi-shi-xian-ji-lu-ri-zhi-he-ping-mu-shu-chu/","link":"","permalink":"https://blog.zhangcun.store/2021/12/27/nohup-tong-shi-shi-xian-ji-lu-ri-zhi-he-ping-mu-shu-chu/","excerpt":"","text":"nohup nohup命令：如果你正在运行一个进程，而且你觉得在退出帐户时该进程还不会结束，那么可以使用nohup命令。该命令可以在你退出帐户/关闭终端之后继续运行相应的进程。nohup就是不挂断的意思( no hang up)。该命令的一般形式为：nohup command &amp;使用nohup命令提交作业如果使用nohup命令提交作业，那么在缺省情况下该作业的所有输出都被重定向到一个名为nohup.out的文件中，除非另外指定了输出文件：nohup command &gt; myout.file 2&gt;&amp;1 &amp;在上面的例子中，0 – stdin (standard input)，1 – stdout (standard output)，2 – stderr (standard error) ；2&gt;&amp;1是将标准错误（2）重定向到标准输出（&amp;1），标准输出（&amp;1）再被重定向输入到myout.file文件中。 tail tail -f 等同于–follow=descriptor，根据文件描述符进行追踪，当文件改名或被删除，追踪停止 tail -F 等同于–follow=name –retry，根据文件名进行追踪，并保持重试，即该文件被删除或改名后，如果再次创建相同的文件名，会继续追踪 tailf 等同于tail -f -n 10（貌似tail -f或-F默认也是打印最后10行，然后追踪文件），与tail -f不同的是，如果文件不增长，它不会去访问磁盘文件，所以tailf特别适合那些便携机上跟踪日志文件，因为它减少了磁盘访问，可以省电 然后使用： nohup command &gt; myout.file 2&gt;&amp;1 &amp; tailf myout.file 曲线救国，达到了既记录日志又打屏的目的。","categories":[],"tags":[],"author":"张存"},{"title":"ubuntu 20.04 安装python 3.6.9","slug":"ubuntu-20-04-安装python-3-6-8","date":"2021-12-24T10:25:46.000Z","updated":"2021-12-27T02:17:02.870Z","comments":true,"path":"2021/12/24/ubuntu-20-04-an-zhuang-python-3-6-8/","link":"","permalink":"https://blog.zhangcun.store/2021/12/24/ubuntu-20-04-an-zhuang-python-3-6-8/","excerpt":"","text":"ubuntu 20.04 源码安装python 3.6.9 链接：https://www.python.org/ 安装依赖工具sudo apt-get install -y gcc make build-essential libssl-dev zlib1g-dev libbz2-dev libreadline-dev libsqlite3-dev wget curl llvm libncurses5-dev libncursesw5-dev xz-utils tk-dev libffi-dev liblzma-dev 下载源码文件压缩包wget https://www.python.org/ftp/python/3.6.9/Python-3.6.9.tgz 解压源码文件压缩包xz -d Python-3.6.9.tgztar -xvf Python-3.6.9.tar 配置cd Python-3.6.9 sudo ./configure –enable-optimizations –prefix=/usr/local/bin/python3.6 –prefix=/usr/local/bin/python3.6：编译的时候用来指定程序存放路径。编译sudo make 安装sudo make install 设置软链接sudo ln -s -f /usr/local/bin/python3.6/bin/python3.6 /usr/bin/python3.6 sudo ln -s -f /usr/local/bin/python3.6/bin/pip3.6 /usr/bin/pip3.6 apt方式安装 （不能指定小版本）python3 –version添加python软件源sudo apt updatesudo apt install software-properties-commonsudo add-apt-repository ppa:deadsnakes/ppasudo apt update安装3.6版本并查看sudo apt install python3.6python3.6 -V","categories":[],"tags":[],"author":"张存"},{"title":"服务器ubuntu 20.04关闭自动休眠模式","slug":"服务器ubuntu-20-04关闭自动休眠模式","date":"2021-12-23T07:45:05.000Z","updated":"2021-12-23T07:45:52.348Z","comments":true,"path":"2021/12/23/fu-wu-qi-ubuntu-20-04-guan-bi-zi-dong-xiu-mian-mo-shi/","link":"","permalink":"https://blog.zhangcun.store/2021/12/23/fu-wu-qi-ubuntu-20-04-guan-bi-zi-dong-xiu-mian-mo-shi/","excerpt":"","text":"1.查看是否开启休眠模式systemctl status sleep.target发现如下所示： ● sleep.target - Sleep Loaded: loaded (/lib/systemd/system/sleep.target; static; vendor preset: enabled) Active: inactive (dead) Docs: man:systemd.special(7)2.执行关闭休眠功能的命令，如下： sudo systemctl mask sleep.target suspend.target hibernate.target hybrid-sleep.target可以看到系统返回： Created symlink /etc/systemd/system/sleep.target → /dev/null.Created symlink /etc/systemd/system/suspend.target → /dev/null.Created symlink /etc/systemd/system/hibernate.target → /dev/null.Created symlink /etc/systemd/system/hybrid-sleep.target → /dev/null.3.观察系统休眠状态，如下： systemctl status sleep.target可以看到自动休眠模式已被关闭： ● sleep.target Loaded: masked (Reason: Unit sleep.target is masked.) Active: inactive (dead)","categories":[],"tags":[],"author":"张存"},{"title":"TRACERT命令 windows下的traceroute命令的简单使用","slug":"TRACERT命令-windows下的traceroute命令的简单使用","date":"2021-12-17T07:33:59.000Z","updated":"2021-12-17T07:34:10.838Z","comments":true,"path":"2021/12/17/tracert-ming-ling-windows-xia-de-traceroute-ming-ling-de-jian-dan-shi-yong/","link":"","permalink":"https://blog.zhangcun.store/2021/12/17/tracert-ming-ling-windows-xia-de-traceroute-ming-ling-de-jian-dan-shi-yong/","excerpt":"","text":"最简单的用法，在cmd中输入 tracert /d yande.re 开关d的意思是，不将沿途的路由器IP反向DNS解析为字符串名字，这样可以增加跟踪速度","categories":[],"tags":[],"author":"张存"},{"title":"无法访问github解决方法","slug":"无法访问github解决方法","date":"2021-12-17T07:00:33.000Z","updated":"2021-12-17T07:32:14.866Z","comments":true,"path":"2021/12/17/wu-fa-fang-wen-github-jie-jue-fang-fa/","link":"","permalink":"https://blog.zhangcun.store/2021/12/17/wu-fa-fang-wen-github-jie-jue-fang-fa/","excerpt":"","text":"使用Ghelper去谷歌学术搜文章，页面放在那很久，一回来发现竟然无法再访问谷歌学术了，github也不能访问了！ 解决办法：1.首先参考博客：github.com连接超时在cmd里ping github.com，结果果然是连接超时但是里面的ip地址应该是不能用了2.在查询ip地址里，输入github.com，查询解析地址 从这些地址里随便选一个，在C:\\Windows\\System32\\drivers\\etc\\host 文件的最后写入 13.229.188.59 github.com git185.31.16.184 github.global.ssl.fastly.net 如何保存host文件参照：百度经验3.保存好后打开cmd，输入ipconfig/flushdns 此时再ping github已经可以ping成功了网页里也能进入github和谷歌学术了~","categories":[],"tags":[],"author":"张存"},{"title":"archery docker部署","slug":"archery-docker部署","date":"2021-12-17T05:24:19.000Z","updated":"2021-12-17T05:25:36.914Z","comments":true,"path":"2021/12/17/archery-docker-bu-shu/","link":"","permalink":"https://blog.zhangcun.store/2021/12/17/archery-docker-bu-shu/","excerpt":"","text":"1.安装docker yum -y updateyum remove docker docker-client docker-client-latest docker-common docker-latest docker-latest-logrotate docker-logrotate docker-selinux docker-engine-selinux docker-engineyum install -y yum-utils device-mapper-persistent-data lvm2yum-config-manager –add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repoyum -y install docker-cesystemctl start dockersystemctl enable docker 2.安装 Docker Compose curl -L https://github.com/docker/compose/releases/download/1.17.1/docker-compose-`uname -s-uname -m` &gt; /usr/local/bin/docker-composechmod +x /usr/local/bin/docker-compose123.docker部署archery yum -y install gitgit clone https://github.com/hhyo/Archery.gitcd Archery/src/docker-compose/docker-compose -f docker-compose.yml up -ddocker exec -ti archery /bin/bashcd /opt/archerysource /opt/venv4archery/bin/activatepython3 manage.py makemigrations sqlpython3 manage.py migratepython3 manage.py compilemessagespython3 manage.py createsuperuser 4.登录在浏览器输入http://服务器IP:9123使用第三步中用python3 manage.py createsuperuser命令创建的用户及密码登录即可 注：建议部署时mysql单独在其他服务器安装，不使用docker版本的，将docker-compose.yml中的mysql部分删除再执行docker-compose -f docker-compose.yml up -d并修改配置文件中的mysql地址即可，分开部署在升级时比较简单。","categories":[],"tags":[],"author":"张存"},{"title":"查看redisCluster集群中所有keys值","slug":"查看redisCluster集群中所有keys值","date":"2021-12-17T05:19:24.000Z","updated":"2021-12-17T05:21:57.626Z","comments":true,"path":"2021/12/17/cha-kan-rediscluster-ji-qun-zhong-suo-you-keys-zhi/","link":"","permalink":"https://blog.zhangcun.store/2021/12/17/cha-kan-rediscluster-ji-qun-zhong-suo-you-keys-zhi/","excerpt":"","text":"/opt/redis/bin/redis-cli -c –cluster call 192.168.66.132:7000 keys *1root@redis-node01:~# /opt/redis/bin/redis-cli -c –cluster call 192.168.66.132:7000 keys * &gt;&gt;&gt; Calling keys * 192.168.66.132:7000: aaaa 192.168.66.132:7005: ccccc 192.168.66.132:7004: jiang 192.168.66.132:7003: bbbb 192.168.66.132:7001: 192.168.66.132:7002:","categories":[],"tags":[],"author":"张存"},{"title":"Debian GNU/Linux 换源","slug":"Untitled","date":"2021-12-16T08:21:25.000Z","updated":"2021-12-16T08:21:41.909Z","comments":true,"path":"2021/12/16/untitled/","link":"","permalink":"https://blog.zhangcun.store/2021/12/16/untitled/","excerpt":"","text":"yum可以换源，Debian 也可以直接百度搜索：debian 国内源 换源：Debian 默认源， /etc/apt/sources.list删除/移除 默认源 /etc/apt/sources.list 这里使用163的镜像站执行：echo ‘deb http://mirrors.163.com/debian/ stretch main non-free contribdeb http://mirrors.163.com/debian/ stretch-updates main non-free contribdeb http://mirrors.163.com/debian/ stretch-backports main non-free contribdeb-src http://mirrors.163.com/debian/ stretch main non-free contribdeb-src http://mirrors.163.com/debian/ stretch-updates main non-free contribdeb-src http://mirrors.163.com/debian/ stretch-backports main non-free contribdeb http://mirrors.163.com/debian-security/ stretch/updates main non-free contribdeb-src http://mirrors.163.com/debian-security/ stretch/updates main non-free contrib’ &gt; /etc/apt/sources.list 163镜像站deb http://mirrors.163.com/debian/ stretch main non-free contribdeb http://mirrors.163.com/debian/ stretch-updates main non-free contribdeb http://mirrors.163.com/debian/ stretch-backports main non-free contribdeb-src http://mirrors.163.com/debian/ stretch main non-free contribdeb-src http://mirrors.163.com/debian/ stretch-updates main non-free contribdeb-src http://mirrors.163.com/debian/ stretch-backports main non-free contribdeb http://mirrors.163.com/debian-security/ stretch/updates main non-free contribdeb-src http://mirrors.163.com/debian-security/ stretch/updates main non-free contrib 中科大镜像站deb https://mirrors.ustc.edu.cn/debian/ stretch main contrib non-freedeb-src https://mirrors.ustc.edu.cn/debian/ stretch main contrib non-free deb https://mirrors.ustc.edu.cn/debian/ stretch-updates main contrib non-freedeb-src https://mirrors.ustc.edu.cn/debian/ stretch-updates main contrib non-free deb https://mirrors.ustc.edu.cn/debian/ stretch-backports main contrib non-freedeb-src https://mirrors.ustc.edu.cn/debian/ stretch-backports main contrib non-free deb https://mirrors.ustc.edu.cn/debian-security/ stretch/updates main contrib non-freedeb-src https://mirrors.ustc.edu.cn/debian-security/ stretch/updates main contrib non-free 阿里云镜像站deb http://mirrors.aliyun.com/debian/ stretch main non-free contribdeb-src http://mirrors.aliyun.com/debian/ stretch main non-free contribdeb http://mirrors.aliyun.com/debian-security stretch/updates maindeb-src http://mirrors.aliyun.com/debian-security stretch/updates maindeb http://mirrors.aliyun.com/debian/ stretch-updates main non-free contribdeb-src http://mirrors.aliyun.com/debian/ stretch-updates main non-free contribdeb http://mirrors.aliyun.com/debian/ stretch-backports main non-free contribdeb-src http://mirrors.aliyun.com/debian/ stretch-backports main non-free contrib 华为镜像站deb https://mirrors.huaweicloud.com/debian/ stretch main contrib non-freedeb-src https://mirrors.huaweicloud.com/debian/ stretch main contrib non-freedeb https://mirrors.huaweicloud.com/debian/ stretch-updates main contrib non-freedeb-src https://mirrors.huaweicloud.com/debian/ stretch-updates main contrib non-freedeb https://mirrors.huaweicloud.com/debian/ stretch-backports main contrib non-freedeb-src https://mirrors.huaweicloud.com/debian/ stretch-backports main contrib non-free 清华大学镜像站deb https://mirrors.tuna.tsinghua.edu.cn/debian/ stretch main contrib non-freedeb-src https://mirrors.tuna.tsinghua.edu.cn/debian/ stretch main contrib non-freedeb https://mirrors.tuna.tsinghua.edu.cn/debian/ stretch-updates main contrib non-freedeb-src https://mirrors.tuna.tsinghua.edu.cn/debian/ stretch-updates main contrib non-freedeb https://mirrors.tuna.tsinghua.edu.cn/debian/ stretch-backports main contrib non-freedeb-src https://mirrors.tuna.tsinghua.edu.cn/debian/ stretch-backports main contrib non-freedeb https://mirrors.tuna.tsinghua.edu.cn/debian-security/ stretch/updates main contrib non-freedeb-src https://mirrors.tuna.tsinghua.edu.cn/debian-security/ stretch/updates main contrib non-free 兰州大学镜像站deb http://mirror.lzu.edu.cn/debian stable main contrib non-freedeb-src http://mirror.lzu.edu.cn/debian stable main contrib non-freedeb http://mirror.lzu.edu.cn/debian stable-updates main contrib non-freedeb-src http://mirror.lzu.edu.cn/debian stable-updates main contrib non-freedeb http://mirror.lzu.edu.cn/debian/ stretch-backports main contrib non-freedeb-src http://mirror.lzu.edu.cn/debian/ stretch-backports main contrib non-freedeb http://mirror.lzu.edu.cn/debian-security/ stretch/updates main contrib non-freedeb-src http://mirror.lzu.edu.cn/debian-security/ stretch/updates main contrib non-free 上海交大镜像站deb https://mirror.sjtu.edu.cn/debian/ stretch main contrib non-freedeb-src https://mirror.sjtu.edu.cn/debian/ stretch main contrib non-freedeb https://mirror.sjtu.edu.cn/debian/ stretch-updates main contrib non-freedeb-src https://mirror.sjtu.edu.cn/debian/ stretch-updates main contrib non-freedeb https://mirror.sjtu.edu.cn/debian/ stretch-backports main contrib non-freedeb-src https://mirror.sjtu.edu.cn/debian/ stretch-backports main contrib non-freedeb https://mirror.sjtu.edu.cn/debian-security/ stretch/updates main contrib non-freedeb-src https://mirror.sjtu.edu.cn/debian-security/ stretch/updates main contrib non-free","categories":[],"tags":[],"author":"张存"},{"title":"vue启动项目时，npm无法安装东西的解决办法","slug":"vue启动项目时，npm无法安装东西的解决办法","date":"2021-12-16T08:07:02.000Z","updated":"2021-12-16T08:07:35.570Z","comments":true,"path":"2021/12/16/vue-qi-dong-xiang-mu-shi-npm-wu-fa-an-zhuang-dong-xi-de-jie-jue-ban-fa/","link":"","permalink":"https://blog.zhangcun.store/2021/12/16/vue-qi-dong-xiang-mu-shi-npm-wu-fa-an-zhuang-dong-xi-de-jie-jue-ban-fa/","excerpt":"","text":"echo $PATHnode -vnpm -vnpm config set proxy nullnpm cache clean –forcenpm config set registry https://registry.npm.taobao.org/npm i node-sass –sass_binary_site=https://npm.taobao.org/mirrors/node-sass/npm installnpm run build","categories":[],"tags":[],"author":"张存"},{"title":"linux切割、备份大的nohup日志文件","slug":"linux切割、备份大的nohup日志文件","date":"2021-12-16T07:59:14.000Z","updated":"2021-12-16T08:00:43.049Z","comments":true,"path":"2021/12/16/linux-qie-ge-bei-fen-da-de-nohup-ri-zhi-wen-jian/","link":"","permalink":"https://blog.zhangcun.store/2021/12/16/linux-qie-ge-bei-fen-da-de-nohup-ri-zhi-wen-jian/","excerpt":"","text":"背景：nohup.out日志文件太大了，且一直增长，命令查看日志受阻 目的：①切割大文件变成多个小文件②每天定时保存前一天的日志，重新记录当天日志 具体做法：1.利用split命令切割①按文件大小切割大文件：切割文件：将ohup.out文件每500M切割一个文件放到/home/nginx/logs/newlog/目录下 split -b 500m nohup.out /home/nginx/logs/newlog/eg:split -b 50m /home/nginx/logs/newlog/b.log /home/nginx/logs/newlog/②按文件行数切割大文件：查询文件行数：wc -l b.log2038711 b.log按50W行切割一个文件：split -l 500000 -d -a 4 /home/nginx/logs/b.log /home/nginx/logs/newlog/2.定时备份前一天日志，重新记录当天日志splitlog.sh this_path=$(cd `dirname $0`;pwd) cd $this_path #echo $this_path current_date=`date -d &quot;-1 day&quot; &quot;+%Y%m%d&quot;` #echo $current_date split -b 100m -d -a 4 /home/nginx/logs/nohup.out /home/nginx/logs/newlog/log_$&#123;current_date&#125;_ cat /dev/null &gt; nohup.out 3.定时执行查看定时任务：crontab -l编辑定时任务：crontab -e 0 0 * * * /home/nginx/logs/splitlog.sh 重启定时任务： sudo service crond restart补充：删除10天以前的日志文件，此日期为文件本身的时间，非日志内容时间 #!/bin/sh find /u02/tomcat/service/logs/ -mtime +10 -name &quot;*.tmp&quot; -exec rm -rf &#123;&#125; \\; find /home/tomcat/webApp/javalogs/ -mtime +10 -name &quot;*.log&quot; -exec rm -rf &#123;&#125; \\;","categories":[],"tags":[],"author":"张存"},{"title":"shell 中的 -eq -ne -gt -lt ge le","slug":"shell-中的-eq-ne-gt-lt-ge-le","date":"2021-12-16T06:09:38.000Z","updated":"2021-12-16T06:19:57.141Z","comments":true,"path":"2021/12/16/shell-zhong-de-eq-ne-gt-lt-ge-le/","link":"","permalink":"https://blog.zhangcun.store/2021/12/16/shell-zhong-de-eq-ne-gt-lt-ge-le/","excerpt":"","text":"shell中的比较不是使用简单的&gt; = &lt;等，而是用扩展符，如下所示： -eq //equal 等于 -ne //no equal 不等于 -gt //great than 大于 -lt // low than 小于 -ge // great and equal 大于等于 -le //low and equal 小于等于 注： 1、在shell中进行比较时，结果为0代表真，为1代表假。 2、-eq，-ne等比较符只能用于数字比较，有字符也会先转换成数字然后进行比较。","categories":[],"tags":[],"author":"张存"},{"title":"shell中判断文件大小是否超过指定大小","slug":"shell中判断文件大小是否超过指定大小","date":"2021-12-16T05:54:44.000Z","updated":"2021-12-16T06:05:46.117Z","comments":true,"path":"2021/12/16/shell-zhong-pan-duan-wen-jian-da-xiao-shi-fou-chao-guo-zhi-ding-da-xiao/","link":"","permalink":"https://blog.zhangcun.store/2021/12/16/shell-zhong-pan-duan-wen-jian-da-xiao-shi-fou-chao-guo-zhi-ding-da-xiao/","excerpt":"","text":"#!/bin/sh filename=media.log filesize=ls -l $filename | awk &#39;&#123; print $5 &#125;&#39; maxsize=$((1024*10)) if [ $filesize -gt $maxsize ] then echo “$filesize &gt; $maxsize” mv media.log media”date +%Y-%m-%d_%H:%M:%S“.log else echo “$filesize &lt; $maxsize” fi 1024*1024*200 == 200M `","categories":[],"tags":[],"author":"张存"},{"title":"shell脚本如何判断文件大小","slug":"shell脚本如何判断文件大小","date":"2021-12-16T05:37:56.000Z","updated":"2021-12-16T05:39:06.863Z","comments":true,"path":"2021/12/16/shell-jiao-ben-ru-he-pan-duan-wen-jian-da-xiao/","link":"","permalink":"https://blog.zhangcun.store/2021/12/16/shell-jiao-ben-ru-he-pan-duan-wen-jian-da-xiao/","excerpt":"","text":"1 、ls -lls -l $filename | awk ‘{print $5}’ 执行结果：[root@localhost opt]# ls -l test.txt-rw-r–r–. 1 root root 4 Jun 21 11:40 test.txt[root@localhost opt]# ls -l test.txt | awk ‘{print $5}’42、shell -s $filename文件大小非0时为真 if [ ! -s $filename ]thenecho “$filename 文件大小为0!”exit 1fi3、shell脚本判断[ -f “somefile” ] ：判断是否是一个文件[ -x “/bin/ls” ] ：判断/bin/ls是否存在并有可执行权限[ -n “$var” ] ：判断$var变量是否有值[ “$a” = “$b” ] ：判断$a和$b是否相等-r file 用户可读为真-w file 用户可写为真-x file 用户可执行为真-f file 文件为正规文件为真-d file 文件为目录为真-c file 文件为字符特殊文件为真-b file 文件为块特殊文件为真-s file 文件大小非0时为真-t file 当文件描述符(默认为1)指定的设备为终端时为真","categories":[],"tags":[],"author":"张存"},{"title":"Linux定时任务crontab每三秒执行一次shell","slug":"Linux定时任务crontab每三秒执行一次shell","date":"2021-12-16T03:56:55.000Z","updated":"2021-12-16T04:06:01.392Z","comments":true,"path":"2021/12/16/linux-ding-shi-ren-wu-crontab-mei-san-miao-zhi-xing-yi-ci-shell/","link":"","permalink":"https://blog.zhangcun.store/2021/12/16/linux-ding-shi-ren-wu-crontab-mei-san-miao-zhi-xing-yi-ci-shell/","excerpt":"","text":"第一种方法：当然首先想到的是写一个触发的脚本，在触发脚本中使用死循环来解决此问题，如下： cat kick.sh#!/bin/bashwhile : ;do/home/somedir/scripts.sh 2&gt;/dev/null &amp;sleep 3done 注意第一次运行时不要使用 bash kick.sh &amp; 这种后台运行的方式，它会僵死的。可以把它放到计划任务使其运行，然后将计划任务中的此条目删除即可。 第二种方法： cat cron-seconds.sh#!/bin/bashfor((i=1;i&lt;=20;i++));do/home/somedir/scripts.sh 2&gt;/dev/null &amp;sleep 3done 然后写入的crontab里每分钟执行一次，如下 crontab -e* * * * * /bin/bash /home/somedir/cron-seconds.sh 第三种方法：那么如何使用计划任务来直接实现呢？最后解决方案如下，经验证，脚本运行非常稳定。 ##For excuting scripts.sh every 3 seconds##on 2014-10-15*/1 * * * * /home/somedir/scripts.sh */1 * * * * sleep 3 &amp;&amp; /home/somedir/scripts.sh */1 * * * * sleep 6 &amp;&amp; /home/somedir/scripts.sh */1 * * * * sleep 9 &amp;&amp; /home/somedir/scripts.sh */1 * * * * sleep 12 &amp;&amp; /home/somedir/scripts.sh */1 * * * * sleep 15 &amp;&amp; /home/somedir/scripts.sh */1 * * * * sleep 18 &amp;&amp; /home/somedir/scripts.sh */1 * * * * sleep 21 &amp;&amp; /home/somedir/scripts.sh */1 * * * * sleep 24 &amp;&amp; /home/somedir/scripts.sh */1 * * * * sleep 27 &amp;&amp; /home/somedir/scripts.sh */1 * * * * sleep 30 &amp;&amp; /home/somedir/scripts.sh */1 * * * * sleep 33 &amp;&amp; /home/somedir/scripts.sh */1 * * * * sleep 36 &amp;&amp; /home/somedir/scripts.sh */1 * * * * sleep 39 &amp;&amp; /home/somedir/scripts.sh */1 * * * * sleep 42 &amp;&amp; /home/somedir/scripts.sh */1 * * * * sleep 45 &amp;&amp; /home/somedir/scripts.sh */1 * * * * sleep 48 &amp;&amp; /home/somedir/scripts.sh */1 * * * * sleep 51 &amp;&amp; /home/somedir/scripts.sh */1 * * * * sleep 54 &amp;&amp; /home/somedir/scripts.sh */1 * * * * sleep 57 &amp;&amp; /home/somedir/scripts.sh #—————————————————————–先每隔1秒钟触发定时任务，然后又休眠 3秒、6秒、9秒等间隔 来执行具体的Shell脚本。第一种方法和第二种方法并不是严格的间隔3秒执行的，会大于3秒，因为执行scripts.sh也是需要一定时间的，即使已经加了&amp;符号放到了后台执行也会存在一定的误差。如果对于精确度要求不高，推荐使用第二种方法。","categories":[],"tags":[],"author":"张存"},{"title":"【Linux】crontab 每隔1小时 2小时的执行job写法","slug":"【Linux】crontab-每隔1小时-2小时的执行job写法","date":"2021-12-16T03:46:06.000Z","updated":"2021-12-16T03:49:39.602Z","comments":true,"path":"2021/12/16/linux-crontab-mei-ge-1-xiao-shi-2-xiao-shi-de-zhi-xing-job-xie-fa/","link":"","permalink":"https://blog.zhangcun.store/2021/12/16/linux-crontab-mei-ge-1-xiao-shi-2-xiao-shi-de-zhi-xing-job-xie-fa/","excerpt":"","text":"crontab -l crontab -e 每五分钟执行 */5 * * * * 每小时执行 0 * * * * 每2小时执行 0 */2 * * * 每天执行 0 0 * * * 每周执行 0 0 * * 0 每月执行 0 0 1 * * 每年执行 0 0 1 1 * 星号（*）：代表所有可能的值，例如month字段如果是星号，则表示在满足其它字段的制约条件后每月都执行该命令操作。 逗号（,）：可以用逗号隔开的值指定一个列表范围，例如，“1,2,5,7,8,9” 中杠（-）：可以用整数之间的中杠表示一个整数范围，例如“2-6”表示“2,3,4,5,6” 正斜线（/）：可以用正斜线指定时间的间隔频率，例如“0-23/2”表示每两小时执行一次。同时正斜线可以和星号一起使用，例如*/10，如果用在minute字段，表示每十分钟执行一次。 使用实例 实例1：每1分钟执行一次command 命令： * * * * * command 实例2：每小时的第3和第15分钟执行 命令： 3,15 * * * * command 实例3：在上午8点到11点的第3和第15分钟执行 命令： 3,15 8-11 * * * command 实例4：每隔两天的上午8点到11点的第3和第15分钟执行 命令： 3,15 8-11 */2 * * command 实例5：每个星期一的上午8点到11点的第3和第15分钟执行 命令： 3,15 8-11 * * 1 command 实例6：每晚的21:30重启smb 命令： 30 21 * * * /etc/init.d/smb restart 实例7：每月1、10、22日的4 : 45重启smb 命令： 45 4 1,10,22 * * /etc/init.d/smb restart 实例8：每周六、周日的1 : 10重启smb 命令： 10 1 * * 6,0 /etc/init.d/smb restart 实例9：每天18 : 00至23 : 00之间每隔30分钟重启smb 命令： 0,30 18-23 * * * /etc/init.d/smb restart 实例10：每星期六的晚上11 : 00 pm重启smb 命令： 0 23 * * 6 /etc/init.d/smb restart 实例11：每一小时重启smb 命令： * */1 * * * /etc/init.d/smb restart 实例12：晚上11点到早上7点之间，每隔一小时重启smb 命令： * 23-7/1 * * * /etc/init.d/smb restart 实例13：每月的4号与每周一到周三的11点重启smb 命令： 0 11 4 * mon-wed /etc/init.d/smb restart 实例14：一月一号的4点重启smb 命令： 0 4 1 jan * /etc/init.d/smb restart 实例15：每小时执行/etc/cron.hourly目录内的脚本 命令： 01 * * * * root run-parts /etc/cron.hourly 说明： run-parts这个参数了，如果去掉这个参数的话，后面就可以写要运行的某个脚本名，而不是目录名了","categories":[],"tags":[],"author":"张存"},{"title":"rabbitmq 启用日志跟踪","slug":"rabbitmq-启用日志跟踪-1","date":"2021-12-14T09:41:41.000Z","updated":"2021-12-14T09:41:44.512Z","comments":true,"path":"2021/12/14/rabbitmq-qi-yong-ri-zhi-gen-zong-1/","link":"","permalink":"https://blog.zhangcun.store/2021/12/14/rabbitmq-qi-yong-ri-zhi-gen-zong-1/","excerpt":"","text":"docker run -d -p 5672:5672 -p 15672:15672 –name rabbitmq rabbitmq:management docker exec -it rabbitmq bash rabbitmq-plugins enable rabbitmq_tracing","categories":[],"tags":[],"author":"张存"},{"title":"程序员在外包公司工作怎么样？","slug":"程序员在外包公司工作怎么样？","date":"2021-12-04T11:31:00.000Z","updated":"2021-12-02T11:37:36.721Z","comments":true,"path":"2021/12/04/cheng-xu-yuan-zai-wai-bao-gong-si-gong-zuo-zen-me-yang/","link":"","permalink":"https://blog.zhangcun.store/2021/12/04/cheng-xu-yuan-zai-wai-bao-gong-si-gong-zuo-zen-me-yang/","excerpt":"","text":"今天刚刚好是周六，本来是可以好好休息的，计划好要去哪里玩的，但是天有不测风云，突然说银行领导要来检查，今天周末大家必须和平时一样照常上班，天呐！大哭 图片 !也无奈，只能照常上班咯，谁让别人是地主呢？我经常看到帖子上说或者论坛上大家在讨论程序员在外包公司工作怎么样？福利待遇好吗？工作累吗？上班时间怎么样？等等总之一堆一堆的，现在下班回家闲来无事，我就来说说在外包公司工作到底怎么样？是一种什么样的感觉？大家想不想听呢？那就让我慢慢道来…图片 其实呢，也不能一味的说好和不好，毕竟凡事都是有两面性的，我自己目前也是作为一个外包人员被派遣到某银行去工作，我工作了五年了总共被派遣到银行了两次，分别是不同的外包公司，可能这会有人要笑了，说我怎么去了外包公司一次现在又来二次呢？哎，总之为了赚钱为了生活没办法。外包呢分为两种，一种是项目外包，就是把项目直接给其他公司去做，只要出钱就好了的，这种其实是大部分的公司都是这样子，不想自己养活一堆人，项目经理，产品，前端，后端，UI等等，要是没接到货的话是直接要亏钱养这么多人的，所以很多公司其实都是项目外包，直接有项目的时候外包给其他公司就行了，简单方便。这其实我没什么好说的，因为这种还算是在自己公司上班。 接下来我就说说另外一种才是我们今天的主题，现在隆重推出，人力外包-所谓人力外包就是我们入职是其他公司，但是我们入职的公司就把我们派遣到不同的地方去上班，可能是某银行，也可能是某金融机构，或者某证券公司，总之基本上都是和金融机构相关的地方上班。那到底怎么样呢？ 首先我先来说说好的方面吧，不然一会我都说不好的估计大家都吓跑了，以后估计都听到外包都怕， 哈哈图片。 优点： 第一点：上班时间上 从上班时间来说的话，这其实是还不错的，就按我目前来说的话，我们银行都是早上的9:00上班，到中午的11:30就下班，然后下午的2点开始上班，再上到下午的5.30,算下来的话其实是才6个小时的上班时间，正常情况的话都是不用加班的，基本上我现在大部分时间都是这样的，但是他们银行是算8小时的，也就是我们中午休息时间是都算在内的，反正银行只算八小时就行了，意味着我们不管几点去，只要打满8小时的卡就行了，当然一般都不会太晚，因为除了银行要打卡以外，别忘记了我们只是派遣到那里上班的，还需要再次打卡我们自己公司的卡哦，就是双打卡，自己公司都是9点前打卡，然后下午5：30再次打卡就可以了，所以根据前面说的只要银行打满8小时那中午来打卡然后到晚上8点也是可以的，哈哈，不可能的，因为自己公司还规定9点前打卡啊，当然有特例哦，有些公司是打卡距离特别的远，因为钉钉打卡是可以设置距离的，1公里，2公里，有些住的近的同事每天起床就打卡了，然后就可以晚点来，我之前那家公司就是这样，我住的很近，每天一起床第一件事就是打卡，哈哈，再也不用担心会迟到了，不过这是过去式了，小编现在也是每天都是乖乖的早早的8点起床，9点前到公司，当然基本上都是会有个三次四次的忘记打卡或者迟到的次数可以用，有时候迟到几次是没事的。很多人说经常要996上班，其实不用的，除非是很忙的时候，项目很赶或者要上线的时候，确实有时候急着要赶项目，要上次那是没辙的，大家都是这样，包括项目领导，都是要到晚上一两点，周六可能也会要去加班，不过这情况不是特别多哈，不用太担心！这情况不管是不是外包公司都是要加班的。 第二点：从管理约束方面 在外包公司工作当被派遣去其他地方上班的时候，我个人觉得不会和在原来自己公司上班一样约束，因为现在你上班吃饭正常11：30下班，正常公司都是下班之后才能去吃饭的，我在我上家公司就是12：00下班，我想早点去吃饭提早了10分钟，结果就被领导察觉到了，就和我说以后要是再早下班，就要扣我绩效，尼玛？吓得我，以后再也不敢提早下班去吃饭了，只能乖乖等到12：00准时下班之后才能再去吃饭。但是在银行上班，没有多少人会管你有没有提早去吃饭，甚至领导自己也是提早去吃饭，毕竟到了银行工作，自己也只是一个打工者而已，早上迟到，晚上早走正常是不会有人管你的，除非有事找你的时候。所以还是比较自由的。 第三点：从找工作上 现在的外包工作特别的多，比如比较大的，中软国际，文思海辉，天阳科技，长亮，上海诺祺科技等等等等，数不过来，他们大量的在找人，因为他们要赚钱，只能通过不断的招人，毕竟他们是人力外包，是在每个人员身上抽取利润的，人员多，银行给他们的钱自然就多，人员越少赚的自然也越少，所以这就造成外包公司不断的招人，所以找工作会很好找，如果你想去外包公司工作的话。工资方面不能说比较高，只能说和不是外包的差不多吧，就看自己的面试结果了。 我实在想不出还有什么好处了图片,呜呜！ 接下去我来说说缺点吧！ 缺点： 第一点：从稳定性方面 在稳定性方面，大家应该也可以猜想得到吧，目前我是在建行上班，听说这个项目是做到年底吧，那年底做完了呢？那自然是整个项目组解散咯，只能分别调离到其他的银行去上班了，这就给我们这些流动人口来说很不方便，我租房子租一年的，结果半年不到就要换地方上班了，我们流动人口就是不想太远，所以才租很近上班，这一换地方那简直没法接受天天要赶公交上班，会累死，要么就舍去押金不要了，损失点金钱换上班方便咯。这对于我们流动人口来说是很不好的。尤其是结婚了的人，一大家人在一起，又换地方是特别麻烦的事情。 第二点：从技术发展上 在银行上班，如果是新项目还会好一点，最近两年特别多的微服务架构，如果你遇到的项目是用微服务架构的，那你还算比较幸运的，我上家公司派遣到银行的时候，我那时候做的项目是已经很成熟了的，都是很老很老的架构，都是银行自己搭建起来的，不管是前端还是后端，包括开发的工具都是他们自己开发出来的，封装的特别严重的，你想学东西，那是抱歉很难学到的，那时候就有几个实习生听说是刚刚培训来的，他们肯定是想来学东西的，但是遇到这项目，项目经理都建议他们去找其他公司，在这里是学不到东西的，只是浪费时间而已，因为你只需要跟着步骤一步一步去做就好了，完全不会有自己思考的空间，写代码都是按步骤照搬的，离开了这里你去外面找工作又是一片白纸，毫无工作经验！就算是微服务架构，那做Java技术，或者和你一样的人也不会多，因为他们只会人够就行，银行也是要成本的，你什么都基本上只能靠你自己，有时候遇到事情不会，只能慢慢自己查资料，加班咯，很多人做的都是不一样的事情，我目前就我一个人是负责一个项目，每个人都是负责不同的东西，问别人别人也不懂，当然还是主要靠自己学，在哪里工作都一样。 第三点：从话语权和归属感方面 是最重要的一点了，每个人应该都想自己当家作主吧，在派遣去其他地方上班的时候，你还想什么事情做主，或者自己公司的领导做主，那是不存在的，我们只能是陪衬的，实际干活 的，我说个例子，有一次分配给我一个需求，然后我就和我公司的项目负责人讨论，（对了，在这里我们开发者不但是开发人员还是产品，怎么做都是要自己想，我也是醉了！）讨论好了之后我就开始写代码，我代码写完了，好了这时候项目负责人就和负责我们这项目的银行的负责人说方案这么做，结果行方负责人不满意，他说方案不行，要改，然后就只能继续改代码了，然后后面他又想了想好像也不对，接着又改，哎，只能硬着头皮再次修改，谁让他们是主人呢？什么都不能说，毕竟他也是一个做了十年了的架构师也还算可以，我服你。但是更糟糕的是，他还有一个比我小了好几岁的银行的同事，他只是一个很普通很普通的工作人员而已，但是我们也要听他说的话，按他安排的工作来做，不单单是我，连我们公司的负责人40几岁了还要听他的，感觉有点难以接受。总之就是感觉自己是被买到了这里，有种古代有钱人家的Y头那种感觉，就是干活的，没有任何话语权的，主人说让你做什么就是做什么，谁让他们是金主呢？ 第四点：从福利上 刚刚入职那会还在自己公司上班，那时候和现在在银行上班相比完全不一样，那时候经常公司的领导会去买些零食啊，水果啊，饮料啊等等的，包括节假日也有礼物，现在在银行上班，你还想有这些福利，那是不可能的，连最简单的，纸都没有，全部都是要自己带纸，擦桌子啊，等等反正都是要自己带，而且有时候可能加班到很晚会有发些零食，但是还要想一想，我们外包人员这些零食我们能不能去吃呢？ 第五点：从面试上 如果你是从头到尾从零开始做一个项目的那你还会毕竟熟悉一点，面试的时候你还能说些东西，但是大部分都已经是很成熟的项目了，你完全搞不懂这项目是怎么回事，因为都是一个项目一个项目互相关联的，你做的项目只是其中的某一个环节而已，而你又不了解项目，也没有什么项目介绍，项目文档等等，完全就是蒙蔽的状态，等面试的时候完全是不知道该说什么项目经验。 第六点：从配合上 银行的项目通常都是分为很多的公司来做的，那每个项目之间又都是有关系的，那就涉及到要经常和别人家公司对接接口，这就很麻烦了，大家都互相不认识，要去接触一下都是要走很远，沟通很不方便，别人觉得你也只是一个小打工仔，根本不太爱理你，不得已的时候只能找项目的行方的负责人去协调，这样才能毕竟早点做完项目，如果是自己公司的那完全就方便多了，所以配合上也是不太好,工作也会很累。 总而言之，有好也有坏吧，自己琢磨琢磨哈！ 今天就先写到这了吧，深夜了，该休息了！","categories":[],"tags":[],"author":"张存"},{"title":"Linux中查看是否是固态硬盘（SSD）","slug":"Linux中查看是否是固态硬盘（SSD）","date":"2021-11-29T05:36:17.000Z","updated":"2021-11-29T05:36:46.862Z","comments":true,"path":"2021/11/29/linux-zhong-cha-kan-shi-fou-shi-gu-tai-ying-pan-ssd/","link":"","permalink":"https://blog.zhangcun.store/2021/11/29/linux-zhong-cha-kan-shi-fou-shi-gu-tai-ying-pan-ssd/","excerpt":"","text":"最近在准备测试，需要看看哪些机器挂载的是ssd硬盘，Google了一圈看到了许多方法，但都云里雾里的，不知道怎么确定。ssd硬盘貌似使用的也是scsi接口，所以根据盘符的名称也是判断不出来的。最后群里eric大神告知lsscsi工具，试了一下，非常简单，显示的也很直接，分享一下。废话不多说，直接上图和结果，如下所示：[root@FWD_YF_009_110 ~] # lsscsi[ 0 : 0 : 0 : 0] disk SEAGATE ST3300657SS ES62 -[ 0 : 0 : 1 : 0] disk ATA INTEL SSDSA2CW16 0362 /dev /sda[ 0 : 0 : 2 : 0] disk ATA INTEL SSDSA2CW16 0362 /dev /sdb[ 0 : 0 : 3 : 0] disk ATA INTEL SSDSA2CW16 0362 /dev /sdc[ 0 : 1 : 0 : 0] disk Dell VIRTUAL DISK 1028 /dev /sdd[ 3 : 0 : 0 : 0] cd /dvd TEAC DVD -ROM DV - 28SW R. 2A /dev /sr0看第四列就知道是否是SSD硬盘了，感兴趣的可以试下","categories":[],"tags":[],"author":"张存"},{"title":"胖嘟嘟","slug":"testvideo","date":"2021-11-29T04:49:57.000Z","updated":"2021-11-29T10:25:33.817Z","comments":true,"path":"2021/11/29/testvideo/","link":"","permalink":"https://blog.zhangcun.store/2021/11/29/testvideo/","excerpt":"","text":"","categories":[],"tags":[],"author":"张存"},{"title":"jenkins 禁止自动构建下游项目","slug":"jenkins-禁止自动构建下游项目","date":"2021-11-23T11:15:23.000Z","updated":"2021-11-23T11:20:20.342Z","comments":true,"path":"2021/11/23/jenkins-jin-zhi-zi-dong-gou-jian-xia-you-xiang-mu/","link":"","permalink":"https://blog.zhangcun.store/2021/11/23/jenkins-jin-zhi-zi-dong-gou-jian-xia-you-xiang-mu/","excerpt":"","text":"使用jenkins过程中，发现当A项目被构建时，如果B项目依赖了A项目中某个模块的jar包也会被发起构建 原因是因为jenkins会根据pom的依赖创建项目关系 如上边的情况 A项目就是B项目的上级项目 想取消这种关系，不自动构建下级项目，需要在下级项目，也就是B项目中配置 Build whenever a SNAPSHOT dependency is built 把这个选项取消掉就可以了。 有用请点个赞！","categories":[],"tags":[],"author":"张存"},{"title":"Dockercompose之redis-cluster集群","slug":"Dockercompose之redis-cluster集群","date":"2021-11-19T08:41:36.000Z","updated":"2022-04-13T07:17:12.250Z","comments":true,"path":"2021/11/19/dockercompose-zhi-redis-cluster-ji-qun/","link":"","permalink":"https://blog.zhangcun.store/2021/11/19/dockercompose-zhi-redis-cluster-ji-qun/","excerpt":"","text":"一、环境一台主机：10.210.13.21 主机系统：centos 7.9.2009;Docker version 20.10.5 docker-compose安装: sudo curl -L “https://github.com/docker/compose/releases/download/1.25.0/docker-compose-$(uname -s)-$(uname -m)” -o /usr/local/bin/docker-compose sudo chmod +x /usr/local/bin/docker-compose sudo ln -s /usr/local/bin/docker-compose /usr/bin/docker-compose docker-compose –version二、搭建下载 Redis 镜像（其实这步可以省略，因为创建容器时，如果本地镜像不存在，就会去远程拉取）；编写 Redis 配置文件；编写 Docker Compose 模板文件；创建并启动所有服务容器；创建 Redis Cluster 集群。 编写redis配置文件1.创建目录及文件#创建目录mkdir -p /usr/local/docker-redis/redis-cluster#切换至指定目录cd /usr/local/docker-redis/redis-cluster/#编写 redis-cluster.tmpl 文件vim redis-cluster.tmpl2.编写redis配置文件port ${PORT}requirepass 123456masterauth 123456protected-mode nodaemonize noappendonly yescluster-enabled yescluster-config-file nodes.confcluster-node-timeout 15000cluster-announce-ip 10.210.13.21cluster-announce-port ${PORT}cluster-announce-bus-port 1${PORT}port：节点端口；requirepass：添加访问认证；masterauth：如果主节点开启了访问认证，从节点访问主节点需要认证；protected-mode：保护模式，默认值 yes，即开启。开启保护模式以后，需配置 bind ip 或者设置访问密码；关闭保护模式，外部网络可以直接访问；daemonize：是否以守护线程的方式启动（后台启动），默认 no；appendonly：是否开启 AOF 持久化模式，默认 no；cluster-enabled：是否开启集群模式，默认 no；cluster-config-file：集群节点信息文件；cluster-node-timeout：集群节点连接超时时间；cluster-announce-ip：集群节点 IP，填写宿主机的 IP；cluster-announce-port：集群节点映射端口；cluster-announce-bus-port：集群节点总线端口。 每个 Redis 集群节点都需要打开两个 TCP 连接。一个用于为客户端提供服务的正常 Redis TCP 端口，例如 6379。还有一个基于 6379 端口加 10000 的端口，比如 16379。 第二个端口用于集群总线，这是一个使用二进制协议的节点到节点通信通道。节点使用集群总线进行故障检测、配置更新、故障转移授权等等。客户端永远不要尝试与集群总线端口通信，与正常的 Redis 命令端口通信即可，但是请确保防火墙中的这两个端口都已经打开，否则 Redis 集群节点将无法通信。 3.在主机redis-cluster目录下执行以下脚本for port in seq 7000 7005; domkdir -p ${port}/conf&amp;&amp; PORT=${port} envsubst &lt; redis-cluster.tmpl &gt; ${port}/conf/redis.conf&amp;&amp; mkdir -p ${port}/data;done 编写Docker Compose文件在主机的redis-cluster目录下创建docker-compose.yml文件并编辑 #描述 Compose 文件的版本信息 version: &quot;3.8&quot; #定义服务，可以多个 services: redis-7000: # 服务名称 image: redis:5.0.5 # 创建容器时所需的镜像 container_name: redis-7000 # 容器名称 restart: always # 容器总是重新启动 network_mode: &quot;host&quot; # host 网络模式 volumes: # 数据卷，目录挂载 - /root/redis-cluster/7000/conf/redis.conf:/usr/local/etc/redis/redis.conf - /root/redis-cluster/7000/data:/data command: redis-server /usr/local/etc/redis/redis.conf # 覆盖容器启动后默认执行的命令 redis-7001: image: redis:5.0.5 container_name: redis-7001 network_mode: &quot;host&quot; volumes: - /root/redis-cluster/7001/conf/redis.conf:/usr/local/etc/redis/redis.conf - /root/redis-cluster/7001/data:/data command: redis-server /usr/local/etc/redis/redis.conf redis-7002: image: redis:5.0.5 container_name: redis-7002 network_mode: &quot;host&quot; volumes: - /root/redis-cluster/7002/conf/redis.conf:/usr/local/etc/redis/redis.conf - /root/redis-cluster/7002/data:/data command: redis-server /usr/local/etc/redis/redis.conf redis-7003: image: redis:5.0.5 container_name: redis-7003 restart: always network_mode: &quot;host&quot; volumes: - /root/redis-cluster/7003/conf/redis.conf:/usr/local/etc/redis/redis.conf - /root/redis-cluster/7003/data:/data command: redis-server /usr/local/etc/redis/redis.conf # 覆盖容器启动后默认执行的命令 redis-7004: image: redis:5.0.5 container_name: redis-7004 network_mode: &quot;host&quot; volumes: - /root/redis-cluster/7004/conf/redis.conf:/usr/local/etc/redis/redis.conf - /root/redis-cluster/7004/data:/data command: redis-server /usr/local/etc/redis/redis.conf redis-7005: image: redis:5.0.5 container_name: redis-7005 network_mode: &quot;host&quot; volumes: - /root/redis-cluster/7005/conf/redis.conf:/usr/local/etc/redis/redis.conf - /root/redis-cluster/7005/data:/data command: redis-server /usr/local/etc/redis/redis.conf 创建并启动所有服务容器在主机的docker-redis目录下执行以下命令： docker-compose up -d创建Redis Cluster集群请先确保主机通信正常，然后随便进入一个容器节点，并进入 /usr/local/bin/ 目录： #进入容器docker exec -it redis-6371 bash#切换至指定目录cd /usr/local/bin/接下来我们就可以通过以下命令实现 Redis Cluster 集群的创建 redis-cli -a 123456 --cluster create 10.210.13.21:7000 10.210.13.21:7001 10.210.13.21:7002 10.210.13.21:7003 10.210.13.21:7004 10.210.13.21:7005 --cluster-replicas 1 查看集群状态我们先进入容器，然后通过一些集群常用的命令查看一下集群的状态 #进入容器docker exec -it redis-6371 bash#切换至指定目录cd /usr/local/bin/1.检测集群的状态redis-cli -a 123456 –cluster check 10.210.13.21:70002.检测集群信息和节点信息#连接至集群某个节点redis-cli -c -a 1234 -h 192.168.10.11 -p 6376#查看集群信息cluster info#查看集群结点信息cluster nodes3.在7000节点中执行写入和读取，命令如下：#进入容器并连接至集群某个节点docker exec -it redis-7000 /usr/local/bin/redis-cli -c -a 123456 -h 10.210.13.21 -p 7000#写入数据set name mrhelloworldset aaa 111set bbb 222#读取数据get nameget aaaget bbb客户端连接最后来一波客户端连接操作，随便哪个节点，看看可否通过外部访问 Redis Cluster 集群","categories":[],"tags":[],"author":"张存"},{"title":"Ubuntu  上安装zabbix-agent","slug":"Ubuntu-上安装zabbix-agent","date":"2021-11-17T09:27:37.000Z","updated":"2021-11-17T09:36:59.089Z","comments":true,"path":"2021/11/17/ubuntu-shang-an-zhuang-zabbix-agent/","link":"","permalink":"https://blog.zhangcun.store/2021/11/17/ubuntu-shang-an-zhuang-zabbix-agent/","excerpt":"","text":"1.下载deb包 wget http://repo.zabbix.com/zabbix/5.2/ubuntu/pool/main/z/zabbix-release/zabbix-release_5.2-1%2Bubuntu14.04_all.deb 2.安装deb包 dpkg -i zabbix-release_5.2-1+ubuntu14.04_all.deb apt-get update 3.执行以下命令，安装zabbix-agent： apt-get install -y zabbix-agent 4.修改对应配置 cat /etc/zabbix/zabbix_agentd.conf |egrep ‘^Server|^Hostname=’","categories":[],"tags":[],"author":"张存"},{"title":"ubuntu测试网速","slug":"ubuntu测试网速","date":"2021-11-17T07:54:39.000Z","updated":"2021-11-17T07:55:56.637Z","comments":true,"path":"2021/11/17/ubuntu-ce-shi-wang-su/","link":"","permalink":"https://blog.zhangcun.store/2021/11/17/ubuntu-ce-shi-wang-su/","excerpt":"","text":"ubuntu测试网速 1、sudo apt install speedtest-cli 2、speedtest-cli 查看实时带宽 安装 sudo apt-get install bmon查看网络 bmon -p eth0 输入g控制流量面板的显示和隐藏 输入d控制详情信息的显示和隐藏 输入q退出面板","categories":[],"tags":[],"author":"张存"},{"title":"docker 搭建redis可视化工具treenms","slug":"docker-搭建redis可视化工具treenms","date":"2021-11-16T11:50:42.000Z","updated":"2021-11-16T11:54:11.461Z","comments":true,"path":"2021/11/16/docker-da-jian-redis-ke-shi-hua-gong-ju-treenms/","link":"","permalink":"https://blog.zhangcun.store/2021/11/16/docker-da-jian-redis-ke-shi-hua-gong-ju-treenms/","excerpt":"","text":"docker run -d -p 8085:8080 –name treenms -v /etc/localtime:/etc/localtime –restart=always zhangcun1113/treenms:lastest 访问 :8085 默认用户名：treesoft，密码：treesoft ,用户:admin，密码：treesoft","categories":[],"tags":[],"author":"张存"},{"title":"shell 脚本监控公司外网ip 并实现邮件报警","slug":"shell-脚本监控公司外网ip-并实现邮件报警","date":"2021-11-09T09:02:33.000Z","updated":"2021-11-09T09:09:05.592Z","comments":true,"path":"2021/11/09/shell-jiao-ben-jian-kong-gong-si-wai-wang-ip-bing-shi-xian-you-jian-bao-jing/","link":"","permalink":"https://blog.zhangcun.store/2021/11/09/shell-jiao-ben-jian-kong-gong-si-wai-wang-ip-bing-shi-xian-you-jian-bao-jing/","excerpt":"","text":"#!/bin/bash new_ip=`curl ifconfig.me` #获取新公网ip old_ip=`cat /root/ip` #查看旧ip mail_sender=1776803208@qq.com #发件邮件邮箱 mail_user=xxxxx #接收收邮件邮箱 mail_subject=IP_CHANGED #邮件主题 if [ ! $new_ip == $old_ip ] then echo $new_ip &gt; /root/ip echo &quot;ip has changed, the new ip is $new_ip !!! &quot;|mail -s &quot;$mail_subject&quot; -S from=$mail_sender &quot;$mail_user&quot; fi 注：需要安装mailx 按脚本新建对应得ip文件 –&gt; /root/ip配置定时任务：*/5 * * * * /root/ip.sh &gt;/dev/null 2&gt;&amp;1 其他获取新公网ip方法：curl icanhazip.comcurl ifconfig.mecurl ident.mecurl http://ip.3322.netcurl whatismyip.akamai.comcurl http://members.3322.org/dyndns/getip","categories":[],"tags":[],"author":"张存"},{"title":"ubuntu 安装发送邮件 heirloom-mailx","slug":"ubuntu-安装发送邮件-heirloom-mailx","date":"2021-11-09T08:47:37.000Z","updated":"2021-11-09T08:57:07.829Z","comments":true,"path":"2021/11/09/ubuntu-an-zhuang-fa-song-you-jian-heirloom-mailx/","link":"","permalink":"https://blog.zhangcun.store/2021/11/09/ubuntu-an-zhuang-fa-song-you-jian-heirloom-mailx/","excerpt":"","text":"前言ubuntu使用heirloom-mailx命令发送邮件。遇到一些坑，记录一下安装和配置的过程。 安装安装命令： sudo apt install heirloom-mailx我给俩服务器装这个，一个报错：Package has no installation candidate，一个不报错。最后发现报错的服务器的apt-get使用的是163源，不报错的使用的是阿里云源。163的源里面没有包含这个软件包。所以添加这个软件包所在源： sudo vim /etc/apt/sources.list在文件末端加入： deb http://cz.archive.ubuntu.com/ubuntu xenial main universe 更新软件包列表： apt-get update重新insatll： sudo apt install heirloom-mailx安装成功。 配置网易个人邮箱配置个人邮箱需要在客户端开启smtp功能，允许smtp登录。我这里是网易邮箱，只写了网易邮箱的方法。其它非网易邮箱的smtp如何开启可以自己查一下。 126邮箱为例，登录后在上方设置处选择POP3/SMTP/IMAP这个选项 进去之后把这个SMTP服务开启来，我这里已经开启了。这两个开哪个都行，因为反正我需要的是SMTP，这两个都包含。 会让你发个短信，扫码，然后开完之后给你一个密码 记下这个密码，这个密码可以用于通过SMTP服务登录邮箱 回到服务器上，要在公网发送邮件，需要在安装成功后修改配置文件： sudo vi /etc/s-nail.rc在文件末端加入： set from=”&#120;&#120;&#120;&#x78;&#x40;&#x31;&#x32;&#54;&#x2e;&#x63;&#111;&#x6d;“set smtp=”smtp.126.com”set smtp-auth-user=”&#x78;&#x78;&#120;&#x78;&#64;&#x31;&#50;&#x36;&#46;&#x63;&#x6f;&#109;“set smtp-auth-password=”xxxxx”set smtp-auth=login smtp-auth-user是你的邮箱地址，smtp-auth-password是在网页上开启SMTP服务后获得的那个密码配置完成，保存退出，发邮件测试：echo ‘hello world’ | heirloom-mailx -s “邮件标题” -t &#x78;&#x78;&#x78;&#x78;&#x40;&#x31;&#x32;&#x36;&#x2e;&#99;&#x6f;&#109;","categories":[],"tags":[],"author":"张存"},{"title":"详解几种Linux 查询外网出口IP命令的方法","slug":"详解几种Linux-查询外网出口IP命令的方法","date":"2021-11-09T08:20:27.000Z","updated":"2021-11-09T08:24:12.106Z","comments":true,"path":"2021/11/09/xiang-jie-ji-chong-linux-cha-xun-wai-wang-chu-kou-ip-ming-ling-de-fang-fa/","link":"","permalink":"https://blog.zhangcun.store/2021/11/09/xiang-jie-ji-chong-linux-cha-xun-wai-wang-chu-kou-ip-ming-ling-de-fang-fa/","excerpt":"","text":"Curl 纯文本格式输出:curl icanhazip.comcurl ifconfig.mecurl curlmyip.comcurl ip.appspot.comcurl ipinfo.io/ipcurl ipecho.net/plaincurl www.trackip.net/i curl JSON格式输出:curl ipinfo.io/jsoncurl ifconfig.me/all.jsoncurl www.trackip.net/ip?json curl XML格式输出:curl ifconfig.me/all.xmlcurl 得到所有IP细节 （挖掘机）curl ifconfig.me/all 使用 DYDNS （当你使用 DYDNS 服务时有用）curl -s ‘http://checkip.dyndns.org&#39; | sed ‘s/.*Current IP Address: ([0-9.])./\\1/g’curl -s http://checkip.dyndns.org/ | grep -o “[[:digit:].]+“ 使用 Wget 代替 Curlwget http://ipecho.net/plain -O - -q ; echowget http://observebox.com/ip -O - -q ; echo 使用 host 和 dig 命令如果有的话，你也可以直接使用 host 和 dig 命令。host -t a dartsclink.com | sed ‘s/.*has address //‘dig +short myip.opendns.com @resolver1.opendns.com bash 脚本示例:#!/bin/bash PUBLIC_IP=`wget http://ipecho.net/plain -O - -q ; echo` echo $PUBLIC_IP","categories":[],"tags":[],"author":"张存"},{"title":"内网穿透无需公网IP的工具Holer","slug":"内网穿透无需公网IP的工具Holer","date":"2021-11-09T08:16:23.000Z","updated":"2021-11-09T08:19:17.659Z","comments":true,"path":"2021/11/09/nei-wang-chuan-tou-wu-xu-gong-wang-ip-de-gong-ju-holer/","link":"","permalink":"https://blog.zhangcun.store/2021/11/09/nei-wang-chuan-tou-wu-xu-gong-wang-ip-de-gong-ju-holer/","excerpt":"","text":"Holer是一个免费开源的内网穿透工具，它可以将局域网服务器代理到公网的内网穿透工具，支持转发基于TCP协议的报文。 Holer地址：https://github.com/Wisdom-Projects/holer 1.下载软件包并解压：软件包地址：https://github.com/Wisdom-Projects/holer/tree/master/Binary 解压软件包 holer-client.zip 2.修改配置文件holer-client/conf/holer.conf 公网和内网的地址映射关系 Holer Access Key Internet Address Local AddressHOLER_CLIENT-2F8D8B78B3C2A0AE holer.org:65530 127.0.0.1:8080HOLER_CLIENT-3C07CDFD1BF99BF2 holer.org:65531 127.0.0.1:8088HOLER_CLIENT-2A623FCB6E2A7D1D holer.org:65532 127.0.0.1:80本地的Tomcat端口是8080，选择第一条记录里的Holer Access Key配置到holer-client/conf/holer.conf文件里 HOLER_ACCESS_KEY=HOLER_CLIENT-2F8D8B78B3C2A0AE如果您的Tomcat端口是8088或者80请选择对应的记录进行修改，如果您的Tomcat端口均不在上述列表里，建议将本地的Tomcat端口修改为上述列表里的端口8080或者8088或者80，否则无法访问映射后的公网地址。 3.启动Holer服务cd holer-client/binWindows: 执行命令：startup.bat或者双击startup.bat Linux: 执行命令： sh startup.sh 4.访问映射后的公网地址启动本地的Tomcat，浏览器里输入URL: http://holer.org:65530启动成功就可在公网上也能访问到了本地的Tomcat Web应用了","categories":[],"tags":[],"author":"张存"},{"title":"【shell】shell脚本实现监控端口，端口不存在自动重启","slug":"【shell】shell脚本实现监控端口，端口不存在自动重启","date":"2021-11-09T08:11:00.000Z","updated":"2021-11-09T08:12:49.734Z","comments":true,"path":"2021/11/09/shell-shell-jiao-ben-shi-xian-jian-kong-duan-kou-duan-kou-bu-cun-zai-zi-dong-chong-qi/","link":"","permalink":"https://blog.zhangcun.store/2021/11/09/shell-shell-jiao-ben-shi-xian-jian-kong-duan-kou-duan-kou-bu-cun-zai-zi-dong-chong-qi/","excerpt":"","text":"服务总是自动挂掉，为解决运维人员不能及时重启，所以写个定时脚本，一分钟监控一次端口是否占用，不占用说明服务挂了，自动重启服务。 脚本，以8080端口为例 #vim /usr/local/taskStartTomcat.sh #!/bin/sh tomcat=`netstat -an | grep &quot;:8080&quot; | awk &#39;$1 == &quot;tcp&quot; &amp;&amp; $NF == &quot;LISTEN&quot; &#123;print $0&#125;&#39; | wc -l` if [ $tomcat -eq 0 ];then #如果端口没有占用的话要怎么怎么样 /usr/local/apache-tomcat-jenkins/bin/startup.sh else #如果端口被占用的话要怎么怎么样 echo &quot;运行正常!&quot; fi 创建定时任务 #crontab -e */1 * * * * sh /usr/local/taskStartTomcat.sh","categories":[],"tags":[],"author":"张存"},{"title":"Dockerfile命令详解","slug":"Dockerfile命令详解","date":"2021-11-05T08:15:42.000Z","updated":"2021-11-05T08:16:00.281Z","comments":true,"path":"2021/11/05/dockerfile-ming-ling-xiang-jie/","link":"","permalink":"https://blog.zhangcun.store/2021/11/05/dockerfile-ming-ling-xiang-jie/","excerpt":"","text":"使用docker就会避免不了的要做各种镜像，就会用到dockerfile，记录一下dockerfile的主要命令 1、主要组成部分 dockerfile执行build命令时，是从上倒下依次执行的，dockerfile的基本组成部分如下。 主要部分 代表性命令 基础镜像信息 FROM 维护者信息 MAINTAINER 镜像操作指令 RUN、COPY、ADD、EXPOSE、WORKDIR、ONBUILD、USER、VOLUME、ENV等 容器启动时执行指令 CMD、ENTRYPOINT 2、各命令详解 FROM：指定基础镜像，必须为dockerfile中的第一个命令 格式： FROM FROM : FROM @示例： FROM mysql:5.6注： tag或digest是可选的，如果不使用这两个值时，会使用latest版本的基础镜像 MAINTAINER: 维护者信息 格式： MAINTAINER 示例： MAINTAINER Jack MAINTAINER &#x6a;&#x61;&#x63;&#x6b;&#64;&#x31;&#x36;&#x33;&#x2e;&#99;&#111;&#x6d; MAINTAINER Jack &#106;&#97;&#99;&#x6b;&#x40;&#x31;&#54;&#51;&#x2e;&#x63;&#111;&#109; RUN：构建镜像时执行的命令，一个文件中可以包含多个RUN命令 RUN用于在镜像容器中执行命令，有以下两种命令执行方式：shell执行，即/bin/sh格式： RUN exec执行格式： RUN [“executable”, “param1”, “param2”] 要注意的是，executable是命令，后面的param是参数示例： RUN yum install -y nginx RUN [“yum”, “install”, “-y”, “nginx”]注： RUN指令创建的中间镜像会被缓存，并会在下次构建中使用。如果不想使用这些缓存镜像，可以在构建时指定–no-cache参数，如：docker build –no-cache 由于RUN命令会生成一个镜像层，所以RUN并不是越多越好，需要合理使用，如果一个RUN中执行多个命令，可以使用 &amp;&amp; 连接，如果命令过长，可以使用 \\ 换行，例如 RUN apt-get update &amp;&amp; apt-get install -y \\ bzr \\ cvs \\ git \\ mercurial \\ subversion 并且这样写还有个优点，apt-get update 和 apt-get install 被放在一个 RUN 指令中执行，这样能够保证每次安装的是最新的包。如果 apt-get install 在单独的 RUN 中执行，则会使用 apt-get update 创建的镜像层，而这一层可能是很久以前缓存的 ADD：将本地文件添加到容器中，tar类型文件会自动解压(网络压缩资源不会被解压)，可以访问网络资源，类似wget 如果目的位置不存在，Docker会自动创建所需要的目录结 格式： ADD … ADD [““,… ““] 用于支持包含空格的路径示例： ADD hom* /mydir/ # 添加所有以”hom”开头的文件 ADD hom?.txt /mydir/ # ? 替代一个单字符,例如：”home.txt” ADD test relativeDir/ # 添加 “test” 到 WORKDIR/relativeDir/ ADD test /absoluteDir/ # 添加 “test” 到 /absoluteDir/ 注意： 需要复制的本地文件一定要放在Dockerfile文件的同级目录下 原因： 因为构建环境将会先上传到Docker守护进程，而复制是在Docker守护进程中进行的。任何位于构建环境之外的东西都是不可用的。ADD指令的目的的位置则必须是容器内部的一个绝对路径。 COPY：功能类似ADD，但是是不会自动解压文件，也不能访问网络资源 就是不能解压，其他限制条件跟ADD一样 WORKDIR：指定工作目录，类似于cd命令，之后的命令都是基于此工作目录 格式： WORKDIR /path/to/workdir示例： WORKDIR /a (这时工作目录为/a) WORKDIR b (这时工作目录为/a/b) WORKDIR c (这时工作目录为/a/b/c)注： 通过WORKDIR设置工作目录后，Dockerfile中其后的命令RUN、CMD、ENTRYPOINT、ADD、COPY等命令都会在该目录下执行。在使用docker run运行容器时，可以通过-w参数覆盖构建时所设置的工作目录。 LABEL：用于为镜像添加元数据 格式： LABEL = = = …示例： LABEL version=”1.0” description=”这是一测试工程”注： 使用LABEL指定元数据时，一条LABEL指定可以指定一或多条元数据，指定多条元数据时不同元数据之间通过空格分隔。推荐将所有的元数据通过一条LABEL指令指定，以免生成过多的中间镜像。 ENV：设置环境变量 格式： ENV #之后的所有内容均会被视为其的组成部分，因此，一次只能设置一个变量 ENV = … #可以设置多个变量，每个变量为一个”=“的键值对，如果中包含空格，可以使用\\来进行转义，也可以通过””来进行标示；另外，反斜线也可以用于续行示例： ENV myName John Doe ENV myDog Rex The Dog ENV myCat=fluffy EXPOSE：指定暴露镜像的端口供主机做映射 格式： EXPOSE […]示例： EXPOSE 80 443 EXPOSE 8080 EXPOSE 11211/tcp 11211/udp注： EXPOSE并不会让容器的端口访问到主机。要使其可访问，需要在docker run运行容器时通过-p来发布这些端口，或通过-P参数来发布EXPOSE导出的所有端口 VOLUME：添加卷，用于指定持久化目录 格式： VOLUME [“/path/to/dir”]示例： VOLUME [“/data”] VOLUME [“/var/www”, “/var/log/apache2”, “/etc/apache2”]注： 一个卷可以存在于一个或多个容器的指定目录，该目录可以绕过联合文件系统，并具有以下功能：1 卷可以容器间共享和重用2 容器并不一定要和其它容器共享卷3 修改卷后会立即生效4 对卷的修改不会对镜像产生影响5 卷会一直存在，直到没有任何容器在使用它 USER:指定运行容器时的用户名或 UID，后续的操作都会使用指定用户。使用USER指定用户时，可以使用用户名、UID或GID，或是两者的组合。当服务不需要管理员权限时，可以通过该命令指定运行用户。并且可以在之前创建所需要的用户 格式: USER user USER user:group USER uid USER uid:gid USER user:gid USER uid:group 示例： USER www 注： 使用USER指定用户后，Dockerfile中其后的命令RUN、CMD、ENTRYPOINT都将使用该用户。镜像构建完成后，通过docker run运行容器时，可以通过-u参数来覆盖所指定的用户。 ARG：用于指定传递给构建运行时的变量 格式： ARG [=]示例： ARG site ARG build_user=www ONBUILD：用于设置镜像触发器 格式： ONBUILD [INSTRUCTION]示例： ONBUILD ADD . /app/src ONBUILD RUN /usr/local/bin/python-build –dir /app/src注： 当所构建的镜像被用做其它镜像的基础镜像时（比如用户的镜像需要从某为准备好的位置添加源代码，或者用户需要执行特定于构建镜像的环境的构建脚本），该镜像中的触发器将会被钥触发 例如创建镜像image-A FROM ubuntu … ONBUILD ADD . /var/www … 然后创建镜像image-B，指定image-A为基础镜像，如 FROM image-A … 然后在构建image-B的时候，日志上显示如下: Step 0 : FROM image-A Execting 1 build triggers Step onbuild-0 : ADD . /var/www … CMD：构建容器后调用，也就是在容器启动时才进行调用，存在多个CMD时只有最后一个生效，也支持exec语法。 格式： CMD [“executable”,”param1”,”param2”] (执行可执行文件，优先) CMD [“param1”,”param2”] (设置了ENTRYPOINT，则直接调用ENTRYPOINT添加参数) CMD command param1 param2 (执行shell内部命令)示例： CMD echo “This is a test.” | wc - CMD [“/usr/bin/wc”,”–help”]注： CMD不同于RUN，CMD用于指定在容器启动时所要执行的命令，而RUN用于指定镜像构建时所要执行的命令。 ENTRYPOINT：配置容器，使其可执行化。配合CMD可省去”application”，只使用参数。 格式： ENTRYPOINT [“executable”, “param1”, “param2”] (可执行文件, 优先) ENTRYPOINT command param1 param2 (shell内部命令)示例： FROM ubuntu ENTRYPOINT [“top”, “-b”] CMD [“-c”]注： ENTRYPOINT与CMD非常类似，不同的是通过docker run执行的命令不会覆盖ENTRYPOINT，而docker run命令中指定的任何参数，都会被当做参数再次传递给ENTRYPOINT。Dockerfile中只允许有一个ENTRYPOINT命令，多指定时会覆盖前面的设置，而只执行最后的ENTRYPOINT指令。 注意！！！！ CMD和ENTRYPOINT的区别 CMD和ENTRYPOINT同样作为容器启动时执行的命令，区别有以下几点： CMD的命令会被 docker run 的命令覆盖而ENTRYPOINT不会 如使用CMD [&quot;/bin/bash&quot;]或ENTRYPOINT [&quot;/bin/bash&quot;]后，再使用docker run -ti image启动容器，它会自动进入容器内部的交互终端，如同使用docker run -ti image /bin/bash。 但是如果启动镜像的命令为docker run -ti image /bin/ps，使用CMD后面的命令就会被覆盖转而执行bin/ps命令，而ENTRYPOINT的则不会，而是会把docker run 后面的命令当做ENTRYPOINT执行命令的参数。 放个例子 Dockerfile中为ENTRYPOINT [“/user/sbin/nginx”] 然后通过启动build之后的容器docker run -ti image -g “daemon off” 此时-g “daemon off”会被当成参数传递给ENTRYPOINT，最终的命令变成了/user/sbin/nginx -g “daemon off” 如果Dockerfile中定义的是CMD，则会被覆盖 CMD和ENTRYPOINT都存在时，CMD的指令就变成了ENTRYPOINT的参数，并且此CMD提供的参数也会被 docker run 后面的命令覆盖 Dockerfile中指令..ENTRYPOINT [“echo”,”hello”,”i am”]CMD [“docker”] 之后启动构建之后的容器 使用docker run -ti image输出“hello i am docker” 使用docker run -ti image world输出“hello i am world” 最后说一下docker build命令，Dockerfile写完后要生产镜像，就需要docker build docker build 命令用于使用 Dockerfile 创建镜像，语法 docker build [OPTIONS] PATH | URL |-参数说明： –build-arg=[] :设置镜像创建时的变量； –cpu-shares :设置 cpu 使用权重； –cpu-period :限制 CPU CFS周期； –cpu-quota :限制 CPU CFS配额； –cpuset-cpus :指定使用的CPU id； –cpuset-mems :指定使用的内存 id； –disable-content-trust :忽略校验，默认开启； -f :指定要使用的Dockerfile路径； –force-rm :设置镜像过程中删除中间容器； –isolation :使用容器隔离技术； –label=[] :设置镜像使用的元数据； -m :设置内存最大值； –memory-swap :设置Swap的最大值为内存+swap，”-1”表示不限swap； –no-cache :创建镜像的过程不使用缓存； –pull :尝试去更新镜像的新版本； –quiet, -q :安静模式，成功后只输出镜像 ID； –rm :设置镜像成功后删除中间容器； –shm-size :设置/dev/shm的大小，默认值是64M； –ulimit :Ulimit配置。 –tag, -t: 镜像的名字及标签，通常 name:tag 或者 name 格式；可以在一次构建中为一个镜像设置多个标签。 –network: 默认 default。在构建期间设置RUN指令的网络模式 示例 使用当前目录的 Dockerfile 创建镜像，标签为 runoob/ubuntu:v1。docker build -t runoob/ubuntu:v1 . 使用URL github.com/creack/docker-firefox 的 Dockerfile 创建镜像。docker build github.com/creack/docker-firefox 也可以通过 -f Dockerfile 文件的位置：$ docker build -f /path/to/a/Dockerfile . 在 Docker 守护进程执行 Dockerfile 中的指令前，首先会对 Dockerfile 进行语法检查，有语法错误时会返回：$ docker build -t test/myapp .Sending build context to Docker daemon 2.048 kBError response from daemon: Unknown instruction: RUNCMD","categories":[],"tags":[],"author":"张存"},{"title":"你只是他们其中的一个","slug":"你是他们其中的一个","date":"2021-11-05T07:20:39.000Z","updated":"2021-11-05T07:41:38.002Z","comments":true,"path":"2021/11/05/ni-shi-ta-men-qi-zhong-de-yi-ge/","link":"","permalink":"https://blog.zhangcun.store/2021/11/05/ni-shi-ta-men-qi-zhong-de-yi-ge/","excerpt":"","text":"条件太好的男生和漂亮的女生 很多都是没有空窗期的 听明白了吗 有多少人和想和他们谈恋爱 他们谈过多少 你只是他们其中的一个 你在那自作多情什么呢","categories":[],"tags":[],"author":"张存"},{"title":"redis设置密码","slug":"redis设置密码","date":"2021-11-04T03:29:45.000Z","updated":"2021-11-04T03:31:00.997Z","comments":true,"path":"2021/11/04/redis-she-zhi-mi-ma/","link":"","permalink":"https://blog.zhangcun.store/2021/11/04/redis-she-zhi-mi-ma/","excerpt":"","text":"redis安装过程 $ wget http://download.redis.io/releases/redis-5.0.3.tar.gz$ tar xzf redis-5.0.3.tar.gz$ cd redis-5.0.3$ make 启动服务 $ src/redis-server # 启动redis服务，使用的是默认配置，无密码$ src/redis-cli # 用client端链接本地redis服务redis&gt; set foo barOKredis&gt; get foo“bar” 设置密码等 vim redis.conf/requirepass # 找到设置密码的字段requirepass 123456 # 密码设置为 123456daemonize yes # 设置后台运行port 6379bind 192.168.1.100 10.0.0.1 # 绑定外网可以访问的本机「网卡」地址，可以绑定多个ip，只要本机有这个网卡的iplogfile “/export/logs/redis.log” # 设置日志的存放位置pidfile /var/run/redis_6379.pid # 设置pid文件的存放位置databases 16 # 设置数据库的个数，默认是16个（从0到15） 登录和使用 src/redis-server /export/redis-5.0.3/redis.conf # 启动指定配置文件的redis服务[root@JXQ-97-7-98 redis-5.0.3]# src/redis-server /export/redis-5.0.3/redis.conf520:C 24 Jan 2019 21:40:22.943 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo520:C 24 Jan 2019 21:40:22.943 # Redis version=5.0.3, bits=64, commit=00000000, modified=0, pid=520, just started520:C 24 Jan 2019 21:40:22.943 # Configuration loaded[root@JXQ-97-7-98 redis-5.0.3]#[root@JXQ-97-7-77 redis-3.2.1]# src/redis-cli -h ‘100.97.7.98’ -p ‘6379’ -a ‘123456’ # 客户端连接服务100.97.7.98:6379&gt; set f 3OK100.97.7.98:6379&gt; get f“3” 这里要说一下为什么要设置密码？因为只有本地访问redis是无法满足我们的需求的，我们需要远程访问，这个时候就需要设置密码了，我们需要认证，不是谁都可以访问的。 还有一个问题就是bind，默认是绑的本机网卡ip 127.0.0.1，但这个只能本机访问，所以我们要绑定到本机的网卡上，这样远程就可以根据ip来访问了，注意，服务器有可能会有多块网卡，绑哪个要根据网络情况来定，可以绑定多个ip，如下： ifconfigeth0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 inet 100.97.7.98 netmask 255.255.252.0 broadcast 100.97.7.255 inet6 fe80::f200:64ff:feb1:7c6 prefixlen 64 scopeid 0x20 ether f0:00:64:61:07:c6 txqueuelen 1000 (Ethernet) RX packets 928533 bytes 193136262 (184.1 MiB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 789011 bytes 110711946 (105.5 MiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 lo: flags=73&lt;UP,LOOPBACK,RUNNING&gt; mtu 65536 inet 127.0.0.1 netmask 255.0.0.0 inet6 ::1 prefixlen 128 scopeid 0x10 loop txqueuelen 1 (Local Loopback) RX packets 22553 bytes 922439 (900.8 KiB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 22553 bytes 922439 (900.8 KiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 可以看到，本机有两个ip，分别是 100.97.7.98 和127.0.0.1，所以 redis.conf 中的可以设置为 bind 100.97.7.98 127.0.0.1，也可以设置1个，但是不能设置本机网卡中不存在的ip，那样会无法启动redis服务的","categories":[],"tags":[],"author":"张存"},{"title":"Nginx负载均衡中4层代理和7层代理对比","slug":"Nginx负载均衡中4层代理和7层代理对比","date":"2021-11-04T03:27:11.000Z","updated":"2021-11-04T03:27:31.537Z","comments":true,"path":"2021/11/04/nginx-fu-zai-jun-heng-zhong-4-ceng-dai-li-he-7-ceng-dai-li-dui-bi/","link":"","permalink":"https://blog.zhangcun.store/2021/11/04/nginx-fu-zai-jun-heng-zhong-4-ceng-dai-li-he-7-ceng-dai-li-dui-bi/","excerpt":"","text":"1.4层代理和7层代理什么意思？ 这里的层是OSI 7层网络模型，OSI 模型是从上往下的，越底层越接近硬件，越往上越接近软件，这七层模型分别是物理层、数据链路层、网络层、传输层、会话层、表示层、应用层。 4层是指传输层的 tcp / udp 。 7层是指应用层，通常是http 。 2.代理原理： 4层用的是NAT技术。NAT英文全称是“Network Address Translation”，中文意思是“网络地址转换”，请求进来的时候，nginx修改数据包里面的目标和源IP和端口，然后把数据包发向目标服务器，服务器处理完成后，nginx再做一次修改，返回给请求的客户端。 7层代理：需要读取并解析http请求内容，然后根据具体内容(url,参数，cookie,请求头)然后转发到相应的服务器，转发的过程是：建立和目标机器的连接，然后转发请求，收到响应数据在转发给请求客户端。 3.优缺点对比： 性能： 理论上4层要比7层快，因为7层代理需要解析数据包的具体内容，需要消耗额外的cpu。但nginx具体强大的网络并发处理能力， 对于一些慢连接，nginx可以先将网络请求数据缓冲完了一次性转发给上游server,这样对于上游网络并发处理能力弱的服务器(比如tomcat)，这样对tomcat来说就是慢连接变成快连接(nginx到tomcat基本上都是可靠内网),从而节省网络数据缓冲时间，提供并发性能。 灵活性： 由于4层代理用的是NAT，所以nginx不知道请求的具体内容，所以nginx啥也干不了。 用7层代理，可以根据请求内容(url,参数，cookie,请求头)做很多事情，比如： a:动态代理：不同的url转发到不同服务器。 b.风控：屏蔽外网IP请求某些敏感url；根据参数屏蔽某些刷单用户。 c.审计：在nginx层记录请求日志。 …. 4.结论： 由于现在机器cpu性能都很好，4层代理并没有明显的性能优势，而7层代理在业务层面优势明显，所以一般直接选择7层代理就OK了。","categories":[],"tags":[],"author":"张存"},{"title":"nginx四层、七层负载均衡配置示例","slug":"nginx四层、七层负载均衡配置示例","date":"2021-11-04T03:21:04.000Z","updated":"2021-11-04T03:24:43.475Z","comments":true,"path":"2021/11/04/nginx-si-ceng-qi-ceng-fu-zai-jun-heng-pei-zhi-shi-li/","link":"","permalink":"https://blog.zhangcun.store/2021/11/04/nginx-si-ceng-qi-ceng-fu-zai-jun-heng-pei-zhi-shi-li/","excerpt":"","text":"所谓四层就是基于IP+端口的负载均衡，通过虚拟IP+端口接收请求，然后再分配到真实的服务器；七层通过虚拟的URL或主机名接收请求，然后再分配到真实的服务器七层就是基于URL等应用层信息的负载均衡。 七层负载#定义 upstream phpserver &#123; server192.168.2.3; server192.168.2.4; &#125; upstream htmlserver &#123; server192.168.2.1; server192.168.2.2; &#125; #引用 location / &#123; root /usr/share/nginx/html; index index.html index.htm; if ($request_uri ~*\\.html$)&#123; proxy_pass http://htmlserver; &#125; if ($request_uri~* \\.php$)&#123; proxy_pass http://phpserver; &#125; }四层负载 stream &#123; log_format proxy &#39;$remote_addr $remote_port - [$time_local] $status $protocol &#39; &#39;&quot;$upstream_addr&quot; &quot;$upstream_bytes_sent&quot; &quot;$upstream_connect_time&quot;&#39; ; access_log /var/log/nginx/proxy.log proxy; upstream lb &#123; server 172.16.1.5:80 weight=5 max_fails=3 fail_timeout=30s; server 172.16.1.6:80 weight=5 max_fails=3 fail_timeout=30s; &#125; server &#123; listen 80; proxy_connect_timeout 3s; proxy_timeout 3s; proxy_pass lb; &#125; &#125;","categories":[],"tags":[],"author":"张存"},{"title":"Ubuntu20.04开机运行自定义脚本","slug":"Ubuntu20-04开机运行自定义脚本","date":"2021-11-04T03:08:10.000Z","updated":"2021-11-04T03:11:13.839Z","comments":true,"path":"2021/11/04/ubuntu20-04-kai-ji-yun-xing-zi-ding-yi-jiao-ben/","link":"","permalink":"https://blog.zhangcun.store/2021/11/04/ubuntu20-04-kai-ji-yun-xing-zi-ding-yi-jiao-ben/","excerpt":"","text":"1.简介基于 Debian 的 Linux 系统默认支持 rc-local.service 服务，这个服务主要用来在系统启动时运行用户自定义的脚本命令等。 2.配置要想使用 rc-local.service 服务在系统启动时运行用户自定义的脚本命令，首先需要在 /etc 目录下创建 rc.local 文件（若已创建则跳过创建）并修改可执行权限，然后设置该服务开机自启： sudo touch /etc/rc.localsudo chmod 755 /etc/rc.localsudo systemctl start rc-local.servicesudo systemctl enable rc-local.service3.添加开机自启脚本打开 /etc/rc.local 文件，往其中添加运行自定义脚本的命令即可。添加下列内容： #!/bin/sh echo &quot;看到这行字，说明添加自启动脚本成功。&quot; &gt; /usr/local/test.log #中间这一段就是脚本的内容，例如：sudo ssr start exit 0 【注】/etc/rc.local 以及自定义脚本中都不能使用系统变量（比如 $HOME，原因在于其执行自定义脚本时并没有继承系统变量）。 4.查看脚本执行结果 systemctl status rc-local.service","categories":[],"tags":[],"author":"张存"},{"title":"从ifconfig输出中提取MAC地址","slug":"从ifconfig输出中提取MAC地址","date":"2021-11-03T08:55:23.000Z","updated":"2021-11-03T08:56:27.855Z","comments":true,"path":"2021/11/03/cong-ifconfig-shu-chu-zhong-ti-qu-mac-di-zhi/","link":"","permalink":"https://blog.zhangcun.store/2021/11/03/cong-ifconfig-shu-chu-zhong-ti-qu-mac-di-zhi/","excerpt":"","text":"环境 Ubuntu 20.04 ifconfig eth0 | grep -o -E ‘([[:xdigit:]]{1,2}:){5}[[:xdigit:]]{1,2}’ -o将导致grep只打印与表达式匹配的行部分。[[:xdigit:]]{1,2}将匹配1或2个十六进制数字(Solaris不输出前导零)。","categories":[],"tags":[],"author":"张存"},{"title":"linux命令行显示主机名和当前目录","slug":"linux命令行显示主机名和当前目录","date":"2021-11-03T07:11:15.000Z","updated":"2021-11-03T07:12:46.822Z","comments":true,"path":"2021/11/03/linux-ming-ling-xing-xian-shi-zhu-ji-ming-he-dang-qian-mu-lu/","link":"","permalink":"https://blog.zhangcun.store/2021/11/03/linux-ming-ling-xing-xian-shi-zhu-ji-ming-he-dang-qian-mu-lu/","excerpt":"","text":"在开发中linux server中，如果登录后命令行一直显示（在已经有权限登录的情况下）：bash-3.2$ 如何让其显示主机名和文件路径（并根据不同的颜色显示）： [cvadev@swcvaap3d:/home/cvadev] 我这里server登录方式为：pbrun cvadev。 所以默认路径为/home/cvadev查看改路径下的隐藏文件: ls -a 如果存在.bashrc文件，则直接进行修改，如果不存在就新建改文件。然后添加如下内容： alias ll=&#39;ls -l&#39; alias ls=&#39;ls&#39; alias tl=&#39;tail -500&#39; alias tff=&#39;tail -600f&#39; PS1=`echo &#39;[\\033[1;35m$LOGNAME\\033[0m&#39;&quot;@&quot;&#39;\\033[0;31m$HOSTNAME\\033[0m&#39;&#39;\\033[0;32m:$PWD\\033[0m]&#39;``echo &quot;\\n&gt; &quot;` set -o vi 前面四行为命令的别名，可以根据自己情况设置，也可以不用。后面两行即为修改linux命令行提示信息，颜色可以根据自己的喜好进行修改设置","categories":[],"tags":[],"author":"张存"},{"title":"linux安装库时报错error: command ‘x86_64-linux-gnu-gcc‘ failed with exit status 1","slug":"linux安装库时报错error-command-‘x86-64-linux-gnu-gcc‘-failed-with-exit-status-1","date":"2021-11-03T02:52:15.000Z","updated":"2021-11-03T02:53:36.181Z","comments":true,"path":"2021/11/03/linux-an-zhuang-ku-shi-bao-cuo-error-command-x86-64-linux-gnu-gcc-failed-with-exit-status-1/","link":"","permalink":"https://blog.zhangcun.store/2021/11/03/linux-an-zhuang-ku-shi-bao-cuo-error-command-x86-64-linux-gnu-gcc-failed-with-exit-status-1/","excerpt":"","text":"在Ubuntu18.04上安装nameko时报错： error: command ‘x86_64-linux-gnu-gcc’ failed with exit status 1 解决办法： 安装依赖库 python2： sudo apt-get install build-essential python-dev libssl-dev libffi-dev libxml2 libxml2-dev libxslt1-dev zlib1g-dev python3： sudo apt-get install build-essential python3-dev libssl-dev libffi-dev libxml2 libxml2-dev libxslt1-dev zlib1g-dev 安装nameko时推荐使用python3，使用python2可能会有导包错误： 在使用nameko命令启动时报错：no module named zipp 解决办法： pip install zipp==1.2.0 安装nameko成功后所有安装库，不然可能会有no module named xxx之类的导入错误：","categories":[],"tags":[],"author":"张存"},{"title":"etcd 下载链接","slug":"etcd-下载链接","date":"2021-11-03T02:47:40.000Z","updated":"2021-11-03T02:47:41.425Z","comments":true,"path":"2021/11/03/etcd-xia-zai-lian-jie/","link":"","permalink":"https://blog.zhangcun.store/2021/11/03/etcd-xia-zai-lian-jie/","excerpt":"","text":"https://mirrors.huaweicloud.com/etcd/v3.3.20/","categories":[],"tags":[],"author":"张存"},{"title":"[tcp] WEB服务,Linux下的内核参数调优","slug":"[tcp] WEB服务,Linux下的内核参数调优","date":"2021-11-03T02:41:52.000Z","updated":"2021-11-03T02:45:23.989Z","comments":true,"path":"2021/11/03/tcp-web-fu-wu-linux-xia-de-nei-he-can-shu-diao-you/","link":"","permalink":"https://blog.zhangcun.store/2021/11/03/tcp-web-fu-wu-linux-xia-de-nei-he-can-shu-diao-you/","excerpt":"","text":"前言:web类应用一般会部署像nginx、tomcat、php等应用程序，使用默认的内核参数设置满足大部分场景，如果优化内核参数，也可以释放不少服务器性能，尤其是在高并发下 一.SYN状态的内核参数调优大量SYN_SENT这种是主动连接服务端，而未得到响应，也就是SYN超时，一般是服务端根本不存在或者无法访问如，我随便telnet一个位置的IP和端口 telnet 172.18.11.110:90[root@test bbs]# ss -an|grep SYNSYN-SENT 0 1 172.16.196.145:55052 172.18.11.110:90除了以上，还有种就是你的服务出现异常，比如mysql服务器宕机了，web服务去访问mysql数据库的时候就连不上，也会出现SYN_SENT状态，但无论哪种，都是主动发起连接导致的，因此业务上解决更好 net.ipv4.tcp_syn_retries = 2新建连接如果无响应，内核要发送多少次SYN连接才放弃，默认值为5 在Linux下，默认重试次数为5次，该值不能大于255，重试的间隔时间从1s开始每次都翻倍(因为隔一秒重试后还会等待响应，因此实际上是从3秒开始)，5次的重试时间间隔为3s, 7s, 15s, 31s, 63s，总共63s，TCP才会把断开这个连接。统计成公式2^(n+1) - 1，因此设置越大，翻倍越多，对应内网环境，这个值修改为2比较合适 大量SYN_RECV大量的SYN出现有两种情况，可能是攻击，也可能是正常的业务请求，无论哪种，都大量的占用了服务器资源 net.ipv4.tcp_synack_retries = 2跟参数net.ipv4.tcp_syn_retries一样，只是这个内核参数是控制回应SYN失败的重试次数，默认值也是5，和上面一样修改为2 其他内核参数调整net.ipv4.tcp_syncookies = 1开启SYN cookies，当出现SYN等待队列溢出时，启动cookies来处理 什么是SYN cookies?我们知道SYN攻击是一系列伪造IP源地址的SYN包，IP地址是随意选择且不提供攻击者任何的线索，SYN攻击持续直到服务的SYN队列被用满。如果启用该参数，此时SYN cookies会将TCP请求的SYN缓存起来，当服务器正常的时候，再处理，但是如果攻击并发很高很大，其实用处不大，因此只能少量防范 net.ipv4.tcp_max_syn_backlog = 65535指定所能接受SYN同步包的最大客户端数量，即半连接上限，默认值为128，对于web服务，频繁大量的SYN同步包，应该放大这个值 注:这个值应该&gt;=net.core.somaxconn，net.core.somaxconn后面会提到 二.FIN_WAIT_2状态的内核参数调优FIN_WAIT_2是主动关闭端等待对端关闭连接的状态，如果被动关闭不发送FIN关闭连接，那么这个状态就会一直存在，当然Linux有针对该状态的超时时间，默认为60秒 net.ipv4.tcp_fin_timeout = 10 三.TIME_WAIT状态的内核参数调优TIME_WAIT是主动关闭端的状态，也称为2MSL等待状态，也就是2倍的MSL时间。在RFC 793[Postel 1981c]指出MSL为2分钟，然而现实中的常用值是30秒，1分钟或者2分钟(Linux设置为30秒)，Linux也没有提供能够修改TIME_WAIT状态时间的接口，除非重新编译系统内核 MSL的理解MSL是英文Maximum Segment Lifetime的缩写，翻译为”最长报文段寿命”，每个具体TCP实现必须选择一个报文段最大生存时间(Maximum Segment Lifetime)，而这个最大生存时间是任何报文段被丢弃前在网络内的最长时间 MSL的时间是有限的，因为TCP报文段以IP数据报在网络内传输，而IP数据报则有限制其生存时间的TTL(time to live)字段，TTL可译为生存时间，IP数据报每经过一个路由器，它的值就减1，当这个值为0时，数据报则被丢弃 为什么等待2MSL1.确保有足够的时间让服务端收到ACK，如没有收到，则会响应对方新的FIN+ACK封包。比如主动关闭端(客户端)发送了最后一个ACK报文段给被动关闭端(服务端)，但这个ACK报文段有可能丢失，如果服务端没有收到这个ACK，那么处于LAST_ACK的服务端在超时后回重发FIN+ACK报文段，这样客户端就能在2MSL时间内收到这个重发的FIN+ACK报文段。如果客户端发送了最后的ACK报文不进入TIME_WAIT而是立即释放连接，那么就无法收到客户端重发的FIN+ACK报文段。因此等待2MSL是为了更安全的断开连接 2.有足够的时间让处于TIME_WAIT状态的连接不会跟后面的连接混在一起。比如一些延迟的包发过来，但是如果没有TIME_WAIT，那么就发到了新连接上，这样就混为一团，而如果是TIME_WAIT，则会丢弃这些延迟的包 等待2MSL的缺点TCP连接在2MSL等待期间，这个处于TIME_WAIT状态的连接(客户端的IP地址和端口编号，服务器的IP地址和端口号)不能再被使用，它只能在2MSL结束后才能再被使用，而这些TIME_WAIT状态占用大量服务资源，对于web服务来说是不合理的 修改内核参数防止因为2MSL导致TIME_WAIT过多对于web服务器，由于我们需要经常去连接mysql、redis或者一些RPC调用等，会有大量的主动关闭状态(TIME_WAIT)，因此可以修改内核参数限制TIME_WAIT的数量 net.ipv4.tcp_max_tw_buckets = 20000限制timewait 的数量，防止大量timewait导致系统负载升高，一旦达到限定值，则强制清理TIME_WAIT状态的连接并在打印系统日志(time wait bucket table overflow)，该参数官方文档说明主要用来对抗DDos攻击 net.ipv4.tcp_tw_recycle= 1启用timewait快速回收 net.ipv4.tcp_timestamps = 0时间戳，0关闭，1开启。不能和net.ipv4.tcp_tw_recycle参数同时开启，因为一旦开启net.ipv4.tcp_tw_recycle，服务器就会检查包的时间戳，如果对方发来的包的时间戳是乱跳或者说时间戳是滞后的，这样服务器就不会回复，服务器会把带了”倒退”的时间戳包当作是”recycle”的tw连接的重传数据，不是新的请求，于是丢掉不回包，就容易出现syn不响应 net.ipv4.tcp_tw_reuse = 1开启重用，允许将TIME-WAIT sockets 重新用于新的TCP 连接 TIME_WAIT总结其实TIME_WAIT是主动断开连接，所以如果让对方主动断开连接的话，那么这个TIME_WAIT问题就对方的了。所以如果这个问题出现过多，多从业务着手，比如HTTP服务，NGINX设置keepalive参数(浏览器会重用一个TCP连接来处理多个HTTP请求)，然后让客户端断开连接，当然这个要设置好keepalive_timeout的超时时间，因为有些浏览器可能不会主动断开连接 而如果是主动连接mysql、redis等后端调用，可以考虑使用长连接来避免TIME_WAIT过多的问题 四.长连接(keepalive)的内核参数调整Linux下，keepalive不是默认开启，也无内核参数控制，它需要在TCP的socket中单独开启，Linux内核影响keepalive的参数目的仅仅是探测TCP连接是否存活，然后处理异常连接 net.ipv4.tcp_keepalive_time = 120 单位秒，表示TCP连接在多少秒没有数据报文传输时启动探测报文，探测连接是否正常net.ipv4.tcp_keepalive_intvl = 5 单位秒，前后探测报文之间的时间间隔net.ipv4.tcp_keepalive_probes = 3 探测次数，超过设置后丢弃 五.TCP/UDP内存参数调整(1)TCP内存使用设置针对TCP socket buffernet.ipv4.tcp_mem = 94500000 915000000 927000000指定TCP内存的整体使用状况，单位为页。这3个值为TCP整体内存【低、压力、高】，在web服务中，放大这个值即可第一个值tcp_mem[0]：当TCP全局分配的页数低于此数时，TCP不调整其内存分配第二个值tcp_mem[1]：当TCP分配的内存量超过这个页数，进入内存压力模式，TCP调节内存消耗第三个值tcp_mem[2]：TCP全局使用的最大页数分配，这个会值覆盖任何其他限制，如超过，所有的新的TCP的buffer(缓冲区)内存分配都会失败 其实我们可以设置这个值较大，只要不限制系统分配内存，然后以监控来应对内存问题，一般来说，根据业务所选配置，很难将内存耗尽，否则优化的就不仅仅是这个参数了 net.ipv4.tcp_rmem = 4096 87380 6291456net.ipv4.tcp_wmem = 4096 16384 4194304上面两组参数表示单个TCP连接上的读写buffer(缓冲)内存上限，单位字节，这三个值分别为最小值、默认值(会覆盖rmem_default、wmem_default配置)、最大值 最小值:TCP socket的发送缓冲区(tcp_rmem)/接收缓冲区(tcp_wmem)的内存，默认1页(4K) 默认值:TCP socket使用的发送缓冲区(tcp_rmem)/接收缓冲区(tcp_wmem)初始大小，这个值会覆盖(net.core.wmem_default/net.core.rmem_default)，一般设置要低于(net.core.wmem_default/net.core.rmem_default)这个值，默认值为16K 最大值:TCP socket使用的发送缓冲区(tcp_rmem)/接收缓冲区(tcp_wmem)的最大大小，这个值不会覆盖(net.core.wmem_max/net.core.rmem_max)，默认为4M 这两个内核参数的设置主要是针对每一个TCP连接来说的，使用默认设置就差不多了，如果设置太大，单个TCP连接占用过多内存也是有问题的 什么是TCP读写buffer(缓冲)？实际上，TCP连接所用内存的多少是由读写buffer大小决定，对读buffer来讲，当收到对端连接的TCP报文时，会导致读buffer内存增加，如果这个报文加上当前读buffer内存超过tcp_rmem[3]上限，那么该报文将被丢弃。只有当调用read、recv这样的方法读取TCP流时，读buffer内存就会减少，因此读buffer内存是一个动态变化的，用多少就分配多少buffer，如果这个连接空闲时，而用户进程已经把连接上收到的数据都消费了，那么读buffer使用的内存就为0了 对于写buffer也是一样的，在socket编程中，当调用send或者write时，就会造成写buffer增大，那么什么时候减少？就是当接收到对端TCP连接发来的ACK确认了报文成功发送时，写buffer就会减少，类似于我给你发一个文件，我先拷贝出来发给你，我确认你收到了，我就把这个源文件删除，以免占用空间，如果确认没收到，那么我会重发 所以读写buffer是一直不停变化的，那么怎样的场景会导致读写buffer达到上限呢？就读buffer而言，比如接收TCP对端报文，对端发了很多很多报文，我读取后无法及时读取(read和recv)，导致读buffer堆积越来越多，最终达到上限，最后丢弃报文，写buffer也一样，send或者write大量的报文时，如果TCP对端不能及时read和recv就会导致写buffer堆积。 针对系统的读写buffer参数调整net.core.rmem_default = 4194304 默认读buffer大小，单位字节net.core.wmem_default = 4194304 默认写buffer大小，单位字节net.core.rmem_max = 4194304 最大读buffer大小，单位字节net.core.wmem_max = 4194304 最大写buffer大小，单位字节看到其定义，是不是觉得跟net.ipv4.tcp_mem、net.ipv4.tcp_rmem、net.ipv4.tcp_wmem含义很重合呢？ 其实(net.ipv4.tcp_mem、net.ipv4.tcp_rmem、net.ipv4.tcp_wmem)这几个参数只控制TCP socket的内存大小，而且如果遇到TCP socket申请内存，(net.core.rmem_default、net.core.wmem_default)会被(net.ipv4.tcp_rmem、net.ipv4.tcp_wmem)覆盖 所以(net.core.rmem_default、net.core.wmem_default、net.core.rmem_max、net.core.wmem_max)控制系统所有协议的读写buffer大小 (2)UDP协议内存使用设置net.ipv4.udp_mem = 752832 1003776 1505664net.ipv4.udp_rmem_min = 4096net.ipv4.udp_wmem_min = 4096这几个参数针对UDP协议，则跟上面TCP的含义一致 六.其他内核参数net.ipv4.ip_local_port_range = 1024 65000表示用于向外连接的临时端口范围。缺省情况下很小：32768到61000，因为主动连接需要用到很多临时端口(如连接mysql、redis)，而临时端口最大值为(2^16-1)65535，1000之前一般为系统保留端口，所以建议设置为1024到65000的较大范围 net.core.somaxconn = 65535net.core.somaxconn表示socket监听(listen)的backlog上限，backlog是socket的监听队列，也就是服务端所能accept(socket编程中accpet()函数为建立TCP连接接受连接状态)即处理数据的最大客户端数量队列，默认值为128，如果队列满了的时候新来一条建立连接，该连接会被拒绝 该值应当小于等于net.ipv4.tcp_max_syn_backlog，因为net.ipv4.tcp_max_syn_backlog参数控制的SYN队列客户端的数量，还在建立连接之前，因此设置为65535一样比较合适 fs.file-max = 6553600设置系统所有进程一共可以打开多少个文件句柄，这是一个系统级的设置，管控的是所有进程总共可以同时打开多少文件句柄，如果多个进程打开了较多文件就会导致文件句柄不足，因此设置较大值，不过要注意程序打开的文件越多，就占用更多的内存，因此要根据业务和服务器配置起来设置 如果想单独对某个进程设置可以打开多少文件句柄，那么可以使用ulimit -n命令设置，但该命令只对当前session生效，默认值为1024ulimit -n 655350 也可以写入文件永久生效，对每个进程的打开文件数量限制vim /etc/security/limits.conf soft nofile 655350 hard nofile 655350 总结现在多数线上业务，服务器很少暴露在外网了，前端一般有负载均衡、防火墙等代理。甚至服务器已经变成VPC(虚拟内网)环境，将这些服务器隔离在外网环境之外，这样就减少了像DDOS等攻击，这些攻击一般都让外部代理承受了。 对于服务器的一些内核性能参数范围，如果网络环境及架构设计好，一些范围参数可以设置的偏大，性能偏极限一些，这样能最大释放服务器的性能，其他的就用系统默认的参数配置即可。对于WEB服务的优化，是多方面的，内核参数仅仅是释放了服务器本该有的性能，而更高的承载能力，需要从服务器配置、网络、架构、数据库及缓存和实际业务应用等多方面着手，不同的调整满足不同的需求","categories":[],"tags":[],"author":"张存"},{"title":"如何进入docker 使用root用户的方式","slug":"如何进入docker-使用root用户的方式","date":"2021-11-03T02:34:06.000Z","updated":"2021-11-03T02:34:08.824Z","comments":true,"path":"2021/11/03/ru-he-jin-ru-docker-shi-yong-root-yong-hu-de-fang-shi/","link":"","permalink":"https://blog.zhangcun.store/2021/11/03/ru-he-jin-ru-docker-shi-yong-root-yong-hu-de-fang-shi/","excerpt":"","text":"docker exec -it –user root /bin/bash","categories":[],"tags":[],"author":"张存"},{"title":"dockerfile文件中给debian设置中文支持","slug":"dockerfile文件中给debian设置中文支持","date":"2021-11-03T02:30:23.000Z","updated":"2021-11-03T02:30:30.230Z","comments":true,"path":"2021/11/03/dockerfile-wen-jian-zhong-gei-debian-she-zhi-zhong-wen-zhi-chi/","link":"","permalink":"https://blog.zhangcun.store/2021/11/03/dockerfile-wen-jian-zhong-gei-debian-she-zhi-zhong-wen-zhi-chi/","excerpt":"","text":"#设置字体库RUN apt-get clean &amp;&amp; apt-get update RUN apt-get install -y locales RUN localedef -c -f UTF-8 -i zh_CN zh_CN.utf8 ENV LANG zh_CN.utf8","categories":[],"tags":[],"author":"张存"},{"title":"通过Dockerfile 文件为linux images 添加新用户","slug":"通过Dockerfile-文件为linux-images-添加新用户","date":"2021-11-02T09:49:41.000Z","updated":"2021-11-02T09:50:39.999Z","comments":true,"path":"2021/11/02/tong-guo-dockerfile-wen-jian-wei-linux-images-tian-jia-xin-yong-hu/","link":"","permalink":"https://blog.zhangcun.store/2021/11/02/tong-guo-dockerfile-wen-jian-wei-linux-images-tian-jia-xin-yong-hu/","excerpt":"","text":"要求：（１）增加一个新用户，名为mynewuser（２）让这个用户有root权限（３）设置其密码为mynewpassword（４）container启动后以mynewuser登录,并且直接到mynewuser的home目录下 将下面代码片段放到Dockerfile里面。 RUN useradd –create-home –no-log-init –shell /bin/bash mynewuserRUN adduser mynewuser sudoRUN echo ‘mynewuser:mynewpassword’ chpasswdUSER mynewuserWORKDIR /home/mynewuser","categories":[],"tags":[],"author":"张存"},{"title":"使用docker-compose搭建SkyWalking环境","slug":"使用docker-compose搭建SkyWalking环境","date":"2021-11-02T07:19:21.000Z","updated":"2021-11-02T07:39:04.207Z","comments":true,"path":"2021/11/02/shi-yong-docker-compose-da-jian-skywalking-huan-jing/","link":"","permalink":"https://blog.zhangcun.store/2021/11/02/shi-yong-docker-compose-da-jian-skywalking-huan-jing/","excerpt":"","text":"一、环境说明Linux Centos7ElasticSearch 7.13.1SkyWalking 8.0.1 二、环境搭建1.编写docker-compose.yml文件 version: &#39;3.3&#39; services: elasticsearch: #image: elasticsearch:7.8.0 image: elasticsearch:7.13.1 container_name: elasticsearch restart: always ports: - 9200:9200 environment: discovery.type: single-node TZ: Asia/Shanghai #volumes: # - ./elasticsearch/logs:/usr/share/elasticsearch/logs # - ./elasticsearch/data:/usr/share/elasticsearch/data # - ./elasticsearch/config/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml ulimits: memlock: soft: -1 hard: -1 oap: image: apache/skywalking-oap-server:8.0.1-es7 container_name: oap depends_on: - elasticsearch links: - elasticsearch restart: always ports: - 11800:11800 - 12800:12800 environment: SW_STORAGE: elasticsearch7 # 指定ES版本 SW_STORAGE_ES_CLUSTER_NODES: elasticsearch:9200 TZ: Asia/Shanghai # volumes: # - ./config/alarm-settings.yml:/skywalking/config/alarm-settings.yml ui: image: apache/skywalking-ui:8.0.1 container_name: ui depends_on: - oap links: - oap restart: always ports: - 8083:8080 environment: SW_OAP_ADDRESS: oap:12800 TZ: Asia/Shanghai elastichd: image: containerize/elastichd:latest container_name: elasticsearch-hd restart: always #networks: #- net-es ports: - &quot;9800:9800&quot; depends_on: - &quot;elasticsearch&quot; links: - &quot;elasticsearch:demo&quot; elasticsearch-head: image: mobz/elasticsearch-head:5 container_name: elasticsearch-head ports: - &quot;9100:9100&quot; networks: net-es: external: false 三.启动docker启动容器：docker-compose up -d 查看容器：docker-compose ps 删除容器：docker-compose rm 四.验证浏览器中输入：http://localhost:8080","categories":[],"tags":[],"author":"张存"},{"title":"Linux/CentOS设置全局代理（http）","slug":"Linux-CentOS设置全局代理（http）","date":"2021-11-02T02:24:00.000Z","updated":"2021-11-02T02:24:55.920Z","comments":true,"path":"2021/11/02/linux-centos-she-zhi-quan-ju-dai-li-http/","link":"","permalink":"https://blog.zhangcun.store/2021/11/02/linux-centos-she-zhi-quan-ju-dai-li-http/","excerpt":"","text":"说明：为什么说是http代理，其实这个还不能说是全称走代理，罪名写的区别就是ICMP协议这个设置就无效，只能说是90%的应用都可以使用这个设置来实现代理访问，只有个别不行，比如一些软件根本不走http协议的，那么此种方法绝对不行；下面是讲解http的代理配置，以后会讲解全局级别的代理实现，其实也就是网关，配置网关绝对能100%，这里不做讲解。全局代理配置主要在于环境变量的设置。 还有网上很多都说http配置代理不支持socks协议，其实是不对的。我测试的结果已经支持了。 个人理解：我谈一下这个http_proxy的设置，首先，设置了这个变量不是说只会走http协议，上面我说的应该是普通认为会这样说的说法，我后面觉得上面已经是错误了，比如curl，git这些软件默认使用http_proxy这个环境变量来设置代理服务器，所以在linux下只要设置了这个环境变量就能被这些软件识别，而对于代理服务器用什么协议都行，比如使用http协议或者socks协议等。 那么对于一些比如chrome和yum这些针对http_proxy可能不会生效，比如chrome用的是server_proxy这个变量，而且是在启动时设置才生效。 下面是代理变量的配置： 环境变量 描述 值示例http_proxy 为http变量设置代理；默认不填开头以http协议传输 10.0.0.51:8080user:&#x70;&#97;&#115;&#x73;&#64;&#49;&#x30;&#46;&#48;&#46;&#48;&#x2e;&#49;&#48;:8080socks4://10.0.0.51:1080socks5://192.168.1.1:1080https_proxy 为https变量设置代理； 同上ftp_proxy 为ftp变量设置代理； 同上all_proxy 全部变量设置代理，设置了这个时候上面的不用设置 同上no_proxy 无需代理的主机或域名；可以使用通配符；多个时使用“,”号分隔； .aiezu.com,10...,192.168..,*.local,localhost,127.0.0.1针对上面变量的设置方法： 1、在/etc/profile文件 2、在~/.bashrc 3、在~/.zshrc 4、在/etc/profile.d/文件夹下新建一个文件xxx.sh 写入如下配置： export proxy=”http://192.168.5.14:8118&quot;export http_proxy=$proxyexport https_proxy=$proxyexport ftp_proxy=$proxyexport no_proxy=”localhost, 127.0.0.1, ::1”而对于要取消设置可以使用如下命令，其实也就是取消环境变量的设置： unset http_proxyunset https_proxyunset ftp_proxyunset no_proxy针对yum配置走代理： 经过测试其实只要设置上面的变量之后已经可以走代理了，但如果要单独设置，可以设置如下文件的变量： echo “proxy=http://127.0.0.1:8080/&quot; &gt;&gt; /etc/yum.conf","categories":[],"tags":[],"author":"张存"},{"title":"docker 安装ElasticSearch head","slug":"docker-安装ElasticSearch-head","date":"2021-11-01T10:43:34.000Z","updated":"2021-11-01T10:43:58.934Z","comments":true,"path":"2021/11/01/docker-an-zhuang-elasticsearch-head/","link":"","permalink":"https://blog.zhangcun.store/2021/11/01/docker-an-zhuang-elasticsearch-head/","excerpt":"","text":"github官网地址 https://github.com/mobz/elasticsearch-head 拉取镜像 docker pull mobz/elasticsearch-head:5创建容器 docker create –name elasticsearch-head -p 9100:9100 mobz/elasticsearch-head:5启动容器 docker start elasticsearch-head浏览器打开: http://IP:9100 尝试连接elaseticsearch会发现无法连接上，由于是前后端分离开发，所以会存在跨域问题，需要在服务端做CORS的配置，如下 修改docker中elasticsearch的elasticsearch.yml文件 docker exec -it elasticsearch /bin/bashvi config/elasticsearch.yml在最下面添加2行 http.cors.enabled: truehttp.cors.allow-origin: “*” 退出并重启服务 exitdocker restart elasticsearch 测试连接","categories":[],"tags":[],"author":"张存"},{"title":"elasticsearch 7.13.1在线安装ik分词，亲测有效","slug":"elasticsearch-7-13-1在线安装ik分词，亲测有效","date":"2021-11-01T10:29:48.000Z","updated":"2021-11-02T03:37:34.673Z","comments":true,"path":"2021/11/01/elasticsearch-7-13-1-zai-xian-an-zhuang-ik-fen-ci-qin-ce-you-xiao/","link":"","permalink":"https://blog.zhangcun.store/2021/11/01/elasticsearch-7-13-1-zai-xian-an-zhuang-ik-fen-ci-qin-ce-you-xiao/","excerpt":"","text":"进入容器 docker exec -it elasticsearch /bin/bash 执行安装命令 bin/elasticsearch-plugin install https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v7.13.1/elasticsearch-analysis-ik-7.13.1.zip验证bin/elasticsearch-plugin list 容器重启docker restart elasticsearchik分词器链接地址😊✔https://github.com/medcl/elasticsearch-analysis-ik/tags 持久化docker commit xxxxxxxx es/ik","categories":[],"tags":[],"author":"张存"},{"title":"删除^M和行首的空格","slug":"删除-M","date":"2021-11-01T07:52:27.000Z","updated":"2021-12-02T11:27:09.013Z","comments":true,"path":"2021/11/01/shan-chu-m/","link":"","permalink":"https://blog.zhangcun.store/2021/11/01/shan-chu-m/","excerpt":"","text":"linux下vim编辑文件出现^M是因为不同平台对于回车符的定义差异造成的：windows：0D0A ‘/r/n’unix\\linux: 0A ‘/n’MAC: 0D ‘/r’ 当linux的文件在windows下编辑过，就容易出现^M符号，就是因为多了’/r’解决办法：1、dos2unix fileName 这个最简单，但是有些系统没有安装dosunix工具 2、sed -i ‘s/\\r//g&#39; fileName 这个非常好使 删除行首的空格 sed &#39;s/^ *//&#39; jello.txt &gt; hello.txt","categories":[],"tags":[],"author":"张存"},{"title":"Centos7 Apache站点 强制https访问","slug":"Centos7-Apache站点-强制https访问","date":"2021-11-01T06:02:49.000Z","updated":"2021-11-01T06:08:04.313Z","comments":true,"path":"2021/11/01/centos7-apache-zhan-dian-qiang-zhi-https-fang-wen/","link":"","permalink":"https://blog.zhangcun.store/2021/11/01/centos7-apache-zhan-dian-qiang-zhi-https-fang-wen/","excerpt":"","text":"Apache版本2.4 安装mod_ssl yum install mod_ssl -y apache配置/etc/httpd/conf.d/ssl.conf我把这下面的内容复制到另外一个文件中配置的 &lt;VirtualHost _default_:443&gt; ..... &lt;/VirtualHost&gt;需要修改的几项 DocumentRoot “/var/www/example.com/public_html” ServerName www.example.com:443 SSLCertificateFile /etc/httpd/ssl/apache.crtSSLCertificateKeyFile /etc/httpd/ssl/apache.key重启apache systemctl restart httpd.service 实现强制HTTPS访问 vim /etc/httpd/conf/httpd.conf 添加如下内容: RewriteEngine OnRewriteRule ^(.*)$ https://%{HTTP_HOST}$1 [R,L] 重启apache systemctl restart httpd.service","categories":[],"tags":[],"author":"张存"},{"title":"招行每日答题赢积分【题库】","slug":"招行每日答题赢积分【题库】","date":"2021-11-01T03:59:54.000Z","updated":"2021-11-01T04:03:31.956Z","comments":true,"path":"2021/11/01/zhao-xing-mei-ri-da-ti-ying-ji-fen-ti-ku/","link":"","permalink":"https://blog.zhangcun.store/2021/11/01/zhao-xing-mei-ri-da-ti-ying-ji-fen-ti-ku/","excerpt":"","text":"招行APP每日答题活动，答题不限时，有的说难，索性收集了一些题目，给广大飞友参考，不定期更新。若答案有疑问，请回复告知，欢迎大家分享题目~回复采纳，花花送上每天答对5题可得10积分，每周六日另有瓜分场次。【活动路径】招行APP–我的–积分–答题赢积分有的题目描述容易【混淆】，请看清楚再作答。 Q1：外国人查询到的信用报告为本国语言A：错误Q2：什么理论可以用来描述”小钱也有大用处”A：拿铁理论Q3：良性负债有利于财富的增长，能带来积极的回报，因此应该合理加以利用A：正确Q4：处于同一生命周期的个人，风险承受能力不同，其投资组合各大类资产配置比例也是不同的A：正确Q5：当您的固定额度不能满足消费需求时，可以向我行申请临时额度，关于临时额度，下列说法正确的一项是A：申请和使用不会收取手续费用Q6：使用招行信用卡在电商平台进行支付的时候，都是使用查询密码A：错误Q7：股票应该做集中投资才能赚大钱A：错误Q8：下列哪项不属于信用信息的来源A：居委会走访调查Q9：以下哪个是资产配置实际运用的有效案例A：耶鲁大学捐赠基金Q10：填写贷款/信用卡申请表时，为保护隐私，关键信息可以不填A：错误Q11：任何人、任何机构与任何组织无权知道您的银行卡取款密码、支付密码或短信验证码，您可拒绝任何企图索取您银行卡密码的要求A：正确Q12：您收到一条抽奖链接，中奖后需要您输入个人信息、卡片信息及密码，这种情况属于网络诈骗A：正确Q13：银行理财产品，是由商业银行自行设计并发行的产品，将募集到的资金投入金融市场，获取投资收益后，根据合同约定分配给投资人的一类理财产品，一般具有收益高且流动性也高的特色A：错误Q14：教育金规划需要：提前安排、专款专用、定期投入、安全第一A：正确Q15：我的常住地在上海并且在上海工作时申请了一张招行信用卡，如去往浙江，是需要区分”本地”和”异地”的,因为异地刷卡消费或网上支付，都会有手续费用A：错误Q16：资产配置就是做好资产的’荤素搭配’，家庭紧急预备金可以放在流动性强的资产中，教育金和养老金提前筹划，适当参与资本市场战胜通胀A：正确Q17：小鱼上网聊QQ,这时有人发来一条信息’轻松兼职,每天工作2小时,日入300元’，经了解对方说每单给5元钱手续费,会同购买商品钱一同打回到小鱼卡上。小鱼应该A：不信,是骗子Q18：为了保障网上购物的用卡安全，以下哪项措施可能存在风险隐患A：使用生日作为密码Q19：国家最权威的征信机构是?A：中国人民银行征信中心Q20：影响市场大盘走势的最基本因素A：宏观经济与政策Q21：掌握好负债比例至关重要，当资产的负债率低于3/4、负债比例低于收入的1/2时，家庭的财务是比较安全的。A：错误Q22：根据美国退休金十年期长期绩效的实证调查，91.5%投资报酬来源于A：资产分配Q23：当我们接触到一个新客户时，客户提交的基础材料应该与个人信息交叉验证A：正确Q24：对于大部分国内退休人群，其主要，也最稳定的收入来源是A：政府退休金收入Q25：资产配置中，权益类资产的作用是A：获取高收益Q26：初入社会小资族，工资薪水较低，已积累一定资金，理财收入为主，工资性收入为辅A：错误Q27：以下哪一项不属于现金流入A：购房买车Q28：银行信用卡能提供一定期限的免息时间，可以利用，如果用银行免息期需要有计划、不怕麻烦、执行力强，珍惜征信记录A：正确Q29：小明的招行信用卡是25号的账单日，那么他收到的5月账单中，一般不会包含下列哪一笔交易A：5月26号ATM取现Q30：被法院列入失信被执行人黑名单属于不良信息A：正确Q31：资产配置中，固收类资产的作用是A：构建组合安全垫Q32：本人信用卡可以借给自己的亲朋好友使用A：错误Q33：发现信用报告有错，申请异议时，应当携带本人有效身份证件。A：正确Q34：中国经济未来虽不能保持高速增长，但依然能够维持一定增速，因此仍能保证金融产品的刚性兑付A：错误Q35：在我国，存款产品最突出的特点是A：安全性Q36：按照七二法则，如果10年后要买房，需要手头上的资金翻倍，投资平均年化收益6%的产品则可实现翻倍。A：错误Q37：如果现在要给小孩规划教育金，但是目前的资金有缺口，以下哪些方面调整不可以帮助教育金的规划目标实现A：买彩票Q38：“征信”一词来仅指个人信用调查A：错误Q39：信用报告只有网上查询和现场查询两种途径A：错误Q40：阿基米德曾说’如果给我一个支点我能撬起地球’，所以说金融杠杆越高越好。A：错误Q41：下列哪项属于信用报告中最核心的信息A：信贷信息Q42：贝壳研究院报告显示，2018年首次置业购房者贷款成交占比90%，对贷款的依赖性更强A：正确Q43：房租收入大于房贷额度的负债属于资产性良性负债A：正确Q44：维护良好的信用记录应当认真履约，量入为出A：正确Q45：小赵收到一条短信，说他的手机号被快乐大本营节目组抽中，获得苹果笔记本电脑一台，需给栏目组汇1000元手续费及税款，小李没有理会，直接删除短信A：正确Q46：按七二法则，100万的本金，平均年化收益率为8%，多少年100万的本金能变成200万A：9年Q47：客户可以向法院申请强制执行金融机构修改数据A：正确Q48：一般来说股票PE在21-28之间说明可能被A：高估Q49：根据招行与尼尔森调研公司合作的《中产阶级白皮书》，中产阶级的子女教育水平超出总体平均水平多少A：41万元Q50：小东是某高校在校生，考英语四级前夕收到一条购买考试答案的信息，称一套答案1000元，小东马上联系了对方，并汇款1000元。A：错误Q51：只要客户有需要，征信中心都要免费为客户查询征信报告A：错误Q52:对于初入社会小资族，医疗险和意外险建议配置门槛为3%A:错误Q53:80年-17年，黄金拿过3年当年收益最佳冠军A:错误Q54:发现数据错误，在改/删之前，本人不能给错的信息加标注说明情况A:错误 (265楼Challenge)Q55:统计招商银行管理4万亿中高端客户资产结构，我们发现储蓄存款和单一理财产品占比达到76.7%，这种形态的资产配置，过去10年扣除通胀后的年化收益率仅为1.94A:正确Q56:给出入社会小资族配置建议中，短期理财的建议门槛是A:20%Q57:如果现在大学四年的总开销为150万，每年的学费涨幅为5%，20年大学四年的总开销为多少？A:398Q58:合理的房价收入比的取值范围为__倍，若高于这一范围，则认为其房价偏高A:4-6Q59:在线回答私密问题时，没有时间限制A:错误Q60:国内市场首批向公众发行的公募基金是封闭式基金吗A:正确Q61:2018年购房者人均居住面积为27.8平，其中24.3%的购房者人均居住面积不到20平方米，相当于三口之家住房不到60平方米A:正确Q62:根据招行与尼尔森调研公司合作的《中产阶级白皮书》显示，高资产量的中产阶级平均为子女规划153万元教育准备金，为中资产量与低资产量人群比例的两倍以上。A:正确Q63:所有银行都接受数字证书和银行卡进行身份验证。A:错误Q64:初入社会小资族来说，承担家庭责任较少，有更长的时间来弥补风险损失，因此承担风险承受能力较强A:正确 （感谢@Fatiger 更正）Q65:小久妹刚刚毕业参加工作，目前是“月光族”，对于小久妹来说，目前理财最重要的是下列哪项？A:存钱Q66:每张招行信用卡（外币单标卡除外）都可以设置是否需要在刷卡时验证交易密码，如设为需验证密码，称作开通“刷卡验密功能”，持卡人可以依据个人使用习惯，选择在刷卡时是否验证密码。答案：正确Q67:客户信用有变，应当立即通知银行。答案：正确Q68:企业如果破产，资产变卖后在全面偿还优先股股东后才由普通股股东分享答案：正确Q69:相较于股票，债券收益率波动较小，但收益向上空间较为有限。答案：正确Q70:下面哪项属于长期规划目标?A:子女教育Q71:哪一项风险可以自留A:蚊虫叮咬Q72:网上查询信用报告时，如果已经通过了身份验证，还是可以重新注册A:错误Q73:马克维兹理论中，多少百分比的报酬来源于理想的资产配置？A:91.5%Q74:针对每年保费支出，通常建议大概占比年收入的20%A:正确Q75:如果某先生小孩出国留学需要530万，当前家庭总资产130万，如果按他目前理财的平均年化收益4%来算，10年后总资产约能够增值到180万，可是距离儿子出国留学的总费用仍然有350万左右的差距，所以他的儿子无法出国留学了。A:错误Q76:怎样才是好的现金流管理？A:收入-存下=支出Q77:每月发薪日的第二天适合小白客户定投，答案是正确还是错误？A:正确Q78:下列哪项不属于“创富”守则？(易和Q143混淆)A:改变用钱观念Q79:下列哪项属于征信机构的特征A:不从事放贷业务Q80:恐惧是应激反应，是保护自己，但是不合理的恐惧需要科学的克服A:正确Q81：如果您认为征信报告有错误，提出异议，对异议处理结果不满意，只能选择诉讼解决A：错误Q82：早晨李阿姨的儿子上班后，李阿姨接到一个外地座机电话打来，对方操着外地口音说她儿子出了车祸正在X医院抢救，需给医院账户汇5000元抢救费，李阿姨正确的做法是A：联系儿子核实Q83：征信基础产品是什么A：信用报告Q84：首次申请招行信用卡，可以不提供身份证明，使用财力资料替代也是可以的。A：错误Q85：对于已经退休的投资者来说，考虑的主要是养老以及财富传承的问题，通过终身寿险的指定分配功能起到定向传承作用，避免家庭纠纷，并搭配年金保险稳定增值特性获得养老补充，是较为合理的。A：正确Q86：针对现金类资产，我们通常建议至少留足()的生活支出。A：6个月Q87：债券相比于股票，波动性更大A：错误Q88：接到快递员电话，要求提供手机动态验证码进行身份确认，这种情况属于不正常。A：正确Q89：存钱的开始步骤是A：记账Q90：以下哪个不是金融杠杆A：全款买车Q91：某同学一日收到一号码尾号为95555的手机短信，提醒自己网银到期，请点击附加网站进行更新，他便按照提示进行操作，这样的做法对不对？A：错误Q92：国务院在（）印发了《关于进一步深化城镇住房制度改革加快住房建设的通知》A：1998年Q93：财务规划目标分为长期目标和短期目标A：正确Q94：张小姐加入一个海外代购的群，张小姐让群主代为购买价值4万元的皮包一个，但是在汇款后却迟迟没有收到货物，群主也将张小姐踢出了微信群，此时张小姐应该如何做？A：立刻报警Q95：4008205555是招商银行信用卡的客户服务热线号码。A：正确Q96：租房住容易出现各种不良经历，从而在满足个人居住需要的质量上要低于自有住房，这是抬高个人购房意愿的主要原因之一A：正确Q97：黄金VS股票， 两者常常呈现正向关系，主要原因是黄金具有避险属性，股票的下跌激发黄金的避险需求，带动金价上涨。两者搭配，可对冲股票系统性风险。A：错误Q98：教育金的规划不仅要看当前的学费水平，还要考虑学费的增长率；不仅要关注当前的生活费水平，还要考虑通过膨胀率。A：正确Q99：过去十年，常见的投资工具没有一类收益率能年年冠军，即使是冠军次数最多的黄金，也曾在2013年大跌接近多少？A：30%Q100：意外保障型保险主要功能是为了获取高额的分红收益。A：错误Q101：每月还贷占月收入比例超过（），就会陷家庭于飘摇境地A：50%Q102：放贷机构查询、报送客户的信用信息可以不经过客户同意A：错误Q103：子女教育费用需要考虑的问题不包含A：子女婚假金Q104：耶鲁大学通过资产配置的方式管理其名下的捐赠基金，过去30年年化收益高达A：13%Q105：资产配置之前需要综合考虑流动性、收益性、风险性之间的关联A：正确Q106：使用招行信用卡支付后退货，如果退款已经处理完成并入账，则一定可以冲抵本期应还账单。A：错误Q107：不超过自身风险承受能力，不投资不懂的产品，不过度借钱投资，不盲从跟风投资，能够有效的避免投资风险。A：正确 （271楼肉测正确，249楼Challenge，仅供参考）Q108:下列哪项关于理财工具的说法不正确A：现金类就像船的风帆Q109：发现错误数据，在改/删之前，征信中心会给错的信息加标注说明情况。A：正确Q110：贪婪是不对的，所以我们要完全避免贪婪A：错误Q111：《征信业管理条例》规定只要违约就算不良，哪怕只有一天A：正确Q112:征信中心从第三次查询时开始收取费用，一次费用为多少钱？A：10元（已经更正）Q113：发现信用报告有错，必须本人亲自申请异议A：错误Q114：如果您要在公共场合下查看银行卡账户（如图书馆或咖啡厅），请注意安全并建议在结束查看后在安全的网络环境下更改密码。A：正确Q115：信用报告，是征信机构提供的关于企业或个人信用记录的文件。A：正确Q116:对以小久妹为代表的初入社会小资族，建议留存–时间生活费作为备用金？A：3-6个月Q117:自身或亲友遭遇了诈骗，欠款已汇出，应与多长时间内报案追回被骗钱财几率更大？A：24小时Q118:如果法院判决要求报送数据的金融机构修改数据，金融机构可以不履行判决。A：错误Q119:以下不属于定期型存款的是？A：智能通知存款Q120:根据贝恩咨询的《中国私人财富报告》，国内企业家们的哪一项收入近年来呈现下降趋势？A：企业经营收入Q121:以下哪项不是纪律投资的表现？A：按时定投Q122:教育金规划不需要考虑日常生活开支，要把所有的费用全部考虑规则起来。A：错误Q123:小陈通过微信摇一摇添加了一位头像靓丽的姑娘，两人聊天十分投缘，某天姑娘突然对小陈说，家人得了重病，向他借2万元给家人治病，小李此时应该？A：直接拒绝Q124:信用报告中信贷信息部分能够体现客户3年内的逾期及违约行为。答案：错误Q125:流动性常常被投资者忽视，一般除了需要预留6个月的生活开支外，还需要一部分的应急资金，所以需要做好短期、中期、长期的期限搭配。答案：正确Q126:中国人民银行征信中心为国家最权威的征信机构。答案：正确Q127:投资三要素是安全性、风险性和收益性答案：错误Q128:征信中心有权（可以）修改金融机构的数据A：错误Q129:客户对征信报告提出异议，如果经查贷款记录与征信报告相符，也需要帮助客户修改数据A：错误Q130:哪项原则是征信机构最基本的职业道德，也是征信立法的主要内容之一A:隐私商业秘密保护原则Q131:重复Q132:2006年左右，居民理财渠道较为单一，都在（）上A：存款、国债Q133:以下哪种是追涨杀跌的表现A：指数越高越疯狂Q134:如果客户已经打款，即使钱还没到账户，也算还款A：错误Q135:某城的一套房子1000万，首付30%就能搞定，相当于是用300万撬动了这1000万的房产A:正确Q136:信用卡消费签名前，需要仔细核对卡号，消费金额，币种是否正确。A:正确Q137:对于三明治族的资产配置要点，以下哪些说明不正确？答案：降低风险偏好，投资稳定资产Q138:哪些属于负面信息？答案：未按合同约定还款Q139:目前不良信息在征信报告的存续时间为多久A：5年Q140:贝壳研究院研究发现，影响换房需求有三大核心要素，哪一项不是核心要素？A：价格更优惠Q141:（重复）Q142:信用财富在信用报告中保留5年A:错Q143:下列哪项不属于“享富”守则？(易和Q78混淆)A:为资产做好的多元配置和科学规划Q144:70后三大件 手表 自行车 缝纫机Q145:e租宝涉及90万…A：错Q146:哪些不属于信用报告记录的信息A:金融负债信息Q147:下列哪项不属于征信的原则A:有效性Q148:如果信用报告出现错误，客户提出异议，对异议结果不满意，以下哪项不属于救济方式答案:上访Q149:2018年4月27日，我国发布了《关于规范金融机构资产管理业务的指导意见》（即资管新规），旨在规范金融机构资产管理业务，以下不属于资管新规发布后对银行理财产品的影响是？A:将出现更多3个月以内短期理财Q150：哪些属于不良信息(易和Q263混淆)A：严重违约Q151：在投资理财中，由于存款产品收益都非常低，所以完全无需在投资组合中选择存款产品。A：错误Q152：征信报告中可以查询到我有几次“恶意欠款”。A：错误Q153：发现数据错误，金融机构不改，可以向法院起诉。A：正确Q154：已经步入退休的银发老年族(60岁以上),最主要的理财工具是A：银行理财、存款Q155：发现征信报告有错，可以携带个人护照申请异议。A：正确Q156：大多数人选择的还贷收入比为？A：0-30%Q157：在部分境外商户通过国际组织线路进行消费时，刷卡消费一般不需要输入交易密码。A：正确Q158：黄金和股票通常呈现反向关系A：正确Q159：换手率是指风险和收益的性价比，反映了单位风险基金净值增值率超过无风险收益率的程度A：错误Q160：在餐厅结账时,卡片可以交给服务员拿到收银处自行刷卡结算。A：错误Q161：债券相较于股票，收益向上空间较为有限,但收益率波动也较小,适合风险相对较低客户。A：正确Q162：问题验证是指在线回答”私密性问题”的方式验证您的身份。A：正确Q163：定投越早进场越好A：正确Q164：负债比例低于收入的__时，家庭的财务是比较安全的A:1/3Q165：股票型基金：将__以上的资金投向股票的基金A：80%Q166：不属于人性特征A：人云亦云Q167：法院和政府部门查询信用报告也会体现在信用报告中。A：错误Q168：周某为一家公司的会计…最近刚学会网银购物,他开通哪种网银最合适A：专门办理一张银行卡Q169：基于征信工作的哪项原则,征信机构应该给予被征信人一定的知情权和申诉权答：真实性Q170:信用报告出错无法修改A：错误Q171:三明治族资产配置主要原则：长短搭配，专款专用，多元化配置A：正确Q172:影响大盘走势的最基本因素A：宏观经济与政策Q173:不是影响评估风险承受能力的因素A：持有另类资产的比例Q174:教育支出为刚性A：正确Q175:对于职场新人，由于所积累的财富较少，应采取保守型投资更为妥当。A：错误Q176:征信中心目前支持与中国金融认证中心（CFCA)合作的银行发放的数字证书答案：正确Q177:下列哪项不属于常见投资雷区A：不敢进场Q178:根据住房公积金和养老保险记录，我们可以确定客户当前的工作单位，结合缴费比例，可以测算出客户的收入情况。A：正确Q179:请选出我行网址A：www.cmbchina.comQ180:在子女教育方面，增加保障类配置，确保专款专用的现金流，以备不时之需。A：正确Q181:基金类的强制储蓄小工具是什么A：基金定投Q182:通过征信中心官方网站查询个人信用报告，不需要本人实名注册A：错误Q183:不属于客户的征信权利A：诉讼权Q184:法院冻结个人账户后，应以__方式通知答：法院文书Q185:货币实际需求大于货币供给会导致货币贬值A：错误Q186:如果客户信用记录很差，征信中心可以拒绝为客户查询信用报告。A：错误Q187:健康保障型保险可以在一定程度上解决无钱医病及因病致贫的问题。A：正确Q188:债券VS股票，相较于股票，债券收益率波动较小，但收益线上空间较为优先，两者组合配置，可降低组合波动，提升组合收益空间。A：正确Q189:健康保障型保险可以在一定程度上解决无钱医病及因病致贫的问题。A：正确Q190:72法则指通过固定收益投资是本金翻倍的时间=72/投资回报率A：正确Q191:逾期发生，客户应该立即还款，实在有困难，可以与银行协商。A：正确Q192：灵活性原则指征信机构在采集信息时要尽量实现实时跟踪，能够使用被征信人最新的信用记录，反映其最新的信用状况。A：错误Q193：教育金规划三步走不包含哪一步？A：多不多Q194：征信报告应充分披露任何能够体现被征信人信用状况的信息，这反应了征信机构再生成信用报告时应当遵循哪项原则A:全面性原则Q195:配置组合建立后，如果入场时机不好，正收益概率就会小A:错误Q196:一般情况下，黄金与股票呈现的关系是怎样的？A:反向关系Q197:任何一张银行卡都能验证A:错误Q198:网上查询信用报告时，如果没有通过身份验证，可以重新注册 (Q72相似)A：正确Q199:以下哪一种信用卡信息是可以告诉其他人的A:以上都不可以Q200:三个月前，汪某向朋友洪某借钱。。。A:错误Q201:正面信息是指您拥有贷款或信用卡且正常还款的信息A:正确Q202:配置建立后，任一天进场，持有越久，收益更高A:正确Q203:信用报告最好经常查询A:错误Q204:为保障您的权益，请您在银行卡背面签名条签上本人姓名A:正确Q205:小明为了方便妈妈网上购物 。。。。 留给了妈妈A:错误Q206：对客户自己提供的信息，放贷机构要从其他渠道核实真伪，信用报告只是放贷机构信贷决策的参考因素之一。A：正确Q207:《征信业管理条例》规定的异议处理时间为20天A：正确Q208:对于三口之家，支出压力大，应采取进取型投资获取更多收益。A：错误Q209:财富传承可以通过年金保险、金葵花信托、权益类基金A：正确（已经更正）Q210：如选择对招行信用卡的美元账单进行购汇还款，则当期购汇金额不能超过当期美元账单金额，购汇汇率为还款当日10点公布的招商银行美元卖出价。A：正确Q211:使用指定范围外的银行卡也可以查信用报告A：错误Q212：2001年公募基金行业迎来了首只开放式基金A：华安创新基金Q213：商业银行柜台无法查询征信报告A：错误Q214：征信中心整合数据都会是自动操作，不会产生错误。A：错误Q215：基金过去的绩效也代表未来的绩效。A：错误Q216：信用报告有错误是指客户认为信用报告与其记忆不同，但不一定真错。A：正确Q217:某客户信用报告借贷信息数字显示为7，说明该客户A：逾期Q218:根据帆船理论，保障类资产代表A：救生圈Q219:按照财富小船理论，船体的哪个部位代表的保障类需求？A：救生圈Q220:地铁上有人让你扫她的二维码 。。。A：错误Q221:采集、加工、分析和对外提供信用信息服务的相关制度和措施的总称是A：征信体系Q222:某位好友跟你说她的一个投资理财项目赚了钱，建议你也去试试，这是你应该保持警惕A：正确Q223:下列不属于贝壳研究院对2018年购房结论的是？A：年龄越小月供负担越小Q224:下列哪项不属于维护良好信用记录的方法A：经常查询信用报告Q225:当客户在没有POS机或不能联网的情况下（如国际航班），可以使用手工压单的操作进行信用卡交易，这也是信用卡的一种付款方式。A：正确Q226:储蓄型保险可以实现哪些功能A：以上都对Q227:按照2018年10月公布的通货膨胀率2.5%来计算，在20年后，100万等于现在多少钱的购买力？A：60.27万Q228:信用报告出错，客户委托代理人申请异议时，委托代理人需要带上授权委托书复印件。A：错误Q229:下列哪项属于信用报告出错的原因A：以上全选Q230：过去二十年，人们主要考虑的是如何富起来，未来二十年，考虑更多的则是如何富下去。A：正确Q231：信用卡消费后想怎么还款就怎么还款，无时间规定。A：错误Q232：优先获得股息，预先定好股息收益率，不受公司经营状况影响。A：正确Q233：收入-储蓄=支出是应该改进的存钱方案A：正确Q234:中国的股票认购最早由财政部A：错误Q235:适当利用杠杆投资是可以的A：正确Q236:搞清楚自己理财目标比怎么去配置重要A：正确Q237:信用卡支付过程中密码应妥善保管。。。A：正确Q238:以下哪一项服务不属于银行投融资业务的服务范围A：现金存取款业务Q239：不良信贷信息是指没有按时足额还款的信息。A：正确Q240：2018年全国购房者中80后占比达47.8％，近年来虽然90后逐渐深入市场，不过80后仍旧占据半壁江山A：正确Q241:征信报告出错,办理异议的地点为中国人民银行总部。A：错误Q242:坚持下列哪项原则，是征信工作最重要的条件A：真实性Q243：客户的历史信用记录仅包含负面信息。A：错误Q244：2018年购房者平均年龄为A：29.5Q245:给初入社会小资族配置建议中，基金定投的建议门槛是？A：60%Q246:每年免费查询几次征信报告 or 征信中心有义务每年为您提供几次免费查询服务A：2次Q247:在交易的乙方承诺未来偿还的前提下，另一方为其提供商品或服务的行为是哪一概念的定义A:信用Q248:将资金分为三部分:要花的钱,保障的钱,生钱的钱A:正确Q249:招行信用卡在pos机上刷卡消费没有手续费A:正确Q250:初入社会小资族资产配置主要原则为：简单组合配置、纪律投资？A:正确Q251:网上通过问题验证查信用报告时，需要在线回答几个私密问题A:5个Q252:所有的衣食住行的开支都属于现金流出。A:正确Q253:客户经理录入客户信息有误时，只能通过诉讼途径对客户经理提出诉讼解决。A:错误Q254:网上查信用报告，进行问题验证时答案不需要与信用报告中的信息一致A:错误Q255:适当赚钱可以设立为理财目标，只要收益率合理就可以。A:错误Q256:三次不良后，信用报告将会终身记录。A:错误Q257：信用报告出错，如果是因为自己填写信息有误，则不能修改A：错误Q258：海购时在支付界面中常见的VBV （Verified by VISA）的意思是指的“VISA验证”，指的是一项持卡人的身份识别的验证服务。A：正确Q259：上证指数6124点出现在哪一年？A：2007年Q260:财富传承的工具有年金保险、终身寿险、金葵花财富信托等。A:正确Q261:（重复）Q262:如果需要获得未来持续稳定的回报，那么投资周期应该更（）A:长Q263:下列哪项不属于不良信息（易和Q150混淆）A:离婚信息Q264:疾病风险目前的患病率越来越高，治疗费用也很高，但是随着医疗技术的发展治愈率逐步越来越高。A:正确Q265:当亏损达到50%的时候，需要上涨 才能回本A:100%Q266：资产配置是指根据投资需求，将投资资金在不同资产类别之间，进行分配A：正确Q267：下列哪项关于投资三要素说法不正确？A：收益越高、风险越小Q268：发现信用报告出现问题，不提异议纠正也没有不良后果。A：错误Q269：基金投资越分散，这样可以使得投资者不会过度暴露于单一风险之中，但基金的获利能力可能因此有所减弱。A：正确Q270:在征信中心查询信用报告一周之后可以获得结果A:错误Q271:金融机构在修改错误数据时都能够做到及时不滞后。A:错误Q272:发现信用报告有错误，申请异议，异议处理最少30天。A:错误Q273:信用报告出错，如果是印尼为自己填写信息有误，则不能修改。A:错误Q274:学费年年涨价，规划时不需要考虑增值速度。A:错误Q275:因遭受意外伤害造成去了、残疾、支出医疗费或暂时丧失劳动能力的风险指的是什么风险？A:意外风险Q276: 投资风险属于A：广义的风险Q277:商业柜台无法查询信用报告A:错误Q278:风险的特征不包含哪项？A:确定存在Q279：尼尔森调研对于中产阶级的教育费用调研显示：A：中产阶级需要更好的子女教育规划Q280:负面信息是指未按合同约定还款的信息A:正确Q281:外国人不能在征信中心查询信用报告A:错误Q282:不良报告 10年后消除。A:错误Q283：黄金和股票组合，可以对冲股票的非系统性风险A：错误Q284:下列哪项不属于长期规划A:买车规划Q285:合理消费带来的信用卡负债属于消费性良性负债A:正确Q286:征信机构是指依法设立，以盈利为目的的放贷机构。A:错误Q287:按照信用卡的结算货币方式不同，可以分为磁条卡和芯片卡。A:错误Q288:普通股股息不受公司经营状况影响答：错误Q289：净值型理财产品没有明确的预期收益率，产品收益以净值（资产组合的单价）的形式公布，因此能更为准确、真实、及时地反映所投资资产的价值。A：正确Q290：资产配置中，另类资产的作用是A:分散风险Q291:修改/删除数据，必须由金融中心操作。A:正确Q292:通过征信中心官方网站可以查询他人的信用报告吗？A：错误Q293：恶性负债就是一种财务“黑洞”，会使借款人背上沉重的财务负担，受到财务压力，甚至陷入财务困境。A：正确Q294：对比全球各地，中国人的买房平均年龄更为年轻化。A：正确Q295：现代社会中，黄金虽然不再作为直接进行流通的货币，但仍然具有独一无二的保值增值功能。A：正确Q296:发现信用报告有错误，可以向贷款机构或征信分中心提出异议并要求更正。A：正确Q297：征信系统只有责任清晰才能保证正新数据的准确性、客观性A：正确Q298:还贷收入比60%是危险线，仅适用于而且仅适用于工作稳定、没有孩子、个人年龄较小、升值潜力较大的人群A:错误Q299:自查信用报告是《征信业管理条例》赋予客户的什么权利？A:知情权Q300:发现信用报告有错误，申请异议，如果个人信用报告与贷款合同还款记录真实情况相符，也要按照客户要求修改报告。A:错误Q301：国内高净值人群对于股权投资更感兴趣，而对于资产安全性要求不高。A：错误Q302：社会信用体系的最终目标是形成良好的社会信用环境。A：正确Q303：下列关于负债规划说法不正确的是？A：借款先借低的，还款先还低的Q304;如果发现数据错误，金融机构要派人去征信中心修改数据。A:错误Q305我的户口在广东深圳，是可以在北京查询到自己的信用报告。A:正确Q306招行发行的银联IC芯片信用卡，符合中国金融集成电路卡规范标准，可在带有银联和QuickPass闪付标识的机具上使用，使用地区也包括境外区域A:正确Q307:股票认购证 财政部 90年代初 新股A:错误Q308：IAC公司，号称首创“蚂蚁传播”模式。用户花钱购买“种子”后，种子按会员等级以1%-2.8%的速度生长，收割后可以回收本利，年化收益365%-1022%，请问IAC公司性质是？A：网络传销Q309以下哪项不是基金定投的特点A：获得超高收益Q310:申请招商银行信用卡可以通过代办公司进行办理A:错误Q311:对于35岁中年白领来讲，哪一项不属于当前主要的支出费用A:自己养老Q312-风险的特征不包含哪项？A:确定存在Q313：最低还款额是指您每月最低需偿还的金额，显示在当月账单上。当月可在到期还款日期前，按时还足最低需要偿还的金额，不会影响您的个人信用记录，但不再享受免息待遇。A：正确Q314目前不良记录在征信报告上存续时间为结清不良记录后几年A：5年Q315：每月工资进来，先存钱、再花钱，才能扎实的存下钱A：正确Q316：有效性原则，指征信工作要做到资料全面，内容明晰A：错误Q317:信用卡的卡号、有效期都是不重要信息，可以随便发给陌生人知道。A:错误Q318:以下哪项不应作为选购银行理财产品时的主要参考因素？A:赠送礼品Q319:在公共网吧、使用公共WIFI查询、保存信用报告A:错误Q320:随着货币发行量的增长，黄金价格不断上涨，因此黄金能够在一定程度上抵御通货膨胀A:正确Q321:2014年1月2日，唐某买了辆东风日产汽车。8日，唐某接到电话，对方称是东风日产汽车…告诉唐某可以享受汽车节能退税的优惠。唐某于是持工行银行卡，来到自动柜员机上，按照对方的提示进行操作。这样的做法对不对？A:错误Q322:法院和政府部门查询信用报告会记录在查询记录里A:错误Q323:通胀会使我们所持有的现金的购买力不断降低A:正确Q324:每月工资进来，先存钱、再花钱，才能扎实的存下钱A:正确Q325:预备成家的资深上班族(30岁左右),面对的理财现状是A:结婚、买房开支大Q326:教育支出为刚性支出，为避免突发情况影响孩子教育，应设立专款专用的储备金A:正确Q327:融资融券是指提供担保物，借入资金买入证券（融资）或借入证券并卖出（融券）的行为。A:正确Q328:对外担保不是债，不需要承担偿还义务A:错误Q329:资产配置不是一体成型，而是量体裁衣，风险承受力不同，各大类资产投资比例也不同。A:正确Q330:征信报告查询的越多越好A:错误Q331:还款有难处可以联系银行，免除还款A:错误Q332:网上查信用报告时,无需提供手机号码A:错误Q333:以下哪个渠道不可以参与招行信用卡积分抽奖？A:滴滴出行Q334:现在招行信用卡公众号底部菜单栏有几个选项?A:3Q335:中国的股票认购证最早是90年代初由财政部提出发行的用以认购新股的凭证。A:错误Q336:使用问题验证但无法通过验证可能是因为本人当前真实信息与征信系统中的信息不一致A:正确Q337:不良记录在不良行为终止后，在信用报告中保存10年后删除A:错误Q338:对于印有个人信息的快递单等纸张应如何处理？A:将重要信息掩盖撕毁Q339:在酒店入住或租车时，商家一般会使用招行信用卡预扣一定金额作为押金，并在消费完成后再次刷卡实际结算，此类交易通常被称为“预授权交易”，这也是信用卡使用过程中的一种常见的交易形式？A:正确Q340:预借现金是招商银行信用卡的基本功能之一，该功能为持卡人提供小额现金借款，无需预先存款，持卡人即可通过提取现金或透支转账的方式获取资金，同时预借现金可以享受免息还款待遇，只要在账单出来后及时还清，就不需要额外支付手续费或利息？A:错误Q341:理财只是工具，美好生活才是目的？A:正确Q342:下列哪项不属于信用报告记录的内容A:金融负债信息Q343:信用评分是在信息主体信息的基础上,运用统计方法,对消费者或中小企业未来信用风险的一种综合评价A:正确Q344:2001年9月，我国诞生了第一只开放式基金( )，使我国基金业发展实现了从封闭式基金到开放式基金的历史性跨越A:华安创新基金Q345:投资理财产品时，只要选择收益高的就行了，无需关注产品风险、流动性。A:错误Q346:小额免密免签是银联和发卡银行共同为信用卡持卡人提供的一种小额快速支付服务。当持卡人使用具有“闪付”功能的金融IC卡，在指定商户进行一定金额以下的交易时，只需将卡片或移动设备靠近POS机等受理终端的“闪付”感应区，即可完成支付。支付过程中，持卡人不会被要求输入密码，也无需签名A:正确Q347:70年代，年轻人筹备婚礼需要的三大件是A:手表、自行车、缝纫机Q348:不良征信记录不会影响客户办理信用卡A:错误Q349:一只基金可以有多个基金经理管理吗？A:可以Q350:证券投资基金在世界各国的称谓是否相同？A:不相同Q351:储蓄黄金可以抵御通货膨胀吗？A:可以","categories":[],"tags":[],"author":"张存"},{"title":"yum安装epel源","slug":"yum安装epel源","date":"2021-10-28T09:12:14.000Z","updated":"2021-10-28T09:12:24.840Z","comments":true,"path":"2021/10/28/yum-an-zhuang-epel-yuan/","link":"","permalink":"https://blog.zhangcun.store/2021/10/28/yum-an-zhuang-epel-yuan/","excerpt":"","text":"国内yum源的安装(163，阿里云，epel) —-阿里云镜像源 1、备份 mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup 2、下载新的CentOS-Base.repo 到/etc/yum.repos.d/ CentOS 5 wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-5.repo 或者 curl -o /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-5.repo CentOS 6 wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-6.repo 或者 curl -o /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-6.repo CentOS 7 wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo 或者 curl -o /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo 3、之后运行 yum clean all，yum makecache 生成缓存 —-163镜像源 第一步：备份你的原镜像文件，以免出错后可以恢复。 mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup 第二步：下载新的CentOS-Base.repo 到/etc/yum.repos.d/ CentOS 5 wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.163.com/.help/CentOS5-Base-163.repo CentOS 6 wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.163.com/.help/CentOS6-Base-163.repo CentOS 7 wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.163.com/.help/CentOS7-Base-163.repo 3、之后运行 yum clean all，yum makecache 生成缓存 —-EPEL源 EPEL（Extra Packages for Enterprise Linux）是由 Fedora 社区打造，为 RHEL 及衍生发行版如 CentOS等提供高质量软件包的项目。装上了 EPEL，就像在 Fedora 上一样，可以通过 yum install 软件包名，即可安装很多以前需要编译安装的软件、常用的软件或一些比较流行的软件，比如现在流行的nginx、htop、ncdu、vnstat等等，都可以使用EPEL很方便的安装更新。 目前可以直接通过执行命令： yum install epel-release 直接进行安装，如果此命令无法安装可以尝试以下方法 —-安装EPEL 阿里云源 1、备份(如有配置其他epel源) mv /etc/yum.repos.d/epel.repo /etc/yum.repos.d/epel.repo.backup mv /etc/yum.repos.d/epel-testing.repo /etc/yum.repos.d/epel-testing.repo.backup 2、下载新repo 到/etc/yum.repos.d/ epel(RHEL 7) wget -O /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-7.repo epel(RHEL 6) wget -O /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-6.repo epel(RHEL 5) wget -O /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-5.repo —-官方源直接安装 CentOS/RHEL 5 ： rpm -Uvh https://dl.fedoraproject.org/pub/epel/epel-release-latest-5.noarch.rpm CentOS/RHEL 6 ： rpm -Uvh https://dl.fedoraproject.org/pub/epel/epel-release-latest-6.noarch.rpm CentOS/RHEL 7 ： rpm -Uvh https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm","categories":[],"tags":[],"author":"张存"},{"title":"nginx通过域名访问项目（不接项目名称），cookie丢失问题详解","slug":"nginx通过域名访问项目（不接项目名称），cookie丢失问题详解","date":"2021-10-28T08:50:26.000Z","updated":"2021-10-28T08:54:40.635Z","comments":true,"path":"2021/10/28/nginx-tong-guo-yu-ming-fang-wen-xiang-mu-bu-jie-xiang-mu-ming-cheng-cookie-diu-shi-wen-ti-xiang-jie/","link":"","permalink":"https://blog.zhangcun.store/2021/10/28/nginx-tong-guo-yu-ming-fang-wen-xiang-mu-bu-jie-xiang-mu-ming-cheng-cookie-diu-shi-wen-ti-xiang-jie/","excerpt":"","text":"最近搞了个域名，想用它直接去访问Tomcat上部署的项目，开始一直必须加上项目名称，经过短暂配置，成功了。 访问一次，到达登陆页面，结果死活登录不进去，一直在登陆界面，原来是由于cookie丢失，现配置如下，完美解决问题： server &#123; listen 80; #listen somename:8080; server_name www.XXX.cn; location / &#123; proxy_pass http://IP:8080/projectName/; proxy_cookie_path /projectName/ /; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; #root html; #index index.html index.htm; &#125; location /projectName/ &#123; proxy_pass http://IP:8080/projectName/; proxy_cookie_path /projectName/ /; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; &#125; &#125; proxy_cookie_path /projectName/ /; 用于改变cookie路径，解决cookie丢失问题的 在配置域名访问应用时，常出现cookie丢失问题，原因是普通的配置cookie的路径为（没有经过代理的地址）： http://IP:8080/projectName cookie_path：/project 但是为了不添加项目名就能访问应用，我们把location的代理地址设置为/ ，所以要改变cookie的路径，语法： proxy_cookie_path path replacement; path就是你需要替换的路径，replacement就是你需要替换的值 proxy_set_header Host $host; host变量的值按照如下优先级获得： 请求行中的host. 请求头中的Host头部. 与一条请求匹配的server name. 很清楚，有三点，取优先级最高的那个。仅从字面意思上来理解，这个选择的过程为：如果请求行中有host信息，则以请求行中的host作为host变量的 值（host与host变量不是一个东西，很拗口）；如果请求行中没有host信息，则以请求头中的Host头的值作为host变量的值；如果前面两者都没有，那 么host变量就是与该请求匹配所匹配的serve名。 proxy_set_header X-Real-IP $remote_addr; 用于获取用户真实IP的 详解如下： 经过反向代理后，由于在客户端和web服务器之间增加了中间层，因此web服务器无法直接拿到客户端的ip，通过$remote_addr变量拿到的将是Nginx的ip地址， 但是Nginx是可以获取用户的真实IP的，也就是说Nginx通过$remote_addr变量时获取的就是用户真实IP，那么想在web服务器获取用户真实IP，那咱们就需要赋 值一下，如上面的配置，Nginx将用户的真实IP赋值给X-Real-IP，然后在web端request.getAttribute(“X-real-ip”)获取IP proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; 用于获取用户真实IP的 另附上获取IP的工具 import java.io.IOException; import javax.servlet.http.HttpServletRequest; /** * 常用获取客户端信息的工具 * */ public final class NetworkUtil &#123; /** * 获取请求主机IP地址,如果通过代理进来，则透过防火墙获取真实IP地址; * * @param request * @return * @throws IOException */ public final static String getIpAddress(HttpServletRequest request) throws IOException &#123; // 获取请求主机IP地址,如果通过代理进来，则透过防火墙获取真实IP地址 String ip = request.getHeader(&quot;X-Forwarded-For&quot;); if (ip == null || ip.length() == 0 || &quot;unknown&quot;.equalsIgnoreCase(ip)) &#123; if (ip == null || ip.length() == 0 || &quot;unknown&quot;.equalsIgnoreCase(ip)) &#123; ip = request.getHeader(&quot;Proxy-Client-IP&quot;); &#125; if (ip == null || ip.length() == 0 || &quot;unknown&quot;.equalsIgnoreCase(ip)) &#123; ip = request.getHeader(&quot;WL-Proxy-Client-IP&quot;); &#125; if (ip == null || ip.length() == 0 || &quot;unknown&quot;.equalsIgnoreCase(ip)) &#123; ip = request.getHeader(&quot;HTTP_CLIENT_IP&quot;); &#125; if (ip == null || ip.length() == 0 || &quot;unknown&quot;.equalsIgnoreCase(ip)) &#123; ip = request.getHeader(&quot;HTTP_X_FORWARDED_FOR&quot;); &#125; if (ip == null || ip.length() == 0 || &quot;unknown&quot;.equalsIgnoreCase(ip)) &#123; ip = request.getRemoteAddr(); &#125; &#125; else if (ip.length() &gt; 15) &#123; String[] ips = ip.split(&quot;,&quot;); for (int index = 0; index &lt; ips.length; index++) &#123; String strIp = (String) ips[index]; if (!(&quot;unknown&quot;.equalsIgnoreCase(strIp))) &#123; ip = strIp; break; &#125; &#125; &#125; return ip; &#125; &#125;","categories":[],"tags":[],"author":"张存"},{"title":"Ubuntu20.04 安装和卸载MySQL8","slug":"Ubuntu20-04-安装和卸载MySQL8","date":"2021-10-28T08:40:42.000Z","updated":"2021-10-28T08:41:38.900Z","comments":true,"path":"2021/10/28/ubuntu20-04-an-zhuang-he-xie-zai-mysql8/","link":"","permalink":"https://blog.zhangcun.store/2021/10/28/ubuntu20-04-an-zhuang-he-xie-zai-mysql8/","excerpt":"","text":"安装MySQL8安装mysql-server sudo apt install mysql-server 初始化配置信息 sudo mysql_secure_installation VALIDATE PASSWORD COMPONENT…..（使用密码强度校验组件） 输入： nNew Password:（设置新密码,并重复一遍)Remove anonymous users (删除匿名用户) nDisallow root login remotely(拒绝远程root账号登录） nRemove test database and access to it(移除test数据库） nReload privilege tables now (现在就重新载入权限表） y登入到数据库并配置远程访问 sudo mysql -uroot -p配置root用户外网也可以连接并登录use mysqlupdate user set Host=’%’ where User=’root’; # 这里插一句如果表中已经存在的话就会报错，请认真查看报错信息，已经设置的话就不需要再设置了GRANT ALL ON . TO ‘root‘@’%’;FLUSH PRIVILEGES; # 刷新权限解惑物理机链接不到虚拟机的MySQL（错误排查）首先查看IP是否可以互相ping通（LinuxL:ifconfig-a， Windows：ipconfig）使用sudo netstat -tupln 或者 sudo lsof -i:端口 查看端口状态使用sudo vi /etc/mysql/mysql.conf.d/mysqld.cnf 将 bind-address = 127.0.0.1 注释 然后保存退出使用 sudo service mysql restart 重启MySQL服务 MySQL8 卸载查看MySQL依赖 ： dpkg –list|grep mysql 卸载： sudo apt-get remove mysql-common 卸载： sudo apt-get autoremove –purge mysql-server-8.0(这里版本对应即可) 清除残留数据: dpkg -l|grep ^rc|awk ‘{print$2}’|sudo xargs dpkg -P 再次查看MySQL的剩余依赖项: dpkg –list|grep mysql(这里一般就没有输出了，如果有执行下一步) 继续删除剩余依赖项，如：sudo apt-get autoremove –purge mysql-apt-config 【在执行过程中有的需要sudo】 【第6部执行完了就彻底删除了】","categories":[],"tags":[],"author":"张存"},{"title":"crontab每秒执行一次脚本","slug":"crontab每秒执行一次脚本","date":"2021-10-27T12:09:27.000Z","updated":"2021-10-27T12:11:02.621Z","comments":true,"path":"2021/10/27/crontab-mei-miao-zhi-xing-yi-ci-jiao-ben/","link":"","permalink":"https://blog.zhangcun.store/2021/10/27/crontab-mei-miao-zhi-xing-yi-ci-jiao-ben/","excerpt":"","text":"crontab的最小时间时间是一分钟，那么，如果想要更快的话，可以通过调用shell脚本，然后脚本中循环执行即可，代码如下 crontab中，每分钟调用一次sheel */1 * * * * bash /data/www/test.sh test.sh脚本如下 #!/bin/bash #循环29次 for((i=1; i&lt; 30; i++)); do /data/www/test/yii test/test #控制节奏，执行一次休息1秒 sleep 1; done 自己根据需要调整频率即可","categories":[],"tags":[],"author":"张存"},{"title":"服务器","slug":"服务器","date":"2021-10-27T11:40:42.000Z","updated":"2021-10-27T11:41:17.504Z","comments":true,"path":"2021/10/27/fu-wu-qi/","link":"","permalink":"https://blog.zhangcun.store/2021/10/27/fu-wu-qi/","excerpt":"","text":"服务器 目录1 远程管理 31.1 常用软件 31.2 Telnet：23 31.3 VNC：5905（默认5905） 31.4 xrdp：tcp/2820、tcp/2821 31.5 SSH：tcp/22 42 rsyslog网络日志系统 53 rsync备份与文件同步 54 unison双向文件同步 55 NFS与autofs远程文件调用 66 samba文件共享协议 67 vsftpd 68 dns 69 dhcp 710 LAMP-web apache 711 nginx 712 LEMP编译安装 713 tomcat 814 openvpn 815 postfix邮件服务器 816 IP-SAN iscsi 817 rsnapshot备份服务器 918 keepalive高可用集群 919 iptables防火墙 920 SVN版本控制服务 9 1 远程管理1.1 常用软件服务器端：Telnet、tigervnc、openssh客户端：Telnet、xmanager、putty、xshell … …1.2 Telnet：23默认root不登陆，明文yum install telnet.x86_64 telnet-server.x86_64systemctl list-unit-files | grep telnetsystemctl start telnet.socketlsof -i:23mv /etc/securetty /etc/securetty.bak1.3 VNC：5905（默认5905）yum install tigervnc-server.x86_64 tigervnc.x86_64cp /lib/systemd/system/vncserver@.service /etc/systemd/system/vncserver@:5.servicevi /etc/systemd/system/vncserver@:5.servicevncservernetstat -apn | grep vnc1.4 xrdp：tcp/2820、tcp/2821服务器端：yum install xrdp.x86_64 xrdp-devel.x86_64 xorgxrdp.x86_64chcon -R -t bin_t /usr/sbin/xrdpchcon -R -t bin_t /usr/sbin/xrdp-sesmansystemctl restart xrdp.servicenetstat -antup | grep xrdp客户端：linux：vinagrewindows：mstsc1.5 SSH：tcp/22主要功能：加密远程管理，加密远程文件传输（scp、sftp）1、Putty:(和puttygen一起使用)mkdir /root/.ssh vi authorized_keys 复制public keysystemctl restart sshd2、远程连接ssh -X &#114;&#111;&#x6f;&#x74;&#64;&#x31;&#57;&#x32;&#x2e;&#49;&#x36;&#56;&#x2e;&#x31;&#46;&#49;&#x38;&#50; #可以查看图形界面scp file &#x72;&#111;&#x6f;&#116;&#x40;&#x31;&#57;&#50;&#x2e;&#x31;&#x36;&#x38;&#46;&#49;&#46;&#49;&#56;&#x32;:/opt/ #传输文件scp -rp /home/ &#x72;&#x6f;&#x6f;&#116;&#64;&#49;&#57;&#x32;&#46;&#x31;&#54;&#56;&#46;&#x31;&#46;&#49;&#x38;&#x32;:/opt/ #传输目录sftp &#114;&#x6f;&#x6f;&#116;&#x40;&#x31;&#57;&#50;&#x2e;&#49;&#x36;&#x38;&#x2e;&#49;&#x2e;&#49;&#x38;&#x32;put a.txt #上传get b.txt #下载rename、rm3、秘钥级身份认证ssh-keygenssh-copy-id -i /root/.ssh/id_rsa.pub &#114;&#x6f;&#111;&#116;&#64;&#49;&#x39;&#50;&#x2e;&#x31;&#54;&#56;&#46;&#49;&#46;&#49;&#x38;&#x32;ssh 192.168.1.1824、ssh访问控制1）vi /etc/ssh/sshd_confAllowUsers 用户名/组名DenyUsers 用户名2）vi /etc/pam.d/sshd添加auth required /lib/security/pam_listfile.so item=user sense=denyfile=/etc/sshd_user_deny_list onerr=succeed所有/etc/sshd_user_deny_list里面的用户被拒绝ssh登录2 rsyslog网络日志管理系统 3 rsync备份与文件同步端口：tcp873远程文件同步，网站的备份，（不同系统）文件的同步，手动备份增量差异备份，单项文件同步rsync备份与文件同步.docx4 unison双向文件同步端口：使用ssh端口22双向同步操作，跨平台使用不仅支持本地对本地同步，也支持通过SSH、RSH和Socket等网络协议进行同步。unison双向文件同步.docx5 NFS与autofs远程文件调用端口：tcp2049Linux/unix，局域网，可以跨网段、RPC远程调用协议NFS与autofs服务.docx6 samba文件共享协议端口：tcp139、tcp445SMB文件共享协议（信息服务块）用于Linux与Windows，linux与linux的文件共享局域网文件共享、windows域控samba文件共享协议.docx7 vsftpd端口： tcp/20、tcp/21（被动方式下数据传输端口不固定）远程文件存取、不受平台限制、跨广域网vsftpd文件传输协议.docx8 dns端口：53域名解析服务器递归解析（本地名称服务器查）与迭代解析（客户端自己查）DNS.docx9 dhcpdhcp动态主机分配协议DHCP.docx10 LAMP-web apacheLAMP：linux-apache-mysql-phpapache端口：80mariadb端口：3306php-fpm端口：9000https加密端口：443LAMP-apache.docx11 nginx 12 LEMP编译安装LEMP：linux-nginx-mysql-php编译安装的方法wordpress、owncloud发布LEMP-nginx.docx13 tomcat 14 openvpn 15 postfix邮件服务器postfix邮件发送服务端口：25pop3邮件接收服务端口：110IMAP邮件访问协议端口：143加密–发送服务器smtp：995 –接受服务器pop3：25postfix邮件服务器.docx16 IP-SAN iscsi端口：3260IP-SAN.docx17 rsnapshot备份服务器备份服务器-rsnapshot.docx18 keepalive高可用集群一台web服务器出现故障，从服务器可以直接工作keepalived高可用集群.docx19 iptables防火墙 20 SVN版本控制服务SVN+http：80、8080","categories":[],"tags":[],"author":"张存"},{"title":"基本配置","slug":"基本配置","date":"2021-10-27T11:36:47.000Z","updated":"2021-10-27T11:53:55.409Z","comments":true,"path":"2021/10/27/ji-ben-pei-zhi/","link":"","permalink":"https://blog.zhangcun.store/2021/10/27/ji-ben-pei-zhi/","excerpt":"","text":"一、查看系统1、lscpu2、free -m #查看内存swap虚拟内存（交换分区）swap分区在系统的物理内存不够用的时候，把硬盘空间中的一部分空间释放出来，以供当前运行的程序使用。那些被释放的空间可能来自一些很长时间没有什么操作的程序，这些被释放的空间被临时保存到swap分区中，等到那些程序要运行时，再从swap分区中恢复保存的数据到内存中。主要应用于数据库服务器与 web 优化服务器（面试可能会问到）3、lsblk #查看服务器磁盘分布状态4、df -h #显示分区5、lspci #用来显示系统中所有PCI总线设备或连接到该总线上 的所有设备的工具lspci | grep Ethernet #网卡 VGA #显卡 audio #声卡6、lsusb #显示服务器usb接口数量7、查看系统版本cat /etc/redhat-release # 查看系统发行版本CentOS Linux release 7.2.1511 (Core) uname -r # 显示内核版本3.10.0-327.el7.x86_64 #3主版本号 10次版本号 稳定版(偶数)uname -n # 显示主机名 二、基础配置1、更换源cd /etc/yum.repos.d/yum clean allyum makecacheyum repolist 本地源vi junxi.repo[junxi_repo]name=www.junxilinux.combaseurl=http://192.168.1.5/hadoop/enable=1gpgcheck=0epel源yum install epel-release.noarch 1、防火墙iptables -L #防火墙规则iptables -t nat -L #防火墙nat表规则 2、服务systemctl list-unti-files | grep fire #查找fire的服务target #单元组socket #接口systemctl start/stop/restart/status firewalld.servicesystemctl enable/disable/is-actives firewalld.servicesystemctl list-dependencise firewalld.service #树形查看相关服务 3、centos7运行级别systemctl isolate proweroff.target #启动单元组 init 0 proweroff.target.wants #启动单元组成员 reboot.target init 6 multi-user.target init 3 #命令行模式 graphical.target init 5 #图形界面 rescue.target init 1 #单用户模式systemctl get-defaultrunlevel #查看当前运行级别systemctl set-defauil multi-user.target #修改默认运行级别 /etc/systemd/system #启动单元组.wants，优先级高，/usr/lib/systemd/system #链接到/etc下 4、网络设备命名vi /etc/sysconfig/grubGRUB_CMDLINE_LINUX=”net.ifnames=0 biosdevname=0 rd.lvm.lv=JUNXI/root rd.lvm.lv=JUNXI/swap rhgb quiet”grub2-mkconfig -o /boot/grub2/grub.cfg#把修改的配置文件设置生成道/boot/grub2/grub.cfg（重新生成GRUB配置，并更新内核参数） 5、修改网卡配置文件cd /etc/sysconfig/networkmv ifcfg-eno16 ifcfg-eth0vi ifcfg-eth0DEVICE=”eth0”DNS1=”192.168.1.1”IPADDR=192.168.1.181GATEWAY=192.168.1.1systemctl network restart Linux主流的发行版本：debianubuntun red hat什么是shell：它接收用户命令，然后调用相应的应用程序。 cd /etc/yum.reposlsmv Cent-B Cen..-bak 备份原有源ls /optmv /opt/Cen .lsyum clean all 清除缓存yum makecache 建立本地缓存yum repolist 列出系统中以配置的源yum search epel 查找epel源yum install epel-release.noarchyum repolist yum remove 关闭防火墙iptables -L 查看防火墙规则iptables -t nat -L 查看防火墙nat表规则systemctl list-unit-files 列出所有服务system list-unit-files | grep fire 列出有关防火墙的服务systemctl is-active firewalld.service 查看防火墙状态systemctl stop firewalld.service 关闭防火墙sys disable firewalld.ser 永久关闭防火墙 删除虚拟网络接口virbr0virsh net-list 查看所有虚拟网络删除default网络virsh net-destroy default 重启libvirtd后恢复virsh net-undefine def 重启系统后不回复 网络设备命名ifconfig 查看 ip addr编辑vi /etc/sysconfig/grub 文件 （nano 编辑 gedit图形界面编辑）添加GRUB_CMDLINE_LINUX=”net.ifnames=0 biosdevname=0 rd.lvm…’cat /etc/sysconfig/grub 查看是否成功写入grub2-mkconfig -o /boot/grub2/grub.cfg 把修改的配置文件设置生成道/boot/grub2/grub.cfg（重新生成GRUB配置，并更新内核参数）修改网卡配置文件cd /etc/sysconfig/network 跳转目录mv ifcfg-eno ifcfg-eth0 更改配置文件名称编辑vi ifcfg-eth0文件 将里面的eno16 改为eth0reboot 重启poweroff 关闭系统","categories":[],"tags":[],"author":"张存"},{"title":"网络管理服务","slug":"网络管理服务","date":"2021-10-27T11:34:57.000Z","updated":"2021-10-27T11:35:24.158Z","comments":true,"path":"2021/10/27/wang-luo-guan-li-fu-wu/","link":"","permalink":"https://blog.zhangcun.store/2021/10/27/wang-luo-guan-li-fu-wu/","excerpt":"","text":"网络管理服务有两个：NetworkManager：修改连接名-连接名连接配置文件优势：支持wifi，不会发生漂移，network:直接修改设备配置文件nmtui修改时，设备连接名改为一致 vi /etc/sysconfig/grubGRUB_CMDLINE_LINUX=……rhgb quiet net.ifnames=0 biosdevname=0”grub2-mkconfig -o /boot/grub2/grub.cfgsystemctl stop NetworkManager.servicesystemctl disable NetworkManager.servicerebootmv ifcfg-eno16777736 ifcfg-eth0vi ifcfg-eth0NAME=”eth0”DEVICE=”eth0”mv ifcfg-ens37 ifcfg-eth1NAME=”eth1”DEVICE=”eth1”","categories":[],"tags":[],"author":"张存"},{"title":"压缩与解压缩","slug":"压缩与解压缩","date":"2021-10-27T11:30:20.000Z","updated":"2021-10-27T11:31:12.226Z","comments":true,"path":"2021/10/27/ya-suo-yu-jie-ya-suo/","link":"","permalink":"https://blog.zhangcun.store/2021/10/27/ya-suo-yu-jie-ya-suo/","excerpt":"","text":"1 常用压缩工具gzip：压缩与解压缩工具bzip2：块排序压缩工具tar：归档工具zip：打包压缩工具，支持正则，有自己的转义符2 gzipgzip：用于压缩一个或多个文件，并且原文件会被压缩文件取代gunzip：用于将压缩文件还原为原文件压缩文件是原文件的1、实例gzip aaa.doc #压缩文件du -sh aaa.doc.gzgunzip aaa.doc.gz #解压文件gzip -d aaa.doc.gz #解压文件du -sh aaa.doc2、查看压缩文件内容gunzip -c rsnapshot.conf.gzzcat rsnapshot.conf.gzzless rsnapshot.conf.gzzmore rsnapshot.conf.gz3 bzip2降低压缩速度，提高压缩质量bzip2 aaa.docbunzip2 aaa.doc.bz24 tartar：归档文件工具，没有压缩功能选项c：创建新的归档文件r：将某一文件或某些文件追加到已经存在的归档文件t：列出文档内容，查看已经备份了哪些文件u：更新文件x：释放归档文件辅选项-f：（必选）后面紧跟文件名-v：现实操作时的详细信息-z：调用gzip进行压缩-j：调用bzip2进行压缩-p：不改变文件原来的属性-k：不覆盖已经存在的同名的文件-N：只打包比DATE日期新的文件-C：指定解压目录实例mkdir -p /opt/dir/test{1..50}.txttar cvf dir.tar dir #归档dir目录tar xvf dir.tar #释放归档文件tar tvf dir.tar | more #查看归档文件内容tar zcvf dir.tar.gz dir #调用gzip归档并压缩tar zxvf dir.tar.gz dir #解压缩tar zxvf dir.tar.gz -C /mnt/ #指定解压目录tar rvf dir.tar test/ #将test目录归档追加到归档文件dir.tar中5 zip选项-r：递归处理-l：列出压缩文件内容-d：指定解压目录实例zip -r dir.zip dir/ #递归压缩unzip dir.zip #解压缩unzip -l dir.zip #列出压缩文件内容unzip dir.zip -d /mnt #指定解压目录","categories":[],"tags":[],"author":"张存"},{"title":"关闭selinux：","slug":"关闭selinux：","date":"2021-10-27T11:27:34.000Z","updated":"2021-10-27T11:33:42.533Z","comments":true,"path":"2021/10/27/guan-bi-selinux/","link":"","permalink":"https://blog.zhangcun.store/2021/10/27/guan-bi-selinux/","excerpt":"","text":"setenforce 0如果http为编译安装，selinux上下文策略与rpm安装不同，需要使用audit2allow，该工具读物审计日志并创建selinux允许审计失败的政策：yum install /usr/bin/audit2allow #进行安装或者yum install setroubleshoot #安装selinux排障工具过滤审计日志文件的失败写下上下文被拒绝日志audit.loggrep check.py /var/log/audit/audit.log在找到所有否认上下文我使用audit2allow创建允许政策ps -efZ |grep keepalived #确认Keepalived进程上下文为keepalived_tgrep keepalived_t /var/log/audit/audit.log | audit2allow -M keepalived_tsemodule -i keepalived_t.pp #独立创建新的Keepalived访问策略 SelinuxGentenforce 0 —- permissive //临时关闭 1 —–enforcingvi /etc/selinux/config chcon -R -t httpd_sys_content_t /web //修改目录的上下文ll -Z -d /web/ //查看上下文 semanage port -l | grep httpd //查看默认端口Getsebool -a //布尔值","categories":[],"tags":[],"author":"张存"},{"title":"vi编辑器","slug":"vi编辑器","date":"2021-10-27T11:23:33.000Z","updated":"2021-10-27T11:24:49.586Z","comments":true,"path":"2021/10/27/vi-bian-ji-qi/","link":"","permalink":"https://blog.zhangcun.store/2021/10/27/vi-bian-ji-qi/","excerpt":"","text":"Vi是linux/unix系统内置的最高效的创建和编辑的文本工具。命令模式编辑模式末行模式i光标所在左侧输入正文a光标所在右侧输入正文s光标所在字符输入正文复制nyy1,5 co 10 将1到5行的所有内容，复制到第10行K（上） j（下）h（左）l（右）删除dG 删除至文件末尾d0：删除至行首d$: 删除至行尾：1，5 dx/X 向后 向前/char ?char /从上往下 ？从下往上n/N 继续查找替换r/R:1,10s /old/new 在第一行到第十行这个范围内替换，只替换每行的一个old：1,10s /old/new/g 在第一行到第十行这个范围内进行全部替换。：%s /old/new/g 进行全文替换：%s#old#new#g 进行全文替换。分隔符可以是/#:%s ,old,new,g 进行全文替换:%s /^/#/g:%s /$/#/g:%s #\\#/#g 将\\替换成/:%s /#/$/g:1,12w /root/filename 另存为：r ~/filename 读一个文件：r ！ls –l 将ls –l 命令查果，读到文件中。：19 r aa.txt 将aa.txt 文件，读到19行的下面。：！ ls –l 执行shell命令：e /etc/filename 打开/etc/filename文件：set nu 设置行号：set nonu 关闭行号vim -o FORWARD.sh FORWARD.sh.bc 同时打开两个文件Ctrl+shift++ #放大Ctrl+- #缩小Ctrl+w #跳转窗口","categories":[],"tags":[],"author":"张存"},{"title":"centos7通过yum安装JDK1.8","slug":"centos7通过yum安装JDK1-8","date":"2021-10-27T07:47:04.000Z","updated":"2021-10-27T07:47:15.180Z","comments":true,"path":"2021/10/27/centos7-tong-guo-yum-an-zhuang-jdk1-8/","link":"","permalink":"https://blog.zhangcun.store/2021/10/27/centos7-tong-guo-yum-an-zhuang-jdk1-8/","excerpt":"","text":"安装之前先检查一下系统有没有自带open-jdk 命令： rpm -qa |grep java rpm -qa |grep jdk rpm -qa |grep gcj 如果没有输入信息表示没有安装。 如果安装可以使用rpm -qa | grep java | xargs rpm -e –nodeps 批量卸载所有带有Java的文件 这句命令的关键字是java 首先检索包含java的列表 yum list java* 检索1.8的列表 yum list java-1.8* 安装1.8.0的所有文件 yum install java-1.8.0-openjdk* -y 使用命令检查是否安装成功 java -version 到此安装结束了。这样安装有一个好处就是不需要对path进行设置，自动就设置好了","categories":[],"tags":[],"author":"张存"},{"title":"linux下显示完整路径，linux下显示绝对路径","slug":"linux下显示完整路径，linux下显示绝对路径","date":"2021-10-27T07:44:28.000Z","updated":"2021-10-27T07:45:41.079Z","comments":true,"path":"2021/10/27/linux-xia-xian-shi-wan-zheng-lu-jing-linux-xia-xian-shi-jue-dui-lu-jing/","link":"","permalink":"https://blog.zhangcun.store/2021/10/27/linux-xia-xian-shi-wan-zheng-lu-jing-linux-xia-xian-shi-jue-dui-lu-jing/","excerpt":"","text":"linux下，命令行显示路径仅最后一个文件名，非常不方便，想显示完整路径。环境背景：linux，无root权限，可sudo(为了服务器安全，一般只给管理员root账号和密码，普通账号仅sudo权限) 回到顶部【1】修改环境变量PS1 （1）临时生效命令行提示符完全显示完整的工作目录名称：export PS1=’[\\u@\\h $PWD]$’ （2）永久生效vi编辑/etc/profile文件在最后加上export PS1=’[\\u@\\h $PWD]$’ 修改完成后，执行: source /etc/profile 使配置生效即可。 （3）其他方式相关命令行提示符只列出最后一个目录： export PS1=’[\\u@\\h \\W]$’ 命令行提示符显示完整工作目录，当前用户目录会以 ~代替： export PS1=’[\\u@\\h \\w]$’ 回到顶部 【2】命令释义复制代码\\u 显示当前用户账号\\h 显示当前主机名\\W 只显示当前路径最后一个目录\\w 显示当前绝对路径（当前用户目录会以 ~代替）$PWD 显示当前全路径$ 显示命令行’$’或者’#’符号复制代码然后问题来了，vi 退出时，’:wq!‘回车后提示：E45: ‘readonly’ option is set (add ! to override) 。原因是权限不够，非root权限。解决方法:q! 退出，然后命令行输入 sudo !!，再次vi编辑即可。sudo !! // 解释：sudo来执行上一条命令，’!!’ 表示上一条命令，linux中’!’的用法可以参见参考[3]参考：[1] Linux 修改命令提示符当前路径的显示方式[2] VIM提文件权限问题:…e45 readonly option is set (add!to override)[3] Linux命令行下”!”的十个神奇用法","categories":[],"tags":[],"author":"张存"},{"title":"k8s创建ubuntu容器时出现Back-off restarting failed container问题","slug":"k8s创建ubuntu容器时出现Back-off-restarting-failed-container问题","date":"2021-10-27T07:39:24.000Z","updated":"2021-10-27T07:40:52.612Z","comments":true,"path":"2021/10/27/k8s-chuang-jian-ubuntu-rong-qi-shi-chu-xian-back-off-restarting-failed-container-wen-ti/","link":"","permalink":"https://blog.zhangcun.store/2021/10/27/k8s-chuang-jian-ubuntu-rong-qi-shi-chu-xian-back-off-restarting-failed-container-wen-ti/","excerpt":"","text":"1、问题：k8s创建ubuntu容器时出现Back-off restarting failed container，容器一直进行重启。 2.原因：对于像ubuntu这样的系统级docker ，用k8s集群启动管理后，会自动关闭，解决方法就是 让其一直在运行，所以在yaml文件中增加command命令即可。3.解决：在yaml中添加如下参数：command: [ “/bin/bash”, “-c”, “–” ]args: [ “while true; do sleep 30; done;” ] ubuntu.yaml apiVersion: extensions/v1beta1kind: Deploymentmetadata: name: ubuntu-deployspec: replicas: 1 template: metadata: labels: name: ubuntu spec: containers: - name: ubuntu-tz command: [“/bin/bash”,”-c”,”–”] args: [“while true; do sleep 30; done;”] securityContext: privileged: true image: ubuntu:16.04 重新进行部署就可以了~~~","categories":[],"tags":[],"author":"张存"},{"title":"Linux开启ipv4转发","slug":"Linux开启ipv4转发","date":"2021-10-27T06:44:47.000Z","updated":"2021-10-27T06:46:27.162Z","comments":true,"path":"2021/10/27/linux-kai-qi-ipv4-zhuan-fa/","link":"","permalink":"https://blog.zhangcun.store/2021/10/27/linux-kai-qi-ipv4-zhuan-fa/","excerpt":"","text":"查看IP转发功能的状态，若net.ipv4.ip_forward为0，表示禁止进行ip转发。 sysctl net.ipv4.ip_forwardnet.ipv4.ip_forward = 0修改 /etc/sysctl.conf： net.ipv4.ip_forward = 1执行如下命令使修改生效： sysctl -p /etc/sysctl.conf","categories":[],"tags":[],"author":"张存"},{"title":"用Nginx快速搭建文件服务器","slug":"用Nginx快速搭建文件服务器","date":"2021-10-27T06:38:46.000Z","updated":"2021-10-27T06:42:25.995Z","comments":true,"path":"2021/10/27/yong-nginx-kuai-su-da-jian-wen-jian-fu-wu-qi/","link":"","permalink":"https://blog.zhangcun.store/2021/10/27/yong-nginx-kuai-su-da-jian-wen-jian-fu-wu-qi/","excerpt":"","text":"使用Nginx在局域网内和同事共享文件的好方法。 1 安装nginx sudo apt-get install nginx2 创建conf文件 sudo gedit /etc/nginx/conf.d/file_server.conf修改conf文件如下： server &#123; listen 80; server_name 10.1.2.3; # 自己PC的ip或者服务器的域名 charset utf-8; # 避免中文乱码 root /home/xx/share; location / &#123; autoindex on; # 索引 autoindex_exact_size on; # 显示文件大小 autoindex_localtime on; # 显示文件时间 &#125; &#125; 3 使配置生效 sudo rm /etc/nginx/sites-enabled/defaultsudo service nginx reload4 访问 浏览器里直接输入 http://10.1.2.3","categories":[],"tags":[],"author":"张存"},{"title":"centos7使用yum安装MongoDB4.4","slug":"centos7使用yum安装MongoDB4-4","date":"2021-10-27T06:26:13.000Z","updated":"2021-10-27T06:27:39.982Z","comments":true,"path":"2021/10/27/centos7-shi-yong-yum-an-zhuang-mongodb4-4/","link":"","permalink":"https://blog.zhangcun.store/2021/10/27/centos7-shi-yong-yum-an-zhuang-mongodb4-4/","excerpt":"","text":"创建repovi /etc/yum.repos.d/mongodb-org-4.4.repo 写入repo[mongodb-org-4.4]name=MongoDB 4.4 Repositorybaseurl=https://repo.mongodb.org/yum/redhat/$releasever/mongodb-org/4.4/$basearch/gpgcheck=0enabled=1 yun 安装yum -y install mongodb-org 设置启动systemctl enable mongodsystemctl start mongod 本机命令行进入MongoDBmongo 至此安装完毕","categories":[],"tags":[],"author":"张存"},{"title":"Linux 硬盘分区生效命令partprobe","slug":"Linux-硬盘分区生效命令partprobe","date":"2021-10-27T06:22:19.000Z","updated":"2021-10-27T06:25:06.438Z","comments":true,"path":"2021/10/27/linux-ying-pan-fen-qu-sheng-xiao-ming-ling-partprobe/","link":"","permalink":"https://blog.zhangcun.store/2021/10/27/linux-ying-pan-fen-qu-sheng-xiao-ming-ling-partprobe/","excerpt":"","text":"在Linux中使用fdisk命令进行分区时，有时会遇到“WARNING: Re-reading the partition table failed with error 16: Device or resource busy.The kernel still uses the old table.The new table will be #used at the next reboot.”这种告警信息。如下所示 [root@localhost ~]# fdisk /dev/sde The number of cylinders for this disk is #set to 18928.There is nothing wrong with that, but this is larger than 1024,and could in certain setups cause problems with: software that runs at boot time (e.g., old versions of LILO) booting and partitioning software from other OSs(e.g., DOS FDISK, OS/2 FDISK) Command (m for help): p Disk /dev/sde: 155.6 GB, 155692564480 bytes255 heads, 63 sectors/track, 18928 cylindersUnits = cylinders of 16065 * 512 = 8225280 bytes Device Boot Start End Blocks Id System/dev/sde1 1 18275 146793906 5 Extended/dev/sde5 1 18275 146793874+ 83 Linux Command (m for help): nCommand action l logical (5 or over) p primary partition (1-4)pPartition number (1-4): 2First cylinder (18276-18928, default 18276):Using default value 18276Last cylinder or +size or +sizeM or +sizeK (18276-18928, default 18928):Using default value 18928 Command (m for help): wThe partition table has #been #altered! Calling ioctl() to re-read partition table. WARNING: Re-reading the partition table failed with error 16: Device or resource busy.The kernel still uses the old table.The new table will be #used at the next reboot.Syncing disks. 此时使用fdisk命令看不到新建的分区信息，可以使用partprobe命令解决这个问题而不用重启系统，因为partprobe可以使kernel重新读取分区信息，从而避免重启系统。 partprobe - inform the OS of partition table changes DESCRIPTION This manual page documents briefly the partprobe command. partprobe is a program that informs the operating system kernel of partition table changes, by requesting that the operating system re-read the partition table.","categories":[],"tags":[],"author":"张存"},{"title":"华为SSLVPN客户端","slug":"华为SSLVPN客户端","date":"2021-10-27T05:55:53.000Z","updated":"2021-10-27T06:03:33.606Z","comments":true,"path":"2021/10/27/hua-wei-sslvpn-ke-hu-duan/","link":"","permalink":"https://blog.zhangcun.store/2021/10/27/hua-wei-sslvpn-ke-hu-duan/","excerpt":"","text":"工具名称secoclient工具介绍 secoclient-android-7.0.2.26.apk //用于Aandroidhttp://www.corem.com.cn/sites/default/files/tools/secoclient/secoclient-android-7.0.2.26.apk secoclient-iOS-7.0.2.26.ipa//用于ioshttp://www.corem.com.cn/sites/default/files/tools/secoclient/secoclient-iOS-7.0.2.26.ipa secoclient-linux-32-7.0.2.26.run//用于linux 32bithttp://www.corem.com.cn/sites/default/files/tools/secoclient/secoclient-linux-32-7.0.2.26.run secoclient-linux-64-7.0.2.26.run//用于linux 64nethttp://www.corem.com.cn/sites/default/files/tools/secoclient/secoclient-linux-64-7.0.2.26.run secoclient-macosx-7.0.2.26.tar.gz用于macOShttp://www.corem.com.cn/sites/default/files/tools/secoclient/secoclient-macosx-7.0.2.26.tar.gz secoclient-win-32-7.0.2.26.exe//用于windows32bithttp://www.corem.com.cn/sites/default/files/tools/secoclient/secoclient-win-32-7.0.2.26.exe secoclient-win-64-7.0.2.26.exe//用于windows64bithttp://www.corem.com.cn/sites/default/files/tools/secoclient/secoclient-win-64-7.0.2.26.exe","categories":[],"tags":[],"author":"张存"},{"title":"vim删除空行和注释","slug":"vim删除空行和注释","date":"2021-10-27T05:48:08.000Z","updated":"2021-10-27T05:48:54.349Z","comments":true,"path":"2021/10/27/vim-shan-chu-kong-xing-he-zhu-shi/","link":"","permalink":"https://blog.zhangcun.store/2021/10/27/vim-shan-chu-kong-xing-he-zhu-shi/","excerpt":"","text":"删除空行 :g/^$/d删除空行以及只有空格的行 :g/^\\s*$/d删除以 # 开头或 空格# 或 tab#开头的行 :g/^\\s*#/d对于 php.ini 配置文件，注释为 ; 开头 :g/^\\s*;/d使用正则表达式删除行 如果当前行包含 bbs ，则删除当前行 :/bbs/d删除从第二行到包含 bbs 的区间行 :2,/bbs/d删除从包含 bbs 的行到最后一行区间的行 :/bbs/,$d删除所有包含 bbs 的行 :g/bbs/d删除匹配 bbs 且前面只有一个字符的行 :g/.bbs/d删除匹配 bbs 且以它开头的行 :g/^bbs/d删除匹配 bbs 且以它结尾的行 :g/bbs$/d.ini 的注释是以 ; 开始的，如果注释不在行开头，那么删除 ; 及以后的字符 :%s/;.+//g删除 # 之后所有字符 %s/#.*//g","categories":[],"tags":[],"author":"张存"},{"title":"会计帮：“等我做会计发财了，就跟你离婚！”","slug":"会计帮：“等我做会计发财了，就跟你离婚！”","date":"2021-10-27T05:45:35.000Z","updated":"2021-10-27T05:45:47.939Z","comments":true,"path":"2021/10/27/hui-ji-bang-deng-wo-zuo-hui-ji-fa-cai-liao-jiu-gen-ni-chi-hun/","link":"","permalink":"https://blog.zhangcun.store/2021/10/27/hui-ji-bang-deng-wo-zuo-hui-ji-fa-cai-liao-jiu-gen-ni-chi-hun/","excerpt":"","text":"0 1 “等我做会计发财了，就和你离婚” 他淡淡地说 听完后，她心里暖暖的， 她想，没有比这更天长地久。 海枯石烂的承诺了。 （因为她深知，做会计的永远也不会发财） ——2018年度最佳微小说奖 0 2 “等我干财务发财了，我就买房和你结婚” 他暖暖地说， 听完后，她心里拔凉拔凉的！ 她想，这大概是最婉转的分手了。 （因为她深知，干财务的永远也不会发财） ——2018最佳微型小说提名奖 0 3 一位做会计的结婚不久，与几个朋友喝酒，醉倒后不省人事。被抬回家后，老婆试着用各种办法给他醒酒，都无济于事，于是打电话询问他的同事。同事说，我给他邮箱发一个报表，突然老公手机短信微信邮件同时响了，只见男人噌的一下从床上蹦起来，精神抖擞，大喊：“报表又出问题了？”老婆此时已泪流满面！原来老公养家真不容易！ ——致敬财会行业奉献青春、挥洒热血的兄弟姐妹 0 4 在财会这个行业，在行业内都称呼为“某经理”；李经理、陈经理、张经理，其实，就是一个“出报表的”，加班加通宵，吃饭更没规律，只因你要必须时刻保证每个数字都不能有错；连亲人和你见个面都要预约，不知道的人、不了解的人以为你早出晚归外面有娇娘，一年365天日夜没休息以为你是来自星星，赚着卖白菜的钱，操着卖白粉的心！做这行的没有一个会脑痴呆，因为每天大脑都在高速运转，回来了还要回忆一下整个部门的对照状况。 工作是高端大气上档次，工资是低调奢华接地气！这就是财会人的精神。 0 5 我问大师：“我是做会计的，压力大，吃不好，睡不好，工资少，别人有时间休假，而我却不行，感觉特别累且迷茫，心理堵的慌，大师，我该怎么办？” 禅师右手捂左胸，不语。 我追问大师：“您是说不要抱怨，要问心无愧，要对得起心中梦想，对吗？” 禅师摇了摇头说：“你离我远点，我出家以前就是做这行的！今天听你又说这些，心里堵得慌！ 0 6 有一天，在公园里····· 女：“有三室两厅吗？” 男：“没有！” 女：“有路虎，奥迪吗？” 男：“没有！” 女：“有7位数存款吗？” 男：“没有！” 女：“那你有啥？” 男：“我………” 女转身就要走··· 突然男的说：“我是做会计的” 女立刻回头拉住男的手，满脸崇拜的说道： “你不早说，工作量那么多，压力那么大，你还能活下来，一定是个潜力股，这就够了！够了！” ——这是2018年度最励志的段子！ 0 7 记者问一位大爷说：大爷，您保持年轻的秘诀是什么？ 大爷说：白天出报表，晚上忙加班，一天四包烟，天天吃泡面。 记者：啊？大爷您是做什么工作的？ 大爷：会计。 记者：那大爷您今年高寿？ 大爷：32 0 8 做会计的人吧，表面风光，内心彷徨；容颜未老，心已沧桑；小有成就，郁闷经常；比骡子累，比蚂蚁忙。 ——处理报表的时侯脑袋脱发面容憔悴，为的是多赚点钱回家孝敬父母，照顾妻儿。 如果你身边有做会计的朋友，请多给他一点帮助，因为如今财会这行不赚钱。 吃饭聚会就不要和他AA了，你请他吧； 有时间多陪陪他，约他吃饭，喝酒各种消费时你来买单吧，不要跟他提钱了； 工作压力已经很大，请理解她、包容他、打牌也故意输给他； 临走再塞个万儿八千的红包也行，让他感受到人间的温暖吧； 请紧密陪伴他，生活是相互扶持的！ 不说了，前边有人扔了个咸鸭蛋！！！ 看完以上的段子，你是不是感同身受，哭笑不得呢？ 虽然有一丢丢夸张搞笑的成分在，但是财会行业是真心不容易！每一个财会人都是可亲可敬的超级英雄！","categories":[],"tags":[],"author":"张存"},{"title":"jumpserver 重置用户密码、新建管理员账户以及重置mfa","slug":"jumpserver-重置用户密码以及新建管理员账户","date":"2021-10-27T03:49:37.000Z","updated":"2021-11-05T03:36:30.987Z","comments":true,"path":"2021/10/27/jumpserver-chong-zhi-yong-hu-mi-ma-yi-ji-xin-jian-guan-li-yuan-zhang-hu/","link":"","permalink":"https://blog.zhangcun.store/2021/10/27/jumpserver-chong-zhi-yong-hu-mi-ma-yi-ji-xin-jian-guan-li-yuan-zhang-hu/","excerpt":"","text":"进入容器：docker exec -it jms_core /bin/bash 重置密码命令：python manage.py changepassword xxxxpython manage.py changepassword 用户名 手动新建管理员账户： python manage.py createsuperuser –username=xxxxx –email=xxxxxxxxxxxxx jumpserver的mfa重置功能 ，解决jumpserver 某个用户得mfa得账户出现手机丢失，换手机得情况，我们就需要把这个人得mfa码给重置掉。docker exec -it jms_core /bin/bashcd appspython manage.py shell 设置需要修改的用户，xxxx, 修改后，第二次登录就需要重新绑定mfa了 from users.models import Useru = User.objects.get(username=’xxxx’)u.mfa_level=’0’u.otp_secret_key=’’u.save()","categories":[],"tags":[],"author":"张存"},{"title":"HTTP状态码","slug":"HTTP状态码","date":"2021-10-27T03:17:12.000Z","updated":"2021-10-27T03:19:08.559Z","comments":true,"path":"2021/10/27/http-zhuang-tai-ma/","link":"","permalink":"https://blog.zhangcun.store/2021/10/27/http-zhuang-tai-ma/","excerpt":"","text":"HTTP状态码当浏览者访问一个网页时，浏览者的浏览器会向网页所在服务器发出请求。当浏览器接收并显示网页前，此网页所在的服务器会返回一个包含HTTP状态码的信息头（server header）用以响应浏览器的请求。 HTTP状态码的英文为HTTP Status Code。 下面是常见的HTTP状态码： 200 - 请求成功301 - 资源（网页等）被永久转移到其它URL404 - 请求的资源（网页等）不存在500 - 内部服务器错误HTTP状态码分类HTTP状态码由三个十进制数字组成，第一个十进制数字定义了状态码的类型，后两个数字没有分类的作用。HTTP状态码共分为5种类型： HTTP状态码分类分类 分类描述1** 信息，服务器收到请求，需要请求者继续执行操作2** 成功，操作被成功接收并处理3** 重定向，需要进一步的操作以完成请求4** 客户端错误，请求包含语法错误或无法完成请求5** 服务器错误，服务器在处理请求的过程中发生了错误HTTP状态码列表: HTTP状态码列表状态码 状态码英文名称 中文描述100 Continue 继续。客户端应继续其请求101 Switching Protocols 切换协议。服务器根据客户端的请求切换协议。只能切换到更高级的协议，例如，切换到HTTP的新版本协议200 OK 请求成功。一般用于GET与POST请求201 Created 已创建。成功请求并创建了新的资源202 Accepted 已接受。已经接受请求，但未处理完成203 Non-Authoritative Information 非授权信息。请求成功。但返回的meta信息不在原始的服务器，而是一个副本204 No Content 无内容。服务器成功处理，但未返回内容。在未更新网页的情况下，可确保浏览器继续显示当前文档205 Reset Content 重置内容。服务器处理成功，用户终端（例如：浏览器）应重置文档视图。可通过此返回码清除浏览器的表单域206 Partial Content 部分内容。服务器成功处理了部分GET请求300 #Multiples# Choices 多种选择。请求的资源可包括多个位置，相应可返回一个资源特征与地址的列表用于用户终端（例如：浏览器）选择301 Moved Permanently 永久移动。请求的资源已被永久的移动到新URI，返回信息会包括新的URI，浏览器会自动定向到新URI。今后任何新的请求都应使用新的URI代替302 Found 临时移动。与301类似。但资源只是临时被移动。客户端应继续使用原有URI303 See Other 查看其它地址。与301类似。使用GET和POST请求查看304 Not Modified 未修改。所请求的资源未修改，服务器返回此状态码时，不会返回任何资源。客户端通常会缓存访问过的资源，通过提供一个头信息指出客户端希望只返回在指定日期之后修改的资源305 Use Proxy 使用代理。所请求的资源必须通过代理访问306 Unused 已经被废弃的HTTP状态码307 Temporary Redirect 临时重定向。与302类似。使用GET请求重定向400 Bad Request 客户端请求的语法错误，服务器无法理解401 Unauthorized 请求要求用户的身份认证402 Payment Required 保留，将来使用403 Forbidden 服务器理解请求客户端的请求，但是拒绝执行此请求404 Not Found 服务器无法根据客户端的请求找到资源（网页）。通过此代码，网站设计人员可设置”您所请求的资源无法找到”的个性页面405 Method Not Allowed 客户端请求中的方法被禁止406 Not Acceptable 服务器无法根据客户端请求的内容特性完成请求407 Proxy Authentication Required 请求要求代理的身份认证，与401类似，但请求者应当使用代理进行授权408 Request Time-out 服务器等待客户端发送的请求时间过长，超时409 Conflict 服务器完成客户端的 PUT 请求时可能返回此代码，服务器处理请求时发生了冲突410 Gone 客户端请求的资源已经不存在。410不同于404，如果资源以前有现在被永久删除了可使用410代码，网站设计人员可通过301代码指定资源的新位置411 Length Required 服务器无法处理客户端发送的不带Content-Length的请求信息412 Precondition Failed 客户端请求信息的先决条件错误413 Request Entity Too Large 由于请求的实体过大，服务器无法处理，因此拒绝请求。为防止客户端的连续请求，服务器可能会关闭连接。如果只是服务器暂时无法处理，则会包含一个Retry-After的响应信息414 Request-URI Too Large 请求的URI过长（URI通常为网址），服务器无法处理415 Unsupported Media Type 服务器无法处理请求附带的媒体格式416 Requested range not satisfiable 客户端请求的范围无效417 Expectation Failed 服务器无法满足Expect的请求头信息500 Internal Server Error 服务器内部错误，无法完成请求501 Not Implemented 服务器不支持请求的功能，无法完成请求502 Bad Gateway 作为网关或者代理工作的服务器尝试执行请求时，从远程服务器接收到了一个无效的响应503 Service Unavailable 由于超载或系统维护，服务器暂时的无法处理客户端的请求。延时的长度可包含在服务器的Retry-After头信息中504 Gateway Time-out 充当网关或代理的服务器，未及时从远端服务器获取请求505 HTTP Version not supported 服务器不支持请求的HTTP协议的版本，无法完成处理| 排序方法 | 平均情况 | 最好情况 | 最坏情况 | 辅助空间 | 稳定性 ||:—–|:—–|:—–|:—–|:—–|:—–|| 冒泡排序 | O(n²) | O(nlogn) | O(n²) | O(1) | 稳定 || 简单选择 | O(n²) | O(n²) | O(n²) | O(1) | 稳定 || 直接插入 | O(n²) | O(n) | O(n²) | O(1) | 稳定 || 希尔排序 | O(nlogn)O(n²) | O(n^1.3) | O(n²) | O(1) | 不稳定 || 堆排序 | O(nlogn) | O(nlogn) | O(nlogn) | O(1) | 不稳定 || 归并排序 | O(nlogn) | O(nlogn) | O(nlogn) | O(n) | 不稳定 || 快速排序 | O(nlogn) | O(nlogn) | O(n²) | O(nlogn)O(n) | 不稳定 |","categories":[],"tags":[],"author":"张存"},{"title":"Centos 更改MySQL5.7数据库目录位置","slug":"Centos-更改MySQL5-7数据库目录位置","date":"2021-10-27T03:14:09.000Z","updated":"2021-10-27T03:15:40.280Z","comments":true,"path":"2021/10/27/centos-geng-gai-mysql5-7-shu-ju-ku-mu-lu-wei-zhi/","link":"","permalink":"https://blog.zhangcun.store/2021/10/27/centos-geng-gai-mysql5-7-shu-ju-ku-mu-lu-wei-zhi/","excerpt":"","text":"Centos 通过yum安装(RPM分发进行安装)MySQL的几个人默认目录如下： 目录 目录内容/usr/bin 客户端程序和脚本/usr/sbin mysqld服务器/var/lib/mysql 日志文件，数据库文件/usr/share/mysql 错误消息和字符集文件/etc/my.cnf 配置文件假如要把目录移到/home/data下需要进行下面几步： 1、home目录下建立data目录 1 mkdir -p /home/data &amp; cd /home/data/ 2、把MySQL服务进程停掉 1 [root@localhost data]# mysqladmin -u root -p shutdown2 Enter password: 3、把/var/lib/mysql整个目录移到/home/data 1 mv /var/lib/mysql /home/data/ 或者 1 cp -R /var/lib/mysql /home/data/ 这样就把MySQL的数据文件移动到了/home/data/mysql下 4、设置/home/data/下mysql文件夹的属主和权限 1 chown -R mysql:mysql /home/data/mysql复制代码1 [root@localhost data]# ls2 mysql3 [root@localhost data]# ll4 drwxr-x–x. 5 root root# 4096 10月 31 04:03 mysql5 [root@localhost data]# chown -R mysql:mysql /home/data/mysql6 [root@localhost data]# ll7 drwxr-x–x. 5 mysql mysql# 4096 10月 31 04:03 mysql复制代码 5、修改配置文件/etc/my.cnf 为保证MySQL能够正常工作，需要指明mysql.sock文件的产生位置。修改socket=/var/lib/mysql/mysql.sock一行中等号右边的值为：/home/data/mysql/mysql.sock 以及修改datadir为/home/data/mysql操作如下： 1 #datadir=/var/lib/mysql2 datadir=/home/data/mysql3 #socket=/var/lib/mysql/mysql.sock4 socket=/home/data/mysql/mysql.sock 6、重新启动MySQL服务 1 service mysqld start 往往坑总是一个接着一个。 启动异常 以上截图看不到任何问题，我们来查看一下日志 1 tail -n 1000 /var/log/mysqld.log -f 详细的日志信息 1 2017-10-31T08:48:06.533321Z 0 [Warning] Can’t create test file /home/data/mysql/localhost.lower-test2 2017-10-31T08:48:06.533401Z 0 [Note] /usr/sbin/mysqld (mysqld 5.7.20) starting as process 25325 …3 2017-10-31T08:48:06.536585Z 0 [Warning] Can’t create test file /home/data/mysql/localhost.lower-test4 2017-10-31T08:48:06.536617Z 0 [Warning] Can’t create test file /home/data/mysql/localhost.lower-test 解决：设置一个SELinux即可 1 setenforce 0 纵然世间炎凉百态！我自依旧初心不改！！","categories":[],"tags":[],"author":"张存"},{"title":"Nginx的四层和七层代理","slug":"Nginx的四层和七层代理","date":"2021-10-27T03:11:12.000Z","updated":"2021-10-27T03:11:57.773Z","comments":true,"path":"2021/10/27/nginx-de-si-ceng-he-qi-ceng-dai-li/","link":"","permalink":"https://blog.zhangcun.store/2021/10/27/nginx-de-si-ceng-he-qi-ceng-dai-li/","excerpt":"","text":"理论部分： 所谓四层负载均衡，也就是主要通过报文中的目标地址和端口，再加上负载均衡设备设置的服务器选择方式，决定最终选择的内部服务器，它一般走的是tcp，udp协议 所谓七层负载均衡，也称为“内容交换”，也就是主要通过报文中的真正有意义的应用层内容，再加上负载均衡设备设置的服务器选择方式，决定最终选择的内部服务器，他走的是http协议。 四层代理实例： 和http同等级：所以一般只在http上面一段设置， stream { server { listen 30028; proxy_pass appserver; } upstream appserver{ server 10.0.0.12:8080 weight=2; server 10.0.0.13:8080 weight=2; }} 七层代理实例： 在http段里设置： upstream appserver { server 10.0.0.12:8080 weight=2; server 10.0.0.13:8080 weight=2;}server { listen 80; server_name localhost; location / { proxy_pass http://appserver; }","categories":[],"tags":[],"author":"张存"},{"title":"Docker利用Dockerfile构建tomcat7-jdk8环境","slug":"Docker利用Dockerfile构建tomcat7-jdk8环境","date":"2021-10-27T02:36:53.000Z","updated":"2021-10-27T02:37:38.905Z","comments":true,"path":"2021/10/27/docker-li-yong-dockerfile-gou-jian-tomcat7-jdk8-huan-jing/","link":"","permalink":"https://blog.zhangcun.store/2021/10/27/docker-li-yong-dockerfile-gou-jian-tomcat7-jdk8-huan-jing/","excerpt":"","text":"Dockerfile构建tomcat7-jdk8环境Dockerfile常用命令(1) FROM: 制作image时依据的基本image(2) RUN：制作image时执行的命令，一般在Dockerfile中多次出现(3) CMD：启动docker时执行的命令，在Dockerfile中只出现一次(4) ENV：设置环境变量(5) COPY：制作image时，将文件系统中的文件复制到Docker镜像中(6) WORKDIR：设置工作目录(7) EXPOSE：设置向外暴露的端口(8) VOLUME：设置容器与外界映射的目录[1].创建dockerfile存放目录mkdir -p /app/Docker/Tomcatcd /app/Docker/Tomcat/ [2].编写Dockerfile文件cat&gt;/app/Docker/Tomcat/Dockerfile&lt;&lt;EOFFROM centos#指定基础镜像来自于哪里MAINTAINER Tomcat7 images#进行说明ADD jdk1.8.0_144/ /opt/jdk#添加jdkADD apache-tomcat-7.0.75 /opt/tomcat#添加tomcat#COPY xxx.war /opt/tomcat/webapps/#war包可进行挂在或者直接拷贝EXPOSE 8080#开发端口RUN /usr/bin/sed -i ‘107a JAVA_HOME=/opt/jdk’ /opt/tomcat/bin/catalina.sh#配置环境变量CMD [“/bin/bash”,”-c”,”/opt/tomcat/bin/catalina.sh run”]#开启TomcatEOF [3].构建镜像docker build -t tomcat7:01 /app/Docker/Tomcat[4].启动容器docker run -d –name “math_tomcat01” -p8080:8080 tomcat7:01docker ps[5].测试,并查看日志测试：curl 127.0.0.1:8080 -I查看日志：docker logs -f math_tomcat01[6].查看负载docker stats tomcat01[7].利用数据方式启动 mkdir -p /app/tomcatcd /app/tomcatdocker run -d –name “tomcat01” tomcat:01#拷贝出需要后续配置的文件（保持与镜像内文件格式相同）docker cp -a tomcat01:/opt/tomcat/webapps ./docker cp -a tomcat01:/opt/tomcat/logs ./docker cp -a tomcat01:/opt/tomcat/bin ./docker cp -a tomcat01:/opt/tomcat/conf ./docker rm -f tomcat01echo “欢迎使用tomcat7-jdk8”&gt;&gt;/app/data/tomcat/webapps/ROOT/index.html创建数据卷:docker run –name “web_data” -v /app/data/tomcat/webapps:/opt/tomcat/webapps -v /app/data/tomcat/bin:/opt/tomcat/bin -v /app/data/tomcat/conf:/opt/tomcat/conf -v /app/data/tomcat/logs:/opt/tomcat/logs centos创建tomcat容器启动:docker run -d -p8080:8080 –name “tomcat” –volumes-from web_data tomcat:01","categories":[],"tags":[],"author":"张存"},{"title":"linux系统负载检查方法","slug":"linux系统负载检查方法","date":"2021-10-27T02:27:11.000Z","updated":"2021-10-27T02:33:16.816Z","comments":true,"path":"2021/10/27/linux-xi-tong-fu-zai-jian-cha-fang-fa/","link":"","permalink":"https://blog.zhangcun.store/2021/10/27/linux-xi-tong-fu-zai-jian-cha-fang-fa/","excerpt":"","text":"1：load Average 1.1：什么是Load？什么是Load Average? Load 就是对计算机干活多少的度量（WikiPedia：the system Load is a measure of the amount of work that a compute system is doing） 简单的说是进程队列的长度。Load Average 就是一段时间（1分钟、5分钟、15分钟）内平均Load。【参考文章：unix Load Average Part1：How It Works】 1.2：查看指令： w or uptime or procinfo or top load average: 0.02, 0.27, 0.17 1 per/minute 5 per/minute 15 per/minute 1.3：如何判断系统是否已经Over Load？对一般的系统来说，根据cpu数量去判断。如果平均负载始终在1.2一下，而你有2颗cup的机器。那么基本不会出现cpu不够用的情况。也就是Load平均要小于Cpu的数量1.4：Load与容量规划（Capacity Planning） 一般是会根据15分钟那个load 平均值为首先。 1.5：Load误解：1：系统load高一定是性能有问题。 真相：Load高也许是因为在进行cpu密集型的计算 2：系统Load高一定是CPU能力问题或数量不够。 真相：Load高只是代表需要运行的队列累计过多了。但队列中的任务实际可能是耗Cpu的，也可能是耗i/0奶子其他因素的。3：系统长期Load高，首先增加CPU 真相：Load只是表象，不是实质。增加CPU个别情况下会临时看到Load下降，但治标不治本。 2：在Load average 高的情况下如何鉴别系统瓶颈。 是CPU不足，还是io不够快造成或是内存不足？ 2.1：查看系统负载vmstatVmstatprocs ———–memory———- —swap– —–io—- –system– —-cpu—-r b swpd free buff cache si so bi bo in cs us sy id wa0 0# 100152 2436 97200 289740 0 1 34 45 99 33 0 0# 99 0 procsr 列表示运行和等待cpu时间片的进程数，如果长期大于1，说明cpu不足，需要增加cpu。b 列表示在等待资源的进程数，比如正在等待I/O、或者内存交换等。cpu 表示cpu的使用状态us 列显示了用户方式下所花费 CPU 时间的百分比。us的值比较高时，说明用户进程消耗的cpu时间多，但是如果长期大于50%，需要考虑优化用户的程序。sy 列显示了内核进程所花费的cpu时间的百分比。这里us + sy的参考值为80%，如果us+sy 大于 80%说明可能存在CPU不足。wa 列显示了IO等待所占用的CPU时间的百分比。这里wa的参考值为30%，如果wa超过30%，说明IO等待严重，这可能是磁盘大量随机访问造成的，也可能磁盘或者磁盘访问控制器的带宽瓶颈造成的(主要是块操作)。id 列显示了cpu处在空闲状态的时间百分比system 显示采集间隔内发生的中断数in 列表示在某一时间间隔中观测到的每秒设备中断数。cs列表示每秒产生的上下文切换次数，如当 cs 比磁盘 I/O 和网络信息包速率高得多，都应进行进一步调查。memoryswpd 切换到内存交换区的内存数量(k表示)。如果swpd的值不为0，或者比较大，比如超过了100m，只要si、so的值长期为0，系统性能还是正常free 当前的空闲页面列表中内存数量(k表示)buff 作为buffer cache的内存数量，一般对块设备的读写才需要缓冲。cache: 作为page cache的内存数量，一般作为文件系统的cache，如果cache较大，说明用到cache的文件较多，如果此时IO中bi比较小，说明文件系统效率比较好。swapsi 由内存进入内存交换区数量。so由内存交换区进入内存数量。IObi 从块设备读入数据的总量（读磁盘）（每秒kb）。bo 块设备写入数据的总量（写磁盘）（每秒kb）这里我们设置的bi+bo参考值为1000，如果超过1000，而且wa值较大应该考虑均衡磁盘负载，可以结合iostat输出来分析。 2.2：查看磁盘负载iostat每隔2秒统计一次磁盘IO信息，直到按Ctrl+C终止程序，-d 选项表示统计磁盘信息， -k 表示以每秒KB的形式显示，-t 要求打印出时间信息，2 表示每隔 2 秒输出一次。第一次输出的磁盘IO负载状况提供了关于自从系统启动以来的统计信息。随后的每一次输出则是每个间隔之间的平均IO负载状况。 #iostat -x 1 10Linux 2.6.18-92.el5xen 02/03/2009avg-cpu: %user %nice %system %iowait %steal %idle 1.10 0.00 4.82 39.54 0.07 54.46Device: rrqm/s wrqm/s r/s w/s rsec/s wsec/s avgrq-sz avgqu-sz await svctm %util rrqm/s: 每秒进行 merge 的读操作数目。即 delta(rmerge)/s wrqm/s: 每秒进行 merge 的写操作数目。即 delta(wmerge)/s r/s: 每秒完成的读 I/O 设备次数。即 delta(rio)/s w/s: 每秒完成的写 I/O 设备次数。即 delta(wio)/s rsec/s: 每秒读扇区数。即 delta(rsect)/s wsec/s: 每秒写扇区数。即 delta(wsect)/s rkB/s: 每秒读K字节数。是 rsect/s 的一半，因为每扇区大小为512字节。(需要计算) wkB/s: 每秒写K字节数。是 wsect/s 的一半。(需要计算) avgrq-sz: 平均每次设备I/O操作的数据大小 (扇区)。delta(rsect+wsect)/delta(rio+wio) avgqu-sz: 平均I/O队列长度。即 delta(aveq)/s/1000 (因为aveq的单位为毫秒)。 await: 平均每次设备I/O操作的等待时间 (毫秒)。即 delta(ruse+wuse)/delta(rio+wio) svctm: 平均每次设备I/O操作的服务时间 (毫秒)。即 delta(use)/delta(rio+wio) %util: 一秒中有百分之多少的时间用于 I/O 操作，或者说一秒中有多少时间 I/O 队列是非空的。即 delta(use)/s/1000 (因为use的单位为毫秒) 如果 %util 接近 100%，说明产生的I/O请求太多，I/O系统已经满负荷，该磁盘 可能存在瓶颈。 idle小于70% IO压力就较大了,一般读取速度有较多的wait. 同时可以结合vmstat 查看查看b参数(等待资源的进程数)和wa参数(IO等待所占用的CPU时间的百分比,高过30%时IO压力高) 另外还可以参考 一般: svctm &lt; await (因为同时等待的请求的等待时间被重复计算了)， svctm的大小一般和磁盘性能有关:CPU/内存的负荷也会对其有影响，请求过多也会间接导致 svctm 的增加。 await: await的大小一般取决于服务时间(svctm) 以及 I/O 队列的长度和 I/O 请求的发出模式。 如果 svctm 比较接近 await，说明I/O 几乎没有等待时间； 如果 await 远大于 svctm，说明 I/O队列太长，应用得到的响应时间变慢， 如果响应时间超过了用户可以容许的范围，这时可以考虑更换更快的磁盘，调整内核 elevator算法，优化应用，或者升级 CPU。 队列长度(avgqu-sz)也可作为衡量系统 I/O 负荷的指标，但由于 avgqu-sz 是按照单位时间的平均值，所以不能反映瞬间的 I/O 洪水。 别人一个不错的例子.(I/O 系统 vs. 超市排队) 举一个例子，我们在超市排队 checkout 时，怎么决定该去哪个交款台呢? 首当是看排的队人数，5个人总比20人要快吧?除了数人头，我们也常常看看前面人购买的东西多少，如果前面有个采购了一星期食品的大妈，那么可以考虑换个队排了。还有就是收银员的速度了，如果碰上了连钱都点不清楚的新手，那就有的等了。另外，时机也很重要，可能 5分钟前还人满为患的收款台，现在已是人去楼空，这时候交款可是很爽啊，当然，前提是那过去的 5 分钟里所做的事情比排队要有意义(不过我还没发现什么事情比排队还无聊的)。 I/O 系统也和超市排队有很多类似之处: r/s+w/s 类似于交款人的总数 平均队列长度(avgqu-sz)类似于单位时间里平均排队人的个数 平均服务时间(svctm)类似于收银员的收款速度 平均等待时间(await)类似于平均每人的等待时间 平均I/O数据(avgrq-sz)类似于平均每人所买的东西多少 I/O 操作率 (%util)类似于收款台前有人排队的时间比例。 我们可以根据这些数据分析出 I/O 请求的模式，以及 I/O 的速度和响应时间。 下面是别人写的这个参数输出的分析 #iostat -x 1 avg-cpu: %user %nice %sys %idle 16.24 0.00 4.31 79.44 Device: rrqm/s wrqm/s r/s w/s rsec/s wsec/s rkB/s wkB/s avgrq-sz avgqu-sz await svctm %util /dev/cciss/c0d0 0.00 44.90 1.02 27.55 8.16 579.59 4.08 289.80 20.57 22.35 78.21 5.00 14.29 /dev/cciss/c0d0p1 0.00 44.90 1.02 27.55 8.16 579.59 4.08 289.80 20.57 22.35 78.21 5.00 14.29 /dev/cciss/c0d0p2 上面的 iostat 输出表明秒有 28.57 次设备 I/O 操作: 总IO(io)/s = r/s(读) +w/s(写) = 1.02+27.55 = 28.57 (次/秒) 其中写操作占了主体 (w:r = 27:1)。 平均每次设备 I/O 操作只需要 5ms 就可以完成，但每个 I/O 请求却需要等上 78ms，为什么? 因为发出的 I/O 请求太多 (每秒钟约 29 个)，假设这些请求是同时发出的，那么平均等待时间可以这样计算: 平均等待时间 = 单个 I/O 服务时间 * ( 1 + 2 + … + 请求总数-1) / 请求总数 应用到上面的例子: 平均等待时间 = 5ms * (1+2+…+28)/29 = 70ms，和 iostat 给出的78ms 的平均等待时间很接近。这反过来表明 I/O 是同时发起的。 每秒发出的 I/O 请求很多 (约 29 个)，平均队列却不长 (只有 2 个 左右)，这表明这 29 个请求的到来并不均匀，大部分时间 I/O 是空闲的。 一秒中有 14.29% 的时间 I/O 队列中是有请求的，也就是说，85.71% 的时间里 I/O 系统无事可做，所有 29 个 I/O 请求都在142毫秒之内处理掉了。 delta(ruse+wuse)/delta(io) = await = 78.21 =&gt; delta(ruse+wuse)/s=78.21 * delta(io)/s = 78.21*28.57 =2232.8，表明每秒内的I/O请求总共需要等待2232.8ms。所以平均队列长度应为 2232.8ms/1000ms = 2.23，而iostat 给出的平均队列长度 (avgqu-sz) 却为 22.35，为什么?! 因为 iostat 中有 bug，avgqu-sz值应为 2.23，而不是 22.35。","categories":[],"tags":[],"author":"张存"},{"title":"Linux服务器下shell脚本加密与破解方法盘点","slug":"Linux服务器下shell脚本加密与破解方法盘点","date":"2021-10-26T10:49:28.000Z","updated":"2021-10-26T10:51:58.914Z","comments":true,"path":"2021/10/26/linux-fu-wu-qi-xia-shell-jiao-ben-jia-mi-yu-po-jie-fang-fa-pan-dian/","link":"","permalink":"https://blog.zhangcun.store/2021/10/26/linux-fu-wu-qi-xia-shell-jiao-ben-jia-mi-yu-po-jie-fang-fa-pan-dian/","excerpt":"","text":"当前服务器服务器操作系统主要分为：WINDOWS、LINUX、NETWARE、UNIX四大流派，而Linux系统深受喜爱，今天我们就来盘点Linux系统的shell脚本加密与解密方法。假设有hanming.com.sh脚本。我们要对其进行加密， 废话不多，开始由简单到复杂的介绍。 一、gzexe压缩加密1、加密方法执行“gzexe hanming.com.sh”，出现“hanming.com.sh”（密文）和“hanming.com.sh~”（明文）两个文件，其hanming.com.sh就是加密好的脚本了。 2、解密方法就以刚才加密的脚本进行解密，此时我们需要删除刚才的原文文件hanming.com.sh~，直接执行“rm hanming.com.sh”来进行删除，删除的原因是防止干扰大家。 (1)加密的脚本存在已经存在于目录“/root/”下，我们直接执行“gzexe -d hanming.com.sh”，此时执行“ls”发现也出现了“hanming.com.sh”（明文）和“hanming.com.sh~”（密文）两个文件，hanming.com.sh即解密好的脚本。 二、shc加密解密1、加密方法(1)安装，依次执行下面代码进行安装。sudo add-apt-repository ppa:neurobin/ppasudo apt-get update sudo apt-get install shc 上方命令不能安装可以执行下方代码wget -q http://www.datsi.fi.upm.es/~frosal/sources/shc-3.8.9.tgztar zxvf shc-3.8.9.tgzcd shc-3.8.9 make (2)加密环节 shc -v -r -T -f hanming.com.sh 说明：hanming.com.sh是原来脚本，hanming.com.sh.x的已经编译后的二进制可执行文件，而hanming.com.sh.x.c 的是转化的C语言源文件。2、解密方法 使用unshc.sh脚本解密 wget https://raw.githubusercontent.com/yanncam/UnSHc/master/latest/unshc.sh chmod 777 ./unshc.sh . /unshc.sh hanming.com.sh.x -o hanming.com.sh 说明：“hanming.com.sh.x”是加密的脚本名，而“hanming.com.sh”是明文 三、upx加密解密1、加密方法 (1)下载 wget https://github.com/upx/upx/releases/download/v3.95/upx-3.95-amd64_linux.tar.xz tar vxf upx-3.95-amd64_linux.tar.xz cd upx-3.95-amd64_linux chmod 777 ./upx (2)下次需要使用先执行 cd upx-3.95-amd64_linux (3)加密环节 ./upx /root/hanming.com.sh 此外，upx还能加密后变异一下，让其不能使用脚本解密，但也能够手脱upx加密。 2、解密方法 cd upx-3.95-amd64_linux ./upx -d /root/hanming.com.sh 综合的加密解密手段1、加密方法先gzexe加密，再shc加密，最后upx需要注意的是进行了upx加密的脚本不能进行shc加密2、解密方法upx解密→shc解密→gzexe解密 综合来讲，市面上的加密就这几种，防小白，但也不安全。需要更安全的脚本请使用C语言写脚本，有句话说得好，shell能做的，C语言都能做，为什么呢？因为shell是一个用C语言编写的程序，它是用户使用 Linux 的桥梁，既然是C语言编写的，那么shell能做的，C语言当然都能做到。通过C语言编写程序再编译的脚本会更加的安全。","categories":[],"tags":[],"author":"张存"},{"title":"dpkg 批量卸载","slug":"dpkg-批量卸载","date":"2021-10-26T10:42:39.000Z","updated":"2021-10-26T10:42:44.968Z","comments":true,"path":"2021/10/26/dpkg-pi-liang-xie-zai/","link":"","permalink":"https://blog.zhangcun.store/2021/10/26/dpkg-pi-liang-xie-zai/","excerpt":"","text":"dpkg -l |grep deepin|awk ‘{print $2}’|xargs sudo dpkg -P","categories":[],"tags":[],"author":"张存"},{"title":"ES-9200端口与9300端口","slug":"ES-9200端口与9300端口","date":"2021-10-26T10:37:09.000Z","updated":"2021-10-26T10:37:11.682Z","comments":true,"path":"2021/10/26/es-9200-duan-kou-yu-9300-duan-kou/","link":"","permalink":"https://blog.zhangcun.store/2021/10/26/es-9200-duan-kou-yu-9300-duan-kou/","excerpt":"","text":"（1）Elasticsearch是基于lucene的全文检索服务器 （1）9300：ES节点之间的通讯使用 （2）9200：ES节点和外部通讯使用","categories":[],"tags":[],"author":"张存"},{"title":"linux安装ping","slug":"linux安装ping","date":"2021-10-26T10:09:52.000Z","updated":"2021-10-26T10:11:55.242Z","comments":true,"path":"2021/10/26/linux-an-zhuang-ping/","link":"","permalink":"https://blog.zhangcun.store/2021/10/26/linux-an-zhuang-ping/","excerpt":"","text":"使用docker仓库下载的ubuntu 14.04 镜像。里面精简的连 ping 命令都没有。google 百度都搜索不到ping 命令在哪个包里。 努力找了半天，在一篇文章的字里行间发现了 ping 的来历～ root@node2:/# apt-get install inetutils-ping 还有ifconfig可以用 apt-get install net-tools 来安装～","categories":[],"tags":[],"author":"张存"},{"title":"MongoDB给数据库创建用户","slug":"MongoDB给数据库创建用户","date":"2021-10-26T02:39:08.000Z","updated":"2021-10-26T02:39:31.604Z","comments":true,"path":"2021/10/26/mongodb-gei-shu-ju-ku-chuang-jian-yong-hu/","link":"","permalink":"https://blog.zhangcun.store/2021/10/26/mongodb-gei-shu-ju-ku-chuang-jian-yong-hu/","excerpt":"","text":"一.先以非授权的模式启动MongoDB非授权： linux/Mac : mongod -f /mongodb/etc/mongo.conf windows : mongod –config c:\\mongodb\\etc\\mongo.conf 或者 net start mongodb （前提是mongo安装到了服务里面） 备注： /mongodb/etc/mongo.conf 位mongo配置文件所在的地址 授权： mongod -f /mongodb/etc/mongo.conf –auth 备注： 1.–auth代表授权启动，需要帐号密码才能访问 2.auth=true可以加到mongo.conf配置文件里面去进行统一管理 二.创建管理员1.通过非授权的方式启动mongo 2.创建admin数据库 use admin 3.添加管理员用户db.createUser({user:”admin”,pwd:”123456”,roles:[“root”]}) 备注：用户名和密码可随意定 4.认证 db.auth(“admin”, “123456”) 三.以授权的方式启动Mongo,给使用的数据库添加用户1.切换数据库 use test 2.创建用户 db.createUser({user: “root”, pwd: “123456”, roles: [{ role: “dbOwner”, db: “test” }]}) 3.通过客户端连接test数据库","categories":[],"tags":[],"author":"张存"},{"title":"docker动态查看日志最后100行","slug":"docker动态查看日志最后100行","date":"2021-10-26T02:22:30.000Z","updated":"2021-10-26T02:23:44.555Z","comments":true,"path":"2021/10/26/docker-dong-tai-cha-kan-ri-zhi-zui-hou-100-xing/","link":"","permalink":"https://blog.zhangcun.store/2021/10/26/docker-dong-tai-cha-kan-ri-zhi-zui-hou-100-xing/","excerpt":"","text":"docker logs -f -t –tail=100 c337e9df72a7指的是实时查看容器id为c337e9df72a7的最后100行日志 $ docker logs [OPTIONS] CONTAINER Options: –details 显示更多的信息 -f, –follow 跟踪实时日志 –since string 显示自某个timestamp之后的日志，或相对时间，如42m（即42分钟） –tail string 从日志末尾显示多少行日志， 默认是all -t, –timestamps 显示时间戳 –until string 显示自某个timestamp之前的日志，或相对时间，如42m（即42分钟） 例子： 查看指定时间后的日志，只显示最后100行： $ docker logs -f -t –since=”2018-02-08” –tail=100 CONTAINER_ID 查看最近30分钟的日志: $ docker logs –since 30m CONTAINER_ID 查看某时间之后的日志： $ docker logs -t –since=”2018-02-08T13:23:37” CONTAINER_ID 查看某时间段日志： $ docker logs -t –since=”2018-02-08T13:23:37” –until “2018-02-09T12:23:37” CONTAINER_ID","categories":[],"tags":[],"author":"张存"},{"title":"MySQL创建用户与授权","slug":"MySQL创建用户与授权","date":"2021-10-25T05:26:07.000Z","updated":"2021-10-25T05:30:18.243Z","comments":true,"path":"2021/10/25/mysql-chuang-jian-yong-hu-yu-shou-quan/","link":"","permalink":"https://blog.zhangcun.store/2021/10/25/mysql-chuang-jian-yong-hu-yu-shou-quan/","excerpt":"","text":"一. 创建用户 命令:CREATE USER ‘username‘@’host’ IDENTIFIED BY ‘password’; 说明：username：你将创建的用户名host：指定该用户在哪个主机上可以登陆，如果是本地用户可用localhost，如果想让该用户可以从任意远程主机登陆，可以使用通配符%password：该用户的登陆密码，密码可以为空，如果为空则该用户可以不需要密码登陆服务器例子：CREATE USER ‘dog‘@’localhost’ IDENTIFIED BY ‘123456’;CREATE USER ‘pig‘@’192.168.1.101_’ IDENDIFIED BY ‘123456’;CREATE USER ‘pig‘@’%’ IDENTIFIED BY ‘123456’;CREATE USER ‘pig‘@’%’ IDENTIFIED BY ‘’;CREATE USER ‘pig‘@’%’; 二. 授权: 命令:GRANT privileges ON databasename.tablename TO ‘username‘@’host’ 说明:privileges：用户的操作权限，如SELECT，INSERT，UPDATE等，如果要授予所的权限则使用ALLdatabasename：数据库名tablename：表名，如果要授予该用户对所有数据库和表的相应操作权限则可用表示，如.*例子:GRANT SELECT, INSERT ON test.user TO ‘pig‘@’%’;GRANT ALL ON . TO ‘pig‘@’%’;GRANT ALL ON maindataplus.* TO ‘pig‘@’%’;注意:用以上命令授权的用户不能给其它用户授权，如果想让该用户可以授权，用以下命令:GRANT privileges ON databasename.tablename TO ‘username‘@’host’ WITH GRANT OPTION; 尝试连接，连接成功 三.设置与更改用户密码 命令:SET PASSWORD FOR ‘username‘@’host’ = PASSWORD(‘newpassword’); 如果是当前登陆用户用:SET PASSWORD = PASSWORD(“newpassword”);例子:SET PASSWORD FOR ‘pig‘@’%’ = PASSWORD(“123456”); 四. 撤销用户权限命令:REVOKE privilege ON databasename.tablename FROM ‘username‘@’host’;说明:privilege, databasename, tablename：同授权部分 例子:REVOKE SELECT ON . FROM ‘pig‘@’%’;注意:假如你在给用户‘pig‘@’%’授权的时候是这样的（或类似的）：GRANT SELECT ON test.user TO ‘pig‘@’%’，则在使用REVOKE SELECT ON . FROM ‘pig‘@’%’;命令并不能撤销该用户对test数据库中user表的SELECT 操作。相反，如果授权使用的是GRANT SELECT ON . TO ‘pig‘@’%’;则REVOKE SELECT ON test.user FROM ‘pig‘@’%’;命令也不能撤销该用户对test数据库中user表的Select权限。 具体信息可以用命令SHOW GRANTS FOR ‘pig‘@’%’; 查看。 五.删除用户命令:DROP USER ‘username‘@’host’;","categories":[],"tags":[],"author":"张存"},{"title":"Tomcat项目自动部署脚本","slug":"Tomcat项目自动部署脚本","date":"2021-10-18T11:47:29.000Z","updated":"2021-10-18T11:49:26.783Z","comments":true,"path":"2021/10/18/tomcat-xiang-mu-zi-dong-bu-shu-jiao-ben/","link":"","permalink":"https://blog.zhangcun.store/2021/10/18/tomcat-xiang-mu-zi-dong-bu-shu-jiao-ben/","excerpt":"","text":"一般情况下使用的Linux环境都是加固的，root路径只有超级管理员权限才能进入。我们新建一个自己的用户，在/home下会有一个用户目录，传输war包都放在这个目录下，此时不动webapps文件下的内容，传输包的时候，项目不会中断。 如下是部署脚本deploy.sh： 复制代码#!/bin/bash#自动部署脚本 #tomcat路径tomcatBinPath=/alidata/server/tomcat-7.0.54/bin#war包和脚本目录homepath=/home/baihuidong/DeployApplicationForTomcat echo ‘——–开始部署——–’ #检查war包是否存在cd $homepathif [ $(find ./ -maxdepth 1 -name “*.war”|wc -l) -ne 1 ]; then echo ‘请保证DeployApplicationForTomcat文件中有且只有一个war包！’ exit 1fi #进入tomcat目录cd $tomcatBinPathif [ $? -ne 0 ];then echo ‘请检查tomcat的bin路径是否正确！’ exit 1fiecho “进入tomcat的bin目录：$tomcatBinPath” pid=$(ps -fu whoami|grep “$tomcatBinPath”|grep -v grep|awk ‘{print $2}’)if [ -z “$pid” ];then echo “相关tomcat进程已关闭:$pid”else ./shutdown.sh #停止tomcat服务 sleep 8 kill -9 $pid echo ‘成功关闭tomcat服务！’fi #清空oldWarPackage目录cd $homepathif [ $? -ne 0 ];then echo ‘请检查homepath路径是否正确或者是否有权限进入！’ exit 1fi if [ -d $homepath/oldWarPackage ];then echo “oldWarPackage文件夹存在！” rm -rf $homepath/oldWarPackage/*else echo “oldWarPackage文件夹不存在！” mkdir $homepath/oldWarPackagefi cd $tomcatBinPath/../webapps/if [ $? -ne 0 ];then echo ‘请检查webapps路径是否正确！’ exit 1fiecho “进入webapps目录：$(pwd)” cp *.war $homepath/oldWarPackage/if [ $? -ne 0 ];then echo ‘请检查webapps下是否有war包或者oldWarPackage目录是否存在！’ exit 1fi rm -rf *cp $homepath/*.war ./ chown root:root *.warchmod 755 *.war cd $tomcatBinPath./startup.sh echo ‘——–部署结束——–’复制代码若部署中间出错，则使用回滚脚本 回滚脚本rollback.sh： 复制代码#!/bin/bash#回滚脚本 #war包和脚本目录homepath=/home/baihuidong/DeployApplicationForTomcat cd $homepath/oldWarPackageif [ $(find ./ -maxdepth 1 -name “*.war”|wc -l) -ne 1 ]; then echo ‘请保证oldWarPackage文件中有且只有一个war包！’ exit 1fi echo ‘——回滚开始——‘cd ../rm -rf ./.warcp ./oldWarPackage/.war ././deploy.shecho ‘——回滚结束——‘复制代码其实这里的回滚脚本，是重新部署原war包的方案。还有一种方案，就是备份webapps路径下的war包和ROOT文件夹，回滚之后拷贝到webapps下，重启tomcat，这样省去了Tomcat解压war包的时间。 注意： 如果在Linux下使用vim命令编写脚本，需添加相关执行权限才能被执行（文件名变成绿色）。 如果在windows下编写的sh脚本，传到Linux上，需要增加相关执行权限，且需要格式转化 使用如下命令进行转换： chmod 755 deploy.sh //设置执行权限dos2unix deploy.sh //格式转化busybox dos2unix deploy.sh //如果提示dos2unix命令找不到，使用这条还可以使用vim进行格式转化。","categories":[],"tags":[],"author":"张存"},{"title":"Linux 常用命令（一）：操作文件命令","slug":"Linux-常用命令（一）：操作文件命令","date":"2021-10-18T11:42:20.000Z","updated":"2021-10-18T11:44:29.837Z","comments":true,"path":"2021/10/18/linux-chang-yong-ming-ling-yi-cao-zuo-wen-jian-ming-ling/","link":"","permalink":"https://blog.zhangcun.store/2021/10/18/linux-chang-yong-ming-ling-yi-cao-zuo-wen-jian-ming-ling/","excerpt":"","text":"目录 一、命令的基本格式 1. 命令的提示符 2. 命令的基本格式二、目录操作命令 1．ls命令 2．cd命令 3．pwd命令 4．mkdir命令 5．rmdir命令三、文件操作命令 1．touch命令 2．stat命令 3．cat命令 4．more命令 5．less命令 6．head命令 7．tail命令 8．ln命令四、目录和文件都能操作的命令 1．rm命令 2．cp命令 3．mv命令一、命令的基本格式 命令的提示符[root@localhost ~][]：这是提示符的分隔符号，没有特殊含义。root：显示的是当前的登录用户，超哥现在使用的是root用户登录 。@：分隔符号，没有特殊含义。localhost：当前系统的简写主机名（完整主机名是localhost.localdomain）。~：代表用户当前所在的目录，此例中用户当前所在的目录是家目录。#：命令提示符。超级用户是#，普通用户是$ 命令的基本格式[root@localhost ~]# 命令 [选项] [参数]ls是最常见的目录操作命令，主要作用是显示目录下的内容。 命令名称：ls。英文原意：list。所在路径：/bin/ls。执行权限：所有用户。功能描述：显示目录下的内容。复制代码[root@localhost ~]#ls [选项] [文件名或目录名]选项： -a: 显示所有文件 --color=when: 支持颜色输出，when的值默认是always（总显示颜色），也可以是never（从不显示颜色）和auto（自动） -d：显示目录信息，而不是目录下的文件 -h：人性化显示，按照我们习惯的单位显示文件大小 -i：显示文件的i节点号 -l：长格式显示 复制代码举几个例子： [root@localhost ~]# ls -l总用量 44 -rw——-. 1 root root# 1207 1月 14 18:18 anaconda-ks.cfg#权限引用计数所有者所属组大小文件修改时间文件名 我们已经知道“-l”选项用于 显示文件的详细信息，那么“-l”选项 显示的这7列分别 是什么含义？ 第一列：权限。具体权限的含义将在4.5节中讲解。 第二列：引用计数。文件的引用计数代表该文件的硬链接个数，而目录的引用计数代表该目录有多少个一级子目录。 第三列：所有者，也就是这个文件属于哪个用户。默认所有者是文件的建立用户 第四列：所属组。默认所属组是文件建立用户的有效组，一般情况下就是建立用户的所在组。 第五列：大小。默认单位是字节。 第六列：文件修改时间。文件状态修改时间或文件数据修改时间都会更改这个时间，注意这个时间不是文件的创建时间。 第七列：文件名。选项：是用于调整命令的功能的。参数：是命令的操作对象，如果省略参数，是因为有默认参数 注：选项：是用于调整命令的功能的。参数：是命令的操作对象，如果省略参数，是因为有默认参数 二、目录操作命令1．ls命令见前一小节的内容。 2．cd命令 cd是切换所在目录的命令，这个命令的基本信息如下。 命令名称：cd。 英文原意：change directory。 所在路径：Shell内置命令。 执行权限：所有用户。 功能描述：切换所在目录。2.1cd命令的简化用法特殊符号 作 用 ~ 代表用户的家目录 代表上次所在目录. 代表当前目录.. 代表上级目录 2.2 绝对路径和相对路径 绝对路径：以跟目录为参照物，从根目录开始，一级一级进入目录 相对路径：以当前目录作为参照物，进行目录查找 3．pwd命令 pwd命令是查询所在目录的命令，基本信息如下： 命令名称：pwd英文原意：print name of current/working directory 所在路径：/bin/pwd执行权限：所有用户。 功能描述：查询所在的工作目录。4．mkdir命令 mkdir是创建目录的命令，其基本信息如下。 命令名称：mkdir。英文原意：make directories。 所在路径：/bin/mkdir。 执行权限：所有用户。 功能描述：创建空目录。命令格式 [root@localhost ~]# mkdir [选项] 目录名选项： -p：递归建立所需目录5．rmdir命令 既然有建立目录的命令，就一定会有删除目录的命令rmdir，其基本信息如下。 命令名称：rmdir。 英文原意：remove empty directories。 所在路径：/bin/rmdir。 执行权限：所有用户。 功能描述：删除空目录。命令格式 root@localhost ~]# rmdir [选项] 目录名选项： -p：递归删除目录 注：rmdir命令的作用十分有限，因为只能删除空目录，所以一旦目录中有内容，就会报错。这个命令比较“笨”，所以我们不太常用。后续我们不论删除的是文件还是目录，都会使用rm命令 三、文件操作命令1．touch命令 创建空文件或修改文件时间，这个命令的基本信息如下。 命令名称：touch。 英文原意：change file timestamps。 所在路径：/bin/touch。 执行权限：所有用户。 功能描述：修改文件的时间戳。2．stat命令 stat是查看文件详细信息的命令，而且可以看到文件的这三个时间，其基本信息如下。 命令名称：stat。 英文原意：display file or file system status。 所在路径：/usr/bin/stat。 执行权限：所有用户。功能描述：显示文件或文件系统的详细信息。命令格式 复制代码[root@localhost ~]# stat anaconda-ks.cfg 文件：”anaconda-ks.cfg” 大小：1453 块：8 IO 块：4096 普通文件设备：803h/2051d Inode：33574991 硬链接：1权限：(0600/-rw——-) Uid：( 0/ root) Gid：( 0/ root)环境：system_u:object_r:admin_home_t:s0最近访问：2018-11-06 23:22:23.409038121 +0800最近更改：2018-10-24 00:53:08.760018638 +0800 #数据修改时间最近改动：2018-10-24 00:53:08.760018638 +0800 #状态修改时间创建时间：-复制代码3．cat命令 cat命令用来查看文件内容。这个命令的基本信息如下。 命令名称：cat。 英文原意：concatenate files and print on the standard output。 所在路径：/bin/cat。 执行权限：所有用户。 功能描述：合并文件并打印输出到标准输出。命令格式 复制代码[root@localhost ~]# cat [选项] 文件名选项： -A：相当于-vET选项的整合，用于列出所有隐藏符号 -E：列出每行结尾的回车符$ -n：显示行号 -T：把Tab键用^I显示出来 -v：列出特殊字符复制代码4．more命令 more是分屏显示文件的命令，其基本信息如下。 命令名称：more。 英文原意：file perusal filter for crt viewin。 所在路径：/bin/more。 执行权限：所有用户。 功能描述：分屏显示文件内容。 more命令比较简单，一般不用什么选项，命令会打开一个交互界面，可以识别一些交互命令。常用的交互命令如下。 空格键：向下翻页。 b：向上翻页。 回车键：向下滚动一行。 /字符串：搜索指定的字符串。 q：退出 。5．less命令 less命令和more命令类似，只是more是分屏显示命令，而less是分行显示命令，其基本信息如下。 命令名称：less。 英文原意：opposite of more。 所在路径：/usr/bin/less。 执行权限：所有用户。功能描述：分行显示文件内容6．head命令 head是用来显示文件开头的命令，其基本信息如下。 命令名称：head。 英文原意：output the first part of files。 所在路径：/usr/bin/head。 执行权限：所有用户。 功能描述：显示文件开头的内容。命令格式 [root@localhost ~]# head [选项] 文件名选项： -n 行数：从文件头开始，显示指定行数 -v：显示文件名 7．tail命令 既然有显示文件开头的命令，就会有显示文件结尾的命令。tail命令的基本信息如下。 命令名称：tail。 英文原意：output the last part of files。 所在路径：/usr/bin/tail。执行权限：所有用户。 功能描述：显示文件结尾的内容。命令格式 [root@localhost ~]# tail [选项] 文件名选项： -n 行数：从文件结尾开始，显示指定行数 -f：监听文件的新增内容 8．ln命令 我们来看看ln命令的基本信息。 命令名称：ln。 英文原意：make links between file。 所在路径：/bin/ln。 执行权限：所有用户。 功能描述：在文件之间建立链接。命令格式 [root@localhost ~]# ln [选项] 源文件目标文件选项： -s：建立软链接文件。如果不加“-s”选项，则建立硬链接文件 -f：强制。如果目标文件已经存在，则删除目标文件后再建立链接文件注：链接文件的意思我认为就是文件挂载 8.1 硬链接命令格式 [root@localhost ~]# touch cangls[root@localhost ~]# ln /root/cangls /tmp/#建立硬链接文件，目标文件没有写文件名，会和原名一致#也就是/root/cangls和/tmp/cangls是硬链接文件硬链接特征： 源文件和硬链接文件拥有相同的Inode和Blockl 修改任意一个文件，另一个都改变 删除任意一个文件，另一个都能使用 硬链接标记不清，很难确认硬链接文件位置，不建议使用 硬链接不能链接目录l硬链接不能跨分区8.1 软链接命令格式 [root@localhost ~]# touch bols[root@localhost ~]# ln -s /root/bols /tmp/#建立软链接文件软链接特征： 软链接和源文件拥有不同的Inode和Block 两个文件修改任意一个，另一个都改变 删除软链接，源文件不受影响；删除源文件，软链接不能使用 软链接没有实际数据，只保存源文件的Inode，不论源文件多大，软链接大小不变 软链接的权限是最大权限lrwxrwxrwx.，但是由于没有实际数据，最终访问时需要参考源文件权限 软链接可以链接目录 软链接可以跨分区l软链接特征明显，建议使用软连接四、目录和文件都能操作的命令1．rm命令 rm是强大的删除命令，不仅可以删除文件，也可以删除目录。这个命令的基本信息如下。 命令名称：rm。 英文原意：remove files or directories。 所在路径：/bin/rm。 执行权限：所有用户。 功能描述：删除文件或目录。 命令格式 [root@localhost ~]# rm [选项] 文件或目录选项： -f：强制删除（force） -i：交互删除，在删除之前会询问用户 -r：递归删除，可以删除目录（recursive）2．cp命令 cp是用于复制的命令，其基本信息如下： 命令名称：cp。 英文原意：copy files and directories。 所在路径：/bin/cp。 执行权限：所有用户。 功能描述：复制文件和目录 。 命令格式 复制代码[root@localhost ~]# cp [选项] 源文件 目标文件选项： -a：相当于-dpr选项的集合，这几个选项我们一一介绍 -d：如果源文件为软链接（对硬链接无效），则复制出的目标文件也为软链接 -i：询问，如果目标文件已经存在，则会询问是否覆盖 -p：复制后目标文件保留源文件的属性（包括所有者、所属组、权限和时间） -r：递归复制，用于复制目录复制代码3．mv命令 mv是用来剪切的命令，其基本信息如下。 命令名称：mv。 英文原意：move (rename) files。 所在路径：/bin/mv。 执行权限：所有用户。 功能描述：移动文件或改名。命令格式 [root@localhost ~]# mv [选项] 源文件目标文件选项： -f：强制覆盖，如果目标文件已经存在，则不询问，直接强制覆盖 -i：交互移动，如果目标文件已经存在，则询问用户是否覆盖（默认选项） -v：显示详细信息","categories":[],"tags":[],"author":"张存"},{"title":"centos7 安装docker-compose","slug":"docker-compose安装","date":"2021-10-18T11:22:13.000Z","updated":"2021-10-18T11:41:19.553Z","comments":true,"path":"2021/10/18/docker-compose-an-zhuang/","link":"","permalink":"https://blog.zhangcun.store/2021/10/18/docker-compose-an-zhuang/","excerpt":"","text":"推荐使用docker官方的docker-compose安装教程官网安装教程 推荐使用pip安装docker-compose，因为pip可以为你自动对应版本问题安装pipyum -y install epel-releaseyum -y install python3-pip确认版本pip –version更新pippip3 install –upgrade pip安装docker-composepip3 install docker-compose查看版本docker-compose version","categories":[],"tags":[],"author":"张存"},{"title":"docker构建python3.7镜像","slug":"docker构建python3-7镜像","date":"2021-10-18T10:28:51.000Z","updated":"2021-10-18T10:38:43.427Z","comments":true,"path":"2021/10/18/docker-gou-jian-python3-7-jing-xiang/","link":"","permalink":"https://blog.zhangcun.store/2021/10/18/docker-gou-jian-python3-7-jing-xiang/","excerpt":"","text":"安装 Docker Engine-Community使用 Docker 仓库进行安装 在新主机上首次安装 Docker Engine-Community 之前，需要设置 Docker 仓库。之后，您可以从仓库安装和更新 Docker。 设置仓库 安装所需的软件包。yum-utils 提供了 yum-config-manager ，并且 device mapper 存储驱动程序需要 device-mapper-persistent-data 和 lvm2。 $ sudo yum install -y yum-utils \\ device-mapper-persistent-data \\ lvm2使用以下命令来设置稳定的仓库。 $ sudo yum-config-manager \\ –add-repo \\ https://download.docker.com/linux/centos/docker-ce.repo安装 Docker Engine-Community 安装最新版本的 Docker Engine-Community 和 containerd，或者转到下一步安装特定版本： $ sudo yum install docker-ce docker-ce-cli containerd.io如果提示您接受 GPG 密钥，请选是。 启动 Docker。 $ sudo systemctl start docker构建python3镜像一.在Dockerfile/Dockerfile 中写入以下代码 注意：Dockerfile目录中最好不要有多余的文件,也会发送给docker引擎，速度会变慢 ############################################## #基于centos7构建python3运行环境 #构建命令: 在Dockerfile文件目录下执行 docker build -t python:37 . #容器启动命令: docker run -itd --name python --restart always --privileged=true -v /root/dockers/python:/root/python -v /root/dockers/python/cron:/var/spool/cron python:37 /usr/sbin/init #进入容器：docker exec -it python /bin/bash ############################################## FROM centos:7.6.1810 MAINTAINER mioshu # 指定作者信息 RUN set -ex \\ # 预安装所需组件 &amp;&amp; yum install -y wget tar libffi-devel zlib-devel bzip2-devel openssl-devel ncurses-devel sqlite-devel readline-devel tk-devel gcc make initscripts \\ &amp;&amp; wget https://www.python.org/ftp/python/3.7.0/Python-3.7.0.tgz \\ &amp;&amp; tar -zxvf Python-3.7.0.tgz \\ &amp;&amp; cd Python-3.7.0 \\ &amp;&amp; ./configure prefix=/usr/local/python3 \\ &amp;&amp; make \\ &amp;&amp; make install \\ &amp;&amp; make clean \\ &amp;&amp; rm -rf /Python-3.7.0* \\ &amp;&amp; yum install -y epel-release \\ &amp;&amp; yum install -y python-pip #设置默认为python3 RUN set -ex \\ # 备份旧版本python &amp;&amp; mv /usr/bin/python /usr/bin/python27 \\ &amp;&amp; mv /usr/bin/pip /usr/bin/pip27 \\ # 配置默认为python3 &amp;&amp; ln -s /usr/local/python3/bin/python3.7 /usr/bin/python \\ &amp;&amp; ln -s /usr/local/python3/bin/pip3 /usr/bin/pip #修复因修改python版本导致yum失效问题 RUN set -ex \\ &amp;&amp; sed -i &quot;s#/usr/bin/python#/usr/bin/python2.7#&quot; /usr/bin/yum \\ &amp;&amp; sed -i &quot;s#/usr/bin/python#/usr/bin/python2.7#&quot; /usr/libexec/urlgrabber-ext-down \\ &amp;&amp; yum install -y deltarpm #基础环境配置 RUN set -ex \\ # 修改系统时区为东八区 &amp;&amp; rm -rf /etc/localtime \\ &amp;&amp; ln -s /usr/share/zoneinfo/Asia/Shanghai /etc/localtime \\ &amp;&amp; yum install -y vim \\ # 安装定时任务组件 &amp;&amp; yum -y install cronie #支持中文 RUN yum install kde-l10n-Chinese -y RUN localedef -c -f UTF-8 -i zh_CN zh_CN.utf8 #更新pip版本 RUN pip install --upgrade pip ENV LC_ALL zh_CN.UTF-8 二 dockerfile构建命令: 在Dockerfile文件目录下执行 docker build -t python:37 .-t：指定镜像名称 三 启动容器 docker run -itd –name python –restart always –privileged=true -v /root/dockers/python:/root/python -v /root/dockers/python/cron:/var/spool/cron python:37 /usr/sbin/initdocker run 命令会创建一个名为python的容器-i：互交模式-t：终端模式-d：后台启动–name： 容器名称，即后面的python-v：资源卷映射，主机目录、文件映射到容器目录、文件四 进入容器 docker exec -it python /bin/bash五 导出容器 Ctrl + d 退出当前容器后执行下面语句 docker export python &gt; python.tar六、导入容器 docker import python.tar python:3通过export+import的方法创建镜像不会保留镜像历史，可以缩小镜像体积 七、push到hub 需要先到 https://hub.docker.com 注册一个账号 上传完成后可以在任一主机上拉取镜像： docker pull vfrtgb158/python:3","categories":[],"tags":[],"author":"张存"},{"title":"ubuntu 20.04 安装 nfs","slug":"ubuntu-16-04-安装-nfs","date":"2021-10-18T10:09:05.000Z","updated":"2022-06-15T08:56:12.255Z","comments":true,"path":"2021/10/18/ubuntu-16-04-an-zhuang-nfs/","link":"","permalink":"https://blog.zhangcun.store/2021/10/18/ubuntu-16-04-an-zhuang-nfs/","excerpt":"","text":"Ubuntu 20.04系统上NFS的安装与使用 摘要：本文介绍了NFS服务器的安装过程、配置文件和常用命令行工具，以及NFS客户端上如何安装常用工具，介绍如何挂载共享目录，并通过实验进行验证。 一、服务器端： 1.1安装NFS服务： #执行以下命令安装NFS服务器， #apt会自动安装nfs-common、rpcbind等13个软件包 sudo apt install nfs-kernel-server 1.2编写配置文件： #编辑/etc/exports 文件： sudo vi /etc/exports #/etc/exports文件的内容如下： /tmp *(rw,sync,no_subtree_check,no_root_squash) /data *(rw,sync,no_subtree_check,no_root_squash) /logs *(rw,sync,no_subtree_check,no_root_squash) 1.3创建共享目录 #在服务器端创建/tmp /data和/logs共享目录 sudo mkdir -p /tmp sudo mkdir -p /data sudo mkdir -p /logs 1.4重启nfs服务： sudo service nfs-kernel-server restart 1.5常用命令工具： #在安装NFS服务器时，已包含常用的命令行工具，无需额外安装。 #显示已经mount到本机nfs目录的客户端机器。 sudo showmount -e localhost #将配置文件中的目录全部重新export一次！无需重启服务。 sudo exportfs -rv #查看NFS的运行状态 sudo nfsstat #查看rpc执行信息，可以用于检测rpc运行情况 sudo rpcinfo #查看网络端口，NFS默认是使用111端口。 sudo netstat -tu -4 二、客户端： 2.1安装客户端工具： #在需要连接到NFS服务器的客户端机器上， #需要执行以下命令，安装nfs-common软件包。 #apt会自动安装nfs-common、rpcbind等12个软件包 sudo apt install nfs-common 2.2查看NFS服务器上的共享目录 #显示指定的（192.168.3.167）NFS服务器上export出来的目录 sudo showmount -e 192.168.3.167 2.3创建本地挂载目录 sudo mkdir -p /mnt/data sudo mkdir -p /mnt/logs 2.4挂载共享目录 #将NFS服务器192.168.3.167上的目录，挂载到本地的/mnt/目录下 sudo mount -t nfs 192.168.3.167:/data /mnt/data sudo mount -t nfs 192.168.3.167:/logs /mnt/logs #注：在没有安装nfs-common或者nfs-kernel-server软件包的机器上， #直接执行showmount、exportfs、nfsstat、rpcinfo等命令时， #系统会给出友好的提示， #比如直接showmount会提示需要执行sudo apt install nfs-common命令， #比如直接rpcinfo会提示需要执行sudo apt install rpcbind命令。 实验附图： 1-在没有安装nfs相关软件包的机器上，直接执行nfsstat和rpcinfo命令时，会给出安装提示 2-在没有安装nfs相关软件包的机器上，直接执行exportfs和showmount命令时，会给出的安装提示 3-在NFS服务器上使用apt命令，安装nfs-kernel-server软件包，系统提示同时安装nfs-common,rpcinfo等13个软件包 4-完成NFS服务器端的安装以后，查看etc下exports文件的默认内容 5-查看NFS服务器端的目录，创建共享目录，重启nfs服务 6-在NFS服务器端查看共享出来的目录 7-重启NFS服务，查看服务器端的共享目录，查看NFS的状态，以及RPC信息 8-在客户端192.168.3.166机器上，查看NFS服务器167上的共享目录 9-在客户端192.168.3.166上使用mount命令挂载NFS服务器167上的共享目录，查看目录中的内容 mac挂载: sudo mount -o resvport -o nolock -t nfs x.x.x.x:/xxxx xxxxx 【结束】 参考链接： 超全面的NFS详解 http://server.51cto.com/sManage-150923.htm ubuntu 16.04 nfs服务的搭建 http://www.cnblogs.com/MoreExcellent/p/7222895.html","categories":[],"tags":[],"author":"张存"},{"title":"Linux下批量ping某个网段的脚本","slug":"Linux下批量ping某个网段的脚本","date":"2021-10-18T10:03:57.000Z","updated":"2021-10-18T10:07:05.702Z","comments":true,"path":"2021/10/18/linux-xia-pi-liang-ping-mou-ge-wang-duan-de-jiao-ben/","link":"","permalink":"https://blog.zhangcun.store/2021/10/18/linux-xia-pi-liang-ping-mou-ge-wang-duan-de-jiao-ben/","excerpt":"","text":"比如现在需要对192.168.1.0/24网段的ip进行检查，检查哪些ip现在被占用，哪些ip没有被占用，可以通过ping命令来检查，也可以通过nmap接参数来检查 ping命令脚本如下： 复制代码[root@ZFVM-APP-0-172 shell]# vim ping.sh#!/bin/bash. /etc/init.d/functionsfor var in {1..254};doip=192.168.1.$varping -c2 $ip &gt;/dev/null 2&gt;&amp;1if [ $? = 0 ];thenaction “$ip” /bin/trueelseaction “$ip” /bin/falsefidone 复制代码复制代码[root@uatdns01 opt]# bash ping.sh172.168.1.1 [FAILED]172.168.1.2 [FAILED]172.168.1.3 [FAILED]172.168.1.4 [FAILED]172.168.1.5 [FAILED]………………192.168.1.249 [FAILED]192.168.1.250 [FAILED]192.168.1.251 [FAILED]192.168.1.252 [FAILED]192.168.1.253 [FAILED]192.168.1.254 [FAILED]复制代码用nmap需要先安装nmap命令 复制代码[root@ZFVM-APP-0-172 shell]# yum install -y nmap [root@ZFVM-APP-0-172 shell]# nmap -v -sP 192.168.1.0/24 |grep downNmap scan report for 192.168.1.0 [host down]Nmap scan report for 192.168.1.2 [host down]Nmap scan report for 192.168.1.3 [host down]Nmap scan report for 192.168.1.4 [host down]Nmap scan report for 192.168.1.5 [host down]…………Nmap scan report for 192.168.1.251 [host down]Nmap scan report for 192.168.1.252 [host down]Nmap scan report for 192.168.1.253 [host down]Nmap scan report for 192.168.1.254 [host down]Nmap scan report for 192.168.1.255 [host down]复制代码 检查192.168.1.1网关是否可达的脚本 复制代码[root@ZFVM-APP-0-161 shells]# vim ping.sh#!/bin/bashping www.baidu.com -c 4 -W 5 &gt; /dev/null 2&gt;&amp;1if [ $? -eq 0 ]then echo “网络已通”else echo “网络不可达”fi复制代码 执行结果 [root@ZFVM-APP-0-161 shells]# sh ping.sh网络可通 运维攻城狮","categories":[],"tags":[],"author":"张存"},{"title":"samba用户自行修改密码","slug":"samba用户自行修改密码","date":"2021-10-15T10:16:15.000Z","updated":"2021-10-15T10:43:06.383Z","comments":true,"path":"2021/10/15/samba-yong-hu-zi-xing-xiu-gai-mi-ma/","link":"","permalink":"https://blog.zhangcun.store/2021/10/15/samba-yong-hu-zi-xing-xiu-gai-mi-ma/","excerpt":"","text":"最近一直在潜心研究linux shell,所以好久没有更新了。今天也是在QQ有人和我聊到samba密码ldap集中验证时，想到一个问题，内网使用samba服务器来存储用户数据，所有的用户不能登陆LINUX后台，如何让客户自行修改密码？ 想要解决客户端实现修改samba密码，其实不需要去搭建ldap(维护成本较高)，也不需要利用行政手法统计客户端密码（毕竟同事也不好意思告诉你他平时习惯用的密码），网上google了下，利用changepassword这个工具即可利用其WEB界面让普通用户登录WEB修改自己的密码，大大提高了工作效率。 SAMBA: CentOS默认yum源 CHANGEPASSWORD: changepassword-0.9 APACHE: httpd-2.4.4 一.环境搭建： 1.配置前先关闭iptables和SELINUX，避免配置过程中报错。 #service iptables stop #setenforce 0 #vi /etc/sysconfig/selinux SELINUX=disabled 2.安装开发包 #yum install gcc -y 3.安装apache#yum install httpd -y 传送门：http://www.linuxidc.com/Linux/2013-05/83788.htm 二.配置samba： 1.安装samba: #yum install samba -y 2.配置samba: 要使用changepassword程序实现，客户端更改密码必须设置系统密码和samba密码同步 #vi /etc/samba/smb.conf 搜索security = user 添加以下内容(这里注释了默认一行内容) security = user pam password change = no passwd chat = *NEWUNIXpassword %n\\n RetypenewUNIXpassword* %n\\n successfully passwd program = LANG=en_US /usr/bin/passwd %u unix password sync = yes passdb backend = smbpasswd smb passwd file = /etc/samba/smbpasswd #passdb backend = tdbsam #service smb restart 注：上述修改其实将tdbsam认证方式修改该成smbpasswd,并将认证文件加密保存在/etc/samba/smbpasswd下 创建smb账户 #useradd -s /sbin/nologin test04 #passwd test04 #smbpasswd -a test04 注：这里创建samba账户时必须设置系统账户密码，以及smb账户密码 因为changepassword更改密码的机制是，先修改系统账户密码，然后将系统账户密码同步到 /etc/samba/smbpasswd SMB密码库文件下。 二.安装配置changepassword 1,下载解压: #wget http://prdownloads.sourceforge.net/changepassword/changepassword-0.9.tar.gz #tar -zxvf changepassword-0.9.tar.gz #cd changepassword-0.9 vim conf.h 将前三行的定义修改为自己创建的目录（这里我修改到了/var/smbchangepwd目录下）： // temporary directory and files to usechar TMPFILE[]=”/var/smbchangepwd/changepassword-shadow-XXXXXX”;char TMPSMBFILE[]=”/var/smbchangepwd/changepassword-smb-XXXXXX”;char TMPSQUIDFILE[]=”/var/smbchangepwd/changepassword-squid-XXXXXX”; 创建需要用到的目录 mkdir –pv /var/smbchangepwd 2.编译changepassword前需要安装一个依赖包 #cd smbencrypt/ #tar -xzvf libdes-4.04b.tar.gz #cd des/ #make #cp libdes.a ../ #cd ../.. 3.编译安装changepassword #./configure -enable-cgidir=/var/www/cgi-bin -enable-language=Chinese -enable-smbpasswd=/etc/samba/smbpasswd -disable-squidpasswd -enable-logo=logo.jpg 注：-enable-smbpasswd=/etc/samba/smbpasswd # 修改保存samba密码的库文件 -disable-squidpasswd # 禁用squid -enable-cgidir # 自定义apache根目录路径 -disable-squidpasswd # 自定义smbpassword的密码文件路径 -enable-logo # 设置web根目录logo文件,此处的相对路径对应的是apache根目录 #也就是 samba/logo.jpg对应/var/www/cgi-bin/logo.jpg #make &amp;&amp; make install 4.设置apache支持cgi模块 #vim /etc/httpd/conf/httpd.conf 搜索cgi 去掉如下注释： AddHandler cgi-script .cgi ————– 将AddDefaultCharset的值改为 GB2312，以防中文乱码 重启服务 #service httpd restart 5.访问web后台： http://192.168.1.28/cgi-bin/changepassword.cgi 按照提示修改密码提交即可","categories":[],"tags":[],"author":"张存"},{"title":"K8S中Harbor使用Nginx反向代理无法获取image","slug":"K8S中Harbor使用Nginx反向代理无法获取image","date":"2021-10-13T11:11:23.000Z","updated":"2021-10-13T11:12:09.758Z","comments":true,"path":"2021/10/13/k8s-zhong-harbor-shi-yong-nginx-fan-xiang-dai-li-wu-fa-huo-qu-image/","link":"","permalink":"https://blog.zhangcun.store/2021/10/13/k8s-zhong-harbor-shi-yong-nginx-fan-xiang-dai-li-wu-fa-huo-qu-image/","excerpt":"","text":"问题：Kubernetes创建Pod失败，无法获取image Failed create pod sandbox: rpc error: code = Unknown desc = failed pulling image “harbor.od.com/public/pause:latest”: Error response from daemon: Get http://harbor.od.com/v2/public/pause/manifests/latest: Get http://harbor.od.com:180/service/token?scope=repository%3Apublic%2Fpause%3Apull&amp;service=harbor-registry: net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers 环境：harbor.od.com二进制包安装，使用docker-compose启动，harbor.yaml配置port：180然后通过部署nginx，反向到后端harbor上 故障排查： 1.使用docker pull 仓库镜像也无法获取 Error response from daemon: Get http://harbor.od.com/v2/public/pause/manifests/latest: Get http://harbor.od.com:180/service/token?scope=repository%3Apublic%2Fpaue%3Apull&amp;service=harbor-registry: net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers) 2.使用docker loginx登录Harbor Error response from daemon: Get https://harbor,od,com/v2/: dial tcp: lookup harbor,od,com: no such host 3.修改成使用IP的方式登录Harbor Error response from daemon: Get http://harbor.od.com/v2/: Get http://harbor.od.com:180/service/token?account=admin&amp;client_id=docker&amp;offline_token=true&amp;service=habor-registry: net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers) 分析问题： docker使用Http请求获取镜像，harbor是通过nginx的80端口访问，但是通过Log上看到的是使用Get方式，另外还要带有域名加180端口方式验证，应该是配置问题引起 #https://www.cnblogs.com/liucx/ 解决问题：修改harbor.yml配置文件，取消external_url注释，设置为： external_url: http://harbor.od.com:80然后，docker-compose down停止所有服务，删除当前配置目录：rm -rf ./common/config下配置清单，重新执行install.sh生成配置，即可解决 配置大概解释：如果使用外部代理就要启动该项#Uncomment external_url if you want to enable external proxy#And when it enabled the hostname will no longer used","categories":[],"tags":[],"author":"张存"},{"title":"Docker镜像的导入导出","slug":"Docker镜像的导入导出","date":"2021-10-13T11:02:06.000Z","updated":"2021-10-13T11:03:20.306Z","comments":true,"path":"2021/10/13/docker-jing-xiang-de-dao-ru-dao-chu/","link":"","permalink":"https://blog.zhangcun.store/2021/10/13/docker-jing-xiang-de-dao-ru-dao-chu/","excerpt":"","text":"Docker镜像的导入导出本文介绍Docker镜像的导入导出，用于迁移、备份、升级等场景，准备环境如下： CentOS 7.0Docker 1.18导入导出命令介绍涉及的命令有export、import、save、load save命令docker save [options] images [images…] 示例docker save -o nginx.tar nginx:latest或docker save &gt; nginx.tar nginx:latest其中-o和&gt;表示输出到文件，nginx.tar为目标文件，nginx:latest是源镜像名（name:tag）load命令docker load [options] 示例docker load -i nginx.tar或docker load &lt; nginx.tar其中-i和&lt;表示从文件输入。会成功导入镜像及相关元数据，包括tag信息export命令docker export [options] container 示例docker export -o nginx-test.tar nginx-test其中-o表示输出到文件，nginx-test.tar为目标文件，nginx-test是源容器名（name）import命令docker import [options] file|URL|- [REPOSITORY[:TAG]] 示例docker import nginx-test.tar nginx:imp或cat nginx-test.tar | docker import - nginx:imp区别export命令导出的tar文件略小于save命令导出的 export命令是从容器（container）中导出tar文件，而save命令则是从镜像（images）中导出基于第二点，export导出的文件再import回去时，无法保留镜像所有历史（即每一层layer信息，不熟悉的可以去看Dockerfile），不能进行回滚操作；而save是依据镜像来的，所以导入时可以完整保留下每一层layer信息。如下图所示，nginx:latest是save导出load导入的，nginx:imp是export导出import导入的。 建议可以依据具体使用场景来选择命令 若是只想备份images，使用save、load即可若是在启动容器后，容器内容有变化，需要备份，则使用export、import","categories":[],"tags":[],"author":"张存"},{"title":"curl 的用法指南","slug":"curl-的用法指南","date":"2021-10-13T10:57:35.000Z","updated":"2021-10-13T10:58:16.725Z","comments":true,"path":"2021/10/13/curl-de-yong-fa-zhi-nan/","link":"","permalink":"https://blog.zhangcun.store/2021/10/13/curl-de-yong-fa-zhi-nan/","excerpt":"","text":"简介curl 是常用的命令行工具，用来请求 Web 服务器。它的名字就是客户端（client）的 URL 工具的意思。 它的功能非常强大，命令行参数多达几十种。如果熟练的话，完全可以取代 Postman 这一类的图形界面工具。 本文介绍它的主要命令行参数，作为日常的参考，方便查阅。内容主要翻译自《curl cookbook》。为了节约篇幅，下面的例子不包括运行时的输出，初学者可以先看我以前写的《curl 初学者教程》。 不带有任何参数时，curl 就是发出 GET 请求。 $ curl https://www.example.com上面命令向www.example.com发出 GET 请求，服务器返回的内容会在命令行输出。 -A-A参数指定客户端的用户代理标头，即User-Agent。curl 的默认用户代理字符串是curl/[version]。 $ curl -A ‘Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/76.0.3809.100 Safari/537.36’ https://google.com上面命令将User-Agent改成 Chrome 浏览器。 $ curl -A ‘’ https://google.com上面命令会移除User-Agent标头。 也可以通过-H参数直接指定标头，更改User-Agent。 $ curl -H ‘User-Agent: php/1.0’ https://google.com-b-b参数用来向服务器发送 Cookie。 $ curl -b ‘foo=bar’ https://google.com上面命令会生成一个标头Cookie: foo=bar，向服务器发送一个名为foo、值为bar的 Cookie。 $ curl -b ‘foo1=bar;foo2=bar2’ https://google.com上面命令发送两个 Cookie。 $ curl -b cookies.txt https://www.google.com上面命令读取本地文件cookies.txt，里面是服务器设置的 Cookie（参见-c参数），将其发送到服务器。 -c-c参数将服务器设置的 Cookie 写入一个文件。 $ curl -c cookies.txt https://www.google.com上面命令将服务器的 HTTP 回应所设置 Cookie 写入文本文件cookies.txt。 -d-d参数用于发送 POST 请求的数据体。 $ curl -d’login=emma＆password=123’-X POST https://google.com/login#或者$ curl -d ‘login=emma’ -d ‘password=123’ -X POST https://google.com/login使用-d参数以后，HTTP 请求会自动加上标头Content-Type : application/x-www-form-urlencoded。并且会自动将请求转为 POST 方法，因此可以省略-X POST。 -d参数可以读取本地文本文件的数据，向服务器发送。 $ curl -d ‘@data.txt’ https://google.com/login上面命令读取data.txt文件的内容，作为数据体向服务器发送。 –data-urlencode–data-urlencode参数等同于-d，发送 POST 请求的数据体，区别在于会自动将发送的数据进行 URL 编码。 $ curl –data-urlencode ‘comment=hello world’ https://google.com/login上面代码中，发送的数据hello world之间有一个空格，需要进行 URL 编码。 -e-e参数用来设置 HTTP 的标头Referer，表示请求的来源。 curl -e ‘https://google.com?q=example&#39; https://www.example.com上面命令将Referer标头设为https://google.com?q=example。 -H参数可以通过直接添加标头Referer，达到同样效果。 curl -H ‘Referer: https://google.com?q=example&#39; https://www.example.com-F-F参数用来向服务器上传二进制文件。 $ curl -F ‘file=@photo.png’ https://google.com/profile上面命令会给 HTTP 请求加上标头Content-Type: multipart/form-data，然后将文件photo.png作为file字段上传。 -F参数可以指定 MIME 类型。 $ curl -F ‘file=@photo.png;type=image/png’ https://google.com/profile上面命令指定 MIME 类型为image/png，否则 curl 会把 MIME 类型设为application/octet-stream。 -F参数也可以指定文件名。 $ curl -F ‘file=@photo.png;filename=me.png’ https://google.com/profile上面命令中，原始文件名为photo.png，但是服务器接收到的文件名为me.png。 -G-G参数用来构造 URL 的查询字符串。 $ curl -G -d ‘q=kitties’ -d ‘count=20’ https://google.com/search上面命令会发出一个 GET 请求，实际请求的 URL 为https://google.com/search?q=kitties&amp;count=20。如果省略--G，会发出一个 POST 请求。 如果数据需要 URL 编码，可以结合–data–urlencode参数。 $ curl -G –data-urlencode ‘comment=hello world’ https://www.example.com-H-H参数添加 HTTP 请求的标头。 $ curl -H ‘Accept-Language: en-US’ https://google.com上面命令添加 HTTP 标头Accept-Language: en-US。 $ curl -H ‘Accept-Language: en-US’ -H ‘Secret-Message: xyzzy’ https://google.com上面命令添加两个 HTTP 标头。 $ curl -d ‘{“login”: “emma”, “pass”: “123”}’ -H ‘Content-Type: application/json’ https://google.com/login上面命令添加 HTTP 请求的标头是Content-Type: application/json，然后用-d参数发送 JSON 数据。 -i-i参数打印出服务器回应的 HTTP 标头。 $ curl -i https://www.example.com上面命令收到服务器回应后，先输出服务器回应的标头，然后空一行，再输出网页的源码。 -I-I参数向服务器发出 HEAD 请求，然会将服务器返回的 HTTP 标头打印出来。 $ curl -I https://www.example.com上面命令输出服务器对 HEAD 请求的回应。 –head参数等同于-I。 $ curl –head https://www.example.com-k-k参数指定跳过 SSL 检测。 $ curl -k https://www.example.com上面命令不会检查服务器的 SSL 证书是否正确。 -L-L参数会让 HTTP 请求跟随服务器的重定向。curl 默认不跟随重定向。 $ curl -L -d ‘tweet=hi’ https://api.twitter.com/tweet–limit-rate–limit-rate用来限制 HTTP 请求和回应的带宽，模拟慢网速的环境。 $ curl –limit-rate 200k https://google.com上面命令将带宽限制在每秒 200K 字节。 -o-o参数将服务器的回应保存成文件，等同于wget命令。 $ curl -o example.html https://www.example.com上面命令将www.example.com保存成example.html。 -O-O参数将服务器回应保存成文件，并将 URL 的最后部分当作文件名。 $ curl -O https://www.example.com/foo/bar.html上面命令将服务器回应保存成文件，文件名为bar.html。 -s-s参数将不输出错误和进度信息。 $ curl -s https://www.example.com上面命令一旦发生错误，不会显示错误信息。不发生错误的话，会正常显示运行结果。 如果想让 curl 不产生任何输出，可以使用下面的命令。 $ curl -s -o /dev/null https://google.com-S-S参数指定只输出错误信息，通常与-s一起使用。 $ curl -s -o /dev/null https://google.com上面命令没有任何输出，除非发生错误。 -u-u参数用来设置服务器认证的用户名和密码。 $ curl -u ‘bob:12345’ https://google.com/login上面命令设置用户名为bob，密码为12345，然后将其转为 HTTP 标头Authorization: Basic Ym9iOjEyMzQ1。 curl 能够识别 URL 里面的用户名和密码。 $ curl https://bob:12345@google.com/login上面命令能够识别 URL 里面的用户名和密码，将其转为上个例子里面的 HTTP 标头。 $ curl -u ‘bob’ https://google.com/login上面命令只设置了用户名，执行后，curl 会提示用户输入密码。 -v-v参数输出通信的整个过程，用于调试。 $ curl -v https://www.example.com–trace参数也可以用于调试，还会输出原始的二进制数据。 $ curl –trace - https://www.example.com-x-x参数指定 HTTP 请求的代理。 $ curl -x socks5://james:&#x63;&#x61;&#116;&#115;&#64;&#x6d;&#121;&#x70;&#114;&#111;&#x78;&#121;&#x2e;&#x63;&#x6f;&#109;:8080 https://www.example.com上面命令指定 HTTP 请求通过myproxy.com:8080的 socks5 代理发出。 如果没有指定代理协议，默认为 HTTP。 $ curl -x james:&#99;&#97;&#116;&#115;&#64;&#109;&#x79;&#x70;&#x72;&#x6f;&#x78;&#121;&#x2e;&#99;&#111;&#x6d;:8080 https://www.example.com上面命令中，请求的代理使用 HTTP 协议。 -X-X参数指定 HTTP 请求的方法。 $ curl -X POST https://www.example.com上面命令对https://www.example.com发出 POST 请求。","categories":[],"tags":[],"author":"张存"},{"title":"E: 错误，pkgProblemResolver::Resolve 发生故障，这可能是有软件包被要求保持现状的缘故。 E: 无法更正依赖关系","slug":"E-错误，pkgProblemResolver-Resolve-发生故障，这可能是有软件包被要求保持现状的缘故。-E-无法更正依赖关系","date":"2021-10-13T10:52:55.000Z","updated":"2021-10-13T10:52:58.390Z","comments":true,"path":"2021/10/13/e-cuo-wu-pkgproblemresolver-resolve-fa-sheng-gu-zhang-zhe-ke-neng-shi-you-ruan-jian-bao-bei-yao-qiu-bao-chi-xian-zhuang-de-yuan-gu-e-wu-fa-geng-zheng-yi-lai-guan-xi/","link":"","permalink":"https://blog.zhangcun.store/2021/10/13/e-cuo-wu-pkgproblemresolver-resolve-fa-sheng-gu-zhang-zhe-ke-neng-shi-you-ruan-jian-bao-bei-yao-qiu-bao-chi-xian-zhuang-de-yuan-gu-e-wu-fa-geng-zheng-yi-lai-guan-xi/","excerpt":"","text":"mentohust:i386 已经是最新的版本了。您可能需要运行“apt-get -f install”来纠正下列错误：下列软件包有未满足的依赖关系： mentohust:i386 : 依赖: libpcap0.8:i386 但是它将不会被安装 或 libpcap0.9:i386 但无法安装它 或 libpcap1.0:i386 但无法安装它 或 libpcap1:i386 但无法安装它 wps-office : 依赖: libc6:i386 (&gt;= 2.12) 但是它将不会被安装 依赖: libstdc++6:i386 (&gt;= 4.5) 但是它将不会被安装 依赖: libfreetype6:i386 (&gt;= 2.4) 但是它将不会被安装 依赖: libglu1-mesa:i386 但是它将不会被安装 依赖: libcups2:i386 但是它将不会被安装 依赖: libglib2.0-0:i386 但是它将不会被安装 依赖: libsm6:i386 但是它将不会被安装 依赖: libxrender1:i386 但是它将不会被安装 依赖: libfontconfig1:i386 但是它将不会被安装 推荐: ttf-mscorefonts-installer 但是它将不会被安装E: 有未能满足的依赖关系。请尝试不指明软件包的名字来运行“apt-get -f install”(也可以指定一个解决办法)。 E: 错误，pkgProblemResolver::Resolve 发生故障，这可能是有软件包被要求保持现状的缘故。 E: 无法更正依赖关系 卸载包 apt-get purge mentohust 或者更换一下源 gedit /etc/apt/sources.list#华中科技大学更新服务器deb http://mirrors.hust.edu.cn/ubuntu/ utopic main restricted universe multiversedeb http://mirrors.hust.edu.cn/ubuntu/ utopic-backports restricted universe multiversedeb http://mirrors.hust.edu.cn/ubuntu/ utopic-proposed main restricted universe multiversedeb http://mirrors.hust.edu.cn/ubuntu/ utopic-security main restricted universe multiversedeb http://mirrors.hust.edu.cn/ubuntu/ utopic-updates main restricted universe multiversedeb-src http://mirrors.hust.edu.cn/ubuntu/ utopic main restricted universe multiversedeb-src http://mirrors.hust.edu.cn/ubuntu/ utopic-backports main restricted universe multiversedeb-src http://mirrors.hust.edu.cn/ubuntu/ utopic-proposed main restricted universe multiversedeb-src http://mirrors.hust.edu.cn/ubuntu/ utopic-security main restricted universe multiversedeb-src http://mirrors.hust.edu.cn/ubuntu/ utopic-updates main restricted universe multiverse 完啦以后apt-get -f install会要求卸载有冲突的软件包","categories":[],"tags":[],"author":"张存"},{"title":"linux mysql5.7设置中文字符集","slug":"linux-mysql5-7设置中文字符集","date":"2021-10-13T03:00:53.000Z","updated":"2021-10-13T03:16:30.152Z","comments":true,"path":"2021/10/13/linux-mysql5-7-she-zhi-zhong-wen-zi-fu-ji/","link":"","permalink":"https://blog.zhangcun.store/2021/10/13/linux-mysql5-7-she-zhi-zhong-wen-zi-fu-ji/","excerpt":"","text":"ubuntu20.04已测试 注意版本，好像从5.6根5.5就不一样，配置文件更深了一层。 1.用vim或nano编辑 /etc/mysql/mysql.conf.d/mysqld.cnf 2.[mysqld]后面添加 character_set_server=utf8 保存退出 3.#service mysql restart 4.登录mysql #mysql -u root -p 后mysql&gt;show variables like ‘character%’查看编码是否都变成了utf8，如果还有latin编码则失败。","categories":[],"tags":[],"author":"张存"},{"title":"ubuntu sudo免密码操作","slug":"ubuntu-sudo免密码操作","date":"2021-10-12T10:28:22.000Z","updated":"2021-10-12T10:32:17.576Z","comments":true,"path":"2021/10/12/ubuntu-sudo-mian-mi-ma-cao-zuo/","link":"","permalink":"https://blog.zhangcun.store/2021/10/12/ubuntu-sudo-mian-mi-ma-cao-zuo/","excerpt":"","text":"sudo vi /etc/sudoers输入密码添加cunzhang ALL=(ALL) NOPASSWD : ALL注释掉 #%sudo ALL=(ALL:ALL) ALL改成%sudo ALL=NOPASSWD: ALL wq! 保存","categories":[],"tags":[],"author":"张存"},{"title":"vmware workstation16许可证密钥","slug":"vmware-workstation16许可证密钥","date":"2021-10-12T10:18:50.000Z","updated":"2021-10-12T10:19:52.707Z","comments":true,"path":"2021/10/12/vmware-workstation16-xu-ke-zheng-mi-yao/","link":"","permalink":"https://blog.zhangcun.store/2021/10/12/vmware-workstation16-xu-ke-zheng-mi-yao/","excerpt":"","text":"vmware workstation16许可证密钥 ZF3R0-FHED2-M80TY-8QYGC-NPKYFYF390-0HF8P-M81RQ-2DXQE-M2UT6ZF71R-DMX85-08DQY-8YMNC-PPHV8 前面的如果已经失效，用下面的 FA1M0-89YE3-081TQ-AFNX9-NKUC0","categories":[],"tags":[],"author":"张存"},{"title":"jenkins ssh连接超时错误","slug":"jenkins-ssh连接超时错误","date":"2021-10-12T10:09:25.000Z","updated":"2021-10-12T10:11:04.778Z","comments":true,"path":"2021/10/12/jenkins-ssh-lian-jie-chao-shi-cuo-wu/","link":"","permalink":"https://blog.zhangcun.store/2021/10/12/jenkins-ssh-lian-jie-chao-shi-cuo-wu/","excerpt":"","text":"SSH: Disconnecting configuration [汇保理测试] …ERROR: Exception when publishing, exception message [Exec timed out or was interrupted after 120,000 ms]Finished: UNSTABLE解决办法很简单： 1.延长timeout时间如下，默认的timeout时间为120秒：11.延长timeout时间如下，默认的timeout时间为120秒： 测试过程中发现及时timeout了调用的脚本也会执行完，只是在Jenkins看不到输出的日志。 3.如果Job会执行很长时间，也不想等timeout可以勾选[Exec in pty]选项 勾选后再执行，成功","categories":[],"tags":[],"author":"张存"},{"title":"docker logs－查看docker容器日志","slug":"docker-logs－查看docker容器日志","date":"2021-10-12T10:00:52.000Z","updated":"2021-10-12T10:03:46.248Z","comments":true,"path":"2021/10/12/docker-logs-cha-kan-docker-rong-qi-ri-zhi/","link":"","permalink":"https://blog.zhangcun.store/2021/10/12/docker-logs-cha-kan-docker-rong-qi-ri-zhi/","excerpt":"","text":"通过docker logs命令可以查看容器的日志。 命令格式： $ docker logs [OPTIONS] CONTAINER Options: –details 显示更多的信息 -f, –follow 跟踪实时日志 –since string 显示自某个timestamp之后的日志，或相对时间，如42m（即42分钟） –tail string 从日志末尾显示多少行日志， 默认是all -t, –timestamps 显示时间戳 –until string 显示自某个timestamp之前的日志，或相对时间，如42m（即42分钟）例子： 查看指定时间后的日志，只显示最后100行： docker logs –tail 50 –follow –timestamps id $ docker logs -f -t –since=”2018-02-08” –tail=100 CONTAINER_ID查看最近30分钟的日志: $ docker logs –since 30m CONTAINER_ID查看某时间之后的日志： $ docker logs -t –since=”2018-02-08T13:23:37” CONTAINER_ID查看某时间段日志： $ docker logs -t –since=”2018-02-08T13:23:37” –until “2018-02-09T12:23:37” CONTAINER_ID","categories":[],"tags":[],"author":"张存"},{"title":"【Docker】容器与系统时间同步","slug":"【Docker】容器与系统时间同步","date":"2021-10-12T08:38:47.000Z","updated":"2021-10-12T08:39:40.619Z","comments":true,"path":"2021/10/12/docker-rong-qi-yu-xi-tong-shi-jian-tong-bu/","link":"","permalink":"https://blog.zhangcun.store/2021/10/12/docker-rong-qi-yu-xi-tong-shi-jian-tong-bu/","excerpt":"","text":"宿主机时间[root@slave-1 ~]# dateFri May 12 11:20:30 CST 2017 容器时间[root@slave-1 ~]# docker exec -ti 87986863838b /bin/bashroot@87986863838b:/# dateFri May 12 03:20:33 UTC 2017发现两者之间的时间相差了八个小时！宿主机采用了CST时区，CST应该是指（China Shanghai Time，东八区时间）容器采用了UTC时区，UTC应该是指（Coordinated Universal Time，标准时间） 统一两者的时区有下面几种方法 1）共享主机的localtime 创建容器的时候指定启动参数，挂载localtime文件到容器内，保证两者所采用的时区是一致的。#docker run -ti -d –name my-nginx -v /etc/localtime:/etc/localtime:ro docker.io/nginx /bin/bash2)复制主机的localtime [root@slave-1 ~]# docker cp /etc/localtime 87986863838b:/etc/ 然后再登陆容器，查看时间，发现已经跟宿主机时间同步了[root@slave-1 ~]# docker exec -ti 87986863838b /bin/bashroot@87986863838b:/# dateFri May 12 11:26:19 CST 20173）创建dockerfile文件的时候，自定义该镜像的时间格式及时区。在dockerfile文件里添加下面内容： ……FROM tomcatENV CATALINA_HOME /usr/local/tomcat…….#设置时区RUN /bin/cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime &amp;&amp; echo ‘Asia/Shanghai’ &gt;/etc/timezone 保存后，利用docker build命令生成镜像使用即可,使用dockerfile创建的镜像的容器改变了容器的时区，这样不仅保证了容器时间与宿主机时间一致（假如宿主机也是CST）,并且像上面使用tomcat作为父镜像的话，JVM的时区也是CST,这样tomcat的日志信息的时间也是和宿主机一致的，像上面那两种方式只是保证了宿主机时间与容器时间一致，JVM的时区并没有改变，tomcat日志的打印时间依旧是UTC。","categories":[],"tags":[],"author":"张存"},{"title":"安装Maven环境","slug":"安装Maven环境","date":"2021-10-12T08:29:13.000Z","updated":"2021-10-12T08:31:54.456Z","comments":true,"path":"2021/10/12/an-zhuang-maven-huan-jing/","link":"","permalink":"https://blog.zhangcun.store/2021/10/12/an-zhuang-maven-huan-jing/","excerpt":"","text":"因为用到的docker镜像中不包含maven，所以要在宿主机中安装，通过文件挂载的方式提供调用 （1）切换到要安装的文件夹 cd /opt/software（2）下载maven包 wget http://mirror.bit.edu.cn/apache/maven/maven-3/3.6.3/binaries/apache-maven-3.6.3-bin.tar.gz（3）解压 tar -xzvf apache-maven-3.6.3-bin.tar.gz（4）配置settings.xml（可选）此处使用了阿里云的Maven仓库 aliyunmaven * 阿里云公共仓库 https://maven.aliyun.com/repository/public （5）添加环境变量 vi /etc/profile在文件底部加上 export M2_HOME=/opt/software/apache-maven-3.6.3export PATH=$PATH:${M2_HOME}/bin保存并退出编辑，使用下面的命令让修改生效 source /etc/profile（6）验证Maven安装 mvn -version","categories":[],"tags":[],"author":"张存"},{"title":"unbuntu 安装cdua11.4","slug":"unbuntu-安装cdua11-4","date":"2021-10-11T08:16:44.000Z","updated":"2021-11-04T07:06:19.645Z","comments":true,"path":"2021/10/11/unbuntu-an-zhuang-cdua11-4/","link":"","permalink":"https://blog.zhangcun.store/2021/10/11/unbuntu-an-zhuang-cdua11-4/","excerpt":"","text":"​1.备份原来的源，将以前的源备份一下，以防以后可以用的。 sudo cp /etc/apt/sources.list /etc/apt/sources.list.bak 2.打开/etc/apt/sources.list文件，在前面添加如下条目，并保存。 deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal main restricted universe multiverse#deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal main restricted universe multiversedeb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-updates main restricted universe multiverse#deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-updates main restricted universe multiversedeb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-backports main restricted universe multiverse#deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-backports main restricted universe multiversedeb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-security main restricted universe multiverse#deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-security main restricted universe multiverse multiverse 3.执行apt-get update 更新源 4.下载pin文件 wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/cuda-ubuntu2004.pinmv cuda-ubuntu2004.pin /etc/apt/preferences.d/cuda-repository-pin-600apt-key adv –fetch-keys https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/7fa2af80.pub 向 source.list 中添加 cuda软件源 add-apt-repository “deb https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/ /“ sed -i ‘s/nvidia.com/nvidia.cn/‘ /etc/apt/sources.list apt-get updateapt-get -y install cuda vim /etc/profile 再最后两行添加 export PATH=/usr/local/cuda-11.4/bin:$PATHexport LD_LIBRARY_PATH=/usr/local/cuda-11.4/lib64:$LD_LIBRARY_PATH source /etc/profile 验证 nvcc -V nvidia-smi 如遇：下图请重启电脑 cuda官网链接：https://developer.nvidia.com/cuda-downloads ​","categories":[],"tags":[],"author":"张存"},{"title":"Ubuntu使用非root用户运行docker","slug":"Ubuntu使用非root用户运行docker","date":"2021-10-08T02:47:00.000Z","updated":"2021-10-08T02:54:06.606Z","comments":true,"path":"2021/10/08/ubuntu-shi-yong-fei-root-yong-hu-yun-xing-docker/","link":"","permalink":"https://blog.zhangcun.store/2021/10/08/ubuntu-shi-yong-fei-root-yong-hu-yun-xing-docker/","excerpt":"","text":"默认情况下，docker 命令会使用 Unix socket 与 Docker 主机通讯，安装完docker主机后默认会创建一个docke用户组。而只有 root 用户和 docker 组的用户才可以访问 Docker 主机的 Unix socket，所以需要把linux非root用户添加到docker组才能直接访问docker 主机。步骤如下： 1.如果没有创建docker用户组，则需要先创建一个docket用户组。$ sudo groupadd docker2.将指定的用户添加到docker用户组。 $ sudo usermod -aG docker userName3.重启docker服务 $ sudo service docker restart //或者 $ sudo /etc/init.d/docker restart4.切换当前回话到docker组或者关闭当前回话重新打开终端。 $ newgrp - docker //切换到docker用户组","categories":[],"tags":[],"author":"张存"},{"title":"ubuntu20.04详细安装教程","slug":"ubuntu20-04详细安装教程","date":"2021-09-30T08:12:18.000Z","updated":"2021-09-30T13:54:26.472Z","comments":true,"path":"2021/09/30/ubuntu20-04-xiang-xi-an-zhuang-jiao-cheng/","link":"","permalink":"https://blog.zhangcun.store/2021/09/30/ubuntu20-04-xiang-xi-an-zhuang-jiao-cheng/","excerpt":"","text":"ubuntu20.04详细安装教程 本文为方便演示采用 VMware Workstation 16 如在生产环境安装基本雷同！ 下载ISO镜像： 从网易的镜像网站下载http://mirrors.163.com/ubuntu-releases/20.04/ 创建虚拟机： 打开vmware，选择【文件】——【新建虚拟机】：典型 【下一步】：“安装客户机操作系统”窗口中，选择：【稍后安装操作系统】。 【下一步】：“选择客户机操作系统”窗口中，操作系统选择：【Linux】，版本选择【Ubuntu 64位】。 【下一步】：“命名虚拟机”窗口中，位置一栏中，选择用于存放虚拟机的目录，这里建议找个空闲的磁盘分区。 【下一步】：“指定磁盘容量”窗口中，大小默认不动，下面选择：【将虚拟磁盘存储为单个文件】。【下一步】：“已准备好创建虚拟机”窗口中，选择：【完成】。 分配虚拟机硬件资源： 打开VMware，选择【虚拟机】——【设置】，打开“虚拟机设置”窗口，快捷键：ctrl + D。 根据自己的硬件条件，适当分配一些硬件资源。 必须设置的一项为：【CD/DVD(STAT)】，在右侧“连接”板块内选择【使用ISO镜像文件】，并指定前面下载的Ubuntu镜像文件存放目录。 分配好虚拟机的硬件资源后点击【确定】。 开始安装Ubuntu 1、运行虚拟机，加载一段时间后弹出“安装”界面。语言栏倒数第三个是中文。点击【安装 Ubuntu】。 2、键盘布局，【继续】 3、更新和其他软件，取消【安装Ubuntu时下载更新】选项，点击【继续】。 4、安装类型，这里如果是学习，或者是为了熟悉这个系统，那直接【现在安装】，让系统自动分配分区，随后弹出“将改动写入此盘吗”，选择【继续】。 5、你在什么地方，选择【Shanghai】——【继续】。 6、你是谁，将各个选项填写一下。点击【继续】。 7、安装完成，重启，进入桌面。","categories":[],"tags":[],"author":"张存"},{"title":"video视频","slug":"video视频","date":"2021-09-29T12:53:30.000Z","updated":"2021-09-29T12:53:35.090Z","comments":true,"path":"2021/09/29/video-shi-pin/","link":"","permalink":"https://blog.zhangcun.store/2021/09/29/video-shi-pin/","excerpt":"","text":"video演示 100%宽度 Your browser does not support the video tag. 50%宽度 Your browser does not support the video tag. Your browser does not support the video tag. Your browser does not support the video tag. Your browser does not support the video tag. 25%宽度 Your browser does not support the video tag. Your browser does not support the video tag. Your browser does not support the video tag. Your browser does not support the video tag. Your browser does not support the video tag. Your browser does not support the video tag. Your browser does not support the video tag. Your browser does not support the video tag.","categories":[],"tags":[],"author":"张存"},{"title":"Text文本样式标签","slug":"111","date":"2021-09-29T12:47:15.000Z","updated":"2021-09-29T12:47:54.273Z","comments":true,"path":"2021/09/29/111/","link":"","permalink":"https://blog.zhangcun.store/2021/09/29/111/","excerpt":"","text":"Text文本样式标签演示 带 下划线 的文本 带 着重号 的文本 带 波浪线 的文本 带 删除线 的文本 键盘样式的文本 command + D 密码样式的文本：这里没有验证码","categories":[],"tags":[],"author":"张存"},{"title":"timeline时间线","slug":"abc","date":"2021-09-29T12:43:36.000Z","updated":"2021-09-29T12:43:59.263Z","comments":true,"path":"2021/09/29/abc/","link":"","permalink":"https://blog.zhangcun.store/2021/09/29/abc/","excerpt":"","text":"2021-01-01 1.0.3 -&gt; 1.0.3 我是一个测试文字ghghgh。我是一个测试问题二’qweqw’，请问企鹅请问请问佛挡杀fgfgf佛第三节课。我是一个测试问题三’fgfgfg’，请问企鹅请问请问佛挡杀trtrtr佛第三节课。 2020-08-15 1.0.2 -&gt; 1.0.2 这是一段测试文字 2020-08-08 1.0.0 -&gt; 1.0.0 我是一个测试文字ghghgh。我是一个测试问题二’qweqw’，请问企鹅请问请问佛挡杀fgfgf佛第三节课。我是一个测试问题三’fgfgfg’，请问企鹅请问请问佛挡杀trtrtr佛第三节课。","categories":[],"tags":[],"author":"张存"},{"title":"title","slug":"line","date":"2021-09-29T12:34:13.000Z","updated":"2021-09-29T12:54:06.496Z","comments":true,"path":"2021/09/29/line/","link":"","permalink":"https://blog.zhangcun.store/2021/09/29/line/","excerpt":"","text":"我是标题 你好啊，未来越来越好哦 我是标题 你好啊，加油哦 我是标题 我是标题 上述事例代码1 &#123;% title h1, 我是标题 %&#125; 2 你好啊，未来越来越好哦 3 &#123;% title h2, 我是标题 %&#125; 4 你好啊，加油哦 5 &#123;% title h2, 我是标题, warning %&#125; 6 % title h2, 我是标题, red %&#125; 我是标题bbb 我是标题bbb 我是标题bbb","categories":[],"tags":[],"author":"张存"},{"title":"使用docker-compose部署wiki","slug":"wiki","date":"2021-09-27T12:12:12.000Z","updated":"2021-10-13T10:29:42.622Z","comments":true,"path":"2021/09/27/wiki/","link":"","permalink":"https://blog.zhangcun.store/2021/09/27/wiki/","excerpt":"","text":"操作系统环境 ubuntu 20.04 1.u盘安装ubuntu 并安装ssh服务（方便后面远程操作）2.安装更新apt源和安装必要软件包3.安装docker和docker-compose （2和3具体见docker部署openvpn-web） 4.具体搭建过程 1.1 基础准备1.1.1 拉取docker镜像，我们选择的版本是cptactionhank/atlassian-confluence:latestmkdir ./confluencecd ./confluencedocker pull cptactionhank/atlassian-confluence:latest 1.1.2 准备好mysql的驱动，我们使用的mysql版本是5.7wget https://repo1.maven.org/maven2/mysql/mysql-connector-java/5.1.47/mysql-connector-java-5.1.47.jar #mysql8.0.20驱动：wget https://repo1.maven.org/maven2/mysql/mysql-connector-java/8.0.20/mysql-connector-java-8.0.20.jar 1.1.3 准备好docker-compose.yml version: &#39;3&#39; services: confluence: image: cptactionhank/atlassian-confluence:latest container_name: confluence restart: always user: root ports: - 8090:8090 - 8091:8091 networks: - traefik volumes: - &quot;/usr/share/zoneinfo/Asia/Shanghai:/etc/localtime&quot; - ./confluence/logs:/opt/atlassian/confluence/logs - ./server.xml:/opt/atlassian/confluence/conf/server.xml - ./confluence-data:/var/atlassian/confluence - ./mysql-connector-java-5.1.47.jar:/opt/atlassian/confluence/confluence/WEB-INF/lib/mysql-connector-java-5.1.47.jar networks: traefik: external: true 1.1.4 在准备好的 msyql 中创建数据库– drop database confluence;create database confluence DEFAULT CHARACTER SET utf8 COLLATE utf8_bin; 1.1.5 下载好破解工具#下载链接：http://image.baishapu.com/confluence破解工具.zip 1.2 部署破解1.2.1 启动#创建网卡docker network create traefik#启动docker-compose up -d#查看日志docker logs -tf –tail 300 confluence#访问地址： yourIp:8090 1.2.2 复制出 atlassian 的 jar 包docker cp confluence:/opt/atlassian/confluence/confluence/WEB-INF/lib/atlassian-extras-decoder-v2-3.4.1.jar ./atlassian-extras-2.4.jar 下载 atlassian-extras-2.4.jar 文件到windows上 注意复制出来的文件名必须为 atlassian-extras-2.4.jar，因为破解工具中指定了此文件名；1.2.3 运行工具，(提前安装好win版jdk 然后进入jar所在目前 执行java -jar confluence_keygen.jar)如图: 成功后，会在原目录下出现atlassian-extras-2.4.back 备份文件，并生成了一个新的破解后的 atlassian-extras-2.4.jar1.2.4 复制破解后的jar包回容器中docker cp ./atlassian-extras-2.4.jar confluence:/opt/atlassian/confluence/confluence/WEB-INF/lib/atlassian-extras-decoder-v2-3.4.1.jar#重启docker restart confluence 1.2.5 剩下的按照页面提示一步一步设置即可注意：mysql连接时，需要设置事务隔离级别 READ-COMMITTED 参考链接：https://confluence.atlassian.com/confkb/confluence-fails-to-start-and-throws-mysql-session-isolation-level-repeatable-read-is-no-longer-supported-error-241568536.html #mysql 5jdbc:mysql://192.168.1.172:3307/confluence?useSSL=false&amp;sessionVariables=tx_isolation=’READ-COMMITTED’ 解决慢时长gc的问题 默认java配置为1G内存使用一段时间后回经常gc造成卡顿，单击“系统信息”可以看到jvm使用情况 进入docker容器 docker exec -it confluence /bin/bash # 进入docker容器 confluence 修改java配置 vi /opt/atlassian/confluence/bin/catalina.sh 在 “cygwin=false” 上面添加如下内容，最大内存为2G CATALINA_OPTS=”-Xms256m -Xmx2048m -XX:PermSize=128m -XX:MaxPermSize=512m” 重启 wiki confluence 二、数据备份与迁移2.1 参考链接：https://www.cwiki.us/display/CONF6EN/Migrating+Confluence+Between+Servers#space-menu-link-content https://confluence.atlassian.com/conf615/migrating-confluence-between-servers-967338806.html #我的迁移过程1、备份mysql数据库；2、备份mysql驱动；3、备份主目录（本文档安装的挂载目录 “- ./data:/var/atlassian/application-data/confluence”）4、备份server.xml（容器目录： /opt/atlassian/confluence/conf/server.xml）5、在新机器上准备好安装过程需要的东西，以及备份的东西拿过去准备覆盖；6、如果需要迁移数据库，可以直接修改配置文件：&lt;confluence.home&gt;/confluence.cfg.xml 迁移后，日志显示启动成功，但页面任然无法访问，此过程大概需要几分钟左右2.2 关闭confluence自带每日备份任务 2.3 手动备份脚本 + crontab定时任务备份数据库，主目录挂载出来即可； 三、导出PDF注意：confluence导出PDF仅支持一种字体，且需要自己手动上传安装；（可以从系统目录C:\\Windows\\Fonts 中复制出来） 四、配置邮件服务器参考链接：https://qinjiangbo.com/mail-server-configuration-of-confluence.html 说明：25、465端口不行，再试试587端口也是可以的 五、版本升级Confluence7 + Mysql8：CREATE DATABASE xxxxxxConfluence CHARACTER SET utf8mb4 COLLATE utf8mb4_bin; #隔离级别的设置， mysql 8 的区别：sessionVariables=transaction_isolation=’READ-COMMITTED’","categories":[],"tags":[],"author":"张存"},{"title":"MySQL查看数据库表容量大小","slug":"MySQL查看数据库表容量大小","date":"2021-09-26T14:16:34.000Z","updated":"2022-05-06T08:29:41.789Z","comments":true,"path":"2021/09/26/mysql-cha-kan-shu-ju-ku-biao-rong-liang-da-xiao/","link":"","permalink":"https://blog.zhangcun.store/2021/09/26/mysql-cha-kan-shu-ju-ku-biao-rong-liang-da-xiao/","excerpt":"","text":"1.查看所有数据库容量大小 select table_schema as &#39;数据库&#39;, sum(table_rows) as &#39;记录数&#39;, sum(truncate(data_length/1024/1024, 2)) as &#39;数据容量(MB)&#39;, sum(truncate(index_length/1024/1024, 2)) as &#39;索引容量(MB)&#39; from information_schema.tables group by table_schema order by sum(data_length) desc, sum(index_length) desc; 2.查看所有数据库各表容量大小 select table_schema as &#39;数据库&#39;, table_name as &#39;表名&#39;, table_rows as &#39;记录数&#39;, truncate(data_length/1024/1024, 2) as &#39;数据容量(MB)&#39;, truncate(index_length/1024/1024, 2) as &#39;索引容量(MB)&#39; from information_schema.tables order by data_length desc, index_length desc; 3.查看指定数据库容量大小 例：查看mysql库容量大小 select table_schema as &#39;数据库&#39;, sum(table_rows) as &#39;记录数&#39;, sum(truncate(data_length/1024/1024, 2)) as &#39;数据容量(MB)&#39;, sum(truncate(index_length/1024/1024, 2)) as &#39;索引容量(MB)&#39; from information_schema.tables where table_schema=&#39;mysql&#39;; 4.查看指定数据库各表容量大小 例：查看mysql库各表容量大小 select table_schema as &#39;数据库&#39;, table_name as &#39;表名&#39;, table_rows as &#39;记录数&#39;, truncate(data_length/1024/1024, 2) as &#39;数据容量(MB)&#39;, truncate(index_length/1024/1024, 2) as &#39;索引容量(MB)&#39; from information_schema.tables where table_schema=&#39;mysql&#39; order by data_length desc, index_length desc;","categories":[],"tags":[],"author":"张存"},{"title":"Let’s Encrypt 泛域名配置证书","slug":"Let’s-Encrypt-泛域名配置证书","date":"2021-09-26T14:01:25.000Z","updated":"2021-10-28T06:19:32.546Z","comments":true,"path":"2021/09/26/let-s-encrypt-fan-yu-ming-pei-zhi-zheng-shu/","link":"","permalink":"https://blog.zhangcun.store/2021/09/26/let-s-encrypt-fan-yu-ming-pei-zhi-zheng-shu/","excerpt":"","text":"安装acme.sh curl https://get.acme.sh | sh Failed connect to raw.githubusercontent.com:443; Please refer to https://curl.haxx.se/libcurl/c/libcurl-errors.html for error code: 7#通过修改host解析 sudo vim /etc/hosts 添加如下内容 140.82.114.4 github.com 185.199.108.153 github.github.io 199.232.69.194 github.global.ssl.fastly.net 199.232.28.133 raw.githubusercontent.com 通过修改之后，上述可以成功 不行的就拿下面这个地址 wget -O - https://raw.githubusercontent.com/Neilpang/acme.sh/master/acme.sh | INSTALLONLINE=1 sh 获取阿里云Accesskey阿里云dns阿里云申请地址：https://ak-console.aliyun.com/#/accesskey export Ali_Key=”对应Access Key ID”export Ali_Secret=”对应Access Key Secret” ./acme.sh –issue –dns dns_ali - d *.hhui.top 接下来将我们的证书安装到 nginx（当然也可以是 tomcat），下面的脚本除了安装之外，也添加了一个自动更新的任务（一般来说，60 天以后会自动更新，并会强制重启 nginx 使新的证书生效，可以通过 crontab -e看到对应的定时任务 ./acme.sh –installcert -d *.hhui.top –key-file /etc/nginx/ssl/key.pem –fullchain-file /etc/nginx/ssl/cert.pem –reloadcmd “service nginx force-reload” 然后就是配置 nginx，支持 https ACME 手动续期命令 acme.sh –cron –force –debug 2","categories":[],"tags":[],"author":"张存"},{"title":"如何清除没用的 docker 镜像 (image) 文件","slug":"如何清除没用的-docker-镜像-image-文件","date":"2021-09-26T13:52:25.000Z","updated":"2021-09-26T13:53:05.366Z","comments":true,"path":"2021/09/26/ru-he-qing-chu-mei-yong-de-docker-jing-xiang-image-wen-jian/","link":"","permalink":"https://blog.zhangcun.store/2021/09/26/ru-he-qing-chu-mei-yong-de-docker-jing-xiang-image-wen-jian/","excerpt":"","text":"当我们每次构建一次 docker 镜像就会替换掉原来的镜像文件。那些文件很占地方。那么如何清除这些文件呢？ 我们可以使用下面的命令： docker system prune 运行以后可以看到以下提示，输入“y”就可以清理无用的 docker 文件了。","categories":[],"tags":[],"author":"张存"},{"title":"grep和sed配合替换文件中的字串","slug":"grep和sed配合替换文件中的字串","date":"2021-09-26T13:42:32.000Z","updated":"2021-09-26T13:45:39.435Z","comments":true,"path":"2021/09/26/grep-he-sed-pei-he-ti-huan-wen-jian-zhong-de-zi-chuan/","link":"","permalink":"https://blog.zhangcun.store/2021/09/26/grep-he-sed-pei-he-ti-huan-wen-jian-zhong-de-zi-chuan/","excerpt":"","text":"grep和sed配合替换文件中的字串 命令：sed -i s/yyyy/xxxx/g grep -rl yyyy –include=”*.txt” ./作用：将当前目录(包括子目录)中所有txt文件中的yyyy字符串替换为xxxx字符串 参数解释:sed:-i 表示操作的是文件，``括起来的grep命令，表示将grep命令的结果作为操作文件s/yyyy/xxxx/表示查找yyyy并替换为xxxx，后面跟g表示一行中有多个yyyy的时候，都替换，而不是仅替换第一个 grep:-r表示查找所有子目录-l表示仅列出符合条件的文件名，用来传给sed命令做操作–include=”*.txt” 表示仅查找txt文件./ 表示要查找的根目录为当前目录 注：如果不需要查找子目录，仅需要在当前目录替换，用sed命令就行了，命令如下： sed -i s/xxxx/yyyy/g ./*.txt 例如：1. nl /etc/passwd | grep ‘test’ | sed -e ‘3,$d’ -e ‘s/bash/blueshell/‘ /sbin/ifconfig eth0 | grep ‘inet addr’ | sed ‘s/^.addr://g’ | sed ‘s/Bcast.$//g’192.168.1.100","categories":[],"tags":[],"author":"张存"},{"title":"docker镜像批量打包","slug":"docker镜像批量打包","date":"2021-09-26T13:39:51.000Z","updated":"2021-09-26T13:40:57.358Z","comments":true,"path":"2021/09/26/docker-jing-xiang-pi-liang-da-bao/","link":"","permalink":"https://blog.zhangcun.store/2021/09/26/docker-jing-xiang-pi-liang-da-bao/","excerpt":"","text":"批量打包镜像: # docker save $(docker images | grep -v REPOSITORY | awk &#39;BEGIN&#123;OFS=&quot;:&quot;;ORS=&quot; &quot;&#125;&#123;print $1,$2&#125;&#39;) -o demo.tar 将机器上的所有镜像打包到demo.tar文件里面。 导入镜像： # docker load -i demo.tar 然后docker images就可以看到拷贝过来的镜像了。","categories":[],"tags":[],"author":"张存"},{"title":"docker删除所有容器/镜像","slug":"docker删除所有容器-镜像","date":"2021-09-26T12:32:28.000Z","updated":"2021-11-16T11:43:19.750Z","comments":true,"path":"2021/09/26/docker-shan-chu-suo-you-rong-qi-jing-xiang/","link":"","permalink":"https://blog.zhangcun.store/2021/09/26/docker-shan-chu-suo-you-rong-qi-jing-xiang/","excerpt":"","text":"1.想要删除容器，则要先停止所有容器（当然，也可以加-f强制删除，但是不推荐）： docker stop $(docker ps -a -q) 2.删除所有容器 docker rm $(docker ps -a -q)docker rm docker ps -a -q 3.删除所有镜像（慎重） docker rmi $(docker images -q) docker rmi docker images -q 4.删除所有没有tag的镜像docker rmi docker images|grep none|awk &#39;&#123;print $3 &#125;&#39;|xargs 5.删除指定的镜像 docker rmi –force docker images |grep pt-* |awk &#39;/0108/ &#123;print $3&#125;&#39; docker rmi -f docker images | grep pt-*| awk &#39;&#123;print $3&#125;&#39; 6.删除状态为created的容器 docker rm $(docker ps -f status=created|awk ‘{print $1}’) 7.删除状态为exited的容器 docker rm $(docker ps -q -f status=exited)","categories":[],"tags":[],"author":"张存"},{"title":"解决任意域名都能访问nginx443端口的问题","slug":"解决任意域名都能访问nginx443端口的问题","date":"2021-09-26T12:16:01.000Z","updated":"2021-09-26T12:20:19.889Z","comments":true,"path":"2021/09/26/jie-jue-ren-yi-yu-ming-du-neng-fang-wen-nginx443-duan-kou-de-wen-ti/","link":"","permalink":"https://blog.zhangcun.store/2021/09/26/jie-jue-ren-yi-yu-ming-du-neng-fang-wen-nginx443-duan-kou-de-wen-ti/","excerpt":"","text":"今天调试时发现，使用b.nbxg.com，c.errb.com等域名也可以访问 a.2kb.com下载目录，这对搜索引擎抓包时应该会产生比较严重的影响，导致搜索引擎误判。 例如 https://www.nbxg.com/index.html 同样也可以访问 https://www.2kb.com/index.html server &#123; listen 443 ssl; server_name a.2kb.com; root html; index index.html index.htm; ssl_certificate cert/a.crt; ssl_certificate_key cert/a.key; ssl_session_timeout 5m; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_prefer_server_ciphers on; ssl_dhparam cert/a.pem; location / &#123; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header Host $http_host; proxy_set_header X-Forwarded-Proto https; proxy_redirect off; proxy_connect_timeout 240; proxy_send_timeout 240; proxy_read_timeout 240; client_max_body_size 1000m; proxy_pass http://localhost/; &#125; &#125; 经查找，采用以下解决方案 添加一个默认的ssl默置，Nginx找不到ssl server_name时，将转向默认的配置，但必须指定一下证书，随意证书即可 server &#123; listen 443 default_server; server_name _ ; ssl on; ssl_certificate cert/a.crt; ssl_certificate_key cert/a.key; #return 404; location / &#123; root /etc/nginx/error; index index.html; &#125; &#125;","categories":[],"tags":[],"author":"张存"},{"title":"vim 给每行首加入#","slug":"vim-给每行首加入","date":"2021-09-26T12:09:01.000Z","updated":"2021-09-26T12:09:25.815Z","comments":true,"path":"2021/09/26/vim-gei-mei-xing-shou-jia-ru/","link":"","permalink":"https://blog.zhangcun.store/2021/09/26/vim-gei-mei-xing-shou-jia-ru/","excerpt":"","text":"每行的行首都添加一个字符串：%s/^/要插入的字符串 每行的行尾都添加一个字符串：%s/$/要插入的字符串 解释： % 代表针对被编辑文件的每一行进行后续操作 $ 代表一行的结尾处 ^ 代表一行的开头处","categories":[],"tags":[],"author":"张存"},{"title":"vim如何删除行首、行位空格、空格行","slug":"5","date":"2021-09-26T12:01:00.000Z","updated":"2022-04-26T10:42:37.367Z","comments":true,"path":"2021/09/26/5/","link":"","permalink":"https://blog.zhangcun.store/2021/09/26/5/","excerpt":"","text":"删除空格行： 非编辑状态下输入:g/^$/d 删除行首空格： 非编辑状态下输入:%s/^\\s*//g 删除行尾空格： 非编辑状态下输入:%s/\\s*$//g","categories":[],"tags":[],"author":"张存"},{"title":"常用地址","slug":"常用地址","date":"2021-09-26T11:50:00.000Z","updated":"2022-04-26T10:45:14.941Z","comments":true,"path":"2021/09/26/chang-yong-di-zhi/","link":"","permalink":"https://blog.zhangcun.store/2021/09/26/chang-yong-di-zhi/","excerpt":"","text":"阿里云 1.https://homenew.console.aliyun.com/home/dashboard/Operation#/main油猴脚本 2.https://greasyfork.org/zh-CN/scripts/422814-%E7%99%BE%E5%BA%A6%E4%BA%91%E5%8E%BB%E5%B9%BF%E5%91%8A-%E5%BF%AB%E6%8D%B7%E9%94%AE%E5%80%8D%E9%80%9F-%E5%85%8Dvip%E8%A7%A3%E9%94%81%E5%80%8D%E9%80%9F-%E7%94%BB%E8%B4%A8-%E5%85%A8%E7%BD%91%E7%8B%AC%E5%AE%B6 佛跳墙 3.https://www.qingfengwuhan.com/cn/?a=gi9cp 腾讯企业邮箱 4.https://exmail.qq.com/cgi-bin/frame_html?sid=s9mygrvxv209cl8_,2&amp;sign_type=&amp;r=9a3e649d7110b94b98d7d3f3dc1b091a 阿里企业邮箱 5.https://qiye.aliyun.com/alimail/auth/login?reurl=%2Falimail%2F%23h%3DWyJmbV8yIixbIjIiLCIiLHsiZklkIjoiMSIsInNlbElkIjoiMV8wOkR6enp6eVN4akpKJC0tLS5LdWs0WExuMCIsIm9mZnNldCI6MCwicmciOltbIm1haWxfc2Vzc2lvbl92aWV3Iix7ImlkIjoibSExXzA6RHp6enp5U3hqSkokLS0tLkt1azRYTG4wIiwic2YiOjAsImNvbnRhaW5lcldpZHRoIjozNjB9XV19LHsibGFiZWwiOiLpgq7ku7YifV1d 公积金查询6.https://grwsyw.gjj.beijing.gov.cn/ish/flow/menu/PPLGRZH0102?_r=0.4468948447490928 谷歌翻译7.https://translate.google.com/vmware8.https://customerconnect.vmware.com/en/downloads/details?downloadGroup=ESXI60U3A&amp;productId=491&amp;rPId=74596 Chrome插件扩展下载网9.https://www.extfans.com/search/extensions/%25E8%25BA%25AB%25E4%25BB%25BD/","categories":[],"tags":[],"author":"张存"},{"title":"testimg","slug":"3","date":"2021-09-26T10:53:12.000Z","updated":"2022-04-26T10:31:35.697Z","comments":true,"path":"2021/09/26/3/","link":"","permalink":"https://blog.zhangcun.store/2021/09/26/3/","excerpt":"","text":"ctrl + R 我是黑体字我是微软雅黑我是华文彩云color=#0099ff size=3 face=”黑体”color=#00ffff size=4color=gray size=5 我是高亮 `文本高亮` 这里的内容显示在内容块中 #!/usr/bin/env python3 print(\"Hello, World!\"); 这是红色字体 这是绿色字体 这是黄色字体 这是蓝色字体 &gt; 这里的内容显示在内容块中 asda – haha – 我是一段文字 asa 第一项 第二项 第三项 第一项 第二项 第三项 第一项 第二项 第三项 第一项： 第一项嵌套的第一个元素 第一项嵌套的第二个元素 第二项： 第二项嵌套的第一个元素 第二项嵌套的第二个元素 第一项 第二项 第三项 一级标题二级标题一级标题二级标题三级标题四级标题五级标题六级标题这是加粗的文字 这是倾斜的文字` 这是斜体加粗的文字 这是加删除线的文字 这是引用的内容 这是引用的内容 这是引用的内容 1.![Image text](/images/pasted-1.jpg)","categories":[],"tags":[]},{"title":"中秋快乐","slug":"2","date":"2021-09-20T13:46:00.000Z","updated":"2022-04-26T10:31:11.093Z","comments":true,"path":"2021/09/20/2/","link":"","permalink":"https://blog.zhangcun.store/2021/09/20/2/","excerpt":"","text":"中秋将至，提前祝您：身体“月”来“月”棒，笑容“月”来“月”甜，钞票“月”来“月”多，生活“月”来“月”顺！ 提前祝大家中秋快乐，祝愿你们幸福安康，万事如意！ Your browser does not support the video tag.","categories":[],"tags":[],"author":"张存"},{"title":"这是我的不归路，因为我要胜天半子","slug":"这是我的不归路，因为我要胜天半子","date":"2021-04-26T10:29:00.000Z","updated":"2022-04-27T09:34:00.207Z","comments":true,"path":"2021/04/26/zhe-shi-wo-de-bu-gui-lu-yin-wei-wo-yao-sheng-tian-ban-zi/","link":"","permalink":"https://blog.zhangcun.store/2021/04/26/zhe-shi-wo-de-bu-gui-lu-yin-wei-wo-yao-sheng-tian-ban-zi/","excerpt":"","text":"我是祁同伟，人生如戏，今天我写下这篇文章，我的人生即将谢幕在孤鹰岭——那片我曾经的福地。我如果十多年前死在这片土地上，我就是一个英雄，一个为了人民的利益不惧流血牺牲的英雄。 而现在，我死以后会遭到唾弃，起码是以人民名义的唾弃。 我是一个不被上天眷顾的人 所以我只能选择人定胜天。记得在那次饭桌上想杀侯亮平，虽未能如愿，但如果时光倒流，我依旧会坚持选择，这是我的不归路，因为我要胜天半子。 十年寒窗卧薪尝胆，为的是事业；以身试险血战孤鹰岭，为的是爱情。 我有我爱的人，我爱的人是陈阳，是这个女孩让我一度觉得老天爷也曾关注过我。 我是一个农民的儿子 一路走来贫困潦倒但我渴望功成名就，渴望出人头地，用自己十二万分的努力学习奋斗去报答我的父母，报答曾经有恩于我的故人。 有人说我与高小琴之间不是爱情是赵瑞龙设计的套，其实我更愿意将我和小琴的相遇描述成邂逅。至于赵瑞龙，在他的棋局上我是他的棋子，但在我下的棋局中他何尝不是。 初识高小琴，我们相见恨晚。哪怕之前我们有再多的差异，但有一处相同就够了——那就是我们都是穷人的孩子。我和小琴就有了我们的孩子，在梁璐那里失去的和得不到的，小琴全部给予我了。 我只是一只蝼蚁 我第一次去到那个司法所见到那位司法所所长的时候，他满脸沟壑纵横，神情呆滞。他是三十年前政法大学的毕业生，在这个岗位一干就是30年。 我终于明白了，在赵立春、梁璐父亲面前，我只是一只蝼蚁。后来我常和别人说，当年在汉东大学操场下向梁璐下跪的那一刻我的心伴随着我的尊严一起死了。 其实，那天在司法所见到老所长的那个瞬间，我的心就已经死了。 我不是心性不坚定 陈海坚持原则，他也为自己的坚持付出了惨痛的代价，即使我不杀他，汉东官场中巴不得他死的人比比皆是。李达康坚持所谓的原则， 深受沙瑞金赏识结果怎么样呢，还不是妻离子散；易学习坚持原则，可差一点不就像当年茅台山区那个终年不见天日的老所长。我可以去哭坟，我可以去刨地，这不是我的创举。 我知道侯亮平一定会把所有的原因归结于我心性不坚定。但当初，如果他是我，他也一样。如果我是他，也不会有后来的祁同伟。 我希望我可以是侯亮平 思绪千回百转间，我也心甘情愿，其实我知道这盘棋我的对手根本就不是神仙。作为一个男人，我追求事业成功、爱情美满，何错之有？ 为人进出的门紧锁着。人生至此，我不遗憾。我会被世人以人民的名义唾弃，但过不了多久这片土地就会抹去我所有的痕迹。 所以我不担心遗臭万年，他们也不可能流芳百世，他只不过会比我多活几十年。如果来生我还是祁同伟，还在当年模样的汉东，我依旧坚持这样选择。 只是如果有来生，我希望我可以是侯亮平…","categories":[],"tags":[],"author":"张存"}],"categories":[],"tags":[]}